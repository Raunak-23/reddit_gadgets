{
  "post": {
    "title": "Intel Arc B580 massively underperforms when paired with older CPUs | Bad news for gamers on a budget",
    "author": "chrisdh79",
    "id": "1huxl0o",
    "score": 1339,
    "created_utc": 1736165402.0,
    "selftext": "",
    "num_comments": 172,
    "subreddit": "gadgets",
    "url": "https://www.reddit.com/r/gadgets/comments/1huxl0o/intel_arc_b580_massively_underperforms_when/"
  },
  "comments": [
    {
      "id": "m5op9vr",
      "author": "AutoModerator",
      "body": "\nWe have a giveaway running, be sure to enter in the post linked below for your chance to win a Unihertz Jelly Max - the World\u2019s Smallest 5G Smartphone!\n\n[Click here to enter!](https://www.reddit.com/r/gadgets/comments/1hfli5p/giveaway_unihertz_jelly_max_rgadgets_win_the/)\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/gadgets) if you have any questions or concerns.*",
      "score": 1,
      "created_utc": 1736165403.0,
      "replies": []
    },
    {
      "id": "m5ot0u9",
      "author": "LupusDeusMagnus",
      "body": "Intel recommends 10th gen or higher, right? So it\u2019s something they were aware, but since it\u2019s just a few titles, I wonder if support can be patched in later on.",
      "score": 431,
      "created_utc": 1736167257.0,
      "replies": [
        {
          "id": "m5otgtb",
          "author": "Stargate_1",
          "body": "THat's just because officially ReBAR support was added with 10th gen but the tech itself is absolutely compatible with and has been backported to older chips. My 8600K supports and uses ReSizeable BAR",
          "score": 230,
          "created_utc": 1736167466.0,
          "replies": [
            {
              "id": "m5owd2c",
              "author": "blownart",
              "body": "What? I always thought my 8700k does not support rebar.",
              "score": 53,
              "created_utc": 1736168776.0,
              "replies": [
                {
                  "id": "m5p097q",
                  "author": "nelrond18",
                  "body": "Update your BIOS, you might be surprised",
                  "score": 84,
                  "created_utc": 1736170404.0,
                  "replies": [
                    {
                      "id": "m5p224q",
                      "author": "HGLatinBoy",
                      "body": "My MB won\u2019t Acceptance the last 2 bios updates that allows for resizeable bar \ud83e\udd37\ud83c\udffd\u200d\u2640\ufe0f",
                      "score": 29,
                      "created_utc": 1736171328.0,
                      "replies": [
                        {
                          "id": "m5p5bex",
                          "author": "Thathappenedearlier",
                          "body": "Try slowly incrementing the bios versions",
                          "score": 44,
                          "created_utc": 1736172605.0,
                          "replies": []
                        },
                        {
                          "id": "m5p6f6m",
                          "author": "kpwsyang",
                          "body": "[You could check this out.](https://github.com/xCuri0/ReBarUEFI)",
                          "score": 21,
                          "created_utc": 1736173022.0,
                          "replies": [
                            {
                              "id": "m5p7x1y",
                              "author": "buckingATniqqaz",
                              "body": "Just make sure you have a backup GPU if you\u2019re going to do this. If you reset your CMOS and CSM gets re-enabled, you\u2019re totally SOL until you boot with the other GPU",
                              "score": 15,
                              "created_utc": 1736173575.0,
                              "replies": [
                                {
                                  "id": "m5t0joj",
                                  "author": "IamNickJones",
                                  "body": "Is it ok to do this if I have an igpu?",
                                  "score": 4,
                                  "created_utc": 1736216134.0,
                                  "replies": [
                                    {
                                      "id": "m5tne7i",
                                      "author": "buckingATniqqaz",
                                      "body": "Yes. That\u2019s the backup GPU",
                                      "score": 3,
                                      "created_utc": 1736224484.0,
                                      "replies": []
                                    }
                                  ]
                                },
                                {
                                  "id": "m5ypgps",
                                  "author": "BShotDruS",
                                  "body": "It's weird as I didn't have this issue with a x99 e5-2690v4 build. I did the mod and it worked flawlessly without a 2nd GPU or iGPU.",
                                  "score": 1,
                                  "created_utc": 1736294399.0,
                                  "replies": [
                                    {
                                      "id": "m5yqcer",
                                      "author": "buckingATniqqaz",
                                      "body": "No, the backup is only if you mess up and enable CSM or disable 4G decoding. You\u2019ll get a \u201cno gpu detected\u201d error and won\u2019t POST\n\nIf you do a CMOS reset or re-flash your BIOS, this will happen. I learned this the hard way.\n\n\nI also run ASUS x99 Deluxe with i7 5930k\nWas thinking of going Xeon since it\u2019s dirt cheap now. How do you like yours?",
                                      "score": 1,
                                      "created_utc": 1736294689.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m5q0fw5",
                  "author": "cafk",
                  "body": "It's been in the PCIe spec since 2.0 - it depends on the Mainboard vendor to implement a toggle for it. The CPU and chipset already support it.",
                  "score": 11,
                  "created_utc": 1736182870.0,
                  "replies": [
                    {
                      "id": "m5qoxmd",
                      "author": "JeffTek",
                      "body": "I was about to say, I had rebar on my 9600K. No idea if it was really doing anything but the option was there and it didn't stop me from turning it on.",
                      "score": 5,
                      "created_utc": 1736190199.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m5q4zyn",
                  "author": "caribbean_caramel",
                  "body": "There is a mod to add rebar to older systems, rebarUEFI mod",
                  "score": 7,
                  "created_utc": 1736184211.0,
                  "replies": [
                    {
                      "id": "m5yq2y3",
                      "author": "BShotDruS",
                      "body": "It works flawlessly too if one follows the steps and does it correctly. I did it on a dirt cheap x99 e5-2690v4 build and GPUz showed it as enabled. Woot! There are two ways of doing it if I remember correctly, one for Nvidia GPUs and another for all other GPUs. Not sure why Nvidia needs a special mod, but that's what I remember reading.",
                      "score": 2,
                      "created_utc": 1736294602.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m5pfmkm",
              "author": "trs-eric",
              "body": "they make it wildly clear that you need rebar support. It says it on the box. It says it everywhere.",
              "score": 27,
              "created_utc": 1736176453.0,
              "replies": [
                {
                  "id": "m5pgt0v",
                  "author": "Stargate_1",
                  "body": "Yeah and your point is?",
                  "score": -15,
                  "created_utc": 1736176840.0,
                  "replies": [
                    {
                      "id": "m5plu3w",
                      "author": "trs-eric",
                      "body": "that this news is hardly news at all.",
                      "score": 19,
                      "created_utc": 1736178449.0,
                      "replies": [
                        {
                          "id": "m5q572j",
                          "author": "caribbean_caramel",
                          "body": "The issue is happening in systems with rebar, that is the problem.",
                          "score": 4,
                          "created_utc": 1736184270.0,
                          "replies": [
                            {
                              "id": "m5yrhyz",
                              "author": "BShotDruS",
                              "body": "Yep, that's what has been shown in some Ryzen and Intel configs with rebar that are older, but not as old as say a 2600x, so it's weird. Maybe just an architecture thing or a driver issue, dunno. I'm sure we'll find out since many people will be testing this. Some tests show the 4060 whooping the B580s butt in some games when paired with an older CPU. B580 was in the 30s and 4060 was in the 50-60s fps wise in some games. That's pretty bad lol damn",
                              "score": 1,
                              "created_utc": 1736295073.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m5pm1qs",
                          "author": "Stargate_1",
                          "body": "I think you misunderstood the original commebts intention, and the original commenter also mistakenly believes the issue to be related to ReBAR when it is not, both of you are a bit off here lol",
                          "score": 6,
                          "created_utc": 1736178515.0,
                          "replies": [
                            {
                              "id": "m5poxor",
                              "author": "trs-eric",
                              "body": "orly. I'll have to rewatch the video cuz I obviously missed this!",
                              "score": 2,
                              "created_utc": 1736179414.0,
                              "replies": [
                                {
                                  "id": "m5pp4vn",
                                  "author": "Stargate_1",
                                  "body": "I mean you ARE correct, ReBAR being required is indeed literally printed right on the Box and was well known sinc ethe first Arc cards",
                                  "score": 2,
                                  "created_utc": 1736179477.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m5oy3tk",
              "author": "shalol",
              "body": "Same with a 2600x, it does support and work with rebar",
              "score": 10,
              "created_utc": 1736169520.0,
              "replies": []
            },
            {
              "id": "m5ped6y",
              "author": "chubby464",
              "body": "What\u2019s rebar?",
              "score": 5,
              "created_utc": 1736176029.0,
              "replies": [
                {
                  "id": "m5pfw8s",
                  "author": "trs-eric",
                  "body": "it's a memory management feature. https://www.youtube.com/watch?v=gRWVE8VRE7g",
                  "score": 7,
                  "created_utc": 1736176544.0,
                  "replies": [
                    {
                      "id": "m5puaiy",
                      "author": "VerifiedPersonae",
                      "body": "Why does someone need it?",
                      "score": 2,
                      "created_utc": 1736181049.0,
                      "replies": [
                        {
                          "id": "m5q1dqa",
                          "author": "cafk",
                          "body": "It allows faster data loading over PCIe between components.  \n  \nBy default data size accessible via PCIe is limited to 256mb, meaning larger data sets require multiple calls to load it all (and determining the file size and number of calls) - with rebar it's configurable to directly access and load 2gb+ (depending on PCIe version) in one go.  \n  \nI.e. instead of CPU loading texture to memory and then transfer it to the GPU, it's possible for the GPU to directly stream data from SSD to GPU memory.",
                          "score": 8,
                          "created_utc": 1736183148.0,
                          "replies": [
                            {
                              "id": "m5q6yrp",
                              "author": "VerifiedPersonae",
                              "body": "So this is like the equivalent of modding a car for more air intake, 99% of people don't need it but if you feel like tweaking out on small percentages of performance improvements it could be of interest",
                              "score": 3,
                              "created_utc": 1736184789.0,
                              "replies": [
                                {
                                  "id": "m5qjrzh",
                                  "author": "cafk",
                                  "body": "With the data sets modern games use its relevant, high detail textures, shaders and models require permanent access to data and Intel has optimized their GPUs & drivers to work with rebar and sam, which enable loading data in bursts - over in segments.  \n  \nBasically making loading any kind of data to GPU dependent on this technology.  \nIt's not turning, but building the GPU and drivers to expect those features to be available from the ground up, over creating fallback methods to handle it otherwise.  \n  \nOr think of it other way - an ice built for forced injection will work better with forced injection over being naturally aspirated.",
                                  "score": 6,
                                  "created_utc": 1736188513.0,
                                  "replies": [
                                    {
                                      "id": "m5r3p7n",
                                      "author": "VerifiedPersonae",
                                      "body": "Force injecting ice? What chu going on about? \n\nY'all going through a lot of trouble just to be able switch a couple boxes from medium to high",
                                      "score": -6,
                                      "created_utc": 1736194485.0,
                                      "replies": [
                                        {
                                          "id": "m5r8kqf",
                                          "author": "piratep2r",
                                          "body": "ICE = internal combustion engine. Also I'm not the person you are responding to, just for clarity.",
                                          "score": 4,
                                          "created_utc": 1736195894.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "m5tj9c9",
                              "author": "Emu1981",
                              "body": ">I.e. instead of CPU loading texture to memory and then transfer it to the GPU, it's possible for the GPU to directly stream data from SSD to GPU memory.\n\nResizeable Bar basically makes the entire GPU VRAM addressible by the CPU at the same time instead of only having (up to) 256mb chunks being addressable at any one time.  It makes no other changes.  \n\nDirectly streaming data from storage to VRAM is not possible on PCs with consumer GPUs\\*.  Data still needs to be copied from storage to system RAM and then from system RAM to VRAM even with DirectStorage.  All DirectStorage does is enables better transfer rates between fast storage and system RAM by optimising the access and transfer of small files from storage into RAM.\n\nCopying data directly to VRAM is possible on the consoles because the GPU and CPU share memory so the only real difference is that the data is copied to RAM blocks that are allocated to the GPU rather than RAM that is allocated to the CPU.\n\n\\*Nvidia does have GPUDirect Storage which allows GPUs to access storage directly and transfer data via DMA but it is only supported on their enterprise compute cards like the Tesla and Quadro models (e.g. A100, V100, T4).  I am sure that AMD has something similar for their compute cards.",
                              "score": 1,
                              "created_utc": 1736222786.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m5q0k46",
                          "author": "trs-eric",
                          "body": "Rebar improves memory speed by making it possible to access graphics memory all at the same time, instead of smaller chunks.\n\nIt can improve both cpu and gpu performance substantially on intel cards. It also improves performance on other cards too.",
                          "score": 5,
                          "created_utc": 1736182904.0,
                          "replies": []
                        },
                        {
                          "id": "m5pzmhs",
                          "author": "eviLocK",
                          "body": "This video card needs ReBar to perform, other it's performance is mediocre.",
                          "score": 3,
                          "created_utc": 1736182629.0,
                          "replies": [
                            {
                              "id": "m5q5kie",
                              "author": "VerifiedPersonae",
                              "body": "Don't really see the issue. If you have the arc just run your games on lower settings or buy a different GPU. There's a reason I went with the 4060. 80% of computers with an arc are just playing Minecraft rat or watching youtube anyway",
                              "score": -4,
                              "created_utc": 1736184379.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m5p3vc1",
              "author": "hedanio",
              "body": "Gesundheit!",
              "score": 1,
              "created_utc": 1736172047.0,
              "replies": []
            },
            {
              "id": "m5ozwvo",
              "author": "Ok-Camp-7285",
              "body": "aRe yoU suRe aboUt thAt?",
              "score": -12,
              "created_utc": 1736170265.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5t08rm",
          "author": "_CatLover_",
          "body": "Hardware unboxed thought intel being hellbent on marketing it as a 1440p card (so you're gpu bottlenecked) might be hinting at them being aware of its shortcomings in a 1080p budget build",
          "score": 2,
          "created_utc": 1736216028.0,
          "replies": []
        },
        {
          "id": "m5p1bln",
          "author": "PotusThePlant",
          "body": "It's not a support issue because it still underpferforms with \"supported\" cpus. Read the article.",
          "score": 7,
          "created_utc": 1736171001.0,
          "replies": [
            {
              "id": "m5pguop",
              "author": "LupusDeusMagnus",
              "body": "No, you\u2019re the one who should read it.\n\nThe article is clear that intel ARC support is 10th gen plus or AMD Series 5000 plus.\u00a0\n\n\nIntel ARC supports 10th gen plus or 5000 series plus. They are testing with series 2000, 3000 and 9th gen, not officially supported.\n\nIn the Intel site they say those gens + mobos with ReBAR/SAM.\n\nThat has been so since the Alchemist family.\n\nIf Intel is going to manage to add support to older ReBAR/SAM enabled CPUs/MOBO it\u2019s another story.",
              "score": 26,
              "created_utc": 1736176855.0,
              "replies": [
                {
                  "id": "m5plpot",
                  "author": "PotusThePlant",
                  "body": "ReBAR/SAM works even with Ryzen 1000.\n\nEven disregarding that, they also tested with 5000 and 7000 AMD cpus. There's a very significant difference even with those cpus. Since reading the article seems troublesome for you, [here's an image](https://www.techspot.com/images2/news/bigimage/2025/01/2025-01-06-image-20.jpg).\n\nTo summarize it even more. With a 7600, the RTX 4060 gets 90/126 and the B580 gets 80/114. If you change the cpu for a 9800X3D (ridiculous cpus to use with that gpu), the 4060 gets 90/127 (basically same performance) and the B580 skyrockets to 105/152.",
                  "score": 7,
                  "created_utc": 1736178411.0,
                  "replies": [
                    {
                      "id": "m5ptyy4",
                      "author": "LupusDeusMagnus",
                      "body": "You\u2019re either really confused or changing the subject. My original comment was about the performance drop in some games when coupled with a non-supported CPUs and the possibility of future patching to expand compatibility. I did not make a comparison to Nvidia\u2019s cards or its performance with newer CPUs.",
                      "score": -10,
                      "created_utc": 1736180952.0,
                      "replies": [
                        {
                          "id": "m5q2bm1",
                          "author": "FreshPrinceOfNowhere",
                          "body": "Oh my god, [WATCH THE ORIGINAL VIDEO ALREADY](https://youtu.be/00GmwHIJuJY?t=108). It specifically addresses that:\n\n1) ReBAR works perfectly fine on \"unsupported\" CPUs exactly as it does on \"supported\" ones, and results in large performance uplifts on BOTH  \n2) the above is has been known for ages  \n3) the issue currently being discussed has NOTHING to do with ReBAR, and NOTHING to do with whether ReBAR support is \"official\" or not  \n4) rather, it is about the B580's performance being heavily dependent on raw CPU power, a LOT more so than Nvidia or AMD cards.  \n\nIn the video, at 8:37, you can clearly see that there is a MASSIVE difference between a 9800X3D, 7600X and an 5700X3D (obviously, all three have official ReBAR support) when using a B580, where you would normally expect to have zero CPU bottlenecking with a md-range GPU. Meanwhile, a 4060 performs identically across all three, as expected. THIS is what we are talking about - the B580 for some reason requires far more beefier CPU than it has any business requiring.",
                          "score": 19,
                          "created_utc": 1736183427.0,
                          "replies": [
                            {
                              "id": "m5q5h4y",
                              "author": "None",
                              "body": "Using a Sony PC port as reference...\ud83e\udd21",
                              "score": -12,
                              "created_utc": 1736184352.0,
                              "replies": [
                                {
                                  "id": "m5qigts",
                                  "author": "FreshPrinceOfNowhere",
                                  "body": "Mind shining a light on how that is relevant? From a technical perspective?",
                                  "score": 5,
                                  "created_utc": 1736188134.0,
                                  "replies": [
                                    {
                                      "id": "m5qisoq",
                                      "author": "gramathy",
                                      "body": "sony's pc ports (i.e. non-native) are notoriously garbage",
                                      "score": -5,
                                      "created_utc": 1736188229.0,
                                      "replies": [
                                        {
                                          "id": "m5qlx87",
                                          "author": "FreshPrinceOfNowhere",
                                          "body": "What exactly is non-native about running the exact same binary code on the exact same AMD CPU and GPU cores?The OS? Lmao. What exactly is there to port? :)",
                                          "score": 4,
                                          "created_utc": 1736189293.0,
                                          "replies": [
                                            {
                                              "id": "m5qrju3",
                                              "author": "gramathy",
                                              "body": "Unified memory on a console allows for some optimizations that don't necessarily translate well to a discrete GPU",
                                              "score": 0,
                                              "created_utc": 1736190970.0,
                                              "replies": [
                                                {
                                                  "id": "m5t8xs3",
                                                  "author": "FreshPrinceOfNowhere",
                                                  "body": "Eh. A Steamdeck, for example, also has unified memory, and no one needs to do any specific optimizations for it. The console-specific optimizations are minuscule today, compared to the exotic and wildly different architectures of the PS3 and X360 days.",
                                                  "score": 1,
                                                  "created_utc": 1736219040.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        },
                                        {
                                          "id": "m5qkp96",
                                          "author": "FreshPrinceOfNowhere",
                                          "body": "1) Are you aware that both PlayStation and Xbox have been on the x86_64 PC architecture for the last 12 years?\n\n2) How the fuck is that relevant to the topic at matter, considering the issue affects only one specific card from one manufacturer, and does across all of the games tested?",
                                          "score": 1,
                                          "created_utc": 1736188783.0,
                                          "replies": [
                                            {
                                              "id": "m5qrm77",
                                              "author": "gramathy",
                                              "body": "Just because the code is there doesn't mean it's running the same on bespoke hardware vs commodity PC hardware",
                                              "score": 0,
                                              "created_utc": 1736190990.0,
                                              "replies": []
                                            },
                                            {
                                              "id": "m5qx3m8",
                                              "author": "VailonVon",
                                              "body": "I have no business talking about technical stuff like this but consoles are specific hardware are they not? They don't change besides maybe the SSD you use. So it doesn't really matter if they are on x86 when you are optimizing for specific hardware. When you port something to pc you are now going back and trying to optimize a game for multiple configurations of hardware that may or may not like it.",
                                              "score": 0,
                                              "created_utc": 1736192587.0,
                                              "replies": [
                                                {
                                                  "id": "m5t9qs4",
                                                  "author": "FreshPrinceOfNowhere",
                                                  "body": "Really the only differentiating factor between console and PC development these days is that on console you only need to optimize for AMD hardware, while on PC there's also Intel and Nvidia. Still, the leeway you have is minuscule when you consider how it was in the PS3 and X360 days.\n\nAnd I still fail to see the point of this off-topic tangent.",
                                                  "score": 1,
                                                  "created_utc": 1736219324.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m5qpv6a",
                                      "author": "None",
                                      "body": "You must not be a gamer, otherwise you would absolutely know about Sony's PC ports are not good.",
                                      "score": -9,
                                      "created_utc": 1736190476.0,
                                      "replies": [
                                        {
                                          "id": "m5r1uw3",
                                          "author": "BeingRightAmbassador",
                                          "body": "innocent summer hurry desert gray zealous plants smart door joke\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
                                          "score": 2,
                                          "created_utc": 1736193951.0,
                                          "replies": [
                                            {
                                              "id": "m5r4ip1",
                                              "author": "TheBabyEatingDingo",
                                              "body": "Imaginary refrigerators are not a relevant comparison. Sony ports are notorious for being optimized for narrow hardware configurations and delivering inconsistent performance outside of those configurations.",
                                              "score": 1,
                                              "created_utc": 1736194721.0,
                                              "replies": [
                                                {
                                                  "id": "m5r8141",
                                                  "author": "BeingRightAmbassador",
                                                  "body": "innocent pen liquid sulky cooing steep direction voracious relieved long\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
                                                  "score": 2,
                                                  "created_utc": 1736195739.0,
                                                  "replies": [
                                                    {
                                                      "id": "m5tafuf",
                                                      "author": "FreshPrinceOfNowhere",
                                                      "body": "Username checks out.",
                                                      "score": 1,
                                                      "created_utc": 1736219572.0,
                                                      "replies": []
                                                    }
                                                  ]
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "m5qj5rk",
                          "author": "gramathy",
                          "body": "there's a performance drop in every CPU that isn't a 9800x3d, and it's not just a CPU performance difference. Either the overhead is so much higher that anything worse can't keep up, or the cache is so significant to performance that it hides other flaws in the driver.",
                          "score": 1,
                          "created_utc": 1736188334.0,
                          "replies": []
                        },
                        {
                          "id": "m5qcys6",
                          "author": "PotusThePlant",
                          "body": "Once again, you failed to read properly.",
                          "score": 0,
                          "created_utc": 1736186527.0,
                          "replies": [
                            {
                              "id": "m5qkkxs",
                              "author": "ineververify",
                              "body": "Doing my best to follow all the comments here and all I can determine is once again all you GPU nerds are annoying.",
                              "score": -2,
                              "created_utc": 1736188747.0,
                              "replies": [
                                {
                                  "id": "m5uv2h3",
                                  "author": "PotusThePlant",
                                  "body": "Feel free to not engage and go somewhere else.",
                                  "score": 0,
                                  "created_utc": 1736249661.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m5qao5j",
                  "author": "thatnitai",
                  "body": "Look at the tests. The 5600 etc. are still making worse use 9f the B580.\n\n\nClearly there's a CPU overhead, so in some games it'll be a limiter with even recent, mid tier CPUs.\u00a0",
                  "score": 0,
                  "created_utc": 1736185867.0,
                  "replies": []
                },
                {
                  "id": "m5rny2a",
                  "author": "Brisslayer333",
                  "body": "This issue is not related to ReBAR, and 10th gen is also affected.",
                  "score": 0,
                  "created_utc": 1736200307.0,
                  "replies": []
                },
                {
                  "id": "m5torxn",
                  "author": "initialbc",
                  "body": "You\u2019re so fkn wrong lmao.",
                  "score": 0,
                  "created_utc": 1736225074.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m5qsyt2",
          "author": "Plank_With_A_Nail_In",
          "body": "People who own 10th gen aren't buying budget GPU's. Its an awful situation to be honest and they also tricked the tech media into recommending a card that is basically awful for budget gaming they very are much better off buying a 4060 for $50 more.",
          "score": -8,
          "created_utc": 1736191381.0,
          "replies": [
            {
              "id": "m5rem6e",
              "author": "rpkarma",
              "body": "People with 4 year old CPUs won\u2019t be buying budget GPUs? What are you smoking and can I have some?",
              "score": 6,
              "created_utc": 1736197611.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m5oq7eu",
      "author": "BitRunr",
      "body": ">According to Hardware Unboxed's testing, the B580 performed much worse than the RTX 4060 in games like Warhammer 40,000: Space Marine 2 when paired with either a Ryzen 7 9800X3D or a Ryzen 5 2600.\n\nJust generally underperforms, and doesn't pass muster on old CPUs.",
      "score": 164,
      "created_utc": 1736165872.0,
      "replies": [
        {
          "id": "m5otnjw",
          "author": "None",
          "body": "They also tested it on i5s. They don\u2019t mention anything about it on intel hardware from the past 7 years. But I can\u2019t imagine intel would cater to amd for any specific reasons if they don\u2019t have to",
          "score": 60,
          "created_utc": 1736167554.0,
          "replies": [
            {
              "id": "m5q3nmz",
              "author": "ShadowShot05",
              "body": "If they don't, no one will buy their gpus either.  Amd has the lions share of the CPU market",
              "score": 15,
              "created_utc": 1736183819.0,
              "replies": [
                {
                  "id": "m5q7pqj",
                  "author": "AlfieOwens",
                  "body": "Their growth has been impressive, but 40% isn\u2019t the lion\u2019s share.",
                  "score": 21,
                  "created_utc": 1736185006.0,
                  "replies": [
                    {
                      "id": "m5qtta6",
                      "author": "Plank_With_A_Nail_In",
                      "body": "On desktop AMD  does have lions share its only Laptops where it lags.",
                      "score": 3,
                      "created_utc": 1736191627.0,
                      "replies": [
                        {
                          "id": "m5rowpt",
                          "author": "AlfieOwens",
                          "body": "Q3 2024, AMD had ~30% of the desktop market.",
                          "score": 8,
                          "created_utc": 1736200588.0,
                          "replies": []
                        },
                        {
                          "id": "m5vmea3",
                          "author": "BlackEric",
                          "body": "You\u2019re just making stuff up?",
                          "score": 3,
                          "created_utc": 1736261237.0,
                          "replies": []
                        },
                        {
                          "id": "m5rwd0x",
                          "author": "Bacon_Techie",
                          "body": "It\u2019s mostly servers where they are dominant iirc. They are doing well enough in desktop, and slightly behind on laptops (though there are plenty of options with them now).",
                          "score": -3,
                          "created_utc": 1736202870.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m641z9m",
                      "author": "DaemonG",
                      "body": "More importantly, the place where AMD is winning is in New CPUs, since around the Zen 2 days. Older users who want a cheap upgrade to their GTX or 20 series cards are likelier to be running Intel.",
                      "score": 1,
                      "created_utc": 1736369581.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m5otqwj",
          "author": "oshinbruce",
          "body": "Under performs on a new resource intensive game is what it should read like. Reality is if you want the \"best\" performance on a new Under optimised game, get Nvidia who will rush out new drivers before the release. Its all part of there strategy imo",
          "score": 31,
          "created_utc": 1736167598.0,
          "replies": [
            {
              "id": "m5p9o1c",
              "author": "jaaval",
              "body": "It\u2019s more that nvidia is what the developers use when developing the game. Nvidia doesn\u2019t have to do much game testing because games are already made for them.",
              "score": 25,
              "created_utc": 1736174294.0,
              "replies": []
            },
            {
              "id": "m5owjdz",
              "author": "Party_Cold_4159",
              "body": "Exactly what I was thinking. Reminds me of buying Radeon cards back in the day.",
              "score": 11,
              "created_utc": 1736168853.0,
              "replies": []
            },
            {
              "id": "m5rsxsg",
              "author": "BitRunr",
              "body": ">Under performs on a new resource intensive game is what it should read like.\n\n... Compared to a 4060. If you can't do budget performance roughly on par with a 4060, then you're not in the running.",
              "score": 3,
              "created_utc": 1736201808.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5pvguh",
          "author": "mercm8",
          "body": "The 9800x3d is a strange pairing to choose with the b580",
          "score": 7,
          "created_utc": 1736181402.0,
          "replies": [
            {
              "id": "m5rs90q",
              "author": "BitRunr",
              "body": "Sure. But. That's going to entirely miss the point that it's not performing well whether you pair it with low end or high end AMD CPUs.",
              "score": 4,
              "created_utc": 1736201598.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5orz5v",
          "author": "Nattekat",
          "body": "I can't believe a budget GPU underperforms when compared to a higher range model.\u00a0",
          "score": -13,
          "created_utc": 1736166756.0,
          "replies": [
            {
              "id": "m5oyufr",
              "author": "Crazyinferno",
              "body": "The 4060 is a direct competitor, not a higher model",
              "score": 29,
              "created_utc": 1736169829.0,
              "replies": []
            },
            {
              "id": "m5otbxi",
              "author": "Stargate_1",
              "body": "The point is that, while the 4060 would get the same fps with older CPUs that still resulted in a GPU bottleneck (hence the same fps each time) the B580 continuously declined. It literally just loses performance the older the CPU is",
              "score": 42,
              "created_utc": 1736167403.0,
              "replies": []
            },
            {
              "id": "m5ptuzu",
              "author": "fafarex",
              "body": "You really didn't understood the subject and tried to by sarcastic about it...\n\nThe point is the card underperform compare to other card of the same budget range when it's pair with lower tier CPU",
              "score": 3,
              "created_utc": 1736180920.0,
              "replies": []
            },
            {
              "id": "m5ox4m3",
              "author": "raptir1",
              "body": "They cost the same though.\u00a0",
              "score": 4,
              "created_utc": 1736169105.0,
              "replies": [
                {
                  "id": "m5pdi61",
                  "author": "None",
                  "body": "They don\u2019t cost the same. 4060 is 50 bucks more for less vram",
                  "score": 2,
                  "created_utc": 1736175733.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m5ov6aa",
      "author": "hardy_83",
      "body": "I mean the video was a bit over-dramatic in some parts but it basically boiled down to drivers needing work for older systems/platforms and not a fundamental issue that can't be fixed with updates. Also it only affected some games, not all.\n\nDidn't read the article because I assumed it was being click bait.",
      "score": 78,
      "created_utc": 1736168247.0,
      "replies": [
        {
          "id": "m5qtp4r",
          "author": "Plank_With_A_Nail_In",
          "body": "Don't buy things based on the promise of future deliverables as they might never arrive. Its not like this card is the only choice.",
          "score": 23,
          "created_utc": 1736191594.0,
          "replies": [
            {
              "id": "m5t5282",
              "author": "ArchusKanzaki",
              "body": "At 250$ or less? I don't think you have a lot of choice",
              "score": 6,
              "created_utc": 1736217701.0,
              "replies": [
                {
                  "id": "m5thy3u",
                  "author": "Tom_The_Moose",
                  "body": "250 for a reason",
                  "score": -1,
                  "created_utc": 1736222277.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m5opxct",
      "author": "XtremeStumbler",
      "body": "Dodge Charger Massively Underperforms with Flat Tires, Bad News for Racers on a Budget",
      "score": 232,
      "created_utc": 1736165733.0,
      "replies": [
        {
          "id": "m5or91k",
          "author": "FalconZA",
          "body": "It's more your cheap super charger is better than a more expensive super charger when paired with a top of the line v8. \n\nWhen paired with an inline 4 cylinder the more expensive super charger is competing against beats it. \n\nThis data actually is pretty relevant for budget buyers to know, you need to make sure the combination of this card and your CPU is better than another card in your price range when paired with your specific CPU and not a top of the line CPU you definitely do not have.",
          "score": 70,
          "created_utc": 1736166395.0,
          "replies": []
        },
        {
          "id": "m5orjzf",
          "author": "StaysAwakeAllWeek",
          "body": "That would be a valid analogy if the new tires cost 50% more than the entire car",
          "score": 33,
          "created_utc": 1736166545.0,
          "replies": [
            {
              "id": "m5otjw1",
              "author": "_RADIANTSUN_",
              "body": "You can get a 12400 for like $100",
              "score": 6,
              "created_utc": 1736167507.0,
              "replies": [
                {
                  "id": "m5p3pu3",
                  "author": "rudedude94",
                  "body": "A lot of people looking to upgrade have old rigs and old CPUs. Need new CPU, Motherboard and potentially ram to support. So at least 50% of a new PC",
                  "score": 17,
                  "created_utc": 1736171988.0,
                  "replies": [
                    {
                      "id": "m5pozdw",
                      "author": "BEEFTANK_Jr",
                      "body": "I mean...if your PC is that old and you're looking for something new, you're going to have to consider that this is a PCIe 4.0 card. Like, how old are we talking here that the CPU can't be swapped without a full upgrade but the GPU can without limiting the card on older gen PCI?",
                      "score": 2,
                      "created_utc": 1736179429.0,
                      "replies": [
                        {
                          "id": "m5t7722",
                          "author": "AtomicSymphonic_2nd",
                          "body": "From what I\u2019ve been reading around, it looks like Intel generally changes the socket every two generations, with exception to the last one before the current one.\n\n8th and 9th were on LGA 1151\n\n10th and 11th were on LGA 1200\n\n12th, 13th (and 14th!) are on LGA 1700\n\nNewest one is LGA 1851 for the Core Ultra CPUs.\n\nEssentially, you\u2019re generally locked into to only two gens of Intel CPUs \n\nSo, most PC users wanting to use the Arc GPUs will also need to fork out additional cash for a new motherboard *AND* CPU.\n\n[The hard cutoff is 10th gen.](https://community.intel.com/t5/Graphics/Intel-Arc-A380/m-p/1523010/highlight/true#M122241)\n\nIt\u2019s not great for those of us that are near-poverty or cannot spend much of any money on electronics for whatever reason\u2026 that\u2019s probably what the news article is implying.",
                          "score": 1,
                          "created_utc": 1736218440.0,
                          "replies": [
                            {
                              "id": "m5tl4nb",
                              "author": "BEEFTANK_Jr",
                              "body": "I know, but my point is that an LGA 1151 system almost definitely has a PCIe 3.0 motherboard and is going to throttle the Intel card anyway. Realistically, what GPU is a system that old running? For me, that was a GTX 970 until last year. I could have potentially upgraded to a Nvidia 1000 series card from there, but that's it. What if you already have a 1070, though? The only other upgrade you can realistically get now is an RTX 2070, but those cost more than an Arc B580.\n\nMy point is that a system that old doesn't have realistic upgrade options anyway. It doesn't really matter that much if an Arc B580 doesn't work great with someone's i7-9700.",
                              "score": 1,
                              "created_utc": 1736223536.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m5p907y",
                      "author": "_RADIANTSUN_",
                      "body": "Compatible DDR4 mobo with reBAR support is like $50-80.",
                      "score": 1,
                      "created_utc": 1736173977.0,
                      "replies": [
                        {
                          "id": "m5pkj2t",
                          "author": "GnarApple",
                          "body": "I think you\u2019re missing the point just a little bit. All the fuss about this issue is that this basically forces out the people with older cpu looking for gpu upgrade only. Also this means the upgrade package is now arc gpu price plus $50-$80 which is not insignificant, given that it\u2019s a low-mid end card. The price comparison with 4060 suddenly looks worse than before, now that you also need a cpu/motherboard upgrade else the fps cripples.",
                          "score": 11,
                          "created_utc": 1736178037.0,
                          "replies": [
                            {
                              "id": "m5qrxjw",
                              "author": "_RADIANTSUN_",
                              "body": "I understand that and that's definitely valid.\n\nStill you will get a newer 12th gen CPU which are still reasonably good, efficient and modern vs the 9th gens which are oooooold (2017ish). So I still think it's a viable option if you were doing an economical upgrade on both fronts. If you wanted to do a GPU-only upgrade for a 8th gen Intel CPU then IMO a 4060 is tbh also a bad choice. I would go for a 6700XT or something cuz probably raster performance and VRAM is more important than RT at this level.",
                              "score": 1,
                              "created_utc": 1736191081.0,
                              "replies": []
                            },
                            {
                              "id": "m5rdri5",
                              "author": "rudedude94",
                              "body": "Thank you was just about reply with this. Simply pointed out something like a 3060 Ti or amd equivalent hits a few use cases/customer needs that this doesn\u2019t. Also telling me a new cpu + mobo is added $200 total with tax doesn\u2019t fix this shortcoming. I want to see intel succeed as much as the next person too \ud83d\ude05",
                              "score": 1,
                              "created_utc": 1736197369.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m5qgdq9",
                          "author": "Acheron-X",
                          "body": "Cheapest **new** compatible mobo I can find is like $85 (MSI PRO H610M). Used motherboard is very sketch, so wouldn't go that route (at that point get a used 6700XT/6800 instead of a B580 for $250).",
                          "score": 2,
                          "created_utc": 1736187527.0,
                          "replies": [
                            {
                              "id": "m5qsr75",
                              "author": "_RADIANTSUN_",
                              "body": "I agree 6700 XT is probably the best option for someone at this range and in this scenario, with CPU of this age.",
                              "score": 1,
                              "created_utc": 1736191320.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m5ptagn",
                  "author": "diuturnal",
                  "body": "So almost 50% the cost of the car.",
                  "score": 2,
                  "created_utc": 1736180749.0,
                  "replies": []
                },
                {
                  "id": "m5otqh9",
                  "author": "StaysAwakeAllWeek",
                  "body": "Exactly, the difference in price between the cpu you need for an nvidia or AMD gpu vs the cpu you need for the intel is more than the entire cost of the intel gpu.\n\nThe B580 might perform well against a 4060 when they both have $500 cpus attached but it sure as hell doesn't perform well against a 4070 paired with that 12400",
                  "score": 3,
                  "created_utc": 1736167592.0,
                  "replies": [
                    {
                      "id": "m5ouwjd",
                      "author": "_RADIANTSUN_",
                      "body": "No I'm saying 12400 is like $100 and is reported to work pretty well with B580. That's vs the B580's $250. That's not really so bad for someone building o na budget I think.",
                      "score": 8,
                      "created_utc": 1736168125.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m5oq0ix",
          "author": "kazuviking",
          "body": "In SOME titles and not all. These clickbait titles.",
          "score": 32,
          "created_utc": 1736165777.0,
          "replies": [
            {
              "id": "m5os2pe",
              "author": "psychocopter",
              "body": "It seems to be all right with a 7600 performing similarly to the 4060 in most titles. That means its still a decent option for a cheap gpu on a budget build with new parts. Sadly its not a good option for a slot in upgrade on older systems.",
              "score": 13,
              "created_utc": 1736166804.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5r6wbc",
          "author": "haarschmuck",
          "body": "Congrats on completely missing the point.",
          "score": 2,
          "created_utc": 1736195412.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5oru9m",
      "author": "None",
      "body": "[removed]",
      "score": 39,
      "created_utc": 1736166689.0,
      "replies": [
        {
          "id": "m5osuyr",
          "author": "Dude-e",
          "body": "Iirc, Intel officially replied and they acknowledged that the issue and are looking into fixing it. Hardware Canucks were the first to report this problem",
          "score": 54,
          "created_utc": 1736167180.0,
          "replies": []
        },
        {
          "id": "m5p55eg",
          "author": "yalyublyutebe",
          "body": "If you're on AM4, you can get a 5700X3D for a song compared to upgrading to a DDR5 system.",
          "score": 24,
          "created_utc": 1736172543.0,
          "replies": [
            {
              "id": "m5p7yuq",
              "author": "UnsorryCanadian",
              "body": "I bought a 5700x3d before Christmas and it just came in last week.\u00a0 Absolutely loving it, huge improvement over my 4th Gen Xeon.",
              "score": 16,
              "created_utc": 1736173593.0,
              "replies": [
                {
                  "id": "m5pvlf8",
                  "author": "yalyublyutebe",
                  "body": "Well ya. I hope so.",
                  "score": 4,
                  "created_utc": 1736181440.0,
                  "replies": []
                },
                {
                  "id": "m5q64ac",
                  "author": "Gregus1032",
                  "body": "Same. I bought the 5700x3d and got a huge improvement over my 4th gen i5. So much smoother. \n\nThat being said, if it wasn't I was going to be very upset.",
                  "score": 3,
                  "created_utc": 1736184540.0,
                  "replies": [
                    {
                      "id": "m5qlvsb",
                      "author": "UnsorryCanadian",
                      "body": "I'm just shocked that I can play Cyberpunk and Helldivers 2 at 60fps on max graphics now considering I was limited to a little over 30fps no matter what the graphics were because I was CPU limited\nAccess to resizable BAR is cool too",
                      "score": 2,
                      "created_utc": 1736189281.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m5p9u7i",
              "author": "mao_dze_dun",
              "body": "Indeed. Although it seems the problem is present even with a 5700X3D. Apparently, it's more of a general CPU overhead than an old CPU problem, per se. In other words, even though you get the most out of a 9800x3D today, as more CPU demanding titles come out, you'd gradually lose extra performance due to the driver overhead. Which is kind of a problem for a budget card, where the target audience doesn't likely have a 9800X3D to begin with.",
              "score": 6,
              "created_utc": 1736174384.0,
              "replies": []
            },
            {
              "id": "m5pnl9n",
              "author": "thedoc90",
              "body": "As someone on AM5 I'm alo going to throw in that in general AM4 seemed easier to work with. I've had to clear my cmos more since switching to AM5 than I did the entire time I was on AM4 because minor changes to bios settings sometimes just cause my pc to fail to post for no discernable reason, and when I initially built it I had to RMA a set of RAM and a board. I've seen a bunch of other people talking about AM5 being finnicky as well.",
              "score": 1,
              "created_utc": 1736178999.0,
              "replies": [
                {
                  "id": "m5qjbte",
                  "author": "None",
                  "body": ">because minor changes to bios settings sometimes just cause my pc to fail to post for no discernable reason,\n\nIt's because memory training sometimes goes wrong and ends with a failure to post and it needs to be cleared.  It's just a super common thing with DDR5 systems in general.",
                  "score": 1,
                  "created_utc": 1736188384.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m5p5hbs",
          "author": "22Sharpe",
          "body": "Keep in mind it\u2019s only really prevalent in CPU intensive games and only really a concern at 1080. If you aren\u2019t CPU bound and / or you are playing at a higher resolution it\u2019s totally fine. I\u2019m rocking a B580 and a 5700x and have no issues at 1440.",
          "score": 4,
          "created_utc": 1736172668.0,
          "replies": []
        },
        {
          "id": "m5os1nq",
          "author": "None",
          "body": "Are you using the CPU\u2019s listed here? Also it only slows on some games, not all",
          "score": 0,
          "created_utc": 1736166790.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5pvqz2",
      "author": "ymmvmia",
      "body": "I feel like the testing is extremely flawed here. They aren't testing \"equivalent\" predecessor cpus. In fact, I think the inclusion of x3d cpus is EXTREMELY dishonest, we know how they change and enhance performance different than most cpus of the past with their x3d cache. \n\nI'd have tested the 9600, the 7600, the 5600, the 3600, then the 2600. Then do similarly for Intel cpus. AND they should have tested AMD gpus versus the B580 and if cpus present the same issues for AMD and Intel or just Intel.\n\nAnother problem, probably a much more major problem here in methodology. They are cherry picking the worst games of Arc, and the best games for Nvidia. As well as testing on 1080p. From the reviews and initial benchmarks, we know the Arc B580 outperforms most everything in that price range for 1440p and 4k (except for a FEW bad game examples like Starfield), but drops a \"little\" behind depending on the game for 1080p. And DEPENDING ON THE GAME is important here. They tested two games I haven't seen any other outlet test when reviewing the b580. \n\nNow, if you CHECK and investigate a little the gpu benchmarks for Space Marine 2, you will notice that Nvidia has a clear outsized advantage over AMD. The game is clearly optimized for Nvidia, with any non nvidia card being gimped. Especially noticeable as AMD is far superior in rasterization performance for the price. Nvidia should NOT be performing better than AMD in general, as long as ray tracing or DLSS are not on. I wouldn't be surprised if AMD performance scaled in a similar way in Space Marine 2, being \"limited\" by the cpu.\n\nThis is likely just a case of extreme optimization for nvidia in some games and unintentional/intentional gimping of non-nvidia gpus.\n\n\"However, these problems seem limited to a handful of titles. In many other games, the B580's performance is in line with expectations. For instance, in games such as Alan Wake 2, Doom Eternal, Horizon: Forbidden West, and even Call of Duty: Black Ops 6, the B580 delivers playable frame rates when paired with the i5-9600K.\"\n\nThey even mention their cherrypicking in the dang article! I really don't understand this, it's sketchy. AMD has always had problems in specific games. And then vice versa, some AMD sponsored games have bad Nvidia performance. \n\nListen to the reviews folks. Not this clickbait garbage manufacturing drama about Intel.\n\nNow sure, they have a lot of work to do on their drivers. But as evidenced by last generation, they're working hard on it. Alchemist cards of last generation got SO much better after 3-6 months of driver updates. I wouldn't expect \"that\" much of an improvement as that was Intel's first consumer discrete graphics card generation, so they had MAJOR issues at launch. But I would expect them, especially as the new underdog in the gpu space, to do as much as humanly possible to work on their drivers. Anything to gain market share and good will with the gaming community.",
      "score": 24,
      "created_utc": 1736181486.0,
      "replies": [
        {
          "id": "m5q3atk",
          "author": "anotherwave1",
          "body": "\nRelax, it's Hardware Unboxed who did the review - they are pretty good with their methodology, and were responding to a poll which put certain CPU's to them\n\nThey will do a full retest (these things take time) with the 5600 (which came top of that poll) for all games. Plus their recommendation is that they dont have a recommendation for now - they need more data.\n\nHardware Canucks also noticed the issue.",
          "score": 1,
          "created_utc": 1736183715.0,
          "replies": []
        },
        {
          "id": "m5quiey",
          "author": "Plank_With_A_Nail_In",
          "body": "You can infer well enough from what they chose.",
          "score": 1,
          "created_utc": 1736191830.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5pxu7k",
      "author": "dustofdeath",
      "body": "It needs the BAR.\n\n\nThat does not eliminate budget CPU. Its just a problem with old ones.\n\n\n5600 is under 100\u20ac new.",
      "score": 8,
      "created_utc": 1736182106.0,
      "replies": []
    },
    {
      "id": "m5oz2nr",
      "author": "Jacek3k",
      "body": "is 1600x old? It still works fine for me",
      "score": 3,
      "created_utc": 1736169924.0,
      "replies": [
        {
          "id": "m5p69t3",
          "author": "LasersTheyWork",
          "body": "I have a 1600x and while it's still perfectly usable it's not even technically supported by Windows 11.  It's kinda old.",
          "score": 13,
          "created_utc": 1736172966.0,
          "replies": [
            {
              "id": "m5p74oh",
              "author": "Jacek3k",
              "body": "I'm on linux myself, so the win11 problem doesn't concern me. Also one of the reasons I dont want nvidia and their drivers.",
              "score": 5,
              "created_utc": 1736173286.0,
              "replies": [
                {
                  "id": "m5p7kgy",
                  "author": "LasersTheyWork",
                  "body": "Nice, That is the way to go with that cpu.  Who knows if the benchmarks would be similar or completely different in that regards between Windows and Linux.",
                  "score": 2,
                  "created_utc": 1736173450.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m61n6gc",
              "author": "moonunit170",
              "body": "I just upgraded my 2700x to a 5800 X 3D. It worked perfectly under Windows 11 but I mainly run it in Linux also. I use my computer for math intensive multi-threaded research and the 5800x3D gave me about a 40% boost in processing speeds.",
              "score": 1,
              "created_utc": 1736342865.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5pvckq",
          "author": "gfewfewc",
          "body": "It came out just about 8 years ago, that's pretty damn old.",
          "score": 7,
          "created_utc": 1736181366.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5qjyh0",
      "author": "Spotter01",
      "body": "Ill just echo a comment I saw on Twitter.... \"Intel said it will run poorly on anything older then 10th Gen or AMD  Equivalent and people are shocked when they try to run it on a 8th gen CPU\"",
      "score": 3,
      "created_utc": 1736188566.0,
      "replies": []
    },
    {
      "id": "m5otkbt",
      "author": "Lardzor",
      "body": "Ugh, my 4 year old CPU is officially an 'older' CPU. Technology moves so fast.",
      "score": 6,
      "created_utc": 1736167512.0,
      "replies": [
        {
          "id": "m5p3hvg",
          "author": "None",
          "body": "[removed]",
          "score": 6,
          "created_utc": 1736171902.0,
          "replies": [
            {
              "id": "m5pnfg4",
              "author": "Lardzor",
              "body": "I'm not upgrading from Windows 10 pro unless software I need or want to use requires it.",
              "score": 4,
              "created_utc": 1736178949.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m5p8uor",
          "author": "chadwicke619",
          "body": "My 7700K from 2017 still runs pretty much everything just fine. \ud83e\udd37\u200d\u2642\ufe0f",
          "score": 1,
          "created_utc": 1736173919.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5r2d5e",
      "author": "None",
      "body": "[deleted]",
      "score": 3,
      "created_utc": 1736194101.0,
      "replies": [
        {
          "id": "m64fl44",
          "author": "SweetLou_",
          "body": "It's specifically says ReBar is enabled on each of these CPUs.",
          "score": 1,
          "created_utc": 1736373509.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5oxb6t",
      "author": "maxx0rNL",
      "body": "Theres something to say for this. If youre not implementing older stuff you can focus on new tech and make a better card for new systems. A Ryzen 5000 doesnt have to be that expensive. The mentioned ryzen 3000 is 6 years old this year",
      "score": 3,
      "created_utc": 1736169183.0,
      "replies": [
        {
          "id": "m5p0w4p",
          "author": "nelrond18",
          "body": "And even if you have an older CPU, you can upgrade later and get more head room.\n\nI alternate between CPU and GPU upgrades and it feels like getting a new computer each time.",
          "score": 2,
          "created_utc": 1736170659.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m5pdq1o",
      "author": "TheJesusGuy",
      "body": "Dont upvote this tripe.",
      "score": 4,
      "created_utc": 1736175809.0,
      "replies": []
    },
    {
      "id": "m5q95vy",
      "author": "_Darkside_",
      "body": "Why would that be bad for gamers on a budget? I mean you can just buy the last generation stuff for cheap instead.",
      "score": 2,
      "created_utc": 1736185430.0,
      "replies": []
    },
    {
      "id": "m5qwbt8",
      "author": "im_thatoneguy",
      "body": "You could upgrade your CPU but then you\u2019re spending more total than just upgrading to a 4060.\n\nIntel needs to race through their driver updates before the 5060 ships. Nvidia has a lot of room for price movement down for the 4060 when that launches.",
      "score": 1,
      "created_utc": 1736192362.0,
      "replies": []
    },
    {
      "id": "m5r6bk5",
      "author": "kalirion",
      "body": "So I'm not gonna pair one with my i7-920, go tit.",
      "score": 1,
      "created_utc": 1736195244.0,
      "replies": []
    },
    {
      "id": "m5s0fyo",
      "author": "gay_manta_ray",
      "body": "microcenter has bundles with a 7600x, mobo, and ram for like $350. CPU prices are really not the issue when putting together a gaming pc. yes it sucks if you're still using skylake or something, but aside from GPUs, hardware is very very cheap.",
      "score": 1,
      "created_utc": 1736204152.0,
      "replies": []
    },
    {
      "id": "m5s1l83",
      "author": "None",
      "body": "I saw this card was coming out and was very excited. I\u2019ve been running an old GPU since 2019 (and it was old then) but it has held its own and I don\u2019t play anything like CoD or whatever. My games are mostly fairly light and don\u2019t take a lot of resources in general. But I saw this report and I got worried since I already placed my order. After, I searched for a video on YouTube of someone playing games on similar hardware to mine and I was happy with the results. Overall, I\u2019m not worried anymore. I also plan to upgrade to the AM5 platform over the next year or two slowly.",
      "score": 1,
      "created_utc": 1736204522.0,
      "replies": []
    },
    {
      "id": "m5s88uy",
      "author": "121PB4Y2",
      "body": "Bad news for anyone planning to drop this in in a surplus workstation running a Xeon E of the Products formerly Coffee Lake generation.",
      "score": 1,
      "created_utc": 1736206703.0,
      "replies": []
    },
    {
      "id": "m62xtsz",
      "author": "hwertz10",
      "body": "I'd like to see a test in Linux.\u00a0 The Mesa Gallium 3D drivers for Intel GPUs are *completely* unrelated to the ones used in Windows so it'd be VERY interesting to see a comparison there.",
      "score": 1,
      "created_utc": 1736357965.0,
      "replies": []
    },
    {
      "id": "me8cx0e",
      "author": "Peace_Maker_2k",
      "body": "So I have a Ryzen 7 2700x with Asus ROG Strix X470-F. I had installed it and the performance was on par with my AMD RX580, which disappointed me. But then I realized my model had ReBar and I turned it on and the performance went up a lot!",
      "score": 1,
      "created_utc": 1740258827.0,
      "replies": []
    },
    {
      "id": "m5pka6x",
      "author": "EnigmaSpore",
      "body": "Basically this boils down to shit drivers by intel. They\u2019ve got a lot of work to do still on this front. A lot. So if you\u2019re building new budget pc with recent cpus from the amd 7000+ or intel 13/14 gen+, then youre ok. But if you have amd 3000 or lower, you might as well skip the b350 and go with amd/nvda for an upgrade",
      "score": 2,
      "created_utc": 1736177959.0,
      "replies": []
    },
    {
      "id": "m5q4jx9",
      "author": "None",
      "body": "Wait so if you pair a PCI Express 4.0 card with a CPU that only uses 3.0 protocol... or less.\n\n\nYou get significantly less performance?\n\n\nWho knew?\n\n\n/s",
      "score": 0,
      "created_utc": 1736184080.0,
      "replies": []
    },
    {
      "id": "m5qaycc",
      "author": "darqy101",
      "body": "Intel GPU drivers suck. Nothing new.",
      "score": 0,
      "created_utc": 1736185947.0,
      "replies": []
    },
    {
      "id": "m5oz6h0",
      "author": "Picolete",
      "body": "To no ones surprise",
      "score": -1,
      "created_utc": 1736169966.0,
      "replies": []
    },
    {
      "id": "m5p50y3",
      "author": "ghostdasquarian",
      "body": "\u201cI supercharged my grandmas \u201878 station wagon and it blew the engine\u201d",
      "score": 0,
      "created_utc": 1736172496.0,
      "replies": []
    },
    {
      "id": "m5p2eh0",
      "author": "Crono_",
      "body": "There it is",
      "score": -2,
      "created_utc": 1736171470.0,
      "replies": []
    },
    {
      "id": "m5p3g7x",
      "author": "Hyperion1144",
      "body": "For just a moment there, I had actually had some hope.\n\nJust another failure from Intel.",
      "score": -7,
      "created_utc": 1736171884.0,
      "replies": [
        {
          "id": "m5panoi",
          "author": "GimmickMusik1",
          "body": "It\u2019s a select few games. To call this a failure is so blown out of proportion.",
          "score": 8,
          "created_utc": 1736174736.0,
          "replies": []
        },
        {
          "id": "m5p5xvb",
          "author": "22Sharpe",
          "body": "I own one, it seriously isn\u2019t as big of a deal as people are making it out to be. It basically only has issues at 1080 so if you\u2019re playing at 1440 it\u2019s fine and it is only really relevant in CPU intensive games.\n\nYes it\u2019s a problem for sure but it\u2019s not nearly horrible as people are making it out to be.The drivers for Battlemage are also still very new, this is a card that is less than a month old.",
          "score": 3,
          "created_utc": 1736172841.0,
          "replies": [
            {
              "id": "m5plmqw",
              "author": "sorrylilsis",
              "body": "People suddenly realizing that CPU bound games are a thing. That's cute really.",
              "score": 4,
              "created_utc": 1736178385.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m5qtq0e",
      "author": "bozo_master",
      "body": "Backwards compatibility is the greatest pox on hardware today",
      "score": 0,
      "created_utc": 1736191601.0,
      "replies": []
    },
    {
      "id": "m5qie5j",
      "author": "SideburnsG",
      "body": "I won\u2019t be upgrading my 10700k anytime soon maybe 3 or 4 years from now. I\u2019m not going to upgrade my 3070 either unless a new gpu in the 5-600$ Canadian dollars comes out can double its performance. I\u2019ll just have to wait. 1000 dollar mid tier GPUs is insane. I remeber getting a gtx 770 for under 400$ Canadian now a 4070 is like 8-900$ here",
      "score": -1,
      "created_utc": 1736188113.0,
      "replies": []
    }
  ]
}