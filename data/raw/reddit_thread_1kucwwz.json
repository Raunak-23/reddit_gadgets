{
  "post": {
    "title": "AMD claims most gamers don't need more than 8GB of VRAM, after new GPU launch",
    "author": "chrisdh79",
    "id": "1kucwwz",
    "score": 3044,
    "created_utc": 1748096917.0,
    "selftext": "",
    "num_comments": 710,
    "subreddit": "gadgets",
    "url": "https://www.reddit.com/r/gadgets/comments/1kucwwz/amd_claims_most_gamers_dont_need_more_than_8gb_of/"
  },
  "comments": [
    {
      "id": "mu1g8yp",
      "author": "ItsmeWillyP",
      "body": "From the article you guys are either too lazy or too stupid to read.\n\nFrank Azor made the statement in a post on X (formerly Twitter), where he replied to PC hardware YouTuber Michael Quesada, who asked how putting 8GB of VRAM on a new graphics card can be justified in 2025. In response, Azor said that the \"majority of gamers are still playing at 1080p and have no use for more than 8GB of memory, adding that the \"most played games WW [worldwide] are mostly esports games. We wouldn't build it if there wasn't a market for it. If 8GB isn't right for you then there's 16GB. Same GPU, no compromise, just memory options.\" \n\nThere's nothing wrong with what was said.",
      "score": 1573,
      "created_utc": 1748107756.0,
      "replies": [
        {
          "id": "mu2unvy",
          "author": "turikk",
          "body": "It's true. A vast majority of PC gaming worldwide is on low demand \"esports\" games like League of Legends or PUBG at low settings. Think outside the box of Reddit and gamers dreaming about ultra settings, and instead remember places like PC bangs and Internet Cafes.",
          "score": 436,
          "created_utc": 1748124878.0,
          "replies": [
            {
              "id": "mu38ack",
              "author": "Bamstradamus",
              "body": "The last 2 gen's of GPU releases I have been wondering why suddenly VRAM is being treated like this massive bottleneck.  Personally I still look at base raster performance, if the base rasterization is good then thats what matters.  I know frame gen and raytracing lean on the VRAM harder then resolution would alone but if you care about running them at 4K your not buying a mid tier card anyway.",
              "score": 93,
              "created_utc": 1748129997.0,
              "replies": [
                {
                  "id": "mu3btq7",
                  "author": "turikk",
                  "body": "It's interesting because the reasons require a bit of nuance and aren't necessarily false: VRAM is relatively cheap and for the most part, it doesn't cost AMD or NVIDIA that much to double the memory storage on a card.  But the margins on these products are incredibly thin, and as Frank pointed out, for a huge chunk of that audience, it's a great product. Additionally, when you do run out of VRAM, it's catastrophic on performance, not something like a little bit less frames.\n\nVRAM has definitely been victim to being slung around as a huge benefit, or something that doesn't matter, or the key indicator of performance (much rarer, but it used to be told as such!).  But it does matter, just not necessarily in the way it would seem on the surface.",
                  "score": 38,
                  "created_utc": 1748131343.0,
                  "replies": [
                    {
                      "id": "mu3hp3w",
                      "author": "Raddish_",
                      "body": "VRAM is more a limitation nowadays if you\u2019re trying to locally host Ai which a lot of people are suddenly interested in doing. I have a 16gb card that I can\u2019t fathom would have any trouble with any video game but it can only run a dumb distilled deepseek model.",
                      "score": 19,
                      "created_utc": 1748133646.0,
                      "replies": [
                        {
                          "id": "mu49e5o",
                          "author": "coltonbyu",
                          "body": "Feels like if your on AMD you are already hamstrung. I have 24gb vram but still feel super limited on options/tools",
                          "score": 5,
                          "created_utc": 1748145081.0,
                          "replies": [
                            {
                              "id": "mu4cl8e",
                              "author": "Raddish_",
                              "body": "Yeah I have NVIDIA so I can\u2019t really comment on that. So much software is configured for NVIDIA tho like their monopoly (and thus why they\u2019re the second most valuable company in the world right now) is on GPU software compatibility funnily enough it has nothing to do with the hardware in a vacuum.",
                              "score": 2,
                              "created_utc": 1748146613.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mudhi3r",
                          "author": "ilyich_commies",
                          "body": "Yeah and you also have machine learning researchers and engineers running local experiments with toy models before spending half a million on cloud compute for real stuff. A dual/quad 4090 or even 3090 rig is a beast for that kind of stuff",
                          "score": 1,
                          "created_utc": 1748280282.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu4yr6n",
                      "author": "Emu1981",
                      "body": ">it doesn't cost AMD or NVIDIA that much to double the memory storage on a card\n\nIt does cost more than most people realise.  That said, there is also the consideration of if they add too much VRAM to GPUs then people will start buying them for compute workloads which would be detrimental to the gaming market...",
                      "score": 3,
                      "created_utc": 1748159029.0,
                      "replies": [
                        {
                          "id": "mu52b3u",
                          "author": "turikk",
                          "body": "It's less than $30 to move from 2GB chips to 4GB chips (8gb total to 16).  then again, thats about what the cost is for the user, too, with the RX 9060 XT.  so it's not like AMD is ripping people off.\n\nAIB's only make like $10-$20 a card when they sell these, its really abysmal margins.",
                          "score": 5,
                          "created_utc": 1748161178.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu4y3h2",
                      "author": "frostygrin",
                      "body": "> Additionally, when you do run out of VRAM, it's catastrophic on performance, not something like a little bit less frames.\n\nIt's true, and false. Some games do manage a VRAM shortage by shifting the resources in and out of VRAM - but it has a significant, if not catastrophic, impact on framerate - and requires more system RAM too.",
                      "score": 4,
                      "created_utc": 1748158633.0,
                      "replies": [
                        {
                          "id": "mu561ma",
                          "author": "Spaceqwe",
                          "body": "Forza Horizon 5 is one of those games that manages it well. I set the textures to extreme on my 4GB card and I was able to get around 90 fps while being massively out of vram. Game was almost using 4GB of my DDR3 system memory on top of the 4GB of my rx 550.",
                          "score": 4,
                          "created_utc": 1748163475.0,
                          "replies": [
                            {
                              "id": "mu594je",
                              "author": "frostygrin",
                              "body": "One caveat to this is whether you're actually getting extreme textures. Many games downgrade quality, sometimes visibly, in case of VRAM shortage.",
                              "score": 5,
                              "created_utc": 1748165417.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu3ityn",
                  "author": "maaku7",
                  "body": "AI. The reason is AI.",
                  "score": 13,
                  "created_utc": 1748134085.0,
                  "replies": [
                    {
                      "id": "mu6t98d",
                      "author": "Mourdraug",
                      "body": "I am bottlenecked by VRAM on my GPU in modded Skyrim VR",
                      "score": 3,
                      "created_utc": 1748188261.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu6o5p1",
                  "author": "ender89",
                  "body": "VRAM is important because it allows you to preload high definition assets into the VRAM, because PC games don\u2019t have a universal way to stream textures from storage at low latencies.\n\nMicrosoft is pushing for direct storage, which would allow the gpu to pull textures at high speeds from the high speed ssd without passing through the cpu. The technology is already available on modern consoles, but pc players need more vram to make it happen.",
                  "score": 1,
                  "created_utc": 1748186727.0,
                  "replies": []
                },
                {
                  "id": "muwedbx",
                  "author": "FatBoyStew",
                  "body": "People keep thinking their non-4k cards are 4k-cards now. \n\nHell even my 10GB 3080 hasn't hit Vram issues at 1440p -- its being bottlenecked by general speed/processing limitations than VRam.",
                  "score": 1,
                  "created_utc": 1748532715.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu5wffw",
              "author": "typeguyfiftytwix",
              "body": "That and modern AAA games are optimized about as well as a fucking trainwreck, but outside of those most things run fine on older hardware. A friend of mine still uses a 1060 to run things at OK settings as long as he avoids bullshit like space marine 2, which is a crash fest even on newer hardware for no good reason.\n\nAnything that has AI frame gen as an option spent their \"competent software dev\" budget on marketing instead.",
              "score": 3,
              "created_utc": 1748177384.0,
              "replies": [
                {
                  "id": "mugqo2k",
                  "author": "nordic-nomad",
                  "body": "Top tier gaming consoles have 16gb of vram. So that\u2019s what most games are going to be pegged at for a while.",
                  "score": 1,
                  "created_utc": 1748321226.0,
                  "replies": [
                    {
                      "id": "muluy4e",
                      "author": "typeguyfiftytwix",
                      "body": "That's not VRAM. \n\nVRAM is dedicated to specifically GPU processes. VRAM is part of the GPU itself. \"Top tier\" consoles (the ps5 pro) have 16gb of RAM, in total.\n\nFor comparison, a decent gaming pc may have 32GB of ram, plus 8-16GB of vram in the GPU. Ram isn't bottlenecking PC performance. Games run like absolute dogshit because modern devs are nowhere near as good at optimization as they used to be, because it costs time, money and requires skills, and game development isn't a high paying field.",
                      "score": 1,
                      "created_utc": 1748388697.0,
                      "replies": [
                        {
                          "id": "mun9cmr",
                          "author": "nordic-nomad",
                          "body": "Gaming consoles are weird. The vram and system ram are basically the same pool. It\u2019s not one to one for comparing to pc specs. So yes, while on paper it has 16gb of vram it\u2019ll never have access to all of it.",
                          "score": 1,
                          "created_utc": 1748407050.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu331xq",
              "author": "Obi_Vayne_Kenobi",
              "body": "I've played a handful of League of Legends matches since I got my RTX 4080. The thing runs League at 900 fps, which is useless, but also pretty funny. \n\nDoesn't make the game any better though, and I'm happy I spend my time (and fps) with other things now",
              "score": 1,
              "created_utc": 1748128033.0,
              "replies": []
            },
            {
              "id": "mu3wfsl",
              "author": "C10ckw0rks",
              "body": "I had someone ask why I went out of my way for the 12gb VRAM because I do blender stuff and vtubing. However I also know I am not the general public on yhis matter",
              "score": 1,
              "created_utc": 1748139447.0,
              "replies": []
            },
            {
              "id": "mu5x8ja",
              "author": "Skynuts",
              "body": "On the other hand, if you play games that are already easy to run on older hardware, 5060 is probably not for you when you get like ~400 FPS in League of Legends with an old 1060 on low and 1080p. I think this whole \"8GB VRAM is not enough\" is a bit overexaggerate, but there are a handful of games that exceed 8GB at 1080p to 1440p. The Dead Space remake and Hogwarts Legacy just to name a few. For something that's supposed to last for a couple of years, adding 8GB of VRAM to a lower mid-range card makes little sense in 2025.",
              "score": 1,
              "created_utc": 1748177704.0,
              "replies": []
            },
            {
              "id": "mu6thc5",
              "author": "Jonny_Exotics",
              "body": "B-but if u can\u2019t max out cyperfuck 2088 with gay tracing then you shouldn\u2019t even buy the card",
              "score": -1,
              "created_utc": 1748188328.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu5bm0q",
          "author": "Minukaro",
          "body": "They also don't need new cards either...",
          "score": 6,
          "created_utc": 1748166950.0,
          "replies": []
        },
        {
          "id": "mu2pofx",
          "author": "Hanifsefu",
          "body": "Yeah but NVIDIA bros are desperate to manufacture bad press for the competition otherwise they can't justify paying the massive mark up for \"name brand\".",
          "score": 34,
          "created_utc": 1748123065.0,
          "replies": [
            {
              "id": "mu31bbf",
              "author": "ultramatt1",
              "body": "I feel like nvidia gets complained about endlessly on the pcmasterrace super user bubble",
              "score": 32,
              "created_utc": 1748127384.0,
              "replies": [
                {
                  "id": "mu3mhm7",
                  "author": "Hanifsefu",
                  "body": "On posts showing that they've already bought into their shit. There's an endless flood of \"look at my pretty new 3090/4090/5090\" posts and the only place you see shit that isn't pure NVIDIA glazing it's 3-4 comments deep in a thread.\n\nThe bias is very obvious and clear in NVIDIA's favor.",
                  "score": 0,
                  "created_utc": 1748135499.0,
                  "replies": [
                    {
                      "id": "mu5doey",
                      "author": "cdxxmike",
                      "body": "The bias is there because I owned a PC repair shop for 20 years, and no joke, 80% of gamers that brought their PCs in for help had AMD.",
                      "score": -1,
                      "created_utc": 1748168187.0,
                      "replies": [
                        {
                          "id": "mu5wxyj",
                          "author": "typeguyfiftytwix",
                          "body": "AMD is common for first time buyers again because of low cost. It's more popular than market share would indicate for people building PCs, because people that are concerned about price-performance ratio instead of maximum high end will also try to learn to build PCs, but they're not usually the technically oriented types.",
                          "score": 0,
                          "created_utc": 1748177589.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu5vjbd",
              "author": "Nagemasu",
              "body": "what are you on about, NVIDIA has been saying the same thing for the last 3 generations and has been ragged on for it even worse.",
              "score": 1,
              "created_utc": 1748177022.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu3n4y2",
          "author": "None",
          "body": "He uh... He has a point. I'm still on 6GB VRAM.\n\nI don't do e-sports other than The Finals on occasion. Primarily HEAVILY modded Minecraft and Skyrim. \n\nIt never really seems to struggle. For example, I push a consistent 120 FPS in Minecraft with textures out the ass, shaders on high and 400+ mods... Nearly all of which relentless on RAM consumption.\n\nI do have 32GB RAM at least.",
          "score": 1,
          "created_utc": 1748135750.0,
          "replies": [
            {
              "id": "mu5h3yu",
              "author": "MrMPFR",
              "body": "RAM at VRAM aren't the same thing + the games you're playing are ancient so no wonder why even modded version are fine on 6GB. PS5 tripled available shared memory besides OS and that is what caused all the current issues on PC. If PC had caught up and bumped VRAM across the board then we wouldn't have all the current issues and complaints.",
              "score": 1,
              "created_utc": 1748170164.0,
              "replies": [
                {
                  "id": "mu5k2v4",
                  "author": "None",
                  "body": "Yes. I'm aware they aren't the same thing. That's precisely why I typed them as VRAM and RAM... Not RAM and RAM. \ud83e\udd78 I'm also aware the games I primarily play have been around a while, but I play newer games as well. Admittedly not the few which demand an absurd amount of VRAM and actually make use of it.\n\nI would love more VRAM. I just don't really see a particular need for it in my use case. Especially since I'm more than content with 1080p. I respect that's not the case for everyone though.\n\nEdit: Also... Those \"old\" games actually don't even run as well as the newer more visually appealing games either. That's the point of me specifying that it's not vanilla... At all. It's pushed to the maximum limits.",
                  "score": 3,
                  "created_utc": 1748171746.0,
                  "replies": [
                    {
                      "id": "mu65tf5",
                      "author": "MrMPFR",
                      "body": "Sorry mate, might have reached a limit with people defending a $299 8GB card in 2025.\n\nI'm using old HW as well. GTX 1060 6GB and a i7-2600K with 16GB of DDR3 so no indeed not everyone needs to upgrade and you can probably use that 6GB GPU for many years into the future as long as you stick to lastgen and crossgen AAA and current gen eSports and indie games.\n\nYep modded Minecraft and Skyrim can be brutal. Seus PTGI HRR 3 with large view distances and cranked up settings forces my brothers 1660 TI into sub 20 FPS at 1080p xD.",
                      "score": 1,
                      "created_utc": 1748180868.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu5j3ht",
              "author": "IIlIIlIIlIlIIlIIlIIl",
              "body": ">For example, I push a consistent 120 FPS in Minecraft with textures out the ass, shaders on high and 400+ mods\n\nWhat GPU do you have? I still find that shaders absolutely demolish FPS in Minecraft.\n\nMy 5800X3d & 2070S get 120FPS on a big modpack and that quickly drops to 80 and below with some BSL shaders on Medium or High, with the GPU getting maxed out.",
              "score": 1,
              "created_utc": 1748171231.0,
              "replies": [
                {
                  "id": "mu5kdys",
                  "author": "None",
                  "body": "RTX 4050 (Mobile). I know the 4050 was only released for mobile but you'd be surprised how many PC enthusiasts didn't even know it existed when I mentioned it until I pointed out it was mobile only lol.\n\nI run Complementary Shaders - Unbound on High right now since I'm testing to see how it stacks up performance wise against the Euphoria patches. Pretty damn consistent 110-130 FPS no matter what.\n\nI also run mods like Fancy Block Particles, nice textures (albeit not much in terms of resolution) and quite a few other visual enhancement mods I can't name rn lmao.",
                  "score": 1,
                  "created_utc": 1748171904.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu47spr",
          "author": "polopolo05",
          "body": "I am running 3 montors.... I want that vram",
          "score": 1,
          "created_utc": 1748144337.0,
          "replies": []
        },
        {
          "id": "mu588cr",
          "author": "Dendrok7",
          "body": "I only read one sentence and I agree fuck it I\u2019m dumb as fuck. But at least I got more then 8gb of vram",
          "score": 1,
          "created_utc": 1748164850.0,
          "replies": []
        },
        {
          "id": "mu5catj",
          "author": "Xanxost",
          "body": "Thank you.",
          "score": 1,
          "created_utc": 1748167360.0,
          "replies": []
        },
        {
          "id": "mub9g5g",
          "author": "bonesnaps",
          "body": "There is something wrong with shitty clickbait articles though.\n\n\nPeople, stop posting trash on this forum pls",
          "score": 1,
          "created_utc": 1748249563.0,
          "replies": []
        },
        {
          "id": "mv00gme",
          "author": "hirscheyyaltern",
          "body": "except that 8gb vram is no longer enough for 1080p unless you want to compromise your experience. yeah you still can do it, but you have to tweak a lot more settings. more vram, a lot of games would be set it and forget it, rather than \"i have to turn down texture and shadow quality to reduce vram and also turn off the optional RT effects too\", etc. it's been shown that the current popular 8gb cards are capable of running games at 1080p from a raster/compute standpoint, but quality gets lower because 8gb card users are forced to turn down settings in an otherwise playable experience. look at any 5060ti 8 vs 16gb comparison",
          "score": 1,
          "created_utc": 1748572343.0,
          "replies": []
        },
        {
          "id": "my8zw0j",
          "author": "Independent-You-6180",
          "body": "I don't like the notion that people who don't want to read the article are stupid or lazy. News articles often contain like 10 paragraphs of unnecessary preamble and are loaded with shit on them. I don't even open them anymore because they're always a waste of time. There's so much fluff that it feels like an insult to my time even trying to read them. They take for fucking ever to get to the point. I wish people posting them would just add a TL;DR.",
          "score": 1,
          "created_utc": 1750162047.0,
          "replies": []
        },
        {
          "id": "mu4k6a0",
          "author": "MooseBoys",
          "body": "I don't understand the connection between resolution and VRAM requirements. Unless something has changed dramatically recently, games are still very bad at doing dynamic sub-texture residency. Most games don't hit anywhere close to 1:1 texel:pixel ratio, so unless you artificially cut off a MIP level when playing at 1080p vs 4K, you're not going to save any more VRAM than the framebuffer, maybe 100MB max. In theory, with perfect residency, you can render a 4K frame with only 64MB of memory. Obviously we're very far from that.",
          "score": 1,
          "created_utc": 1748150545.0,
          "replies": [
            {
              "id": "mu5grot",
              "author": "MrMPFR",
              "body": "What happened is that the available shared memory on consoles (excluding OS) basically tripled from PS4->PS6 and devs used all that extra memory to push texture quality and graphics fidelity while taking advantage of very sophisticated data streaming APIs to reduce preloading.  \nPC pushes settings even further while often relying on outdated data management APIs. It's no surprise that things have gotten out of control post crossgen when midrange GPUs after nearly a decade still start at RX 480 8GB in 2016 vs RTX 5060 8GB in 2025.\n\nSo yeah it's incredibly inefficient, and I hope that work graphs can somewhat solve that. At least according to AMD it can deliver insane 50-80x VRAM savings at iso complexity in a compute shader demo from GDC 2024.",
              "score": 3,
              "created_utc": 1748169977.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu3vfr2",
          "author": "Possible_Proposal447",
          "body": "I'm still on a 1050ti playing esport titles. Nothing wrong was said.",
          "score": 1,
          "created_utc": 1748139036.0,
          "replies": [
            {
              "id": "mub9plv",
              "author": "Fidodo",
              "body": "I'm on a 1080. Was thinking of upgrading, looked at the prices, then decided my GPU is fine. I play at 1080p still. I don't feel like I'm missing out.",
              "score": 1,
              "created_utc": 1748249721.0,
              "replies": []
            },
            {
              "id": "mu5h878",
              "author": "MrMPFR",
              "body": "He used it to justify the RT 9060XT 8GB's existance. A 1050 TI isn't the same tier of card as a 9060XT. The closest thing NVIDIA currently has is probably the RTX 3050 6GB and for AMD it's the RX 6600",
              "score": 1,
              "created_utc": 1748170227.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu4zi2h",
          "author": "sold_snek",
          "body": "I think it's still hard for a lot of people to realize how small the entire American and European market still is compared to the rest of the world that is packed to the gills with people.",
          "score": 1,
          "created_utc": 1748159471.0,
          "replies": [
            {
              "id": "mu5gu51",
              "author": "MrMPFR",
              "body": "Yeah but those markets aren't buying expensive $299 AMD GPUs en masse.",
              "score": 1,
              "created_utc": 1748170015.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu4bw32",
          "author": "Doom2pro",
          "body": "This is like Bill Gates quote taken out of context lol",
          "score": 0,
          "created_utc": 1748146271.0,
          "replies": []
        },
        {
          "id": "mu53a4k",
          "author": "pmjm",
          "body": "What's wrong with it is that all of the marketing for the card is based on the 16GB version. They're banking on the ignorance of customers who only see a $50 lower price and don't know what they're giving up. \n\nThey're even marketing [the 16GB version against the 8GB version of the 5060 Ti.](https://cdn.videocardz.com/1/2025/05/RADEON-RX-9060-XT-HERO2-1200x624.jpg)",
          "score": 0,
          "created_utc": 1748161783.0,
          "replies": []
        },
        {
          "id": "mu8uijf",
          "author": "Noselessmonk",
          "body": "The issue with looking at it based on how many players those low hardware demand games have is that it's working under an assumption that that is all those players will play.",
          "score": 0,
          "created_utc": 1748211224.0,
          "replies": []
        },
        {
          "id": "mu2xdvi",
          "author": "aviroblox",
          "body": "It's misleading, the vast majority of gamers in that stat playing at 1080p with games like League aren't generally going out to buy the latest and greatest desktop gpu's for their diy PC. They're clocking into their nearby LAN cafe/center, or gaming on some 1080p gaming laptop.\n\nhttps://www.statista.com/statistics/268367/forecast-of-the-global-pc-gaming-hardware-market/#:~:text=In%202019%2C%20branded%20systems%20accounted,billion%20U.S.%20dollars%20by%202022.\n\nThis GPU exists purely to sit in prebuilts and scam people who see 9060xt on the sticker and expect 9060xt 16gb performance they saw on YouTube.",
          "score": -13,
          "created_utc": 1748125902.0,
          "replies": []
        },
        {
          "id": "mu2umhi",
          "author": "Wischiwaschbaer",
          "body": "Why would those gamers buy that expensive AMD card then? For them a used card or an Intel card would be good enough.\n\nThis makes no sense.",
          "score": -13,
          "created_utc": 1748124863.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0jdm9",
      "author": "anirban_dev",
      "body": "Considering they will have only 1 8gb vram card in the market, which will most definitely be outsold heavily by the 5060, they didn't really need to jump on this grenade for Nvidia.",
      "score": 996,
      "created_utc": 1748097342.0,
      "replies": [
        {
          "id": "mu0wgpv",
          "author": "AtlasPwn3d",
          "body": "Or\u2014hear me out\u2014it\u2019s simply true, so much so that they have zero aprehension about stating it.\n\nHere you have the company with the most to gain by parroting what you want to hear, and yet they aren\u2019t (to their own detriment), and you\u2019re still so convinced of your own narrative that you refuse to believe them.",
          "score": 394,
          "created_utc": 1748101454.0,
          "replies": [
            {
              "id": "mu0xpgl",
              "author": "SimiKusoni",
              "body": "Steam survey puts \\~55% of users on 1080p monitors so it's probably correct. It's just really weird for AMD, a company that has based a lot of their marketing on VRAM capacity, to come out and say it.",
              "score": 142,
              "created_utc": 1748101843.0,
              "replies": [
                {
                  "id": "mu173gv",
                  "author": "anirban_dev",
                  "body": "1080p has been the dominant resolution in steam surveys for more than 10 years now. So its not as much correct as it is by design.",
                  "score": 57,
                  "created_utc": 1748104869.0,
                  "replies": [
                    {
                      "id": "mu1gn3l",
                      "author": "_fuck_me_sideways_",
                      "body": "1440p 144 hz is the sweet spot for me. Games genuinely look worse at 1080 unless the art style is less realistic.",
                      "score": 40,
                      "created_utc": 1748107876.0,
                      "replies": [
                        {
                          "id": "mu2fb1d",
                          "author": "Ech_01",
                          "body": "You gotta realise a lot are laptop gamers and 1080 looks almost as good as 1440p",
                          "score": 14,
                          "created_utc": 1748119460.0,
                          "replies": []
                        },
                        {
                          "id": "mu2arsp",
                          "author": "SmooK_LV",
                          "body": "I don't see much difference, I just game on 1080p for more fps.",
                          "score": 25,
                          "created_utc": 1748117932.0,
                          "replies": [
                            {
                              "id": "mu2ft9c",
                              "author": "liquidmasl",
                              "body": "i cant go back to 1080 after being in 1440, still dont see any appeal of 4k tho",
                              "score": 23,
                              "created_utc": 1748119630.0,
                              "replies": [
                                {
                                  "id": "mu2i057",
                                  "author": "Horat1us_UA",
                                  "body": "1080 is good for 24\u201d, 1440 for 27 and 4k for 32",
                                  "score": 25,
                                  "created_utc": 1748120369.0,
                                  "replies": [
                                    {
                                      "id": "mu2mzlw",
                                      "author": "liquidmasl",
                                      "body": "i use 4k on my 32:9 screen, but its still 1440p, can never go back for work or gaming haha",
                                      "score": 1,
                                      "created_utc": 1748122102.0,
                                      "replies": []
                                    },
                                    {
                                      "id": "mu52twn",
                                      "author": "EricAntiHero1",
                                      "body": "I can\u2019t justify the price for a 4K monitor though. 1440 is just the perfect zone.",
                                      "score": 1,
                                      "created_utc": 1748161503.0,
                                      "replies": []
                                    },
                                    {
                                      "id": "mu2kjqb",
                                      "author": "RefrigeratorSome91",
                                      "body": "4k 27 makes 1440 at 27 look like 720p.",
                                      "score": -5,
                                      "created_utc": 1748121244.0,
                                      "replies": []
                                    }
                                  ]
                                },
                                {
                                  "id": "mu2mktq",
                                  "author": "Gretchinlover",
                                  "body": "The way you feel about 4k is how 1080 feels about 1440",
                                  "score": 11,
                                  "created_utc": 1748121957.0,
                                  "replies": [
                                    {
                                      "id": "mu2mv3d",
                                      "author": "liquidmasl",
                                      "body": "think is; i tried 4k. I actually use it daily on my laptop, still wouldt choose it for a nes monitor, but the screen door effect on 1080 is real",
                                      "score": 1,
                                      "created_utc": 1748122058.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "mu2jcem",
                              "author": "reeeelllaaaayyy823",
                              "body": "But if your card could cope you'd run higher.\n\nSo saying, \"most gamers run 1080p so they don't need more than 8Gb\" is silly. Most gamers *can't* run more than 1080p.",
                              "score": 10,
                              "created_utc": 1748120828.0,
                              "replies": [
                                {
                                  "id": "mu3num6",
                                  "author": "dwmfives",
                                  "body": "Who cares about more pixels when most games are moving so fast?  \n\nI don't give a fuck about the sunlight reflecting off a fish scale, just give me smooth game play.",
                                  "score": 11,
                                  "created_utc": 1748136033.0,
                                  "replies": [
                                    {
                                      "id": "mu7t1t6",
                                      "author": "anirban_dev",
                                      "body": "The whole hullabaloo is exactly because we have finally reached a point where a 8 GB card will occasionally not give you smooth gameplay even without the RT bells and whistles. The longer they can keep the vram limited without some visceral pushback, the more assured they are of people buying cards every gen to access updated and sometimes exclusive mitigating technologies like FSR4 multi frame gen.",
                                      "score": 1,
                                      "created_utc": 1748199039.0,
                                      "replies": [
                                        {
                                          "id": "mu9ge3p",
                                          "author": "dwmfives",
                                          "body": "I run nvidia anyway.  \n\nI was responding to the \"But if your card could cope you'd run higher.\" part of the comment.\"\n\nI might spend extra money for a 1440p card, but I wouldn't buy a more expensive version of the same card to get 4k.",
                                          "score": 1,
                                          "created_utc": 1748219260.0,
                                          "replies": []
                                        }
                                      ]
                                    },
                                    {
                                      "id": "mu3vm0g",
                                      "author": "reeeelllaaaayyy823",
                                      "body": "Sounds like something that someone with a card that can't run 4k smoothly would say.",
                                      "score": -13,
                                      "created_utc": 1748139107.0,
                                      "replies": [
                                        {
                                          "id": "mu4h95t",
                                          "author": "MajinSweet",
                                          "body": "Sounds like something that someone that doesn't play videogames would say.",
                                          "score": 6,
                                          "created_utc": 1748148978.0,
                                          "replies": [
                                            {
                                              "id": "mu4mjbe",
                                              "author": "reeeelllaaaayyy823",
                                              "body": "You got me.",
                                              "score": -3,
                                              "created_utc": 1748151850.0,
                                              "replies": []
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                },
                                {
                                  "id": "mu54opq",
                                  "author": "BohunkFunk",
                                  "body": "This is just simply not true. Maybe a portion of 1080p gamers want to splurge and be able to run 1440p maxed out games. But the large portion of 1080p gamers these days are playing eSports titles. Why the heck would any eSport player care about 1440p? They're hunched over their desks, craned onto the screen and chasing 240hz+ why pay more for a system to run it at the same frames at a higher resolution? Especially when most eSport gamers knock down the resolution to 16:10 or even 4:3 if they're CS players. \n\n\nThere's also PC cafes, were people don't care about this stuff anyways. And it'll make more sense for these businesses to build 1080p affordable machines for the eSport titles they'll be running.",
                                  "score": 1,
                                  "created_utc": 1748162643.0,
                                  "replies": [
                                    {
                                      "id": "mw5flaw",
                                      "author": "reeeelllaaaayyy823",
                                      "body": "I'll let Steve answer for me. https://www.youtube.com/watch?v=MG9mFS7lMzU&t=1288",
                                      "score": 0,
                                      "created_utc": 1749137463.0,
                                      "replies": [
                                        {
                                          "id": "mw9gzj5",
                                          "author": "BohunkFunk",
                                          "body": "I can't see why you chose to do so, because none of this pertains to the conversation we're having. \n\nI'm not defending 8gb models, not saying their performance is any good or acceptable. And quite frankly, you weren't discussing it's performance either. \n\nI still think the 8gb option is egregious because it shouldn't exist outright, it confuses consumer and it's a scam, you can just release an 8gb 1080p card under a different name if you want an eSport card for the eSport player base.\n\n What I am saying is in direct relation TO your direct conjecture about people being on 1080p because they can't afford too. Most people on 1080p actually do just choose to play in 1080p. I'm one of those because I'd rather chase frames and many FPS players will agree  And that PC cafes typically run 1080p, i's cheaper to do so. Now if you want to say that 1440p should be the new standard that's a different conversation, I think affordable cards should be offered at that entry point because 1440p monitors are cheap and well never seen the swell and shift to 1440p if cards remain at this level.\n\n\nTl;Dr I DONT think this 8gb 9060 should exist because you can just make it a 9050 for that player base. And I think cards are all overpriced anyhow.  But that was never our conversation and it makes your video irrevalaent. You have to learn how to communicate with people.",
                                          "score": 0,
                                          "created_utc": 1749184199.0,
                                          "replies": [
                                            {
                                              "id": "mwad5vf",
                                              "author": "reeeelllaaaayyy823",
                                              "body": ">You have to learn how to communicate with people.\n\nHow rude.\n\nImagine a world where 5090's were $100.\n\nWhat percentage of people do you think would run at 1080p?",
                                              "score": 1,
                                              "created_utc": 1749202073.0,
                                              "replies": [
                                                {
                                                  "id": "mwf8gxh",
                                                  "author": "BohunkFunk",
                                                  "body": "I only say it because you showed a complete inability to communicate properly in an argumentative setting, when you linked an irrelevant video that just listed benchmarks which is not the point of our conversation. Nor was it conjecture relevant to our discussion  \n  \nAgain here you simply used a hyperbolic example that is just a logical fallacy. In doing so you take the conversation out of the parameters of reality as well which weakns your argument. Even in the realm of our current world 300$ cards on the used do make 1440p accessible and yet 1080p still is the more popular display.\n\nAnd even in that world, I'd run at 1080p personally anyways give me one of those 540hz monitors and id pop off. I hope you have a wonderful rest of your day, if you're still offended I can only apologize for doing so, but I do recommend that you read the book \"everything is an argument\" its incredibly well written, entertaining, and has stuck with me since my AP classes in highschool over a decade ago. Have a great day and again, my apologies if I come off harsh and abrupt--I do not owe you my patience in explaining myself, but I should try at least.",
                                                  "score": 1,
                                                  "created_utc": 1749261517.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "mu415l2",
                              "author": "PM_YOUR_BOOBS_PLS_",
                              "body": "If you have a 1440p monitor, and you're running at 1080p, and you can't see much of a difference...  You legitimately need to have your eyes checked.  Like, this is not some snarky comment.  Digital displays do NOT look right when not running at a full integer multiple of their native resolution.  1080p is not a full integer increment of 1440p, so it will look like *absolute dogshit*.  If you can't see the difference between the two, you legitimately have vision problems and should see an optometrist.",
                              "score": 0,
                              "created_utc": 1748141364.0,
                              "replies": []
                            },
                            {
                              "id": "mu5f6gx",
                              "author": "generally-speaking",
                              "body": "For the actual game, I don't see much difference either but menus and text come out more easy on the eyes at 1440p. \n\nFor me it's the absolute sweet spot.",
                              "score": 0,
                              "created_utc": 1748169073.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mu3k1hk",
                          "author": "thomasutra",
                          "body": "lower resolution looks worse: more on this breaking story at 10.",
                          "score": 1,
                          "created_utc": 1748134553.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu26y2f",
                      "author": "None",
                      "body": "Those people are not the customers of this topic",
                      "score": 1,
                      "created_utc": 1748116605.0,
                      "replies": []
                    },
                    {
                      "id": "mu1cbla",
                      "author": "Iggyhopper",
                      "body": "It gets difficult to just see things after 1080p. I assume a lot of programs have serious issues, including Windows and Linux themselves, with scaling after 1080.\n\n\nIts not just a technology challenge its UI/interfaces as well.",
                      "score": -17,
                      "created_utc": 1748106526.0,
                      "replies": [
                        {
                          "id": "mu27ea6",
                          "author": "QuietDisquiet",
                          "body": "I mean, the difference between 1080 and 1440 is pretty stark.",
                          "score": 2,
                          "created_utc": 1748116763.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu28sx8",
                  "author": "Zilox",
                  "body": "You can play 1440 with 8gb of vram anyways, who tf is telling people you cant",
                  "score": 5,
                  "created_utc": 1748117250.0,
                  "replies": [
                    {
                      "id": "mu2eleo",
                      "author": "octopoddle",
                      "body": "There's been a few games which are horribly optimised, apparently because they ported across from console and used the PC's VRAM instead of the actual RAM because it makes for a lazier port. So 8gb might be fine for a lot of games, but lazy ports like The Last Of Us need more.",
                      "score": 2,
                      "created_utc": 1748119222.0,
                      "replies": [
                        {
                          "id": "mu2fedp",
                          "author": "Zilox",
                          "body": "But ps5 uses 8gb of vram, doesnt make sense",
                          "score": -2,
                          "created_utc": 1748119491.0,
                          "replies": [
                            {
                              "id": "mu2lpop",
                              "author": "Chimwizlet",
                              "body": "PS5 doesn't have 8gb of vram, it has 16gb of total ram, which is used both for vram and system memory.\n\nThe PS5 is also built to optimise that ram for gameplay when needed, unlike PC's where every process running just uses whatever resource it needs.\n\nA PS5 can get more efficiency out of its vram than a PC can too.\n\nPS5 hardware is fixed, so devs can make use of more efficient tools for rendering graphics, while on PC they have to use more generalised tools like dx11 due to hardware variables.\n\nAlso, only having one lot of ram means there's no duplication or data transfer going on between system ram and vram. On PC if both the CPU and GPU need to use the same data, it has to be loaded into both system ram and vram.",
                              "score": 6,
                              "created_utc": 1748121651.0,
                              "replies": []
                            },
                            {
                              "id": "mu5llet",
                              "author": "Eruannster",
                              "body": "PS5 does not have 8 GB VRAM, it has 16 GB shared/unified RAM that both the CPU+GPU can access. Out of that 16, roughly 3 GB is used for the system, so developers have ~13 GB to use for games as they prefer, which is RAM+VRAM in one singular RAM pool.\n\n\nFor comparison, Series X has 10+6 GB RAM (16 GB total) in a similar shared pool, but some of the RAM is faster, some is slower. Series S is 8+2 GB (10 GB total) and PS5 Pro is 16 + 2 GB (18 GB total) where some of the system usage gets moved over to the extra 2 GB, freeing up more of that initial 16 for games.",
                              "score": 2,
                              "created_utc": 1748172525.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu26plg",
                  "author": "Pebble_in_my_toes",
                  "body": "Then shouldn't you be trusting their word?\n\nI don't understand what's the issue here. Is it usually Reddit contrarianness?",
                  "score": 2,
                  "created_utc": 1748116522.0,
                  "replies": []
                },
                {
                  "id": "mu5kxt8",
                  "author": "Kered13",
                  "body": "> Steam survey puts ~55% of users on 1080p monitors\n\nHow many of those are in the market for a new graphics card though? If you're just going to play old games at 1080p, you don't need 8GB of RAM or a new graphics card. But pretty soon new games are probably going to start requiring more than 8GB of VRAM even for 1080p.",
                  "score": 1,
                  "created_utc": 1748172187.0,
                  "replies": [
                    {
                      "id": "mu5lvss",
                      "author": "Eruannster",
                      "body": "Maybe they won't upgrade right this moment, but at some point in the future they will probably want something newer, and if games are made for ~10-12+ GB VRAM and the low end cards are still stuck at 8 GB, we're going to have a problem where brand new GPUs can't run new games.\n\n\nIt's not necessarily a problem today, but it's starting to creep up as a problem and will probably get worse in the near future.",
                      "score": 2,
                      "created_utc": 1748172670.0,
                      "replies": [
                        {
                          "id": "mu5nesb",
                          "author": "Kered13",
                          "body": "Exactly. These cards have an extremely limited future potential. If you just want to play old games on a budget today, you're better off buying something used. If you're spending $300 on a new card, you may as well spend the $50 extra on something that will last at least twice if not three times as long.",
                          "score": 1,
                          "created_utc": 1748173425.0,
                          "replies": [
                            {
                              "id": "mu5p7hc",
                              "author": "Eruannster",
                              "body": "Yeah. Imagine buying a 5060 8 GB card now and thinking \"I'm going to use this to play GTA 6 next year!\" (Wishful thinking, I know, but let's just imagine.) \n\n\nAnd then the game comes out, and woops, it wants 10 GB VRAM card minimum. Now your GPU from this year won't even play a game from next year.",
                              "score": 1,
                              "created_utc": 1748174278.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu2payt",
                  "author": "Arbiter02",
                  "body": "Of those 55%, how many are just playing rocket league, Dota, or CS? If that's all you're playing, then yeah you really don't need more than 8 gigs. But if you're actually playing the latest Un(optimized)real Engine 5 games then you're going to struggle. I'd wager most of that 55% aren't.",
                  "score": 1,
                  "created_utc": 1748122929.0,
                  "replies": []
                },
                {
                  "id": "mu46ay8",
                  "author": "EnvBlitz",
                  "body": "Nah, even Herman Miller the big name in chair has said something to this effect.\n\nThey don't sponsor gaming events for brand advertisement because they believe even their chairs aren't suitable for everyone, and people should use what they are comfortable with.\n\nMaybe they just want to be honest.",
                  "score": 0,
                  "created_utc": 1748143650.0,
                  "replies": []
                },
                {
                  "id": "mumgwzp",
                  "author": "Public-Radio6221",
                  "body": "There's a whole bunch of games that require more than 8GB if Vram even at 1080p, if we're even entertaining this dumbass idea that the 9060XT (a 1440p card) is gonna be used primarily for 1080p.",
                  "score": 0,
                  "created_utc": 1748396154.0,
                  "replies": []
                },
                {
                  "id": "mu3fh69",
                  "author": "Fredasa",
                  "body": "See, it bugs me when anyone, including AMD here, submits that context-free datum about who's using what.\n\nHow do you reckon those surveys would shift if you limited the data to only those who are looking to buy, direct from a retailer, a GPU released in 2025?\n\nBecause, wouldn't you know it, when you're trying to sell your new GPU in 2025, those are the only people who actually count.  _Obviously_ there's a _much_ larger population of folks using older gear.  Literal decades of GPUs and monitors still exist, so people are going to use 'em\u2014many times more than those whose stuff is less than five years old.\n\nAMD were in the wrong for lumping together two separate audiences: the prospective consumers, and the other 90% of folks using whatever's available.  What frustrates is that this train of thought seems to be a _pervasive_ misunderstanding.",
                  "score": -1,
                  "created_utc": 1748132776.0,
                  "replies": [
                    {
                      "id": "mu3wc3t",
                      "author": "SimiKusoni",
                      "body": "AMD didn't throw out that data point, I did. I suspect they have far better data than the Steam survey for what resolution new buyers have on their primary displays.\n\n\nIt's also not a misunderstanding - just a limitation of the dataset that I presumed was self evident and not worthy of four paragraphs of pontification.\n\n\nAlso keep in mind this is a $300 GPU, it's not very likely buyers already own or plan on splurging on expensive monitors. New 1080p monitors are also still inexplicably popular so \"it's 2025\" doesn't mean very much without data justifying why you feel that's relevant.",
                      "score": 1,
                      "created_utc": 1748139404.0,
                      "replies": [
                        {
                          "id": "mu45vcd",
                          "author": "Fredasa",
                          "body": "> AMD didn't throw out that data point\n\nIn direct defense of their 8GB GPU, they stated effectively the same thing.  Top comment:\n\n> > _Azor said that the \"majority of gamers are still playing at 1080p and have no use for more than 8GB of memory_\n\n---\n\n> just a limitation of the dataset that I presumed was self evident\n\nThe the complete irrelevance to the topic of 2025 GPUs of a survey that includes every single PC gamer is apparently not self-evident enough since people still bring it up, and doing so with zero caveats implicitly means nothing less than they believe the survey actually means a damn.  Not to put too fine a point on things.",
                          "score": 0,
                          "created_utc": 1748143450.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0xdjb",
              "author": "m0stly_toast",
              "body": "Yeah, people love to freak out about statements like these on here but the truth is that most people game on 1080p and 8gb vram is plenty.\n\nFar from the only factor that dictates performance but they want to pretend that it is",
              "score": 61,
              "created_utc": 1748101739.0,
              "replies": [
                {
                  "id": "mu0ytfl",
                  "author": "juh4z",
                  "body": "There are a bunch of games today that use more than 8gb of vram even at 1080p, and that number is only going up, why the fuck would you argue against future proofing the gpus?",
                  "score": 180,
                  "created_utc": 1748102197.0,
                  "replies": [
                    {
                      "id": "mu10yt9",
                      "author": "tlst9999",
                      "body": "If they're not futureproof, Nvidia & AMD can sell a newer model to you later.",
                      "score": 65,
                      "created_utc": 1748102883.0,
                      "replies": [
                        {
                          "id": "mu1r7ra",
                          "author": "S31Ender",
                          "body": "And there\u2019s the point. It\u2019s bullshit marketing to get you to buy a card every year instead of every several years.\n\nNo one wants yearly GPU lifecycles.\nWe want to buy a brand new GPU and realistically game on it for a few years before having to buy a new one.\nYou buy low end for 1080p, midline for 1440k, and high end for 4k.\n\nSaying \u201coh, buy this card today for 1080p gaming and then buy another one next year for 1080 gaming just to keep up\u201d is BS.\n\n\nEDIT: premarital changed to realistically\u2026because holy crap autocorrect\u2026..",
                          "score": 11,
                          "created_utc": 1748111251.0,
                          "replies": [
                            {
                              "id": "mu1veie",
                              "author": "HairyBalds",
                              "body": "But you can do that now,   I bought a 3080 4years ago and I don't feel a need to upgrade every year.  That's just because people want the newest and best thing. I can ran almost any game on max settings. I got my PC in 2021.",
                              "score": 11,
                              "created_utc": 1748112640.0,
                              "replies": [
                                {
                                  "id": "mu1z1gy",
                                  "author": "MessiahPrinny",
                                  "body": "What resolution are you gaming at? 10gigs are starting to get strained too. I saw DOOM The Dark Ages use 9gb at 1440p. Some games can use even more than that.",
                                  "score": 0,
                                  "created_utc": 1748113857.0,
                                  "replies": [
                                    {
                                      "id": "mu1zzdv",
                                      "author": "HairyBalds",
                                      "body": "1440p & 144hz refresh rate",
                                      "score": 5,
                                      "created_utc": 1748114177.0,
                                      "replies": []
                                    },
                                    {
                                      "id": "mu29i5a",
                                      "author": "Zilox",
                                      "body": "You mean... the game that runs flawlessly on ps5?",
                                      "score": -3,
                                      "created_utc": 1748117494.0,
                                      "replies": [
                                        {
                                          "id": "mu33194",
                                          "author": "MessiahPrinny",
                                          "body": "No, it's still better on PC. It even has texture pool settings for lower ram GPUs. I'm just using it as an example for what its higher end settings can eat.",
                                          "score": 5,
                                          "created_utc": 1748128026.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "mu5fcd6",
                              "author": "RedMiah",
                              "body": "Premarital game? \n\nWhat about postmarital game?",
                              "score": 2,
                              "created_utc": 1748169169.0,
                              "replies": [
                                {
                                  "id": "mu5qvpu",
                                  "author": "S31Ender",
                                  "body": "I laughed at this. I don\u2019t know what autocorrect was thinking. I fixed it but put it in the edits.",
                                  "score": 2,
                                  "created_utc": 1748175042.0,
                                  "replies": [
                                    {
                                      "id": "mu6mlgp",
                                      "author": "RedMiah",
                                      "body": "Autocorrect can get really ducky these days",
                                      "score": 1,
                                      "created_utc": 1748186250.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu1nfu2",
                      "author": "write_mem",
                      "body": "If I can buy a sufficiently decent 8G GPU and enjoy the games I like for say $200-$300, that\u2019s pretty fair. A $600 or worse yet $2000 GPU may not improve my experience meaningfully. And I can buy a new low-mid range GPU every 2-3 years and still spend less than what I would on getting higher end GPU that I maybe use 5-6 years. Diminishing returns are a thing. And not everyone plays brand new high end titles with all settings maxed on 4K. \n\nI still play on an 2017 era GTX1070Ti. Does well enough for 1080/1440p on the games I play. 8 years on a sub $600 GPU. A $1200 (at the time) 1080 or Titan from that era isn\u2019t going to do significantly better for me at that time or today. Unless I specifically needed that juice to get the job done.",
                      "score": 21,
                      "created_utc": 1748110017.0,
                      "replies": [
                        {
                          "id": "mu2v6j0",
                          "author": "frostygrin",
                          "body": "> I still play on an 2017 era GTX1070Ti. Does well enough for 1080/1440p on the games I play.\n\nThat was a mid-high tier card with excessive VRAM for the time. You wouldn't have the same longevity with the 3GB 1060.",
                          "score": 5,
                          "created_utc": 1748125072.0,
                          "replies": []
                        },
                        {
                          "id": "mu2okds",
                          "author": "memecut",
                          "body": "If you have the money to spend on a 50 series you might as well get 16 to make sure you can play the games that come out the next 5 years (and some that already are out). \n\nIf none of the games you play or want to play the next 5 years require more than 8, you're probably overspending for a 50 series to begin with. \n\nIm doing 6gb for 1440 and its far from pretty in some of the games I play. I can't even get textures to load, and I'm doing low settings on everything. 8gb would barely put a dent in that issue, cause I'm not even doing native resolution.",
                          "score": 0,
                          "created_utc": 1748122662.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu1ynmn",
                      "author": "ChefJoe98136",
                      "body": "$300 budget gets a mid-low card, it isn't future proofing anything.",
                      "score": 11,
                      "created_utc": 1748113726.0,
                      "replies": [
                        {
                          "id": "mu5lb88",
                          "author": "Kered13",
                          "body": "A 16 GB RX 9060, for just $50 more (MSRP, anyways) will likely be a perfectly good card for several years. The 8 GB card is just a bad value.",
                          "score": 0,
                          "created_utc": 1748172382.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu2chj8",
                      "author": "None",
                      "body": "there's a huge market segment out there with aging systems who just want an affordable card to keep playing what they already play",
                      "score": 5,
                      "created_utc": 1748118516.0,
                      "replies": []
                    },
                    {
                      "id": "mu29358",
                      "author": "Zilox",
                      "body": "1 game where this happens? Lol",
                      "score": 1,
                      "created_utc": 1748117351.0,
                      "replies": []
                    },
                    {
                      "id": "mu1ti59",
                      "author": "BERND_HENNING",
                      "body": "You don't need future proofing if you are on a budget and only care about esports anyway. If you know for a fact that your preferred game at your preferred settings doesn't use more than 4-5 GB of vram why pay more If you won't ever need it or at least not for the next 4-5 years.",
                      "score": 0,
                      "created_utc": 1748112008.0,
                      "replies": []
                    },
                    {
                      "id": "mu1v471",
                      "author": "darkmacgf",
                      "body": "Most gamers don't play anything more demanding than Fortnite.",
                      "score": -2,
                      "created_utc": 1748112546.0,
                      "replies": [
                        {
                          "id": "mu5jqq0",
                          "author": "IIlIIlIIlIlIIlIIlIIl",
                          "body": "Fortnite is actually quite demanding. It's a UE5 with capabilities for Lumen, Nanite, etc.\n\nJust because the art style is cartoony doesn't mean it isn't a graphically intense or high quality game.",
                          "score": 0,
                          "created_utc": 1748171570.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu5ji2j",
                      "author": "IIlIIlIIlIlIIlIIlIIl",
                      "body": "The concept of future proofing is dying, at least for anything beyond 2-3 years/generations.\n\nNo point in getting something like a 5090 with the intention of keeping it 5 years if DLSS6 will turn out to be absolutely revolutionary and not be supported on previous gens and so on.",
                      "score": 0,
                      "created_utc": 1748171445.0,
                      "replies": []
                    },
                    {
                      "id": "mu10xfg",
                      "author": "m0stly_toast",
                      "body": "Are those games in the room with us right now? Because that just sounds like poor optimization, people say the exact same thing about 1440p games with 12gb but I max out every demanding game at that resolution and my GPU has never once been the bottleneck. There\u2019s so many other factors that matter than simply the vram, idk why Reddit loves to pretend that the only way to \u201cfuture proof\u201d a gpu is to stuff it full of vram that it will never fill with its intended use case. \u201cBut what about gta6\u201d I guarantee you gta6 will be perfectly runnable at 8gbs once it comes out. The future doesn\u2019t mean you have to run it at max settings.",
                      "score": -53,
                      "created_utc": 1748102870.0,
                      "replies": [
                        {
                          "id": "mu1328j",
                          "author": "C_Madison",
                          "body": "They are not only in the room with us right now, they are even in the article:\n\n> However, demanding titles such as Indiana Jones and the Great Circle are already pushing VRAM requirements hard, with the RTX 5060 unable to cope with this game above the Medium graphics preset, even at 1080p, simply because it doesn't have enough memory. \n\nAnd no, Indiana Jones isn't poorly optimized.",
                          "score": 38,
                          "created_utc": 1748103561.0,
                          "replies": []
                        },
                        {
                          "id": "mu15wjg",
                          "author": "saffeqwe",
                          "body": "Why does it matter if it's poor optimization? How will \"oh it's just poor optimization\" make bad optimized games run faster with 8GB vram? You have to accept  that companies don't care about optimization anymore. Your choice is either accept it and replace an 8gb vram gpu or skip a lot of games. Good luck with oblivion remastered. It's not a valid argument.",
                          "score": 17,
                          "created_utc": 1748104484.0,
                          "replies": [
                            {
                              "id": "mu2nehw",
                              "author": "HanzanPheet",
                              "body": "Yeah my 4060 with 8vram is running on high no issue. This thread is all over the place.\u00a0",
                              "score": 1,
                              "created_utc": 1748122249.0,
                              "replies": []
                            },
                            {
                              "id": "mu1a9iv",
                              "author": "Psychological-Ad8110",
                              "body": "Meh. My 1060 6gb handles it just fine.\u00a0",
                              "score": -10,
                              "created_utc": 1748105878.0,
                              "replies": [
                                {
                                  "id": "mu1ae67",
                                  "author": "saffeqwe",
                                  "body": "Define fine",
                                  "score": 5,
                                  "created_utc": 1748105919.0,
                                  "replies": [
                                    {
                                      "id": "mu1baht",
                                      "author": "Psychological-Ad8110",
                                      "body": "Never drops below 60 frames, everything looks fine, and I can speed jump from dive rock and slam my face into the imperial palace no problem\u00a0",
                                      "score": -9,
                                      "created_utc": 1748106201.0,
                                      "replies": [
                                        {
                                          "id": "mu1cb07",
                                          "author": "saffeqwe",
                                          "body": "[https://www.youtube.com/watch?v=E4yn7jNrkgk](https://www.youtube.com/watch?v=E4yn7jNrkgk)  \n[https://www.youtube.com/watch?v=vhx7ziD-\\_RQ](https://www.youtube.com/watch?v=vhx7ziD-_RQ)  \n[https://www.youtube.com/watch?v=4hzTgAgSR0g](https://www.youtube.com/watch?v=4hzTgAgSR0g)  \n[https://www.youtube.com/watch?v=twiZJ83h8kk](https://www.youtube.com/watch?v=twiZJ83h8kk)\n\nNobody can achieve 60fps on 1060 6gb but you can handle it at stable 60fps and it never drops down. I call this bullshit",
                                          "score": 5,
                                          "created_utc": 1748106521.0,
                                          "replies": [
                                            {
                                              "id": "mu1dh48",
                                              "author": "Psychological-Ad8110",
                                              "body": "Okay!",
                                              "score": -1,
                                              "created_utc": 1748106889.0,
                                              "replies": []
                                            }
                                          ]
                                        },
                                        {
                                          "id": "mu1bnu0",
                                          "author": "saffeqwe",
                                          "body": "Looks fine? what settings? What resolution?",
                                          "score": 2,
                                          "created_utc": 1748106318.0,
                                          "replies": [
                                            {
                                              "id": "mu1cco3",
                                              "author": "Psychological-Ad8110",
                                              "body": "Whatever my tv automatically does. I just let the game do recommended and I turn off shadows. My only real bottleneck game is no mans sky in VR. That's an average of about 40 frames and its pretty unplayable.\u00a0",
                                              "score": -3,
                                              "created_utc": 1748106536.0,
                                              "replies": [
                                                {
                                                  "id": "mu2nmio",
                                                  "author": "HanzanPheet",
                                                  "body": "Love how people are mad at you for stating what you do lol.\u00a0\nTurning shadows down has been the thing since 2002 to get great performance.\u00a0",
                                                  "score": 2,
                                                  "created_utc": 1748122328.0,
                                                  "replies": [
                                                    {
                                                      "id": "mu3rwm4",
                                                      "author": "Psychological-Ad8110",
                                                      "body": "Can't justify a 5k unit if people are achieving their goals at 400",
                                                      "score": 1,
                                                      "created_utc": 1748137622.0,
                                                      "replies": []
                                                    }
                                                  ]
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "mu15xw5",
                          "author": "saffeqwe",
                          "body": "Why does it matter if it's poor optimization? How will \"oh it's just poor optimization\" make bad optimized games run faster with 8GB vram? You have to accept  that companies don't care about optimization anymore. Your choice is either accept it and replace an 8gb vram gpu or skip a lot of games. Good luck with oblivion remastered. It's not a valid argument",
                          "score": 6,
                          "created_utc": 1748104496.0,
                          "replies": []
                        },
                        {
                          "id": "mu15ytk",
                          "author": "MyGoodOldFriend",
                          "body": "The thing about vram is that it just caps out. It\u2019s not like your game crashes, or you get worse performance. It just stops your game from displaying the graphics you\u2019ve set it to display. \n\nUnless you\u2019re on nvidia and Linux, in which case it can actually crash your system, or at least create serious bugs. (Source: first hand experience).",
                          "score": -8,
                          "created_utc": 1748104505.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu1ms4j",
                  "author": "NePa5",
                  "body": "> the truth is that most people game on 1080p and 8gb vram is plenty\n\nYep. Here is the current top played on steam:\n\nhttps://i.imgur.com/Y8I6ITz.png\n\nALL of those dont need much to play at 1080p, these are the people who AMD are hoping will buy this 8gb card.",
                  "score": 19,
                  "created_utc": 1748109805.0,
                  "replies": [
                    {
                      "id": "mu22urn",
                      "author": "SourceNo2702",
                      "body": "I\u2019m really not sure why AMD thinks these people would buy this card though? Most of these folks have been using the same GPU since 2016, and that\u2019s unlikely to change unless it dies on them.",
                      "score": 4,
                      "created_utc": 1748115172.0,
                      "replies": [
                        {
                          "id": "mu25em7",
                          "author": "None",
                          "body": "[deleted]",
                          "score": 11,
                          "created_utc": 1748116063.0,
                          "replies": [
                            {
                              "id": "mu5hyfy",
                              "author": "MrMPFR",
                              "body": "A RTX 3050 or another cheapo sub $250 USD NVIDIA card, possibly even a used card, really anything but a 9060XT 8GB. Pointless DOA product and it'll rot on shelves.",
                              "score": 0,
                              "created_utc": 1748170619.0,
                              "replies": [
                                {
                                  "id": "mu5jght",
                                  "author": "None",
                                  "body": "[deleted]",
                                  "score": 5,
                                  "created_utc": 1748171422.0,
                                  "replies": [
                                    {
                                      "id": "mu64dzu",
                                      "author": "MrMPFR",
                                      "body": "RTX 3050 6GB is selling for sub $200, NVIDIA's new bargain tier entry level 1650 GPU. They also have an upcoming RTX 5050 which will probably be a nerfed RTX 5060 for $50 less.\n\nAs long as you're fine playing 1080p medium-low in outlier games then sure go for it, but that's all 8GB cards will be capable off moving forward with more and more VRAM demanding AAA releases besides perhaps UE5 games which are remarkable VRAM efficient.",
                                      "score": 1,
                                      "created_utc": 1748180367.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "mu3yra4",
                          "author": "remnantsofthepast",
                          "body": "First time PC buyers/former console buyers. I would imagine pre-built companies inventories are primarily these low end 8gb cards",
                          "score": 2,
                          "created_utc": 1748140380.0,
                          "replies": [
                            {
                              "id": "mu5i8cg",
                              "author": "MrMPFR",
                              "body": "It would be interesting if someone had access DIY and prebuilt sales for each tier of product for each gen. Would wager +95% of the sub x60 tier sales are carried by OEMs and SIs.",
                              "score": 1,
                              "created_utc": 1748170768.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu4h4i2",
                      "author": "GodwynDi",
                      "body": "WTH is Bongo Cats?  I know Banana is just money laundering.",
                      "score": 1,
                      "created_utc": 1748148910.0,
                      "replies": [
                        {
                          "id": "mu5lpo3",
                          "author": "Kered13",
                          "body": "I noticed it on the Steam top played list the other day and tried to figure it out. I think it's the same thing.",
                          "score": 1,
                          "created_utc": 1748172584.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu11osx",
                  "author": "None",
                  "body": "[removed]",
                  "score": 42,
                  "created_utc": 1748103115.0,
                  "replies": [
                    {
                      "id": "mu13kpo",
                      "author": "Henry5321",
                      "body": "There are AAA games right now that are memory limited at 1080p. You can blame wasteful design all you want, but that won\u2019t change the fact that the game runs faster with more than 8gb",
                      "score": 21,
                      "created_utc": 1748103728.0,
                      "replies": [
                        {
                          "id": "mu1xrh5",
                          "author": "Eruannster",
                          "body": "Yup. Just look back a few months ago to Indiana Jones. It does *not* like to run on 8 GB cards (and I think a few testers mentioned it would simply crash because it expected at least ~10 GB of VRAM).",
                          "score": 8,
                          "created_utc": 1748113424.0,
                          "replies": [
                            {
                              "id": "mu5inln",
                              "author": "MrMPFR",
                              "body": "They also maxxed out the memory allocation pool slider in the game which isn't neccesary, but even without that the game is an insane VRAM hog just like Doom Eternal on max settings back in2020. Id Tech 8 in Doom TDA on the other hand looks surprisingly VRAM effient.  \nBut PC gaming needs to move past 8GB for anything but a bargain tier sub 200 eSports focused card.",
                              "score": 1,
                              "created_utc": 1748170996.0,
                              "replies": [
                                {
                                  "id": "mu5jw5l",
                                  "author": "Eruannster",
                                  "body": "Sure. But a lot of games more or less expect to be able to use ~10-12 GB VRAM and you'll have to start turning down settings that the GPU can actually handle, but it simply doesn't have enough memory. \n\n\nIn a couple of reviews of the 5060 they found that the graphics processing itself was very often completely fine with particular settings but it just ran out of memory.\n\n\nI've also seen games where you get texture qualities (low/medium/high/ultra etc.) where low and medium are fine on 8 GB cards but they look noticeably, massively worse than high/ultra (which require like 10+ GB VRAM) and there isn't really a performance impact on the game outside of that VRAM requirement.",
                                  "score": 1,
                                  "created_utc": 1748171650.0,
                                  "replies": [
                                    {
                                      "id": "mu64rvr",
                                      "author": "MrMPFR",
                                      "body": "Oh I know I've seen all the HUB tests. 10-12GB is the new requirement for 1080p high-ultra gaming and anyone buying a 8GB card will be forced to run 1080p medium-low or lower moving forward. Basically Xbox Series S garbage tier settings.",
                                      "score": 1,
                                      "created_utc": 1748180504.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu1mpmf",
                      "author": "BrunusManOWar",
                      "body": "Lmao 8GB card in 2025 for 400 dollars lul\n\nEven rx 480 had 8 GB, and that was *ten* years ago",
                      "score": 15,
                      "created_utc": 1748109783.0,
                      "replies": [
                        {
                          "id": "mu5jf1a",
                          "author": "MrMPFR",
                          "body": "It's 299 but yeah it's a joke. Infinity cache and supersized L2 gave AMD and NVIDIA an opportunity skimp on VRAM. 33-50% narrower VRAM bus width = 33-50% less VRAM.",
                          "score": 2,
                          "created_utc": 1748171400.0,
                          "replies": [
                            {
                              "id": "mu5k42z",
                              "author": "BrunusManOWar",
                              "body": "Yeah, it's a joke - but not really, since the MSRP of 300 will only be hit like, a year after the release. And when you add the VAT (or sales tax in the US) it either way shoots past 350 for sure, even at the ever-elusive MSRP\n\nAnd, while I understand that infinity cache and L2 are nice, it means shit when your game starts slugging and stuttering in the worst case, or just looking as if its textures came outta 2011 Skyrim in the best case. Especially with AI models and framegen running, you need all the VRAM you can get.\n\nReally wish people would start punishing Nvidia by not buying their POS GPUs. Yeah AMD is not much better but they're still better and it's in our interest to break the damned NV monopoly which got us into this situation in the first place. Let AMD and Intel cook, stop buying braindead Nvidia GPUs which are eternally gimped the moment the next rip-off generation releases\n\nThe worst thing is AMD/Intel don't release any gaming laptops, so as someone who moves a lot I'm forced to cash out for mobile Nvidia POS which barely work on Linux... Frustrating\n\nUgh I just wish ARM or any European or Chinese company started making mainline/PC GPUs and AI accelerators/ASICs to start chipping away at NV monopoly. Google apparently has custom AI TPUs but they're not quite up to par with Nvidia top of the line stuff, wish at least we would focus more on that and provide some competition in a market that's ripe for it. I understand Nvidia has got a massive brand since at least a decade ago, and they could release a steaming piece of shit and it would sell like hot cakes, but at least some competition for starters would be nice, eventually quality and good customer care would win hopefully against the brand behemoth",
                              "score": 2,
                              "created_utc": 1748171764.0,
                              "replies": [
                                {
                                  "id": "mu67nt8",
                                  "author": "MrMPFR",
                                  "body": "Good point so it's actually even worse than on paper. The fake MSRP BS has to stop. Will we ever get cards at MSRPs anywhere this gen.\n\n100% agreed which is why I said this. Look at 192bit 3060 vs 4060 TI at 128bit. Without L2 cache that 4060 TI card would've had to have a 192bit bus and 12GB of VRAM :C.\n\nAMD isn't serious about competing and notice how they never lower prices enough to force NVIDIA to respond. This is on purpose. Intel on the other hand could actually deliver Polaris esque pricing disruption assuming they can fix their broken \u00b5arch and deliver a cost competitive design instead of competing against 160mm\\^2 of silicon vs +270mm\\^2 on the same process node. Battlemage vs Ada Lovelace is as bad as the 1080 vs Vega 64 and I really hope they can close the gap with Celestial dGPU on 18A.\n\nYeah laptops is just atrocious ATM.\n\nIt's going to happen I think. NVIDIA is already threatened enough to open NVLINK up to competitors. They know the AI ASIC ship has sailed long ago. \n\nIf only we could see the same thing for dGPU market with a viable chinese cookie cutter GPU sold at a very low price completeloy flooding the global market for entry and budget discrete GPUs, and later midrange as well. Basically eat NVIDIA's entire prebuilt cake while pissing them off in the process xD\n\nFingers crossed. This NVIDIA monopoly and AMD NVIDIA duopoly BS has to end.",
                                  "score": 1,
                                  "created_utc": 1748181494.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu3364t",
                      "author": "Mithrawndo",
                      "body": "Isn't the answer right there? Because the buyer can't justify that extra \u00a350, because they only play esports games.\n\nAs you say it's \u00a350 more for someone who wants 16GB; As consumers that's us having our cake and eating it too.",
                      "score": 6,
                      "created_utc": 1748128077.0,
                      "replies": [
                        {
                          "id": "mu50gm4",
                          "author": "Eruannster",
                          "body": "Right, I guess if you only ever intend to play esports titles or older games it's fine, but I'm assuming that you'd maybe at least buy one or two occasional new (or new-ish) games over the next couple of years at which point you're very likely going to run into issues with 8 GB VRAM.",
                          "score": 2,
                          "created_utc": 1748160050.0,
                          "replies": [
                            {
                              "id": "mu5jpkk",
                              "author": "MrMPFR",
                              "body": "...unless you turn down graphics settings significantly and only use 1080p. But having to contend with that in 2025 on a $299-379 product when the 1060 6GB had no trouble with 1080p high 60FPS in 2016 is completely unacceptable.",
                              "score": 0,
                              "created_utc": 1748171553.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mu5iv0k",
                          "author": "MrMPFR",
                          "body": "No one playing eSports is going to buy this card. If AMD thinks they'll sell tons of 9060XT 8GB's to eSports gamers then they're completely clueless.\n\nThat consumer is just going to get a cheap NVIDIA prebuilt instead.",
                          "score": 2,
                          "created_utc": 1748171106.0,
                          "replies": [
                            {
                              "id": "mu5kx3u",
                              "author": "Mithrawndo",
                              "body": "You and I live in very different worlds: In my world, the consumer unwilling to spend \u00a350 to double their VRAM isn't going to spend another \u00a3400 on a motherboard, CPU, RAM, power supply, storage, and case to double their VRAM to get a GPU bundled with it for \u00a3350. *That* consumer already probably runs a laptop.\n\nThey're going to spend the bare minimum and put it into their existing rig - and there's no contention that they're going to sell *tons* of these, only that they'll sell *some*.",
                              "score": 0,
                              "created_utc": 1748172177.0,
                              "replies": [
                                {
                                  "id": "mu68csh",
                                  "author": "MrMPFR",
                                  "body": "The bare minimum card for dGPU slot in upgrade crowd is probably a used GPU, a 1650 tier product like the RTX 3050 6GB or an upcoming RTX 5050, not a $299 dGPU, which in reality with markups, taxes and tariffs will be a lot higher. But sure AMD will sell their 8GB stock eventually at a discounted price.",
                                  "score": 0,
                                  "created_utc": 1748181727.0,
                                  "replies": [
                                    {
                                      "id": "mu7x7u7",
                                      "author": "Mithrawndo",
                                      "body": "I'm certainly on board with saying a used GPU would be a better purchase - every GPU I've owned over the last 20 years has been - but there's a *very* large segment out there that isn't comfortable one way or another with buying second hand.",
                                      "score": 1,
                                      "created_utc": 1748200349.0,
                                      "replies": [
                                        {
                                          "id": "mu8bkw3",
                                          "author": "MrMPFR",
                                          "body": "Indeed. Have seen this firsthand. The majority of people just don't like to bother with second hand and the increased uncertainty even if the deals are insane sometimes.",
                                          "score": 1,
                                          "created_utc": 1748204928.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu4c3fa",
                      "author": "me6675",
                      "body": "Indie games usually don't even require a quarter of that 8GB.",
                      "score": 3,
                      "created_utc": 1748146369.0,
                      "replies": [
                        {
                          "id": "mu50mzw",
                          "author": "Eruannster",
                          "body": "I mean, sure. If you only ever intend to play indie games or esports titles it's probably fine. But I'm assuming that most people will, at some point, play maybe one or two new (or new-ish) games over the lifetime of this card and they will almost certainly run into VRAM-related issues.",
                          "score": 1,
                          "created_utc": 1748160159.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu5jwvq",
                      "author": "IIlIIlIIlIlIIlIIlIIl",
                      "body": "I play pretty demanding new games at 1080p and get ~90FPS (that's my personal sweet spot) on mostly very high to high using a 2070 Super with 8GB VRAM. The games that do push it to the limit (of course they exist) can be brought down by tweaking some basic settings. The GPU is on its last legs but only because of processing power, not VRAM.\n\nNot saying the AMD card is a good deal, but the idea that 8GB is not acceptable in 2025 isn't true. Most people are on 8GB.",
                      "score": 2,
                      "created_utc": 1748171660.0,
                      "replies": [
                        {
                          "id": "mu5k9jb",
                          "author": "Eruannster",
                          "body": "Still, that card is six years old. By now they should have upped the amount of VRAM even on the lower end cards.",
                          "score": 1,
                          "created_utc": 1748171841.0,
                          "replies": [
                            {
                              "id": "mu5s5zm",
                              "author": "IIlIIlIIlIlIIlIIlIIl",
                              "body": "And the amount of RAM on PCs hasn't gone up in about 10 years; high end gaming rigs are still running 16 or 32GB. That hasn't gone up because it hasn't been necessary. It doesn't mean anything that it's been X amount of years without number going up.\n\nLike AMD said: They wouldn't build it if there wasn't a market for it. 8GB has been and is still perfectly doable for 1080p. In 5 years maybe not, but then again a X50 or X60 series card won't last you 5 years anyway.",
                              "score": 2,
                              "created_utc": 1748175608.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu29wwz",
                      "author": "Zilox",
                      "body": "The ps5 has 8gb vram. It has 12gb of free that is uses by both cpu and gpu lmao",
                      "score": 0,
                      "created_utc": 1748117637.0,
                      "replies": [
                        {
                          "id": "mu2g23h",
                          "author": "Eruannster",
                          "body": "Incorrect. The consoles don\u2019t have dedicated VRAM at all. The PS5 has 16 GB shared RAM that can be used by CPU and GPU (so RAM and VRAM). Around ~3 GB of those 16 is reserved by the system, but the rest of it is free to be used as developers prefer.\n\nI suppose some games do use 8 GB of those ~13 GB as VRAM, but it\u2019s entirely possible to do 9+4, 10+3 or 11+2 or whatever works for a particular game.",
                          "score": 3,
                          "created_utc": 1748119714.0,
                          "replies": [
                            {
                              "id": "mu3iwb9",
                              "author": "Zilox",
                              "body": "Its actually 12gb that is free for ram and vram. And 4 ram is used usually by all games",
                              "score": 1,
                              "created_utc": 1748134111.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu2avsk",
                  "author": "darxide23",
                  "body": "You're right, but getting downvoted by people who haven't any idea what they're talking about. At 1080p, 8GB of vram is enough. Barely, but enough. However, that applies to the resolution you're rendering at. Not the resolution you're displaying at. A lot of people on 1080p will see higher vram usage because they've got some supersampling going on and the game is rendering in 1440 or higher and then downsampling to 1080.\n\nOf course this will require more than 8gb of vram, but people are just dumb. They use the \"High\" or \"Ultra\" presets without knowing what they change and what they mean. Yea, those presets will probably use supersampling. Turn it off, dummies, and it will be fine. TXAA is just fine at 1080. You don't need high quality DLSS turned on.\n\nBut with all of that said, an 8gb model of video card shouldn't cost more than $200 these days. It's the budget category, it should be priced as such. This marketing statement from AMD is just bullshit unless they're going to price their 8gb cards for $200.\n\n\nEDIT: I also just feel like adding that the entire cadre of people spouting bs like \"1080p is ugly, how could you play like that?\" just sound like the audiophiles who insist on paying thousands of dollars for a network router that \"conditions the packets\" so the audio sounds crisper when streamed from your media server. It's sheer snobbery. I've played 1080p side-by-side with 1440p and it's often difficult to judge which is which on monitors up to around 30 inches or so. If you have a behemoth monitor bigger than that, then sure. I could probably see the point. Not all of us fart money.",
                  "score": 6,
                  "created_utc": 1748117971.0,
                  "replies": [
                    {
                      "id": "mu2o5s0",
                      "author": "Val_Oraia",
                      "body": "Pretty much agree with you until you said you played 1080p and 1440p side by side and didn't see a difference. I guess you might have been on a 24\"?\n\n1080p is certainly playable especially on 24\", hell I'm happy with my oled steam deck's 800p, ofc it's a much smaller screen.\n\nI did notice a pretty big difference moving from 24\" 1080p to 27\" 1440p though.\n\nIf someone has the extra bucks, it's nice. Otherwise 1080p is perfectly acceptable.\n\nNowadays games made by lazy companies may need more than 8gb even at 1080 tho. There's a lot of unoptimised code, and bugs causing memory leaks, etc. So many games out there using *way* more resources than they should. Wasteful.\n\nI bet the 8gb cards are going to be something stupid like 450$. Maybe even more if tariff go to crazy percentages.",
                      "score": 1,
                      "created_utc": 1748122518.0,
                      "replies": [
                        {
                          "id": "mu5kb86",
                          "author": "IIlIIlIIlIlIIlIIlIIl",
                          "body": ">guess you might have been on a 24\"?\n\nEven on a 24\" it's noticeable unless they're playing from super far away.",
                          "score": 1,
                          "created_utc": 1748171865.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu1hk0g",
                  "author": "Olde94",
                  "body": "From what i\u2019ve seen, it\u2019s more: these don\u2019t have the raw power for these settings anyway. I saw someone trying to make a point yesterday and half of the chart were average fps in the 20\u2019s. Most would lower settings at that point. \n\nI\u2019m saying this as someone who played BG3/Hogwarts on a 6gb 1660ti laptop the last two years on a 1440p screen. My limit was not vram but the fact that i only had playable framerate at low/medium  and even then it was only 45fps.   \n\nI would LOVE to see 16gb on cheap cards, but i think there is SOME truth to it.   \n\nBut it\u2019s still hardly justifiable given price of cards and cost of ram though\u2026.",
                  "score": 3,
                  "created_utc": 1748108162.0,
                  "replies": [
                    {
                      "id": "mu5lzb3",
                      "author": "Kered13",
                      "body": "> these don\u2019t have the raw power for these settings anyway.\n\nThey do though. FPS takes a massive hit when the VRAM limit is hit even when the GPU is not fully utilized, and this can be observed in many games today on 8 GB cards.",
                      "score": 1,
                      "created_utc": 1748172719.0,
                      "replies": [
                        {
                          "id": "mu5pflc",
                          "author": "Olde94",
                          "body": "I was unclear. The 8gb variant were at 8fps. The 16 gb variant of the 60 series card were doing the 24fps. That is why i talk about the cards abilities. A drop from 24 to 8fps is DEVASTATING, but saying the 16gb allows you to run those settings, when the performance is sub 25fps you are at a point where this card would lower settings anyway which then dropped it in to 8gb range if you aimed at 60. \n\nIt\u2019ll be worse in the future though (most likely)",
                          "score": 1,
                          "created_utc": 1748174383.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu298uf",
                      "author": "emodulor",
                      "body": "The RAM we buy for a desktop is slower than the RAM used in video cards, you can't make a direct comparison there",
                      "score": -1,
                      "created_utc": 1748117406.0,
                      "replies": [
                        {
                          "id": "mu29u1w",
                          "author": "Olde94",
                          "body": "I know, but supposedly it\u2019s still gotten cheaper, right",
                          "score": 1,
                          "created_utc": 1748117609.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu26guw",
                  "author": "happy_and_angry",
                  "body": "> Yeah, people love to freak out about statements like these on here but the truth is that most people game on 1080p and 8gb vram is plenty.\n\nMost new games are more than capable of using up 8GB of VRAM at 1080p. I'm sitting at over 9GB in the main menu of Doom: The Dark Ages with the medium preset, as we speak. idTech8 is a pretty well optimized engine and id are notoriously good at optimizations. \n\nI just did the same test with Red Dead Redemption 2, a 7 year old game, and it peaked around 7GB just standing in a field. I hit 7GB in Oblivion Remastered at 1080p inside caves, 10+ outside. Most AAA titles have been listing 16GB as a minimum requirement for a while now, even games like Blue Prince. Claire Obscur says 8GM minimum.\n\nThe article even goes over this a bit. AMD making this statement is a little ridiculous.",
                  "score": 2,
                  "created_utc": 1748116437.0,
                  "replies": []
                },
                {
                  "id": "mu1zkxn",
                  "author": "unematti",
                  "body": "I noticed turning on even minimal ray tracing will push ram so far it maxed out the 8gb. Even at sub 1080p with upscaling 8gb wasn't enough",
                  "score": 1,
                  "created_utc": 1748114039.0,
                  "replies": []
                },
                {
                  "id": "mu19rro",
                  "author": "EncodedNovus",
                  "body": "Not even close for games like marvel rivals, ark, GTA 6 coming up, etc req 12gb in their specs on the store pages to run at at decent fps 120+. Games should be able to run 144fps with 8gb, but the developers cut too many corners nowadays and go for barely 60fps with 8gb",
                  "score": -2,
                  "created_utc": 1748105722.0,
                  "replies": []
                },
                {
                  "id": "mu1a3xx",
                  "author": "Haelphadreous",
                  "body": "Came here to say this, it's actually kind of a shame as well, we don't know exact performance for the 9060 XT 8GB and 9060 8GB cards yet but if they are in the ball park of the 5060 and 5060 Ti 8GB models they have enough processing to run 1440p well in most games, but are already limited to 1080p High/Very High in a few new games by their ram.\n\nI don't understand the people that don't think that's an issue, it's not like games are suddenly going to become significantly more optimized 3 years from now.",
                  "score": -1,
                  "created_utc": 1748105829.0,
                  "replies": []
                },
                {
                  "id": "mu28z22",
                  "author": "Zilox",
                  "body": "8gb is also plenty for 1440p. 12gb is enough for 4k and 16gb is for 8k",
                  "score": -1,
                  "created_utc": 1748117311.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu1qoou",
              "author": "S31Ender",
              "body": "And yet, regularly, my games eat more than 8gb.\n\nSo regardless of what a company with an 8gb model says, reality shows me they are wrong.\n\nI don\u2019t even game in 4k\u2026.",
              "score": 4,
              "created_utc": 1748111078.0,
              "replies": [
                {
                  "id": "mu3duvh",
                  "author": "DrocketX",
                  "body": "Just because it may not need more than 8Gb doesn't necessarily mean that it won't use more than that if it's available. As long as you have extra memory sitting around not being used, your system will frequently just keep old data sitting around in cache just in case it maybe is needed again. Your measurement may show that it's using 12Gb of data or what have you, but a bit chunk of that may be textures that aren't currently being used. Yeah, it slightly improves performance if/when that texture might be used again, but in most cases the different is going to be pretty minor. There's always a trade-off between price and performance, and if the 8Gb version is running perfectly fine, it is rather questionable if it's worth the extra $50 (or whatever it is) to get an extra 2% FPS.",
                  "score": 4,
                  "created_utc": 1748132138.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu0z61x",
              "author": "anirban_dev",
              "body": "You should , slowly this time, read my comment again, and then think about how what you wrote and conclusions you drew about me , relates to that.",
              "score": 2,
              "created_utc": 1748102307.0,
              "replies": [
                {
                  "id": "mu10u7u",
                  "author": "whilst",
                  "body": "I sure don't see what different conclusions they should be drawing!",
                  "score": -8,
                  "created_utc": 1748102841.0,
                  "replies": [
                    {
                      "id": "mu11p1h",
                      "author": "anirban_dev",
                      "body": "Ok so where does my comment say \"what I want to hear\"  and \" my own narrative\" that i'm so convinced about? Or that games won't run anymore on 8GB Vram?",
                      "score": 5,
                      "created_utc": 1748103118.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu11coz",
                  "author": "m0stly_toast",
                  "body": "You should grow some thicker skin and stop acting like the king of reading comprehension because that comment did not make any noteworthy \u201cconclusions about you\u201d",
                  "score": -22,
                  "created_utc": 1748103006.0,
                  "replies": [
                    {
                      "id": "mu11who",
                      "author": "anirban_dev",
                      "body": "the 2nd paragraph seemed almost entirely dedicated to figuring out my inner thoughts.",
                      "score": 7,
                      "created_utc": 1748103183.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu2gkrs",
              "author": "simonbleu",
              "body": "It an be enough - not sure if for every person and every game, let alone for  work which can be more demanding - bu the question is for how long\n\nThat said, the last GPU i bought had 512mb of ram... (9500gt)",
              "score": 1,
              "created_utc": 1748119889.0,
              "replies": []
            },
            {
              "id": "mu5710l",
              "author": "Integeritis",
              "body": "Or maybe games could absolutely use 16 but they are choked by hardware companies. Maybe ask the opinion of a game dev. 8 is not enough.",
              "score": 1,
              "created_utc": 1748164095.0,
              "replies": []
            },
            {
              "id": "mv00qpb",
              "author": "hirscheyyaltern",
              "body": "its not true  \n[https://www.youtube.com/watch?v=IHd95sQ-vWI&t](https://www.youtube.com/watch?v=IHd95sQ-vWI&t)  \nevery year games are needing more and more vram, in 2025 the 1080p experience already forces you to compromise on the majority of aaa releases if you have 8gb vram",
              "score": 1,
              "created_utc": 1748572444.0,
              "replies": []
            },
            {
              "id": "mu1ceka",
              "author": "FourFingersOfFun",
              "body": "This is how I\u2019ve felt about the whole 8gb debacle for a couple years now. \n\nLike it\u2019s almost guaranteed that Nvidia and AMD are tracking various GPU metrics on each customers PC and they can see time and time again that 8gb VRAM is more than sufficient for a majority of customers. Hence why they keep putting only 8gbs of certain tiers of cards",
              "score": 1,
              "created_utc": 1748106552.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu2jdsu",
          "author": "LemurMemer",
          "body": "I\u2019ve had a 2080 Super since 2019 and can tell you I very damn we\u2019ll need more than 8GB of VRAM because games aren\u2019t made by the same wizards we had around in the 5-6th gen of consoles. If my peers in CS classes are anything to go off of, modern game development is so fucking doomed, only passionate part of the industry left is indie games IMO. Games should be made by people who want to make them, not by those that have to make them.",
          "score": 5,
          "created_utc": 1748120842.0,
          "replies": []
        },
        {
          "id": "mu49ovz",
          "author": "2bdb2",
          "body": "A lot of people just want a cheap GPU for casual gaming. That's the target market for this. \n\nMy kids mostly play Minecraft, and an 8gb card will handle that just fine. \n\nJudging by the comments in this thread, it's like half of Reddit can't conceive of somebody just not caring about playing the latest games at 4k.",
          "score": 1,
          "created_utc": 1748145223.0,
          "replies": [
            {
              "id": "mu4k2zy",
              "author": "anirban_dev",
              "body": "Just because a card is the cheapest in its gen doesn't make it objectively cheap. Btw, you should be pissed too. In an ideal world with decent VRAM progression, you would have had a current gen equivalent of 3050 or 6500 that came with 8 GB instead of 6 and sold for 250 or less, which would have worked just fine for your kids.",
              "score": 3,
              "created_utc": 1748150496.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu186q1",
          "author": "tendrils87",
          "body": "You guys have phones don\u2019t you?",
          "score": -1,
          "created_utc": 1748105221.0,
          "replies": []
        },
        {
          "id": "mu1y6eg",
          "author": "unematti",
          "body": "I don't know about that... Lot of big reviewers turned against nvidia.",
          "score": 1,
          "created_utc": 1748113563.0,
          "replies": [
            {
              "id": "mu346q6",
              "author": "FF7Remake_fark",
              "body": "Lots of big reviewers are abandoning integrity and going for ragebait clicks, because that's what the algorithm rewards.\n\nHell, HardwareUnboxed / TechPowerUp are using games that are gpu bound at most resolutions, and games like CS:GO where the FPS is so high it's completely irrelevant, and including that in their overall numbers.  They used to be more trustworthy, but they're doing a LOT of work to exaggerate things instead of focusing on the real problems.",
              "score": -3,
              "created_utc": 1748128455.0,
              "replies": [
                {
                  "id": "mu4nx7m",
                  "author": "unematti",
                  "body": "My experience is that the gpu boundness comes from the ram running at 7.9gb full. It's actually bloody funny, how it can easily run at 50fps (which is enough for me btw. I finished gta vc back in the day playing it at 15 all through...) and then just start doing 1fps for of a minute. Solely due to ram.",
                  "score": 1,
                  "created_utc": 1748152617.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu1977m",
          "author": "HatSimulatorOfficial",
          "body": "Idk man Nvidia also has 8gb cards. I don't think this is a grenade at all. This is just the truth lmao",
          "score": -8,
          "created_utc": 1748105542.0,
          "replies": [
            {
              "id": "mu1ae8q",
              "author": "anirban_dev",
              "body": "The truth is that based on their pricing structure, most gamers can't afford a card with more than 8GB. Spin is to present it like something that is not even required ( which would make their very own 7600 XT from last gen the stupidest product ever, then).  PS3 , 4 and 5 have maintained a similar pricing structure while targeting higher resolutions, for comparison.",
              "score": 15,
              "created_utc": 1748105920.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mu0ibm9",
      "author": "DigitallyDetained",
      "body": "I know this has caused outrage, but wouldn\u2019t this be true for a card that is aimed at 1080p gaming?",
      "score": 453,
      "created_utc": 1748097002.0,
      "replies": [
        {
          "id": "mu0iyva",
          "author": "iamonelegend",
          "body": "Yes, but it doesn't mesh well with any kind of future proofing. Especially with big games like GTA 6 on the horizon, who wants a GPU that might struggle in a year on the most popular game in the world? (This is mostly speculation, though. I don't think recommended specs for GTA 6 have been published yet) It wasn't that long ago where spending anything over $250 would get you a graphics card that would last you half a decade or more at solid settings.",
          "score": 238,
          "created_utc": 1748097210.0,
          "replies": [
            {
              "id": "mu0usof",
              "author": "stogie-bear",
              "body": "I don\u2019t think that future proofing goes with cards where the GPU chip itself is really for 1080p. If the future games would require more than 8gb for 1080, they\u2019d probably also need more GPU.\u00a0\n\nI\u2019m instead going to say that, conversely, the popularity of less expensive gpus APU devices like Steam Decks and Allys gives the game companies an incentive to keep low graphics modes alive and do more optimization that benefits\u00a0",
              "score": 26,
              "created_utc": 1748100934.0,
              "replies": [
                {
                  "id": "mu29948",
                  "author": "dastardly740",
                  "body": "That is the thing. The issue isn't that most gamers don't need 8gb. It is that given the capabilities of that GPU, gamers shouldn't be playing at quality and resolutions where having 8gb would be a problem. For example, at 1440p max quality, the 8gb is crippled, but the 16gb barely averages 40fps and has 20fps 1% lows. Playable? Perhaps. But, you probably end up playing 1080p high quality to get up towards 80fps or so, which the 8gb version handles fine.\n\nAs for future proofing, the GPU would still be a problem.\n\nIf the GPU can push 100fps at 1440p max quality with 16gb VRAM, it is that kind of GPU and an 8gb version makes no sense.\n\nWe can argue about pricing. Like is a 1080p GPU with 8gb VRAM for $299 the right price? I kind of think $279 would get rid of the criticism.",
                  "score": 1,
                  "created_utc": 1748117408.0,
                  "replies": [
                    {
                      "id": "mu2h1y4",
                      "author": "stogie-bear",
                      "body": "If the prices are US post-tariff I guess it makes sense. I\u2019d expect the 8gb to be in the same bracket as the 7600 8gb but if it\u2019s tariffed that might not be feasible.\u00a0",
                      "score": 1,
                      "created_utc": 1748120048.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0kjhn",
              "author": "ricktor67",
              "body": "Yeah but then companies realized pc gamers are dumb and loaded with money and started charging $1500+ for a video card. Now some are pushing $2500+ and people still buy them by the truckload. The price increase will continue until people stop buying.",
              "score": 98,
              "created_utc": 1748097709.0,
              "replies": [
                {
                  "id": "mu0lewx",
                  "author": "Air5uru",
                  "body": "Meanwhile, some of us are rocking a 5600XT from 5 years ago.",
                  "score": 36,
                  "created_utc": 1748097988.0,
                  "replies": [
                    {
                      "id": "mu0m2nc",
                      "author": "TheUltraSonicGamer",
                      "body": "Same here, still pushing my 5700XT I got for like $400 in late 2019!",
                      "score": 19,
                      "created_utc": 1748098199.0,
                      "replies": [
                        {
                          "id": "mu0mg9c",
                          "author": "Universe_Nut",
                          "body": "My rx480 says hello",
                          "score": 15,
                          "created_utc": 1748098320.0,
                          "replies": [
                            {
                              "id": "mu0oim8",
                              "author": "quakeholio",
                              "body": "1060 been on the job from 2017 or so.",
                              "score": 12,
                              "created_utc": 1748098967.0,
                              "replies": [
                                {
                                  "id": "mu0p14z",
                                  "author": "martiHUN",
                                  "body": "My 4GB RX 460 is the same... \n\n...I should really replace that junk.",
                                  "score": 6,
                                  "created_utc": 1748099128.0,
                                  "replies": [
                                    {
                                      "id": "mu0qliy",
                                      "author": "ilikedatunahere",
                                      "body": "My 8GB RX 570 said sup",
                                      "score": 2,
                                      "created_utc": 1748099620.0,
                                      "replies": [
                                        {
                                          "id": "mu0t0eo",
                                          "author": "Jacek3k",
                                          "body": "4gb 1050ti. Still cant justify upgrade, the current prices are unacceptable.",
                                          "score": 9,
                                          "created_utc": 1748100373.0,
                                          "replies": [
                                            {
                                              "id": "mu0u83q",
                                              "author": "ilikedatunahere",
                                              "body": "I mostly play games on my PS5 or Series X so I definitely can\u2019t justify it. I\u2019d just need a whole new PC tbh. Mine is an old Optiplex with a huge CPU bottleneck running an i7-3770.",
                                              "score": 3,
                                              "created_utc": 1748100755.0,
                                              "replies": [
                                                {
                                                  "id": "mu0ujaz",
                                                  "author": "Jacek3k",
                                                  "body": "Yeah. I play on ps4 and those games that still run on my pc. \n\nI might need total upgrade too, but as I said, cant justify it since everything works for me so far.",
                                                  "score": 3,
                                                  "created_utc": 1748100853.0,
                                                  "replies": []
                                                }
                                              ]
                                            },
                                            {
                                              "id": "mu26xis",
                                              "author": "Deep_Pudding2208",
                                              "body": "My 11th gen i5 and 2gb mx450 says slideshows are better anyways.",
                                              "score": 3,
                                              "created_utc": 1748116600.0,
                                              "replies": []
                                            }
                                          ]
                                        },
                                        {
                                          "id": "mu15xjn",
                                          "author": "csaw79",
                                          "body": "Still rocking my 580 I got in 2020",
                                          "score": 1,
                                          "created_utc": 1748104493.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                },
                                {
                                  "id": "mu5ksju",
                                  "author": "MrMPFR",
                                  "body": "Black Friday 1060 6GB from 2017 and a I7-2600K.",
                                  "score": 1,
                                  "created_utc": 1748172112.0,
                                  "replies": []
                                },
                                {
                                  "id": "mu2x8tm",
                                  "author": "OnTheGoatBoat",
                                  "body": "960 gtx reporting in never had any problems",
                                  "score": 1,
                                  "created_utc": 1748125849.0,
                                  "replies": []
                                }
                              ]
                            },
                            {
                              "id": "mu0u3mn",
                              "author": "KnightFan2019",
                              "body": "Hello rx480",
                              "score": 2,
                              "created_utc": 1748100716.0,
                              "replies": []
                            },
                            {
                              "id": "mu0od5r",
                              "author": "SuperMafia",
                              "body": "My secondhand RTX 3060 says \"hola\"",
                              "score": 3,
                              "created_utc": 1748098920.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mu0ofen",
                          "author": "TheUmgawa",
                          "body": "I bought mine the day before Covid lockdown, and it\u2019s still working!",
                          "score": 2,
                          "created_utc": 1748098939.0,
                          "replies": []
                        },
                        {
                          "id": "mu0v8i2",
                          "author": "chr0nicpirate",
                          "body": "I had a 5700 in the first gaming PC I ever built.. except it was gforce 5700 and in 2004. Pretty sure it was right around $200.",
                          "score": 1,
                          "created_utc": 1748101071.0,
                          "replies": []
                        },
                        {
                          "id": "mu0oayy",
                          "author": "UnsorryCanadian",
                          "body": "I got my 5700XT during christmas of last year for $300. Huge upgrade over the old 760 I used to have",
                          "score": 1,
                          "created_utc": 1748098901.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu0osbg",
                      "author": "D-S-S-R",
                      "body": "1050ti here. It really helps that all I seem to enjoy are 2d indie games",
                      "score": 8,
                      "created_utc": 1748099051.0,
                      "replies": []
                    },
                    {
                      "id": "mu0sml0",
                      "author": "ireadthingsliterally",
                      "body": "2080 TI still going strong over here!",
                      "score": 2,
                      "created_utc": 1748100254.0,
                      "replies": []
                    },
                    {
                      "id": "mu0r16t",
                      "author": "greenknight",
                      "body": "It has got me thru the tough times but, by fuck, I've had nothing but hard crashes if I don't intensively manage my system.\u00a0 Ram-mobo-gfx mismatch in Linux",
                      "score": 1,
                      "created_utc": 1748099758.0,
                      "replies": []
                    },
                    {
                      "id": "mu0wseu",
                      "author": "Shaderu",
                      "body": "Was on a 1070ti until just over a month ago.  I felt that pain lol",
                      "score": 1,
                      "created_utc": 1748101555.0,
                      "replies": []
                    },
                    {
                      "id": "mu10d7a",
                      "author": "ZorakOfThatMagnitude",
                      "body": "Baseline RX7600, here.  Performs better than my 10 year old R390, uses less power, and costs $80 less, inflation not calculated.  Tell me how I'm losing again?",
                      "score": 1,
                      "created_utc": 1748102689.0,
                      "replies": []
                    },
                    {
                      "id": "mu2qlkg",
                      "author": "nightsky77",
                      "body": "I\u2019ve just cleared KCD2 on my 4GB RX580 lol. 45fps is decent enough to play with!",
                      "score": 1,
                      "created_utc": 1748123397.0,
                      "replies": []
                    },
                    {
                      "id": "mu3ojuk",
                      "author": "Zedrackis",
                      "body": "Your not wrong. I got ten years out of my gtx1080 before I upgraded.",
                      "score": 1,
                      "created_utc": 1748136308.0,
                      "replies": []
                    },
                    {
                      "id": "mu0zqn3",
                      "author": "KaiserJustice",
                      "body": "My ass on a gtx 1080ti",
                      "score": 1,
                      "created_utc": 1748102489.0,
                      "replies": []
                    },
                    {
                      "id": "mu173m2",
                      "author": "ricktor67",
                      "body": "RX580! Still runs my VR games just fine.",
                      "score": 1,
                      "created_utc": 1748104871.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0wj6f",
                  "author": "Nope_______",
                  "body": "Yeah that's how it works. People voted with their wallets.",
                  "score": 1,
                  "created_utc": 1748101475.0,
                  "replies": []
                },
                {
                  "id": "mu0z65f",
                  "author": "NecroCannon",
                  "body": "It\u2019s why I switched to PC handhelds for gaming. Yeah they\u2019re weaker, but they\u2019re not going to nickel and dime something they\u2019re wanting to become successful, just what they know what they can get away with.\n\nMac Mini to avoid Windows for daily use, PC handheld like the Steam Deck, or maybe in the future being able to get one and load it up with SteamOS",
                  "score": 1,
                  "created_utc": 1748102308.0,
                  "replies": [
                    {
                      "id": "mu12oda",
                      "author": "SScorpio",
                      "body": "AMD Mini PCs also make a great option. The ones with 780M graphics match the specs of the Z1E handhelds, but aren't power constrained and feature upgradable RAM and storage.\n\nMost have at least dual m.2 slots so you could easily dual boot Steam OS for gaming, and whatever you want for daily driving.",
                      "score": 2,
                      "created_utc": 1748103435.0,
                      "replies": [
                        {
                          "id": "mu1boky",
                          "author": "NecroCannon",
                          "body": "Yeah I looked into that and just prefer MacOS to daily\n\nStill though, awesome things are progressing like this",
                          "score": 2,
                          "created_utc": 1748106324.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu0uqz2",
                  "author": "SmoopsMcSwiggens",
                  "body": "I'm not really understanding your point here.the  original Titan was $1000 and it's follow up was $3000. That was 2013. This is hardly a new trend.",
                  "score": -2,
                  "created_utc": 1748100920.0,
                  "replies": [
                    {
                      "id": "mu1m1xb",
                      "author": "beirch",
                      "body": "Mid range GPUs in 2004 were $500-600 adjusted for inflation. People just got used to cheap cards from 2009 to 2017.\n\nAlthough I will admit $2-3000 enthusiast cards were never a trend like it has become with the last three generations. Nvidia made special run cards like the Titan, that were meant for super enthusiasts. \n\nThey never made $2000-3000 cards as the best card in their consumer lineup, i.e. the 80 Ti or 90s.",
                      "score": 2,
                      "created_utc": 1748109573.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0nfuo",
                  "author": "HakimeHomewreckru",
                  "body": "MSRP for even the 5090 is still just 1999 USD. And I believe a majority of those who buy them aren't gamers but professionals.",
                  "score": -7,
                  "created_utc": 1748098632.0,
                  "replies": [
                    {
                      "id": "mu0ql8r",
                      "author": "mastercxxi",
                      "body": "MSRP means nothing, it may as well be $15, they\u2019re charging $3000+ for 5090s.  A good chunk of professionals spending that kind of money will buy professional cards(Quadro, A series, etc), not 5090s",
                      "score": 8,
                      "created_utc": 1748099617.0,
                      "replies": [
                        {
                          "id": "mu19ik0",
                          "author": "HakimeHomewreckru",
                          "body": "5090s and 4090s are faster than any quadro/A card out there, for half the price.\n\n Youre completely clueless if you really believe they're not buying these.",
                          "score": 1,
                          "created_utc": 1748105641.0,
                          "replies": [
                            {
                              "id": "mu1k4tq",
                              "author": "mastercxxi",
                              "body": "RTX Pro 6000 is faster than a 5090 and has 3x the RAM.  If they\u2019re spending $3000 on a card they might as well spend $6000 to get 10% faster and much more RAM, it pays for itself in the time saved alone.\n\nhttps://www.tomshardware.com/pc-components/gpus/rtx-pro-6000-blackwell-tested-performs-roughly-10-15-percent-faster-than-a-stock-rtx-5090",
                              "score": 1,
                              "created_utc": 1748108971.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0p6aa",
              "author": "RiftHunter4",
              "body": ">It wasn't that long ago where spending anything over $250 would get you a graphics card that would last you half a decade or more at solid settings.\n\nNot that I recall. I had a 960 and it struggled way more than my $2060 did and the 2060 was older by the time I bought it.",
              "score": 7,
              "created_utc": 1748099174.0,
              "replies": [
                {
                  "id": "mu0pzfn",
                  "author": "iamonelegend",
                  "body": "I think the 90 series was one that didn't age as well as most folks had hoped. I remember having a 70 series card around then, and seeing people with the 90 series cards saying that they wish they had waited for the 10 series.",
                  "score": 4,
                  "created_utc": 1748099427.0,
                  "replies": [
                    {
                      "id": "mu11ao5",
                      "author": "RiftHunter4",
                      "body": "Back with my 960 or the 750 before it, I wasn't able to play anything on max settings. Prior to the 10 series, a GPU was a requirement to play at all. You have to drop big money to play on max settings, and people were running dual and quad Titan SLI setups, way more than what we pay for a 5090 or 5080 even without inflation. I don't miss the past at all I  terms of GPU's. We bought games assuming we'd play on max settings in 3 to 4 years when better GPU's came out.",
                      "score": 1,
                      "created_utc": 1748102988.0,
                      "replies": [
                        {
                          "id": "mu4fglw",
                          "author": "Dt2_0",
                          "body": "Yea, nowadays AMD laptops come with a iGPU that is actually decent for lighter games at 1080p if you don't mind turning down som settings (MMOs, emulation, games older than about 2020 for the most part). Things are actually really good now for the casual gamer. Yes, us enthusiasts (especially people like me into SFF) are having trouble, but we aren't the target market. The target market is Dell, HP, Cyberpower, etc.",
                          "score": 2,
                          "created_utc": 1748148052.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu19hkr",
                      "author": "fullmetaljackass",
                      "body": "Yep, that was me. My 980ti was a real champ, but in hindsight I definitely wish I'd waited a few more months on that build.",
                      "score": 1,
                      "created_utc": 1748105632.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu11n9o",
              "author": "IvaNoxx",
              "body": "not everyone is playing newest games. there are a lot of people who play low - end games",
              "score": 11,
              "created_utc": 1748103101.0,
              "replies": [
                {
                  "id": "mu1iux9",
                  "author": "Xendrus",
                  "body": "Then you don't need to buy a new gpu? Grab a used 3-4 gen old off facebook marketplace, the new gpu market isn't for you, unless you want to waste money on low end stuff",
                  "score": 3,
                  "created_utc": 1748108572.0,
                  "replies": [
                    {
                      "id": "mu2mq82",
                      "author": "dark_sable_dev",
                      "body": "The people we're talking about are going to be buying prebuilt computers with these or 5060s in them. Or their parents will be buying them, more likely.\n\n\nYou have to remember that as much as *we* know prebuilts are terrible, the average consumer will never, never consider building their own PC. That's just the way of the world.",
                      "score": 8,
                      "created_utc": 1748122010.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu18hs3",
                  "author": "tribe171",
                  "body": "Yep. We have been accumulating worthwhile games for decades now. Even if I never played a game released after 2024, there would still be too many games to play in a lifetime.",
                  "score": 1,
                  "created_utc": 1748105319.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu1iruo",
              "author": "Xendrus",
              "body": "I thought GTA 6 wouldn't be on PC? At least not for a year?",
              "score": 3,
              "created_utc": 1748108545.0,
              "replies": [
                {
                  "id": "mu5lkoo",
                  "author": "MrMPFR",
                  "body": "It's not even on console until another year from now.",
                  "score": 1,
                  "created_utc": 1748172515.0,
                  "replies": [
                    {
                      "id": "mu71yqv",
                      "author": "Xendrus",
                      "body": "I meant post release on consoles, it then has another year to go before the PC release.",
                      "score": 1,
                      "created_utc": 1748190923.0,
                      "replies": [
                        {
                          "id": "mu89pfm",
                          "author": "MrMPFR",
                          "body": "Makes sense. So basically mid to late 2027 for anyone wondering when it'll release on PC.",
                          "score": 1,
                          "created_utc": 1748204324.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0tkv1",
              "author": "DaoFerret",
              "body": "It still has very strong, \u201c640k ought to be enough for anybody\u201d vibes.\n\n(Incorrectly attributed to Bill Gates https://www.computerworld.com/article/1563853/the-640k-quote-won-t-go-away-but-did-gates-really-say-it.html )",
              "score": 10,
              "created_utc": 1748100552.0,
              "replies": []
            },
            {
              "id": "mu28eos",
              "author": "Grimreap32",
              "body": "> Especially with big games like GTA 6 on the horizon, who wants a GPU that might struggle in a year on the most popular game in the world?\n\nGTA 6 won't be on PC for nearly two years. It's console late this year / early next year, and at least 1 year until PC.",
              "score": 4,
              "created_utc": 1748117112.0,
              "replies": [
                {
                  "id": "mu5lh4u",
                  "author": "MrMPFR",
                  "body": "GTA 6 is releasing on console on May 26th 2026, got delayed again :C. PC prob no earlier than mid to late 2027 after Rubin and UDNA has launched.   \nThe only good thing is that when people upgrade by the millions to play GTA VI 24Gb GDDR7 modules will be cheap all new cards will start at 12GB minimum.",
                  "score": 2,
                  "created_utc": 1748172464.0,
                  "replies": [
                    {
                      "id": "mu5putg",
                      "author": "eestionreddit",
                      "body": "the RTX 6060 disagrees",
                      "score": 1,
                      "created_utc": 1748174577.0,
                      "replies": [
                        {
                          "id": "mu6ba1y",
                          "author": "MrMPFR",
                          "body": "3GB GDDR7 will be widely available by 2026-2027, but I guess NVIDIA could be stupid enough to insist on 8GB once again while AMD falls in line to milk their customers and grow margin.",
                          "score": 1,
                          "created_utc": 1748182676.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0lup0",
              "author": "joomla00",
              "body": "Then just pony up the other, very reasonable $50 for 16g?  This just seems like another thing that makes gamers seem super whiney.  I can understand the shit Nvidia is pulling with their 12gb 5070s, or their no performance gain but more ram 5080 (which is really just an hobbyist ai card at this point).  But seems like amd is doing a solid by giving choice.  Between general inflation and prices of wafers getting more expensive, I don't feel like amd is trying to pull one over people here.",
              "score": 13,
              "created_utc": 1748098129.0,
              "replies": [
                {
                  "id": "mu0pivf",
                  "author": "xantec15",
                  "body": ">very reasonable $50 for 16g\n\nWe'll need to wait and see what the retail prices are, but I'll be pleasantly surprised if the 8G and 16G are actually only $50 apart.",
                  "score": 25,
                  "created_utc": 1748099282.0,
                  "replies": []
                },
                {
                  "id": "mu0o4pp",
                  "author": "iamonelegend",
                  "body": "Agreed. I just think telling folks 8GB is fine is the same as telling people the lowest storage option when they get a phone is fine, too. Is it fine in a pinch? Sure. Especially if GPUs start rising in price again. Would I ever recommend an 8GB graphics card to someone in 2025, no way. Isn't there a 3060 out there from 2021 that would be able to go toe to toe with this?",
                  "score": 3,
                  "created_utc": 1748098846.0,
                  "replies": [
                    {
                      "id": "mu11czv",
                      "author": "Pauly_Amorous",
                      "body": "> I just think telling folks 8GB is fine **is the same as telling people the lowest storage option when they get a phone is fine**, too.\n\nThe lowest storage option for my phone was 128gb. I'm not even using 32gb of that. So for *some* people, the lowest storage option is more than adequate.",
                      "score": 9,
                      "created_utc": 1748103009.0,
                      "replies": [
                        {
                          "id": "mu1u9bw",
                          "author": "mxzf",
                          "body": "Yeah, I've had my phone for almost four years, never paid attention to storage, took all the pictures I feel like taking, and I'm sitting at 35/128GB of storage used.  I definitely would have been fine with 64GB instead.",
                          "score": 1,
                          "created_utc": 1748112259.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu0xdnz",
                      "author": "Nope_______",
                      "body": ">Is it fine in a pinch? Sure.\n\nThe people buying these 8 GB cards are in a pinch. That's the reason they make them - for people in a pinch.",
                      "score": 9,
                      "created_utc": 1748101741.0,
                      "replies": []
                    },
                    {
                      "id": "mu0q7rt",
                      "author": "joomla00",
                      "body": "Just read the article.  What he says make sense.  There's a market for it.  I think gamers forget how big this industry is, and how many different types of gamers there are.  For example, you mention one of the next version of one of the most popular games ever is coming out.  I never played any of them for more than a couple of hours, not got into it.   And I've been a gamer for decades.\n\nIf my gf wanted to get into gaming, I might get her an 8gb card just to see if it's a hobby she actually will stick to, and if she even cares about more gfx.",
                      "score": 17,
                      "created_utc": 1748099500.0,
                      "replies": [
                        {
                          "id": "mu0rkkx",
                          "author": "iamonelegend",
                          "body": "I have. I absolutely agree that there's a market for it, but its making a market of folks that will need to upgrade sooner if they stay in the hobby. Right now, a Core i3 PC with 8GB of RAM and a GFX card with 8GB of RAM can game just fine, but it'll show its age by the end of the year.",
                          "score": -2,
                          "created_utc": 1748099923.0,
                          "replies": [
                            {
                              "id": "mu0sb1q",
                              "author": "joomla00",
                              "body": "It's wierd to be complain when you're offered reasonable choices.  It kinda sounds like you're saying gamers are too stupid to make a good choice for themselves.",
                              "score": 5,
                              "created_utc": 1748100153.0,
                              "replies": [
                                {
                                  "id": "mu0t4oz",
                                  "author": "iamonelegend",
                                  "body": "Not at all, I think folks should chose whatever works for them. I just don't believe what AMD is saying.",
                                  "score": 1,
                                  "created_utc": 1748100411.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "mu0wf0v",
                          "author": "mertats",
                          "body": "Your argument is that this would not be enough for vast majority of people but I am not in that vast majority so it is fine?",
                          "score": -5,
                          "created_utc": 1748101438.0,
                          "replies": [
                            {
                              "id": "mu0xmlz",
                              "author": "joomla00",
                              "body": "What?",
                              "score": 2,
                              "created_utc": 1748101818.0,
                              "replies": [
                                {
                                  "id": "mu0z0g4",
                                  "author": "mertats",
                                  "body": "Claim is most gamers don\u2019t need more than 8GB of VRAM which is patently false. \n\nMost gamers need or will need more than 8GB of VRAM. You being one of those that will not need 8GB doesn\u2019t make that statement false. You are in the minority.",
                                  "score": -4,
                                  "created_utc": 1748102258.0,
                                  "replies": [
                                    {
                                      "id": "mu10l6s",
                                      "author": "joomla00",
                                      "body": "Well first I never said I only need 8gb.  If I bought a card for myself I would get at least 16.  \n\nSecond what frank says is *probably* true.  More people game on handhelds, igpus, and 1650 ti's apparently than the rest of the discrete market.  I know for a lot of you gaming is life, but there are more people out there that play games and just don't care that much about gfx.",
                                      "score": 6,
                                      "created_utc": 1748102760.0,
                                      "replies": [
                                        {
                                          "id": "mu13cp3",
                                          "author": "mertats",
                                          "body": "Why would someone get this card when upgrading from 1650ti? A card that is going to obsolete in a few years. \n\nAll the chips that have gone into this card could have gone to 16GB versions, and we wouldn\u2019t have to battle with limited supplies and pay way over MSRP. \n\nIt is clear that this card is there to nickel and dime people that have 0 clue, and they made this statement to re-assure those people that they \u201conly\u201d need 8GB.\n\nEdit:\n\nAlso no, more people are not playing on 1650s and igpus than the rest of the discrete market. Anyone playing on handhelds already don\u2019t need this card.",
                                          "score": -2,
                                          "created_utc": 1748103656.0,
                                          "replies": [
                                            {
                                              "id": "mu14i43",
                                              "author": "joomla00",
                                              "body": "By your standards a 1650 is already obsolete with it's 2-4gb.  But somehow all those people are magically still gaming on it.\n\nNow you're saying gamers are too dumb to make gaming choices for themselves?",
                                              "score": 2,
                                              "created_utc": 1748104028.0,
                                              "replies": [
                                                {
                                                  "id": "mu15lwn",
                                                  "author": "mertats",
                                                  "body": "Those cards are obsolete, they don\u2019t have enough VRAM to play most upcoming AAA games. \n\nYou are missing the fact that those cards are not new. They were perfectly fine cards for their time, and people still can use whatever cards they already got. \n\nThis card however is not fine for its time.",
                                                  "score": 1,
                                                  "created_utc": 1748104388.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu0vax0",
                      "author": "NorysStorys",
                      "body": "I\u2019m still running a 3070 and the only problem it has is the 8gb of vram. It\u2019s more than good enough otherwise.",
                      "score": 1,
                      "created_utc": 1748101092.0,
                      "replies": []
                    },
                    {
                      "id": "mu0vkci",
                      "author": "stogie-bear",
                      "body": "I use 67gb of my phone storage and 6gb of my vram. I think it\u2019s okay for these options to exist, and that there are plenty of people out there who want something that will play Minecraft or Roblox on their 1080 screen.\u00a0",
                      "score": 1,
                      "created_utc": 1748101175.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0q1rb",
                  "author": "ArchusKanzaki",
                  "body": "One thing to note, Nvidia is using GDDR7 for its memory which is rather cutting-edge so it is more justifiable for the chips to be expensive.\n\nAMD is using GDDR6 for its memory. The same being used by 5700XT.... more than 5 years ago. That thing is cheap now. Needing to pay for 50$ for those are just shitty.",
                  "score": 1,
                  "created_utc": 1748099448.0,
                  "replies": [
                    {
                      "id": "mu0rie6",
                      "author": "joomla00",
                      "body": "Nah Nvidia has been pulling this shit for years now.  They're obviously gatekeeping and unfutureproofing their higher end cards by limiting ram.  Don't forget the 10gb 3080, then the 12gb 4080 that turned into a 4070ti",
                      "score": 2,
                      "created_utc": 1748099904.0,
                      "replies": [
                        {
                          "id": "mu0smap",
                          "author": "ArchusKanzaki",
                          "body": "I\u2019m talking less about Nvidia\u2019s shit, but rather AMD being more or less complacent on only being slightly less-shitty than Nvidia. But I guess that\u2019s the state of GPU market right now. \n\nAt least AMD are probably not withholding review drivers from media\u2026. But will be curious if they will be sending 8GB version of the card to the media. Just like 5060 are being embarrassed on titles like Indiana Jones, same thing probably will happen to this too.",
                          "score": 1,
                          "created_utc": 1748100252.0,
                          "replies": [
                            {
                              "id": "mu0ufey",
                              "author": "joomla00",
                              "body": "Bruh they got the 16gb for $50 more.  Neither of us have insight into their costs, but $250 for an 8gb card, considering inflation and wafer costs doesn't sound like a scam.  I guess they could've only sold the 16gb for like 275, but I don't really see an issue with the direction they took.",
                              "score": 1,
                              "created_utc": 1748100819.0,
                              "replies": [
                                {
                                  "id": "mu0vevz",
                                  "author": "ArchusKanzaki",
                                  "body": "250 and 300 is their \u201cMSRP\u201d. They are not producing any reference design so it will easily balloon way past that. Even a 290$ for 8GB version which is only 40$ above MSRP\u2026. will face a challenge from Intel B580 that have aftermarket cards at same price. And AMD better pray that their cards will at least perform better than B580 or else reviews will be pretty scathing.",
                                  "score": 1,
                                  "created_utc": 1748101127.0,
                                  "replies": [
                                    {
                                      "id": "mu0w361",
                                      "author": "joomla00",
                                      "body": "Then.... buy Intel?  Competition is cool like that.",
                                      "score": 1,
                                      "created_utc": 1748101337.0,
                                      "replies": [
                                        {
                                          "id": "mu145l0",
                                          "author": "SScorpio",
                                          "body": "The 9600XT will likely be 10-12% faster than the B580. But Intel's been a decent job with B580s near MSRP getting weekly drops.\n\n$259 for a 12GB card where the supply issues AMD has been having with their higher end cards could mean a $400+ price on the 9600XT for ones people can actually buy.\n\nHopefully Intel can also release B700 series cards. The uplift from the A500s to B500s has been great. If they can have something great in the $500 range it will really shake things up. AMD has just put out a card for slightly less than the NVIDIA card that performs 5% better but is missing advanced features makes everyone just buy NVIDIA instead. Both AMD and NVIDIA need a good kick in the ass to be competitive again. The last time NVIDIA was worried they released the 1080ti for $700, but AMD as usual failed to deliver on the rumored performance.",
                                          "score": 1,
                                          "created_utc": 1748103915.0,
                                          "replies": [
                                            {
                                              "id": "mu156td",
                                              "author": "joomla00",
                                              "body": "I agree Intel is the jolt the industry needed.  Now we just need customers to actually buy Intel, instead of hoping Intel will cause prices to fall, just so they can buy Nvidia for cheaper.",
                                              "score": 1,
                                              "created_utc": 1748104250.0,
                                              "replies": [
                                                {
                                                  "id": "mu19qib",
                                                  "author": "SScorpio",
                                                  "body": "So far the stock Intel is able to supply is being bought up. Hopefully that continues.",
                                                  "score": 2,
                                                  "created_utc": 1748105711.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        },
                                        {
                                          "id": "mu129by",
                                          "author": "ArchusKanzaki",
                                          "body": "So.... because other competition now exist, we should not care about AMD then? What kind of response is that?\n\nAlso, I will be correcting you. Its 300$ MSRP for the 8GB version and 350$ MSRP for 16GB version. [Link for article.](https://www.gamespot.com/articles/amds-new-rx-9060-xt-graphics-card-will-launch-in-8gb-and-16gb-vram-versions/1100-6531802/)",
                                          "score": -2,
                                          "created_utc": 1748103300.0,
                                          "replies": [
                                            {
                                              "id": "mu13t27",
                                              "author": "joomla00",
                                              "body": "I don't understand.  You care that they might be making a poor business decision?",
                                              "score": 2,
                                              "created_utc": 1748103802.0,
                                              "replies": []
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mu5e6rt",
                      "author": "nipsen",
                      "body": "..I mean.. gddr ram (that operates towards a smaller and incomparably much faster cache hub. Which basically makes the vram a glorified SSD) has always been about cost cutting.\n\nIt's been decades since ram was a noticeable part of the production cost. Gddr6 and 7 also use standard modules so that the same ram block can be fused on different card models.\n\nSo what they're doing is to save pennies on using old gddr blocks of ram that have been in storage for several years, and sold to them for cheap.\n\nBut at the same time.. there is really no reason why a graphics card should need gigantic amounts of Ram, given that you are not storing texture packs for the entire game in the SSD on the graphics card to begin with. \n\nThis is a weasel sales-pitch to take crazy amounts of money for an average graphics card - but it is also true that the active(as in it is retrieved actively) amount of used \"vram\" for a graphics context in even 4k rarely exceeds 6Gb. If you further define \"active graphics context\" as the resources used that could not be retrieved from system ram instead because of time restraints, we are talking about maybe 500Mb at the very highest.\n\nOf course, adding cuda routines that only operate on vram through the bus logic on the graphics card might put the requirement higher, with dlss and so on. \n\nBut without that.. having 16Gb or 8Gb extra storage of really fairly slow, one-directional ram with abysmal write speed.. is not that interesting or useful.\n\nIn fact, even Nvidias driver automatically allocates system ram for storing texture information. Both major consoles now use SSDs at the pcie port for storing texture packs. \n\nSo to proclaim that 16Gb plus of the kind of ram we have on graphics cards is necessary is, you know, false. Even if your requirement was optimal speed - it is actually the case that the ram interface on the graphics card is not that fast compared to the pcie interface. Which in turn is not really that fast anyway. It's just faster than needed, when compared to retrieving static resources from gddr blocks.",
                      "score": 1,
                      "created_utc": 1748168492.0,
                      "replies": [
                        {
                          "id": "mu5frac",
                          "author": "ArchusKanzaki",
                          "body": "I think the point is this. If its truly \"pennies\", why not just upgrade it and only sell 1 SKU at competitive price? And if it's truly unnecessary, why we see actual performance reduction in some games like Indiana Jones that is truly caused by VRAM exhaustion? Ppl rag on Apple before for only using 8GB for Unified Memory in Mac, or only having 64GB for base tier in Iphone, because its truly penny-pinching and margin-maxxing and to also maintain a pricr ladder. Why we should give AMD (or Nvidia) a pass here?",
                          "score": 1,
                          "created_utc": 1748169411.0,
                          "replies": [
                            {
                              "id": "mu5lhmj",
                              "author": "nipsen",
                              "body": ">I think the point is this. If its truly \"pennies\", why not just upgrade it and only sell 1 SKU at competitive price?\n\nBecause the \"it's been in storage, no one wants this\" discount is maybe 50 usd per unit. Production cost per memory block is of course higher per Gb for these smaller units, but the production cost more holistically is incredibly low. So had they planned for production of new memory modules in advance, in bulk, the actual \"to-sales\" cost might very well have been lower. It is a weasel sales-move, like pointed out. They're just shifting ram that the factory and distributor are afraid will not be sold at all. So bad planning coupled with weasel salespeople is the reason they're not just selling a bigger gddr block on the exact same unit, indeed for a much more competitive price. They know the market is completely ridiculous, and they are simply making these choices as a consequence of that. And those choices are not reasonable from a technological or production-cost perspective. But they are sound as a marketing move for a sales-person.\n\n>And if it's truly unnecessary, why we see actual performance reduction in some games like Indiana Jones that is truly caused by VRAM exhaustion?\n\nThat's a completely meaningless term. But the reason is that this game, like many UE games, are constantly fetching world resources above a certain minimum limit, regardless of whether they're actually needed or not. And then they will continue to exhaust the available amount of ram if possible. You can configure that in UE, but most just don't really bother.\n\nThe effect in Indiana Jones (which is not really that common, just to point that out - most developers are completely aware of how silly it is to set it up like that) is that once you get past 16Gb, the algorithms stop using shared system ram as resource backup (even if the shared vram pool is allocated as default). And that avoids having to saturate the pci-e bus with memory transfers from this very badly set up prefetch. So it's not that the size of the ram helps with speedily generating information - it's that a slower, badly set up ddr4 system, or a not really that fantastically clocked main system is able to offload the badly optimised prefetch system to only halt the graphics card memory bus instead of both the main memory bus and the pci-e bus.\n\n(...)",
                              "score": 1,
                              "created_utc": 1748172471.0,
                              "replies": [
                                {
                                  "id": "mu5lmca",
                                  "author": "nipsen",
                                  "body": "\n\n>Why we should give AMD (or Nvidia) a pass here?\n\nWe obviously shouldn't. But the problem is that the AMD guy is also right: if you look at how games typically use \"vram\" (which now really is a glorified SSD, as explained) it's a completely reasonable solution to just ditch it altogether. Because we don't have algorithms even on machine instruction level that actually address vram directly. Even if you use direct vram references in code now, that's translated by the driver to some ram-storage that may very well be in system ram rather than on the graphics card.\n\nIt's completely hilarious once you actually look at it, because the thing is that even if you only used the vram storage on the graphics card -- modern games will be designed to have passes that often require some kind of status-fetch or a resource consistency check in main ram before doing the actual operation. So because of the way the graphics card memory bus operates - basically all cards used for gaming (and that don't have specific CUDA instructions on them, that are literally the only way to get hardware-pointers into code after it's been compiled nowadays) could just as well replace the vram with better and not to mention much faster system ram. \n\nBeyond that - just ditching the pci-e bus, at long last, and getting some asynchronous read and writes in instead would of course be the obvious choice. \n\nNote that on ARM, the size of the external ram-modules is also used as storage in this sense. The \"16Gb\" on iPhone basically refers to an ssd. While the closer instruction-level memory is a different model, and has extremely little to do with system operation ram. \n\nAnd that's again very different from how the ddr-ram bus, the pci-e bus and the vram model was desgined to begin with. Which is just on another level when it comes to slowness, where each element here, the cpu, gpu and ddr-ram all operate towards a bus that literally was designed in the 90s. It's .. incredibly outdated now. With the weirdness coming in where a pci-e ssd literally is faster than the main ram today. While having external storage that would be faster than main memory in the 90s would be laughable. Right..? But that's how that system has aged.\n\nAnd adding more \"ssd-storage\" on the graphics card in that sense doesn't matter. It's not doing anything for us on a better configured system, even when keeping the now ancient pci bus..",
                                  "score": 1,
                                  "created_utc": 1748172538.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "mu5muor",
                          "author": "MrMPFR",
                          "body": "While everything you said is true it doesn't matter ~~when games are VRAM hogs stuck in the 90s and reliant on outdated paradigms.~~ PC gaming is stuck in the past.\n\nMicrosoft GPU Upload Heaps functionality they unveiled at GDC 2023 looks promising and bypasses the share copy BS over PCIe and effectively acts as pseudo-unified memory.\n\nThere's also work graphs to allow the GPU to determine what ressources it needs instead of having to ask the CPU all the time. In a compute renderer by AMD at GDC 2024 they showed work graphs can reduce VRAM usage by 50-80 times.\n\nUnfortunately all this *new functionality I mentioned* is too novel to be relevant for another 5 years. Nextgen stuff *unfortunately it seems and I hope it gets implemented alongside your suggestions.*",
                          "score": 1,
                          "created_utc": 1748173152.0,
                          "replies": [
                            {
                              "id": "mu5oed0",
                              "author": "nipsen",
                              "body": "I mean.. it's \"too novel\" to be directly relevant to any PC graphics card made since Geforce 2.\n\n>While everything you said is true it doesn't matter when games are VRAM hogs stuck in the 90s and reliant on outdated paradigms.\n\nThe thing is that both major consoles, the Unreal Engine framework, most other frameworks (even ones that are unsupported at this point, like what Helldivers 2 is made on) -- don't actually require the outdated paradigm. They will treat any ram storage as \"vram\" just fine. Microsoft launched their DirectStorage or whatever it was as if it was something new - it's a caching model that has been used since before the ps2 era. But their framework now just graphs, as you say, the behaviour of the program so the ram can allocate on the even more outdated virtul paging memory model on external storage as if it was on the vram block.\n\nSo everyone is avoiding this paradigm.... except for the hardware manufacturers.\n\nActually, that's not even true. AMD are producing graphics cards for these consoles, and for pc that don't have vram at all. Nvidia made Tegra, which again has no vram next to the graphics cores (the graphics module is stuck to the cpu elements, and the gpu and cpu calls are used against main memory interchangably). This was in.. you know.. 2005 something that we expected would be the next paradigm to keep the \"gpu\" industry alive. That they'd start making at the very least cpu-additions, or else gpu modules placed next to the cpu cache (like amd eventually did). \n\nIt would be better if they just made cpus that could be live-configured with instruction sets (i.e., shader code could be uploaded to instruction cache) like AMD would have were it not for Intel's \"x86 should be free, but not like that!\" lawsuits.\n\nBut that was in 2005. We never thought that any of this would stick around once the vram was not used directly for simd-operations. Right..? Because once you have a faster memory cache where the shader operations happen, you're literally treating \"vram\" as a storage unit. And the entire reason for having it, like really was there in the voodoo era, is gone. Geforce 2, as mentioned, is when this was not having a function any more.\n\nSo it's not that the programs are following 90s conventions. It's that the /peripheral/ graphics card division is in a business where this convention sells a 100 usd graphics card for 2000 usd.",
                              "score": 2,
                              "created_utc": 1748173898.0,
                              "replies": [
                                {
                                  "id": "mu6ai7o",
                                  "author": "MrMPFR",
                                  "body": "Thanks for the interesting info. I was referring to the new functionality I mentioned being too novel.\n\nReally hope this BS stops during 10th gen console era, PC needs to move on instead of being stuck in the past. PC still needs VRAM for bandwidth unless we get something else than dGPU or an entirely new type of VRAM that's hyperoptimized for BW instead of capacity.\n\nBut then there's still the issue of legacy support so I doubt VRAM will ever go down on consumer. Look at the PhysX 32bit backlash with 50 series, and imagine how much worse it would be if older games stopped running on future GPUs. Guess it could technically be possible to make it work with less or no VRAM but the amount of software rewrites and headaches probably makes it not worth it + there's insane demand for VRAM from AI ATM.\n\nDo you think the current trend will ever change, because I don't see AMD or NVIDIA changing a single thing?",
                                  "score": 1,
                                  "created_utc": 1748182430.0,
                                  "replies": [
                                    {
                                      "id": "mu6fu1i",
                                      "author": "nipsen",
                                      "body": "Good question. It's kind of a good example to use PhysX to describe the problem. PhysX never was very fast with dedicated hardware implementation, or when using CPU cores (it always was an Nvidia/Cuda implementation that specifically used Cuda execution flair towards the memory bus/local cache on the graphics card. Similar things could be done in SSE registry .. hacks, basically. But having the toolkit there made it easi..er for a developer to use it). But it was never used in anything except for things specifically sponsored by Nvidia. Mirror's Edge is maybe the only example I can think of, that had a PhysX run that was programmed in a way that required it to run on the graphics card (to escape the resubmit curse/latency).\n\nThe rest has always been made redundant by Opencl or any other kind of \"longer instruction\" programming toolkit, that would then run just on a CPU setup (or with distributed cores and few critical sections).\n\nSo although PhysX in theory could be a good tool, it's really just a Cuda marketing ploy, that also really isn't relevant on a platform where physics-calculations can either be done in software, or with gpgpu applications in entirely different languages. \n\nOr, removing PhysX support in new cards didn't exactly cost Nvidia a lot, because literally nothing being released in the last 20 years or so actually use it, and there is basically no reason to use it because of the stronger CPUs and more cores than what we had back then. So it's sort of a marketing ploy that now just would have Cuda engineers sit and pointlessly implement in new hardware where this type of shader program isn't what you're optimising for any more anyway.\n\nThere still was a huge stink about it. But it's not actually something that new cards from Nvidia would excel at, unless it was implemented in a way that would target very old cards, running with a very weak cpu.\n\nSo is it a legacy concern, to pull that? Not really. It sucks to lose the window crashing in Mirror's Edge, but there's nothing stopping new games from doing this in software a lot faster than Digital Illusions/Dice did it then in PhysX (probably off hand by one of their assembly or shader specialists... probably one before Christina Coffin, who did this kind of implementation for the PS3 spu setup for Battlefields later. I mean, Mirror's Edge was.. 2008? \ud83d\ude06 Remember ME was an unreal engine game with an app for the physics, basically. And that didn't completely run on the GPU on the PS3, which.. probably has an unknown story of some sort associated with it).\n\nBut all of that is genuinely redundant, even on new Nvidia cards.\n\nSo the question isn't really if these conventions change. The question is if these kinds of extra implementations for gameplay elements are even done at all.\n\nBecause that's what we really have now, and have had for a long time. Developers don't choose to implement complicated things, specially when it has to be part of the main loops, and not toolkit-wise being possible to add as a \"free addition\".\n\nFor example, the only games being released on pc recently that have in-scene, per frame type physics or geometry calculations are No Man's Sky and Spintires. Everything else uses gpgpu \"offline\" or not time-dependent calculations like this. Or else it's things like Helldivers2, that has in-scene calculations (again, I should say.. the Sony geniuses had them remove those implementations out of performance concerns and optimisation.. read: someone complains about not getting 3000fps on their 3000 euro graphics card... They've now quietly put those things back in the game for some reason).\n\nBut most games just don't do this at all. They choose an implementation that \"decouples\" frame rate from the physics or geometry. Which means that there is no interaction between live events and the game world at all. You see one-shot resources being fired. And that's the convention that has been PC gaming since the 90s.. albeit with some exceptions.\n\nSo will that change? Doubtful. But the hardware is increasingly capable, even on PC.",
                                      "score": 1,
                                      "created_utc": 1748184147.0,
                                      "replies": [
                                        {
                                          "id": "mu6rizk",
                                          "author": "MrMPFR",
                                          "body": "Sure PhysX was a gimmick when it launched even more than RTX and not supporting it really doesn't matter people just don't like stuff no longer working it seems.\n\nAgain thanks for the interesting info.",
                                          "score": 2,
                                          "created_utc": 1748187747.0,
                                          "replies": []
                                        },
                                        {
                                          "id": "mu6volc",
                                          "author": "MrMPFR",
                                          "body": ">So will that change? Doubtful. But the hardware is increasingly capable, even on PC.\n\nSorry for not being specific enough. I was referring to the way VRAM is being adressed and used by HW vendors stuck in the 90s era. Will that ever change because like I said AMD and NVIDIA doesn't seem too interested in making any changes?",
                                          "score": 1,
                                          "created_utc": 1748188999.0,
                                          "replies": [
                                            {
                                              "id": "mu740gl",
                                              "author": "nipsen",
                                              "body": "Well.. it is changing. That's just the thing. You write programs now and you don't really concern yourself with it. There's always going to be people in the industry who use those conventions when speaking about it, or when creating memory managers, and things like that. You'll always have some folks like Richard Leadbetter in Eurogamer who will be swearing to a convention (or several) like this is the only way to do things, while romanticising the good old days (that he never saw, and have never programmed in, if he has programmed anything at all) when they wrote \"code on the metal\".\n\nBut like I said, it's not really that Nvidia is not interested in making any changes. The Switch (and the follow-up) are based on their Tegra setup, for example, that completely eschews that paradigm.\n\nThe problem is that their peripheral card business is printing money. People buy peripheral graphics cards for mining and llm, sure. There's an element of that driving the peripheral card prices up to comical levels. But the biggest part of the market are, you know, aging gamers (like the people at Sony, or Eurogamer, or IGN or other Ziff-Davis stuff, or Pachter, and so on) who will have disposable incomes high enough to just blow 3000 euro on a graphics card.\n\nAnd a great deal of those people will also have time to go online and call for this and that game to utilize more of the vram, or to create higher texture packs, and things like that. That traditionally was associated with vram, but which now are stored on ssd-storage or system ram.. Making that term, \"vram\", not really refer to anything relevant any more other than in marketing.\n\nThere's a recurring one in the laptop-realm as well. People turn up and are furious that the \"vram\" on their laptop with 32Gb system ram on a ryzen apu is \"only 128Mb\". And not understanding that the graphics driver is allocating system ram as needed to serve as \"vram\" (which already is a meaningless term), and could happily claim 32Gb if it wasn't for how Windows11 wants to sit on at least 9Gb at all times.\n\nWould the programming conventions in schools be changed any time soon, I guess would be a better question. Would it make sense to introduce system design while making it clear that the level1-4 cache paradigms of Intel and AMD, where \"ram\" is on the outer edge, is the exception to computer architectures? Would you start to see Microsoft and Stucky Universities simply treat something as \"ram-storage\" vs. \"instruction memory\"? In an attempt to bridge app-making for phones on ARM and Risc-V with the PC sphere?\n\nProbably. But I'm not going to make any bets about anything. In 2008 I said that if the peripheral graphics card business didn't vanish in three years, it would be a miracle of some sort. Then Intel successfully sued AMD to abandon their programmable core apu (it had generic cpu and gpu cores). And basically then extended the life-time of the cache-layering paradigm (it is literally over 20 years now since saving money on the most expensive piece of memory in the cpu, the first layer cache, made any sense) for 20 years. Which in turn requires the use of peripheral cards for the graphics modules even in gaming applications, even if those graphics card modules are fused to the mainboard.\n\nThis is not a rational business driven by, or frankly even affected by the technically most sound design-proposals. Companies that make the best monitor screens go out of business. The most sensible mobile operating systems are not chosen for mobile applications. The cpu designs that are the most economical now, in the way that they weren't in the 80s, are still not chosen. While programming paradigms that make the job of any programmer incredibly much harder than it should be are not just wished for by some CEO's spawn that can't find their country on a world map, much less their arse with both hands - but also by actual programmers in the industry. Who then after 20 years of loving Big Brother eventually realize that they've been idiots and move on to a database maintenance job that pays twice the salary..\n\nThis business is incredibly strange.",
                                              "score": 2,
                                              "created_utc": 1748191524.0,
                                              "replies": [
                                                {
                                                  "id": "mu8aq3o",
                                                  "author": "MrMPFR",
                                                  "body": "Interesting take, hopefully we see some changes in the future.   \nThe current paradigm on PC is just too damn wasteful.",
                                                  "score": 1,
                                                  "created_utc": 1748204655.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0reak",
              "author": "correctingStupid",
              "body": "The future proofing argument has been going on for how many years now while 8gb cards still hold up for the vast majority of games?",
              "score": 3,
              "created_utc": 1748099869.0,
              "replies": [
                {
                  "id": "mu0s8uf",
                  "author": "iamonelegend",
                  "body": "The cards that have already been out for a few years, back when 8GB was much more acceptable? I'm sure they are doing fine, and probably have some time still left on them, but as far as buying one of those cards new, at MSRP in 2025? I wouldn't recommend it...",
                  "score": 3,
                  "created_utc": 1748100133.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu0vwhf",
              "author": "Carvemynameinstone",
              "body": "While you make a good point, we probably won't see Gta6 on pc before 2027.",
              "score": 2,
              "created_utc": 1748101279.0,
              "replies": []
            },
            {
              "id": "mu0wf21",
              "author": "Nope_______",
              "body": ">Especially with big games like GTA 6 on the horizon, who wants a GPU\n\nIf people don't want it they won't buy it.",
              "score": 1,
              "created_utc": 1748101439.0,
              "replies": []
            },
            {
              "id": "mu2ae1b",
              "author": "Zilox",
              "body": "If gta6 will run on ps5... it will run on 8gb vram",
              "score": 1,
              "created_utc": 1748117799.0,
              "replies": []
            },
            {
              "id": "mu4zov5",
              "author": "sold_snek",
              "body": "> Especially with big games like GTA 6 on the horizon, who wants a GPU that might struggle in a year on the most popular game in the world?\n\nThe majority of the world.",
              "score": 1,
              "created_utc": 1748159583.0,
              "replies": []
            },
            {
              "id": "mu5kju2",
              "author": "MrMPFR",
              "body": "Doubt GTA VI will have any issues at 1080p medium and by the time it arrives on PC 3GB GDDR7 should finally have pushed 12GB to the mainstream. No more 8GB BS on low end cards. But they'll be a huge backlash when people can no longer max out graphics sliders like in GTA V. Unlike some other devs (cough MHW, cough Indy game) Rockstar has no trouble making a capable and efficient engine.\n\nThink the VRAM issue getting worse is overblown. We've already seen the worst examples (Indiana Jones and MHWs) The games that use a truly nextgen engine like UE5 has far fewer issues with VRAM than outdated and inferior games engines. Mesh shaders, tiled textures, image streaming etc... it all adds up to more efficient VRAM ressource management.\n\n8GB isn't going to be unrunnable until post PS5/PS6 crossgen sometime from 2029-2031, if people are fine with 1080p medium-low. But for a midrange product like the 5060 TI 8GB and 9060XT 8GB that's capable of so much more this is still completely unacceptable.",
              "score": 1,
              "created_utc": 1748171990.0,
              "replies": []
            },
            {
              "id": "mu0scio",
              "author": "danny12beje",
              "body": "People can't afford to pay more for GPUs. That's why 1080p is still the norm.",
              "score": 1,
              "created_utc": 1748100166.0,
              "replies": [
                {
                  "id": "mu0u1et",
                  "author": "iamonelegend",
                  "body": "Agreed. I think there's still pricing issues in the supply chain that make AMD want to push lower memory card as a standard. I don't think it would be easy for them to make a cheaper 16GB card, so they just ramble about 8GB being good enough for most.",
                  "score": 1,
                  "created_utc": 1748100697.0,
                  "replies": [
                    {
                      "id": "mu5nkyq",
                      "author": "MrMPFR",
                      "body": "It's not an issue. AMD has sold cards with far lower gross margins in the past and they used to sell Polaris for next to nothing and run heavy discounts on RDNA 1 cards. RDNA 4 is nothing but a cash grab from AMD. If it had the same gross margins as RDNA 3 the 9070XT could've easily been $550 on shelves and 9060XT 16GB $299 on shelves, but AMD was more interested in maximizing their gross margin while appearing competitive. Don't buy their BS.",
                      "score": 1,
                      "created_utc": 1748173509.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0kutp",
              "author": "Mindestiny",
              "body": "Future proofing really isnt a thing though.  There will be a new, faster 8GB card a couple years down the line that will just be *so much better* than todays card you're going to upgrade anyway.\n\nI've been seeing enthusiasts yell about \"future proofing\" for 20+ years, and not once has it actually panned out.  You might get an extra year maybe before there's some specific game or performance now become no longer *tolerable* for you, specifically but financially speaking the ROI just isnt there.  It's a rationalization for buying overspecced hardware.",
              "score": -11,
              "created_utc": 1748097810.0,
              "replies": [
                {
                  "id": "mu0npko",
                  "author": "MercenaryOne",
                  "body": "Yes, but not everyone needs the absolute highest end gfx card to future proof. I went From a 260gtx OC, to a 1060 TI, to a 3060TI, and I'm keeping this card for at least another 3 years. And I guarantee you I will still be able to play every game I want to in the next 3 years. The problem i have is the mid range cards of today are reaching the prices of high end of yesterday.",
                  "score": 3,
                  "created_utc": 1748098715.0,
                  "replies": []
                },
                {
                  "id": "mu0mwb5",
                  "author": "iamonelegend",
                  "body": "This is absolutely untrue. I know multiple people that are still using GTX 10 series cards. They were the standard bearer for an entire generation and were built to be so. Those folks didn't upgrade every three years because the cards had enough overhead. I'm not saying that every card needs to be built to last a generation, but 8GB is at the bottom of basic tier. My wife needed a GPU to play a life sim game and I think this 8GB card wouldn't be a good fit, unless I wanted to buy her another GPU in less than 5 years.",
                  "score": 7,
                  "created_utc": 1748098462.0,
                  "replies": [
                    {
                      "id": "mu0npm0",
                      "author": "Furious_Fred",
                      "body": "1080ti here, does everything it should for me",
                      "score": 4,
                      "created_utc": 1748098715.0,
                      "replies": []
                    },
                    {
                      "id": "mu0niak",
                      "author": "Mindestiny",
                      "body": "That's not \"future proofing\" though.\u00a0 They didn't overspec hardware with the idea that it's going to magically last twice as long as the next lowest hardware.\n\n\nThat's \"my computing needs did not advance past the hardware I already had\".\u00a0 If all your wife wants to do is play that life sim game, of course the card that runs it well today will continue to run it well a decade from now.\u00a0 But future proofing is hedging against tomorrow's unknowns.",
                      "score": 1,
                      "created_utc": 1748098653.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0mrhj",
                  "author": "ArchusKanzaki",
                  "body": "A PS5 have slightly-less of 16GB of VRAM available for developers to use (shared with CPU for some tasks).\n\nA PS5 Pro have full 16 GB of VRAM available for developers to use since it got extra 2GB for CPU now.\n\nThat's what this midrange GPU competition is. And obviously most developers will optimize more for consoles than PC.",
                  "score": 5,
                  "created_utc": 1748098420.0,
                  "replies": [
                    {
                      "id": "mu0nqys",
                      "author": "Mindestiny",
                      "body": "I dunno what to tell you man, the article that includes research from one of the world's most prominent gpu manufacturers disagrees",
                      "score": -4,
                      "created_utc": 1748098727.0,
                      "replies": [
                        {
                          "id": "mu0ok1z",
                          "author": "SoKrat3s",
                          "body": "Self-done research conclusion fits their agenda, more at 11.",
                          "score": 2,
                          "created_utc": 1748098979.0,
                          "replies": [
                            {
                              "id": "mu5so3i",
                              "author": "Mindestiny",
                              "body": "You can be as butthurt about it as you want.\u00a0 Go look at all the other research, whatever source you trust, it concurs with the findings.\n\n\nYour average PC gamer does not have a 4k ultra wide and a 5090 and spend all day reading overclocking forums",
                              "score": 1,
                              "created_utc": 1748175819.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mu0ra3q",
                          "author": "DJKGinHD",
                          "body": "Is that REALLY research? Or is it marketing?",
                          "score": 1,
                          "created_utc": 1748099833.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0ktd8",
              "author": "Omz-bomz",
              "body": "GTA 6 on PC is only coming in 2027, so shouldn't take that into consideration for a card bought now.   \nThough I agree on principle, low end cards should start at 12Gb these days.",
              "score": -4,
              "created_utc": 1748097797.0,
              "replies": [
                {
                  "id": "mu0ngek",
                  "author": "AnalFluid1",
                  "body": "That's a year and a half away, why wouldn't you take that into consideration? No normal person is upgrading GPU every year.",
                  "score": 8,
                  "created_utc": 1748098637.0,
                  "replies": []
                },
                {
                  "id": "mu0ns5n",
                  "author": "HakimeHomewreckru",
                  "body": "Why not? A card will last you for years. 2027 is in 1.5 years already so why wouldn't you take it into consideration? Who buys a new card every year?",
                  "score": 9,
                  "created_utc": 1748098738.0,
                  "replies": []
                },
                {
                  "id": "mu0n21w",
                  "author": "ArchusKanzaki",
                  "body": "I will not be surprised if GTA 6 will start demanding 12GB VRAM as minimum. That's what is available for PS5, and GTA 6 is more or less optimized for consoles. If not 12GB minimum, I would think it will demand at least some kind of DirectStorage technology.",
                  "score": 3,
                  "created_utc": 1748098512.0,
                  "replies": [
                    {
                      "id": "mu0pqa2",
                      "author": "mighty_atom",
                      "body": ">12GB VRAM as minimum. That's what is available for PS5\n\nThat's unified memory though. The GPU and CPU share the same memory so it's not really using 12gb as VRAM. It's using like 6-8 for VRAM functions and the rest is used for CPU operations.",
                      "score": 2,
                      "created_utc": 1748099346.0,
                      "replies": [
                        {
                          "id": "mu14qlf",
                          "author": "SScorpio",
                          "body": "The base PS5 has 16GB of memory and games on average and use up to 12GB as just VRAM. That extra 4GB go to the OS and game.",
                          "score": 3,
                          "created_utc": 1748104103.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mu0nkxn",
                      "author": "TheMythicalArc",
                      "body": "Would have to be an 8gb minimum for Xbox series s optimization as thats a current gen console that only has 8 gigs",
                      "score": 1,
                      "created_utc": 1748098676.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu4dr08",
              "author": "hmmthissuckstoo",
              "body": "This is not correct. Since when 1080p requires 16 gigs vram lol",
              "score": 0,
              "created_utc": 1748147186.0,
              "replies": []
            },
            {
              "id": "mu0jw08",
              "author": "iluvios",
              "body": "Games in those times didn\u2019t had the software to use all that tech effectively.\n\nAnd lately software improvements made hardware work even better.\n\nYou can\u2019t expect that for ever. The technology is maturing and further development are going to be diminishing\u00a0",
              "score": -5,
              "created_utc": 1748097502.0,
              "replies": [
                {
                  "id": "mu0ki9j",
                  "author": "Elman89",
                  "body": "That's not the point. This isn't some hypothetical tech, it's just a fact that having more memory is the best way to increase these cards' longevity. It's just not good for business cause it means your cards last longer, while ideally they want you to replace them in a year or two.",
                  "score": 9,
                  "created_utc": 1748097698.0,
                  "replies": []
                },
                {
                  "id": "mu0pb47",
                  "author": "TheBoBiZzLe",
                  "body": "Physx, cuda, eyefinity, opengl, geforce and many more \u201cused the tech effectively.\u201d\n\nFunny how the tech companies keep saying \u201cpay more our AI(software) is better.\u201d  And people just mindlessly flock to the defense. \n\nMeanwhile games are coming out looking muddy and sloppy.  But that corner number says 120.  Don\u2019t stop looking at that little number!\n\nTruth is that it\u2019s better for business to overcharge a few than mass produce at a lower cost.  They know this.  And they know the few willing to overpay will buy it every year so that little number keeps saying 120.  \n\nOr not.  Whatever.",
                  "score": 3,
                  "created_utc": 1748099214.0,
                  "replies": [
                    {
                      "id": "mu187xp",
                      "author": "iluvios",
                      "body": "I never said to buy the latest gen, notice how I say diminishing returns.\nEvery generation is becoming more expensive for less improvements.\nBut maybe I didn\u2019t explained it right!",
                      "score": 2,
                      "created_utc": 1748105231.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu0ir0x",
          "author": "GABE_EDD",
          "body": "While resolution is a factor in VRAM usage much bigger deciding factors are the quality of textures, the number of textures, other graphical settings, and especially ray tracing. Cyberpunk 2077, for example easily uses 11 to 12 GB of VRAM with settings maxed out and ray tracing enabled at 1080p",
          "score": 32,
          "created_utc": 1748097140.0,
          "replies": [
            {
              "id": "mu0jvt5",
              "author": "None",
              "body": "[deleted]",
              "score": 0,
              "created_utc": 1748097500.0,
              "replies": [
                {
                  "id": "mu15bvp",
                  "author": "None",
                  "body": "[deleted]",
                  "score": 5,
                  "created_utc": 1748104297.0,
                  "replies": [
                    {
                      "id": "mu7066x",
                      "author": "None",
                      "body": "[deleted]",
                      "score": 0,
                      "created_utc": 1748190383.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0xt1e",
              "author": "Moldy_slug",
              "body": "\u201cWith settings maxed out\u201d is beside the point. Most gamers still enjoy games without maxing out the graphics settings.\u00a0\n\nThe question is how much VRAM does it need to run smoothly at medium to low settings?",
              "score": -1,
              "created_utc": 1748101876.0,
              "replies": [
                {
                  "id": "mu2hytl",
                  "author": "JoostinOnline",
                  "body": "While I would normally agree with this statement, the issue is that they can't produce visuals equivalent to a 5 year old console for almost the same price (a lot more when you factor in other parts). That's pretty bad, considering the rest of the card is far more powerful. \n\nMemory bottlenecks are also a pretty big problem. You end up having to disable a lot of features you wouldn't have to  It's essentially an unbalanced card. If it had the same amount of memory as the RTX 3060 (which is 4 years old a cheaper) then there would be far less work finding playable settings.\n\nAs it stands, this is more expensive and worse than an RTX 3070 on all counts.",
                  "score": 2,
                  "created_utc": 1748120356.0,
                  "replies": []
                },
                {
                  "id": "mu0yio8",
                  "author": "GABE_EDD",
                  "body": "That\u2019s not the point. You can\u2019t run the game at maxed settings even if you wanted to because they won\u2019t spend another $8 adding 4GB to the card when manufacturing it. It\u2019s not that people are unlikely to run maxed settings, it\u2019s that they\u2019re not physically able to run the game maxed out. And with the way AAA games have been creeping up VRAM requirements in the last few years maybe in the near future most AAA titles will require 12GB of VRAM for medium settings, who knows.",
                  "score": 6,
                  "created_utc": 1748102102.0,
                  "replies": [
                    {
                      "id": "mu2jsa3",
                      "author": "JoostinOnline",
                      "body": ">because they won\u2019t spend another $8 adding 4GB to the card when manufacturing it.\n\nTo be fair, it's a lot more complex than that. They'd have to redesign the board and use a much higher memory interface, which would significantly increase power draw. We also don't actually know how much more memory would cost, but it's probably more than that. Every customer would be happy to eat an extra $8 if that's all it was.\n\nI'm not saying they shouldn't be using a 12GB design with a 192 bit memory interface. They did it with the 3060. And they should also do that with the 5060 Ti. All I'm saying is it's not as simple as reddit rants makes people think.",
                      "score": 1,
                      "created_utc": 1748120981.0,
                      "replies": []
                    },
                    {
                      "id": "mu1ulbq",
                      "author": "mxzf",
                      "body": "It's exactly the point.  Because the quote is about what \"most gamers need\".  Sure, it's nice to bump up the quality if you can swing it, but most people aren't going to notice the difference between the two once they get playing the game and don't ***need*** the upgrade to play and enjoy the game.",
                      "score": -1,
                      "created_utc": 1748112372.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0jixr",
              "author": "Revoldt",
              "body": "Using maxed settings at 1080p\u2026\nWe in 2005?",
              "score": -12,
              "created_utc": 1748097387.0,
              "replies": [
                {
                  "id": "mu0jzlz",
                  "author": "elixier",
                  "body": "What are you even saying",
                  "score": 6,
                  "created_utc": 1748097533.0,
                  "replies": [
                    {
                      "id": "mu0ka86",
                      "author": "UnsorryCanadian",
                      "body": "I don't know. The first commercially available 1440p monitor was released in 2010 so idk what that guy was using from 2006-2009",
                      "score": 3,
                      "created_utc": 1748097626.0,
                      "replies": []
                    },
                    {
                      "id": "mu0kfz8",
                      "author": "Revoldt",
                      "body": "Guy was talking about using max setting and ray tracing at 1080p\u2026 in CP2077.\n\nThe graphics card in question is a medium settings card\u2026at 1080p",
                      "score": -4,
                      "created_utc": 1748097677.0,
                      "replies": [
                        {
                          "id": "mu42rcz",
                          "author": "2106au",
                          "body": "The card it is competing against 110 fps on 1080p ultra for Cyberpunk.\n\n\nWhere did you pull the medium settings card idea?",
                          "score": 1,
                          "created_utc": 1748142055.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu0k7vo",
                  "author": "Cloudeur",
                  "body": "Not everyone has a 1440p or 4K monitor!\n\nBack in 2005, 1024x728 was more common.",
                  "score": 4,
                  "created_utc": 1748097606.0,
                  "replies": [
                    {
                      "id": "mu0olyo",
                      "author": "UnsorryCanadian",
                      "body": "The PS3 had just come out with it's fancy HDMI back in 2005! You were amazed to be running 720p half the time",
                      "score": 3,
                      "created_utc": 1748098996.0,
                      "replies": [
                        {
                          "id": "mu1dkz7",
                          "author": "Cloudeur",
                          "body": "2006 for the PS3! Xbox 360 was released in 2005 ;)",
                          "score": 1,
                          "created_utc": 1748106923.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu0jw3i",
                  "author": "UnsorryCanadian",
                  "body": "Should I have a higher resolution monitor or be playing on medium?",
                  "score": 2,
                  "created_utc": 1748097503.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu0ij30",
          "author": "paaaaatrick",
          "body": "Not only would it be true, it\u2019s exactly what the article says he said",
          "score": 39,
          "created_utc": 1748097069.0,
          "replies": [
            {
              "id": "mu11onx",
              "author": "DigitallyDetained",
              "body": "I know, but everyone still seems pretty upset about it",
              "score": 4,
              "created_utc": 1748103114.0,
              "replies": []
            },
            {
              "id": "mu0mb1b",
              "author": "MiloIsTheBest",
              "body": "\"He\" being Frank Azor, noted lying liar and biggest liability that company has ever had.",
              "score": 3,
              "created_utc": 1748098274.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu0lmrc",
          "author": "Beastmind",
          "body": "That really depend on the game. Big games like RDR2 can quickly come close or even going above 8GB even on 1080p.\n\nResolution is not everything for vram.",
          "score": 28,
          "created_utc": 1748098058.0,
          "replies": [
            {
              "id": "mu189eo",
              "author": "MyGoodOldFriend",
              "body": "Really? RDR2 specifically has a surprisingly low vram usage for me, on 1440p and high quality. Other games do way worse.",
              "score": 10,
              "created_utc": 1748105245.0,
              "replies": [
                {
                  "id": "mu1rttd",
                  "author": "Beastmind",
                  "body": "Try ultra for a few setting and you'll see it crank up.",
                  "score": -1,
                  "created_utc": 1748111453.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu113i4",
              "author": "DigitallyDetained",
              "body": "Oh, I see. I just assumed that lower resolution would mean vastly smaller texture sizes, requiring much less vram. But yeah, as you say it\u2019s definitely not only about resolution",
              "score": 1,
              "created_utc": 1748102925.0,
              "replies": [
                {
                  "id": "mu1rxga",
                  "author": "Beastmind",
                  "body": "For textures yeah but some graphics effects take load.",
                  "score": 1,
                  "created_utc": 1748111486.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu0vsak",
          "author": "onerb2",
          "body": "Not really, there are 1080p games that already use more than 8gb, like Hogwarts Legacy.",
          "score": 8,
          "created_utc": 1748101243.0,
          "replies": [
            {
              "id": "mu10h1y",
              "author": "DigitallyDetained",
              "body": "Good to know; thanks.",
              "score": 1,
              "created_utc": 1748102723.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu0lac4",
          "author": "im_thatoneguy",
          "body": "No, there\u2019s some benchmarking with the new battlemage GPUs and especially with Console ports it shows massive performance loss even at 1080p\n\nWhen the 8GB 5060 isn\u2019t memory limited it\u2019s like 40-% faster and when it\u2019s memory limited it\u2019s like 40% slower.",
          "score": 10,
          "created_utc": 1748097948.0,
          "replies": [
            {
              "id": "mu0w4se",
              "author": "bootz-pgh",
              "body": "To be fair, only with certain settings enabled. I don\u2019t believe there is a game that needs more than 8GB at 1080p regardless of settings. Using ultra textures is usually the culprit.",
              "score": -1,
              "created_utc": 1748101351.0,
              "replies": [
                {
                  "id": "mu4yace",
                  "author": "frostygrin",
                  "body": "You're implying that ultra textures are useless at 1080p - it's not necessarily the case.",
                  "score": 1,
                  "created_utc": 1748158749.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu0pni6",
          "author": "Prus1s",
          "body": "For future proofing, better to have more 12-16 per minimum at least\n\n1080p is still most widely used, even consoles barely output more that 1080p native still, all is just upscaled nowadays\u2026",
          "score": 2,
          "created_utc": 1748099322.0,
          "replies": []
        },
        {
          "id": "mu13xui",
          "author": "Jamato-sUn",
          "body": "Jedi Survivor eats like 12+ gigs in 1080p RTX off.",
          "score": 2,
          "created_utc": 1748103845.0,
          "replies": []
        },
        {
          "id": "mu0jfx2",
          "author": "DPOP4228",
          "body": "That may be true today, although it isn't for some games, but that will most certainly not be true a couple years from now. If someone is spending $300+ for a computer component, that component should last and be relevant at least a few years. \nHaving an 8gb card feels like planned obsolescence, probably because it is.",
          "score": 6,
          "created_utc": 1748097361.0,
          "replies": []
        },
        {
          "id": "mu0nw6w",
          "author": "ArchusKanzaki",
          "body": "1080p high-refresh monitors are no longer \"midrange\" nowadays. That will be 1440p. Monitors are getting alot cheaper nowadays.",
          "score": 4,
          "created_utc": 1748098773.0,
          "replies": [
            {
              "id": "mu10u5h",
              "author": "DigitallyDetained",
              "body": "Yeah, but I\u2019m taking about if your card can handle 1440, not your monitor",
              "score": 0,
              "created_utc": 1748102840.0,
              "replies": [
                {
                  "id": "mu11rnx",
                  "author": "ArchusKanzaki",
                  "body": "But isn't this a \"midrange\" card? And is it appropriate for \"midrange\" to be promoted as \"best for 1080p\" in this year of 2025? Is it even appropriate for 300$ to only expecting 1080p gameplay in this current year of 2025? For 300$?",
                  "score": 2,
                  "created_utc": 1748103141.0,
                  "replies": [
                    {
                      "id": "mu4fzzl",
                      "author": "Dt2_0",
                      "body": "This is the equivalent to a 60 class from Nvidia. That is lower end. 70 class is midrange, and 80+ class is high end.",
                      "score": 1,
                      "created_utc": 1748148327.0,
                      "replies": [
                        {
                          "id": "mu4iera",
                          "author": "ArchusKanzaki",
                          "body": "....and what are 50-class card then? Trash bin? 70-class is pretty upper-end.",
                          "score": 1,
                          "created_utc": 1748149591.0,
                          "replies": [
                            {
                              "id": "mu54m0f",
                              "author": "Dt2_0",
                              "body": "I honestly can't remember a 50 series that was worth spending money on since the 1050ti, and even then, you could get an RX480 for about the same price most of the time. I think of them as great server cards due to lower power consumption and having core gpu techs like NVENC, and a display out incase you need to work with it, but I have never seen them as worthwhile cards for gamers when better options are almost always available at their prices.\n\nI generally consider the 50 series to be \"Display out with decent video encoding and decoding,\" and the 30 series (EX GT1030) to be \"I need a few more display outs on my office rig.\"",
                              "score": 1,
                              "created_utc": 1748162598.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu0ppnt",
          "author": "StarsMine",
          "body": "It\u2019s not true at 1080p is the issue.\nNew games 2 years ago, 8GB was an issue at QHD.\n\nNew games today it\u2019s an issue at FHD\n\nPs5 has 12 gb of vram (+4 for system)\n\nNew games in the next two years, at sub FHD, 8GB will be an issue\n\nThe number of games that have issues will rapidly start to ramp up\n\nPeople expect buying a NEW gpu will be relevant for at minimum 4 years. 8GB of VRAM is hardly relevant with releases in 2025.",
          "score": 4,
          "created_utc": 1748099341.0,
          "replies": []
        },
        {
          "id": "mu0li5c",
          "author": "Mindestiny",
          "body": "Yes, and RAM is a \"use it or dont\" resource - if your game/program is not using more than 8GB, any additional RAM is literally sitting there functionally not existing.\n\nWhat most \"gamers\" fail to understand is that the *majority* of people who play games are not obsessing over FPS and reading benchmarks and buying $2000 GPUs for ultra-wide screen 4k l33t gaming workstations.  They're buying mid-range, off the shelf gaming PCs targeted at 1080p medium graphics settings priced around the same level as a game console that will deliver totally adequate performance.",
          "score": 2,
          "created_utc": 1748098018.0,
          "replies": [
            {
              "id": "mu0yxiz",
              "author": "Moldy_slug",
              "body": "Yup. Literally nobody I know has a dedicated gaming PC with a top of the line components. We just play games on lower settings at 1080p, and gravitate towards games that don\u2019t have stupidly high graphics requirements.",
              "score": 3,
              "created_utc": 1748102232.0,
              "replies": []
            },
            {
              "id": "mu11gxb",
              "author": "DigitallyDetained",
              "body": "Yeah that\u2019s what I was kind of thinking. Obviously there are a lot of hardcore people on Reddit that focus on the high performance stuff, but it\u2019s probably not a fair representation of PC gaming overall.",
              "score": 2,
              "created_utc": 1748103045.0,
              "replies": []
            },
            {
              "id": "mu4yewy",
              "author": "frostygrin",
              "body": "VRAM shortage will not give you \"totally adequate performance\" the way a slower GPU would.",
              "score": 0,
              "created_utc": 1748158825.0,
              "replies": [
                {
                  "id": "mu5r2t6",
                  "author": "Mindestiny",
                  "body": "Why are you assuming there's a shortage of VRAM?\n\n\nIf you're not playing at those higher resolutions and juiced up settings, most games aren't using more than 8GB of VRAM.\u00a0 There is no shortage.",
                  "score": 0,
                  "created_utc": 1748175128.0,
                  "replies": [
                    {
                      "id": "mu61whe",
                      "author": "frostygrin",
                      "body": "> If you're not playing at those higher resolutions and juiced up settings, most games aren't using more than 8GB of VRAM.  There is no shortage.\n\nThere are too many qualifications in your statement. You're basically saying, \"If you exclude all the games with a shortage of VRAM, there is no shortage of VRAM\". :) \n\nMeanwhile, high-resolution monitors and TVs are cheaper than ever, people buy new cards specifically to run newer games at juiced up settings, and heavily advertised features like frame generation require additional VRAM. If you're not going to use all that, you can just play older and less demanding titles - then indeed *most games* are fine with 8, or even 6 GB. \n\nI'd say there is a shortage of VRAM when you would otherwise be able to run the game at specific resolutions, with specific settings and features - and only VRAM is getting in your way, making games unplayable or much less performant. Something like this happening *at launch* - to the point that manufacturers are suppressing honest reviews - is unacceptable. It's not even futureproofing anymore.",
                      "score": 1,
                      "created_utc": 1748179468.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu0ldcv",
          "author": "EVGACAB",
          "body": "If you are fine with very low settings and no certainty about your ability to play new aaa titles. Plenty of videos of there that show that there are already titles that struggle with 8gb and many more that work fine for now but use the entire 8gb. This is only acceptable for the lowest tier of cards now. Xx50 and x050. But NVIDIA doesn\u2019t even make those cards anymore and call them 60 and sell em for 350.",
          "score": 2,
          "created_utc": 1748097975.0,
          "replies": []
        },
        {
          "id": "mu0ijls",
          "author": "N-Haezer",
          "body": "It totally would.",
          "score": 2,
          "created_utc": 1748097073.0,
          "replies": []
        },
        {
          "id": "mu1h8vl",
          "author": "Gloriathewitch",
          "body": "4k low is viable on my 3060m 6gb so id say a desktop 8gb is a really solid 1440 card and not really viable for a good experience at 4k, most people are on 1080 but will move to 1440 so i think 12gb should be the absolute minimum sold at this point, but 16 costs them barely anything so start there",
          "score": 1,
          "created_utc": 1748108064.0,
          "replies": []
        },
        {
          "id": "mu8wzjt",
          "author": "PaulR504",
          "body": "AMD used to bring me the future. Now they have become Intel",
          "score": 1,
          "created_utc": 1748212112.0,
          "replies": []
        },
        {
          "id": "mu1bee7",
          "author": "None",
          "body": "[removed]",
          "score": 0,
          "created_utc": 1748106234.0,
          "replies": [
            {
              "id": "mu1fueq",
              "author": "DigitallyDetained",
              "body": "Interesting. I\u2019d love to see that if you can find/remember the link or YouTube or whatever.",
              "score": 1,
              "created_utc": 1748107632.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu1aayi",
          "author": "N2-Ainz",
          "body": "If they wouldn't call it 9060 XT, absolutely. \n\nIt's unacceptable to have two completely different cards with the same name, it should've been called 9060",
          "score": 0,
          "created_utc": 1748105890.0,
          "replies": []
        },
        {
          "id": "mu2vt0z",
          "author": "chibicascade2",
          "body": "I got into PC gaming in 2017. At that point AMD had a competitive 1080p card called the rx480 that competed with the GTX 1060. Nvidia had a 3gb and 6gb variant and they made the same arguments back then. AMD beat the low end model by 1gb of vraw, not matching it, and they beat the higher end by 2gb. They were always the option with slightly worse drivers, but more power over time as the drivers matured and you could take advantage of the extra vram. \n\nNow they match the vram and still have worse support, just raytracing support now.",
          "score": 0,
          "created_utc": 1748125306.0,
          "replies": []
        },
        {
          "id": "mu0lohh",
          "author": "Rodman930",
          "body": "Gamers are playing at 1080p because they don't have enough vram.  Gaming monitors have been past that for years.",
          "score": -6,
          "created_utc": 1748098073.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0j4rc",
      "author": "NeedAVeganDinner",
      "body": "Is Intel of all companies the only sane fucking GPU manufacturer at this point?\n\n\nWhat world is this?",
      "score": 260,
      "created_utc": 1748097263.0,
      "replies": [
        {
          "id": "mu0lr2q",
          "author": "ulfhelm",
          "body": "One where Nvidia no longer needs gaming dollars and AMD wishes it would reach that point. Think about it: Intel is doing the worst in the AI datacenter revenue, and thus ironically, will be doing the best in competing for gamers. The only thing preventing Intel from making an actual profit now is that they need to switch off TSMC for their own fab production, but that is going to take some time. I look forward to the next generation of Intel GPUs being truly goated, and that will be the generation I upgrade every PC in my house.",
          "score": 133,
          "created_utc": 1748098096.0,
          "replies": [
            {
              "id": "mu0n9dy",
              "author": "xixbia",
              "body": "Imagine if we reach the point where the best gaming CPU is AMD and the best GPU is Intel.\n\nI definitely wouldn't expect we'd have any chance of ever getting there even a decade ago.",
              "score": 97,
              "created_utc": 1748098576.0,
              "replies": [
                {
                  "id": "mu1bagr",
                  "author": "MaroonIsBestColor",
                  "body": "For the entire 2010s it was Intel CPU paired with Nvidia GPU.",
                  "score": 26,
                  "created_utc": 1748106200.0,
                  "replies": [
                    {
                      "id": "mu4g80u",
                      "author": "Dt2_0",
                      "body": "AMD pulled ahead about late 2018 early 2019 (well they equalized performance, but at cheaper prices). So most of the 2010s were Intel+Nvidia, but at the very end it was AMD+Nvidia.",
                      "score": 2,
                      "created_utc": 1748148441.0,
                      "replies": []
                    },
                    {
                      "id": "mu1pwob",
                      "author": "PolaNimuS",
                      "body": "Yeah, but that doesn't sound nearly as weird. Intel's primarily been a CPU manufacturer and was uninvolved with gaming GPUs at the time and Nvidia only makes GPUs and has never made CPUs.",
                      "score": 5,
                      "created_utc": 1748110822.0,
                      "replies": [
                        {
                          "id": "mu1pzuo",
                          "author": "PolaNimuS",
                          "body": "Just realized you're probably talking about the getting there in a decade part.",
                          "score": 2,
                          "created_utc": 1748110852.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu1iznf",
                  "author": "Tupcek",
                  "body": "poor AMD - finally gaining market share in x86, just in time when everyone switches to ARM",
                  "score": 3,
                  "created_utc": 1748108613.0,
                  "replies": []
                },
                {
                  "id": "mu4gt3q",
                  "author": "classicalySarcastic",
                  "body": ">Imagine if we reach the point where the best gaming CPU is AMD and the best GPU is Intel.\n\nAchievement unlocked: How Did We Get Here?",
                  "score": 1,
                  "created_utc": 1748148744.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu10vkw",
              "author": "SweetTea1000",
              "body": "This. I would be happy to upgrade my 1080 to literally anything that presents both a significant performance uplift and a genuinely good value for the customer... but the years keep rolling by and that keeps not happening.",
              "score": 6,
              "created_utc": 1748102853.0,
              "replies": [
                {
                  "id": "mu1s3k2",
                  "author": "KnightSunny",
                  "body": "lol jesus, are you waiting for. 10x performance uplift? 10 series users gotta be the most delusional bunch",
                  "score": 0,
                  "created_utc": 1748111543.0,
                  "replies": [
                    {
                      "id": "mu3ktjs",
                      "author": "SkyeAuroline",
                      "body": "> lol jesus, are you waiting for. 10x performance uplift?\n\nA low enough price to justify switching away from hardware that still works.",
                      "score": 1,
                      "created_utc": 1748134853.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu2fjy6",
              "author": "very_anonymous",
              "body": "Man this AI shit is going to crash everything. The company I work for is selling off business segments piece by piece because \u201csomething something AI\u201d. It\u2019s a tech company but still not a tech company you would expect would have a significant contribution to AI.",
              "score": 1,
              "created_utc": 1748119542.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu1h4id",
          "author": "cptchronic42",
          "body": "VRAM isn\u2019t everything. Intel proved that by putting more than the 4060 and still getting beat by it overall. Especially with an older cpu and rt on.",
          "score": 3,
          "created_utc": 1748108027.0,
          "replies": [
            {
              "id": "mu4yh2e",
              "author": "frostygrin",
              "body": "No one says VRAM is everything.",
              "score": 0,
              "created_utc": 1748158861.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu5813p",
          "author": "InsightfulLemon",
          "body": "No, they're all sane and driving by real world (not the Reddit echo chamber) stats\n\n\n[Just take a look at Steams hardware survey.](https://i.imgur.com/CCzlcg5.jpeg)\n\n4k is still niche, 1080p dominates",
          "score": 1,
          "created_utc": 1748164727.0,
          "replies": []
        },
        {
          "id": "mubht8b",
          "author": "fractalife",
          "body": "He just said that the majority of people still game at 1080p, and that 8GB is plenty for that resolution. It's not really that off base. They included a single 8GB GPU in the lineup so that 1080p gamers have a cheaper option without VRAM they don't need.",
          "score": 1,
          "created_utc": 1748254575.0,
          "replies": []
        },
        {
          "id": "mu0s65i",
          "author": "StarsMine",
          "body": "IDK, if I would call loosing money on every GPU sold \"sane\"\n\nedit: Im not sure I understand the downvotes. Intel looses money on every b580 and b570 sold. I am not saying AMD cant make the 9060xt 10-20 bucks cheaper, but they are not going to drop the price to the point where they lose money like them. Like Vegan Dinner states, Intel is trying to build market and mind share which is why they are willing to eat the loss this generation, they are below sub 1% market share for dGPUs and dont have a good mind reputation. \n\nNeither AMD or Nvidia are in a situation that requires loosing money on every GPU sold.\n\nFrank Azor is a bad spokesman for sure, always has been imo. He is good at talking to businessmen types, not technical types.",
          "score": -4,
          "created_utc": 1748100110.0,
          "replies": [
            {
              "id": "mu0v4w5",
              "author": "NeedAVeganDinner",
              "body": "They're trying to build market and mind share.",
              "score": 8,
              "created_utc": 1748101040.0,
              "replies": [
                {
                  "id": "mu0x7f3",
                  "author": "StarsMine",
                  "body": "Yup, but thats not a stratagy AMD or Nvidia can justify right now",
                  "score": -4,
                  "created_utc": 1748101685.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu14isz",
              "author": "cloud9ineteen",
              "body": "That's okay they will make it up in volume",
              "score": 1,
              "created_utc": 1748104034.0,
              "replies": []
            },
            {
              "id": "mu23hbc",
              "author": "StormAeons",
              "body": "I wouldn\u2019t normally do this, but since you said it twice, it\u2019s lose and losing. Loose is when something doesn\u2019t fit.",
              "score": 1,
              "created_utc": 1748115388.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu1ljgt",
          "author": "IchBinMalade",
          "body": "It's wild to me reading how people are talking about Intel. It's like hearing Microsoft being talked about as the underdog after witnessing the 2000s lol.\n\nI think the lesson here is pretty obviously monopoly=bad, duopoly=also bad. Any company that gets to dominate that much will behave the exact same way. Even your favorite, ethical, beloved company would. Once you reach that point, it's not your choice, either make shareholders more money or they'll kick you out and bring in someone who will.",
          "score": 0,
          "created_utc": 1748109414.0,
          "replies": []
        },
        {
          "id": "mu1ocu0",
          "author": "lolno",
          "body": "Turns out sanity is inversely correlated with market share",
          "score": 0,
          "created_utc": 1748110316.0,
          "replies": []
        },
        {
          "id": "mu270dh",
          "author": "JoostinOnline",
          "body": "They're the only company desperate enough to sell at a loss. Intel is either going to flop, or they're going to work out their issues and raise their prices. We need to stop acting like companies have good guys and bad guys.",
          "score": 0,
          "created_utc": 1748116627.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0ij8x",
      "author": "UnsorryCanadian",
      "body": "This is true\n\nAs long as you don't care about pushing texture, shadow,and post processing quality past medium-low.",
      "score": 140,
      "created_utc": 1748097070.0,
      "replies": [
        {
          "id": "mu0j2dz",
          "author": "PSIwind",
          "body": "We've hit the point of diminished returns that low/medium quality is still good compared to the difference years ago.",
          "score": 58,
          "created_utc": 1748097242.0,
          "replies": [
            {
              "id": "mu0jgtm",
              "author": "UnsorryCanadian",
              "body": "I usually run in that range because I've only got a 5700xt. Lack of RT lets me occasionally try High quality, but usually Medium or Low.\n\nI flip the settings around constantly in Oblivin Remastered and I have trouble even seeing the difference between them, other than the FPS counter dropping more",
              "score": 13,
              "created_utc": 1748097369.0,
              "replies": [
                {
                  "id": "mu17h86",
                  "author": "wolfsilvergem",
                  "body": "I run an experiment with every new game I buy. I look at the quality of the graphics as I can perceive them on highest versus lowest on my HDR 1440p monitor: 90% of games I can only notice small differences.",
                  "score": 5,
                  "created_utc": 1748104993.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu0sw33",
              "author": "RedditButAnonymous",
              "body": "I run most games at a mix of settings\n\nStuff like volumetrics and post processing, usually low\n\nShadows and reflections, medium\n\nTextures and models, ultra if possible\n\nEnds up looking almost the same as Ultra everything, but runs way smoother. I absolutely love those games that include images of what each setting looks like, or even better, let you see the game world youre in as you change settings, it reveals so much about where the performance is being wasted.",
              "score": 9,
              "created_utc": 1748100337.0,
              "replies": [
                {
                  "id": "mu2zxmg",
                  "author": "DigitallyDetained",
                  "body": "Yeah that helps a bunch. I wish devs would provide optimal specs based on your setup, but that\u2019s a lot to ask.\n\nI guess nvidia/amd do that through their software, though.",
                  "score": 1,
                  "created_utc": 1748126863.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu0tdje",
              "author": "hosky2111",
              "body": "It depends on a lot of factors, but texture resolution is very noticeable - when you come across a blurred object in an otherwise pristine scene, it can really take you out of the experience. Streaming issues like that can be alleviated with more Vram, and the general texture quality raised.\n\nWe also see a lot of games shipping with very compromised textures to accommodate the 8gb GPUs (like the recent doom). That could be fixed with 4k texture packs, but Devs often target the lowest common denominator.\n\nVram is also important for things like ray tracing, which can have a pretty transformative impact on visual quality. I really don't consider path tracing in games like cyberpunk or Indiana Jones to be diminishing returns - it's pretty transformative. If you need frame generation to run these, that also uses more Vram.",
              "score": 2,
              "created_utc": 1748100489.0,
              "replies": [
                {
                  "id": "mu0tp6z",
                  "author": "PSIwind",
                  "body": "I agree on Path Tracing, I just meant more from the other standpoints. Path tracing currently isn't widespread enough but it will probably in a year or two",
                  "score": 1,
                  "created_utc": 1748100590.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu20840",
          "author": "CommanderBly",
          "body": "I legit can't even run Monster Hunter Wilds on my 6GB vram card. The minimum required vram for that game on pc is 8GB vram. Sure it's probably poorly optimized but you actually do need it to play at any quality setting",
          "score": 3,
          "created_utc": 1748114260.0,
          "replies": []
        },
        {
          "id": "mu1bnq8",
          "author": "KeldornWithCarsomyr",
          "body": "Outside of redditors on a tech subreddit, there's the majority of PC gamers playing Solitaire, Age of Empires, Peppa Pigs adventures, and Bluey.",
          "score": 3,
          "created_utc": 1748106317.0,
          "replies": [
            {
              "id": "mu4geqv",
              "author": "Dt2_0",
              "body": "And most PC Enthusiasts on Tech subs are playing YouTube.",
              "score": 3,
              "created_utc": 1748148537.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu0japj",
          "author": "r_a_d_",
          "body": "Is \u201cmedium-low\u201d an objective metric?  What does that even mean?",
          "score": 3,
          "created_utc": 1748097315.0,
          "replies": [
            {
              "id": "mu0jrj6",
              "author": "Double010",
              "body": "Usually those are the terms that settings use. Low, Medium, High, Ultra.",
              "score": 6,
              "created_utc": 1748097463.0,
              "replies": [
                {
                  "id": "mu0lvgy",
                  "author": "Mindestiny",
                  "body": "To be fair to their point, it's *not* an objective metric.  \"Low\" in one game often means something totally different than \"Low\" in another game.  There's absolutely no standardization even among presets",
                  "score": 9,
                  "created_utc": 1748098136.0,
                  "replies": [
                    {
                      "id": "mu0rvs6",
                      "author": "Double010",
                      "body": "For sure. I think games released around the same time generally have pretty similar presets for lower end graphics, but it'll never be standardized. Of course depends on the kind of game and what optimizations they have, etc.\n\nWasn't trying to be unfair to any point, I just thought the guy was unfamiliar with the terms used.",
                      "score": 2,
                      "created_utc": 1748100020.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0ll07",
                  "author": "r_a_d_",
                  "body": "Yes, but every game will have a different meaning for those settings.",
                  "score": 5,
                  "created_utc": 1748098042.0,
                  "replies": [
                    {
                      "id": "mu0r0p5",
                      "author": "Double010",
                      "body": "Oh sure, yeah. Sorry, I thought you were confused why the commenter used those terms. Im still waking up, my b.",
                      "score": 0,
                      "created_utc": 1748099754.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mu0jofj",
              "author": "UnsorryCanadian",
              "body": "There's a few games I've seen where they have more preset graphics levels than Low, Medium, High and Very High.\n\nOr custom graphic settings",
              "score": 4,
              "created_utc": 1748097436.0,
              "replies": [
                {
                  "id": "mu0lql6",
                  "author": "r_a_d_",
                  "body": "Each game will have a different meaning for \u201cmedium\u201d graphics.",
                  "score": 3,
                  "created_utc": 1748098091.0,
                  "replies": [
                    {
                      "id": "mu0osjg",
                      "author": "UnsorryCanadian",
                      "body": "That's why I said medium-low.\n\nMy PC? Cyberpunk? Medium. Oblivion? Low",
                      "score": 2,
                      "created_utc": 1748099053.0,
                      "replies": [
                        {
                          "id": "mu0pe39",
                          "author": "r_a_d_",
                          "body": "Oh, ok, much more clear then. /s",
                          "score": -4,
                          "created_utc": 1748099241.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu5mhip",
          "author": "Kered13",
          "body": "Or playing new games.",
          "score": 1,
          "created_utc": 1748172972.0,
          "replies": [
            {
              "id": "mu6jxbd",
              "author": "UnsorryCanadian",
              "body": "I can run Oblivion on my 5700xt minimum graphics  at native res no upscaling, visually looks the same as high, minus people's hair (I'm an argonian so it matters less)",
              "score": 1,
              "created_utc": 1748185420.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mu0oqns",
      "author": "Vo_Mimbre",
      "body": "Since their marketing group is probably going by popularity by *play* not just popularity of conversations, they're right. Statistically (according to Newzoo and Steam if you trust both), the top games by *played* are lighter-weight titles like Minecraft (still), DoTA (ancient), Roblox (minigames), Fortnite (runs on potatoes by design), CS2 (ancient).\n\nBut people who stay in those experiences aren't also bragging about their 'roided-out rigs, and their defintion of battlestation is because the branded foozles they buy on flash sale on TikTok. \n\ntl;dr: statistically, most PC gamers are not playing CP2077 at 4K with full raytrace.",
      "score": 19,
      "created_utc": 1748099036.0,
      "replies": [
        {
          "id": "mu2qj7p",
          "author": "pwnersaurus",
          "body": "Absolutely, and there\u2019s no way 8GB cards will be scalped because the use cases are limited, for the many people who aren\u2019t playing things that push the cards, it\u2019ll keep prices reasonable too",
          "score": 1,
          "created_utc": 1748123374.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0jb52",
      "author": "Catch_ME",
      "body": "I think this gpu ram issue is really a conflict between game engine developers and GPU manufacturers.\u00a0\n\n\nModern game engines now are inefficient and not very well optimized for low ram. At the same time, AMD and Nvidia are being overly stingy on not giving us enough RAM and saving all the high ram yields of their GPUs to AI/ML developers\u00a0\n\n\nWe are caught in the middle of corporate propaganda. My opinion.\u00a0",
      "score": 67,
      "created_utc": 1748097319.0,
      "replies": [
        {
          "id": "mu0m394",
          "author": "WelpSigh",
          "body": "It's really not a game engine issue. Textures simply have to go into memory to avoid stuttering. 4k textures require more memory. There are techniques, obviously, to manage when things go into memory to try and maximize it, but that's a dev decision and oftentimes you just have physical limitations.",
          "score": 18,
          "created_utc": 1748098204.0,
          "replies": [
            {
              "id": "mu0oeuq",
              "author": "Catch_ME",
              "body": "I understand. It's just we've always have texture compression techniques and art styles that run better on low ram environments.\u00a0\n\n\nI remember when Gotham Knights was released in 2022. It looked like shit compared to Arkham Knight that was released in 2015.\u00a0\n\n\nA lot of the current generation of games don't look as good as 1 generation back. Why?\n\n\nThe silent hill 2 remake is a perfect example of an unoptimized game. The fog isn't used to hide textures. Instead, every polygon and texture behind the fog is fully processed and loaded into memory. A wasted opportunity.\u00a0",
              "score": 15,
              "created_utc": 1748098935.0,
              "replies": [
                {
                  "id": "mu1gp1j",
                  "author": "Crakla",
                  "body": "Exactly, I dont know whats happening, I feel like every new game is increasing in system requirements for no reason, like for example oblivion remaster runs like shit and requires 6gb vram to even start it, while RDR2 has a vram requirement of 2gb, even though RDR2 looks miles ahead in terms of graphic and textures",
                  "score": 5,
                  "created_utc": 1748107893.0,
                  "replies": [
                    {
                      "id": "mu5v6cv",
                      "author": "MrMPFR",
                      "body": "Games are made around the PS5 console spec which is 7-8 times more powerful on GPU and CPU side vs PS4 and has almost 3x higher useable VRAM. At the same time devs have abandoned baked lighting and simpler forms of GI for open world games and are heavily reliant on upscaling. At the same time UE5 is still in beta-testing phase and suffers from terrible stuttering.\n\nNo RDR2 doesn't have amazing textures, they're much lower res than all new releases and the rendering is inferior to UE5's Lumen system. Technically it's inferior but the artstyle is amazing. Also RDR2 needs to fit into the PS4's smaller RAM, while recent games can take advantage of the PS5's +12GB of useable non-OS memory.",
                      "score": 2,
                      "created_utc": 1748176876.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu5o6jv",
                  "author": "MrMPFR",
                  "body": "When you give devs a HW spec they'll max it out. PS5 having 3x the amount of usable RAM than PS4 results in higher VRAM usage on PC.\n\nYep Art style > graphics.\n\nSH2 was a broken betatest of UE 5.1 or 5.2 game built by technically incompetent game devs. UE 5.5 is still a joke and it's only now with some experimental features in UE 5.6 that likely stems from the [CDPR and Epic](https://www.youtube.com/watch?v=JaCf2Qmvy18) that the engine is finally somewhat useable.",
                  "score": 3,
                  "created_utc": 1748173794.0,
                  "replies": []
                },
                {
                  "id": "mu1czlo",
                  "author": "wamj",
                  "body": "We\u2019ve broken the cycle of developers being constrained by hardware for extended periods of time. \n\nLook at super Mario bros vs super Mario bros 3. Both on the NES, one at the beginning of the console cycle and one towards the end. But the graphics improvements are substantial because of programming efficiency from learning the architecture.",
                  "score": 2,
                  "created_utc": 1748106736.0,
                  "replies": [
                    {
                      "id": "mu20zie",
                      "author": "phibetakafka",
                      "body": "They're not the same hardware though, there is the MMC3 mapping chip on SMB3 that allowed bank switching of ROM data, allowing access to much larger amounts of graphical data, alongside the fact that SMB1 was 8 MB and SMB3 was 64 MB. Most of the improved look and feel is due to the fact that they had 8x as much room for sprites and tiles thanks to the MMC3. \n\nThere were of course hardware optimizations, like a framebuffer hack that allowed simultaneous horizonal and vertical scrolling during flight, but in one sense it's the complete opposite conclusion of your argument. SMB3 looked how it did *because* it had access to more memory, they were just able to build that capacity into game cartridges through secondary chips. The best games later in the lifecycle for both NES, SNES, and N64 all used special chips built into the cartridge. It's not at all how things work today; you can kind of think of it like comparing a PS5 to a PS5 Pro, except the additional capacity was built into the games rather than the system. \n\nNow if you were talking about the leaps made from the PSX in 94 to 2000, that's more accurate (although I'd say you have to discount the first year or two as developers were literally learning how to make games in 3D on the fly). And we've never seen such a huge leap in hardware optimization since then over the course of a console generation.",
                      "score": 2,
                      "created_utc": 1748114522.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu0sb6w",
                  "author": "WelpSigh",
                  "body": "Well, I do agree that we are seeing less graphical payoff for newer advances. A game with really strong art direction last gen might look better than a current-gen game with mediocre art. Newer doesn't always mean better. Many of the really expensive advances lately have been things that look amazing in very specific circumstances, and otherwise is barely noticable.\n\nI think I couldn't say if SH 2 is \"unoptimized\" because we (or at least, I) don't know the performance consequences of doing things otherwise. Loading stuff from storage and decompressing textures is computationally expensive. This is the time/space trade-off - more memory means less time spent waiting on the CPU or storage reads, and vice versa. What seems \"unoptimized\" is very often simply a design decision by the dev team. In other words - the more VRAM you use, the faster the game runs. To be clear - maybe they made a bad decision, I don't know, but just based on what you've said there it seems like it could very well be a perfectly reasonable choice.",
                  "score": 2,
                  "created_utc": 1748100154.0,
                  "replies": [
                    {
                      "id": "mu5qulx",
                      "author": "MrMPFR",
                      "body": "SH2 is based on UE 5.1 and the issues with the game stem from the early UE5 build + incompetence on the game dev side (render distance behind fog) and remember something about stupidly non-granular and excessive loading of massive chunks of the games leading to huge stutters.\n\nThe amount of improvements on the engine side made in UE 5.3-5.6 are just insane and UE 5.6 with the experimental streaming features looks like it might finally be getting to a somewhat usable state.\n\nDecompression is handled by CPU and with so many threads being mainstream it can easily be handled by background threads or alternatively run on the GPU with DirectStorage GPU decompression. The overhead is minimal compared to everything else in the game on the GPU side.",
                      "score": 3,
                      "created_utc": 1748175029.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mu2k5vm",
                  "author": "permawl",
                  "body": "Is there even enough resources (fast enough dedicated hardware for decompression, enough bandwidth and enough cache) available on these lower models with 8GB vram for it to make texture compression a viable solution for the amount of assets and textures that modern games have? \n\nLike on paper yeah compression is a solution, but it needs its own set of conditions to work, and for a problem created by hardware manufacturers.",
                  "score": 1,
                  "created_utc": 1748121111.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mu0n6qo",
          "author": "im_thatoneguy",
          "body": "It\u2019s not about optimization so much as people hating loading screens and pop in. Gamers have way higher expectations for what is in game at any given moment. Not to mention since we plateaued at 1080p/1440p being good enough the only way to increase quality year over year is detail of what\u2019s on screen. Which generally means more geometry and higher resolution textures.\n\nPeople complain about ue5 but forget the ue3 era was the era of blurry textures popping in and lots of convenient elevators. Before that we had loading screens every free hundred yards/meters.",
          "score": 11,
          "created_utc": 1748098552.0,
          "replies": [
            {
              "id": "mu5vknj",
              "author": "MrMPFR",
              "body": "I would honestly rather take that vs #StutterStruggle. Really hope the experimental streaming tech in UE 5.6 can finally end most of the stuttering for good in future releases. TW4 better not stutter like current UE5 games.",
              "score": 1,
              "created_utc": 1748177037.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu0o519",
          "author": "Buck_Da_Duck",
          "body": "It\u2019s not even a matter of yields / binning. Memory is on separate chips. It\u2019s purely because they want to sell AI capable chips at higher mark-ups.",
          "score": 3,
          "created_utc": 1748098849.0,
          "replies": []
        },
        {
          "id": "mu1b557",
          "author": "ottermanuk",
          "body": "They hated him for he spoke the truth\n\n\nGimping VRAM to keep gaming level cards away from AI and ML workloads is the only reason they are doing this. Saving on RAM chips on the BoM save some money. Keeping enterprises buying their AI cards with 32/48/96GB makes them A LOT.\n\n4090s are being sent to china and given double the ram just by doubling the RAM module sizes pretty easily because it's the best they can get.",
          "score": -1,
          "created_utc": 1748106154.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0layf",
      "author": "ArchusKanzaki",
      "body": "Why does AMD even need to walk into this mess? Nvidia already drew all the attention and fire for their 5060 launch. Everyone sorta understand that the 8GB-version is there for margin-maxing that is lovely for the SI and shareholders, but they can let it slide just to stick it to Nvidia. They really do not need to justify this existence. \n\nAlso, as a note, at least Nvidia is using GDDR7 memory. AMD is using older GDDR6 memory so it should be cheaper per card for AMD. This card is really made for margin-maxing. At least they no longer walk into the same trap of using only 8-lanes of PCI Express despite it will be PCIe Gen 5. Should be better for older system.\n\nI do hope for AMD's sake, it won't be worse than Intel B580 at least. Will be embarrassing to say the least.",
      "score": 23,
      "created_utc": 1748097953.0,
      "replies": [
        {
          "id": "mu1fain",
          "author": "pewpew62",
          "body": "Because this class of card sells extremely well, it's always atop the amazon and steam charts, so AMD want a piece of the pie, we complain about it but the market speaks, people will buy it",
          "score": 6,
          "created_utc": 1748107460.0,
          "replies": []
        },
        {
          "id": "mu0ripr",
          "author": "MiloIsTheBest",
          "body": "Literally all they had to do was make only a 16 GB variant and sell it for anything less than NVIDIAs 8GB variant. They probably would see 9070 XT levels of hype for it.\n\n\nFrank Azor kicking unforced own-goals as always.",
          "score": 7,
          "created_utc": 1748099906.0,
          "replies": [
            {
              "id": "mu0v5sl",
              "author": "None",
              "body": "[deleted]",
              "score": 9,
              "created_utc": 1748101047.0,
              "replies": [
                {
                  "id": "mu0who3",
                  "author": "MiloIsTheBest",
                  "body": "Yeah. So instead of just a victory lap for AMD (if the performance holds up to that price point, frankly it really needs to actually be a 5060Ti equivalent) there's this whole other thing too.",
                  "score": 1,
                  "created_utc": 1748101462.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu136nb",
              "author": "Aggravating-Dot132",
              "body": "Majority of production will be 16gb version.\n\nKey part here is that he is NOT wrong, because MAJORITY of gamers sit in CS/DOTA/LOL and that kind of games and they don't need more than 8gb of VRAM.\n\nAnd these cards aren't strong enough for running path tracing or 4k CP RT anyway.",
              "score": 8,
              "created_utc": 1748103602.0,
              "replies": [
                {
                  "id": "mu29twk",
                  "author": "m0dru",
                  "body": "uhhh, the majority of those gamers aren't buying new gpus because they don't need too. its why old lower end cards are still prevalent on the steam hardware survey.",
                  "score": 4,
                  "created_utc": 1748117607.0,
                  "replies": [
                    {
                      "id": "mu2btg7",
                      "author": "Aggravating-Dot132",
                      "body": "These 8gb GPUs aren't for \"sale\". They are to dump them into pre-builts.",
                      "score": 5,
                      "created_utc": 1748118291.0,
                      "replies": [
                        {
                          "id": "mu4yslj",
                          "author": "frostygrin",
                          "body": "Doesn't matter. Most people are still upgrading from something. If you're going to play the kinds of games that don't need more than 8GB, chances are you don't need a new pre-built either.",
                          "score": 0,
                          "created_utc": 1748159054.0,
                          "replies": [
                            {
                              "id": "mu4z0uh",
                              "author": "Aggravating-Dot132",
                              "body": "You are seriously overestimating the ability of common user to dig info about that. As well as not understand that DIY Market is ultra low in comparison to pre built.",
                              "score": 3,
                              "created_utc": 1748159188.0,
                              "replies": [
                                {
                                  "id": "mu4zie6",
                                  "author": "frostygrin",
                                  "body": "> You are seriously overestimating the ability of common user to dig info about that.\n\nBut that's exactly why it's such a hot topic. People rightfully see it as Nvidia - and now AMD - taking advantage of people who don't know better.",
                                  "score": 1,
                                  "created_utc": 1748159476.0,
                                  "replies": [
                                    {
                                      "id": "mu504hi",
                                      "author": "Aggravating-Dot132",
                                      "body": "And what's the point of discussing it?\n\n\nFor you to understand. These cards will be planted into 600$ PCs and sold as is. People who buy those will play cs2, dota, cod or fifa 16/7 and they won't care about anything else. Literally.\n\n\nI would support your point against 5070 with 12gb shit show, but this is 5060/9060 with 8gb and for 300$. They will be as cheap as they could be for cooling system and will be the most popular cards. Just look at 3050/4060, they are in almost all pre builts for their respective years.",
                                      "score": 3,
                                      "created_utc": 1748159844.0,
                                      "replies": [
                                        {
                                          "id": "mu50ran",
                                          "author": "frostygrin",
                                          "body": "> And what's the point of discussing it?\n\nThe point is that you could have argued that 8GB is enough when the 4060 came out. It's getting increasingly harder to still argue this. The most popular cards should be decent, and VRAM shouldn't be the bottleneck for the amount of performance the card has. Especially when VRAM is inexpensive. \n\nIf Nvidia put 6GB of VRAM on the 5060, would you still argue that it's enough for CS2?",
                                          "score": 1,
                                          "created_utc": 1748160232.0,
                                          "replies": [
                                            {
                                              "id": "mu51l8b",
                                              "author": "Aggravating-Dot132",
                                              "body": "If it will cost 150$ - yes, it will be enough.",
                                              "score": 2,
                                              "created_utc": 1748160735.0,
                                              "replies": [
                                                {
                                                  "id": "mu522px",
                                                  "author": "frostygrin",
                                                  "body": "Then haven't you seen that people are arguing that 8GB is no longer enough for $350 cards? It's the same logic.",
                                                  "score": 2,
                                                  "created_utc": 1748161034.0,
                                                  "replies": [
                                                    {
                                                      "id": "mu52r5f",
                                                      "author": "Aggravating-Dot132",
                                                      "body": "Again. A bunch of loudmoths on reddit count towards nothing.\n\nWant to change things - don't buy it. Spread the word to the actual buyers (your friends, brother, sister, grandma, anyone).\n\nThe reality is that 8gb cards are enough for sweatlords in competitive games, and 300$ cards will be in Pre-builts. DIY will safely ignore their existense.",
                                                      "score": 2,
                                                      "created_utc": 1748161455.0,
                                                      "replies": []
                                                    }
                                                  ]
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu3jkm7",
      "author": "KGB_cutony",
      "body": "Most gamers aren't using top spec graphics cards either.",
      "score": 3,
      "created_utc": 1748134373.0,
      "replies": []
    },
    {
      "id": "mu191uq",
      "author": "HatSimulatorOfficial",
      "body": "Noticing that reddit just refuses to not only not read articles, but also not understand how the majority of consumers act. This is completely true. If you need more, buy something else. There's a lot of options",
      "score": 15,
      "created_utc": 1748105494.0,
      "replies": []
    },
    {
      "id": "mu0rmcx",
      "author": "DeeceeCreator",
      "body": "Game developers are recommending we use 16gb cards, that's why I wouldn't buy a card under 16gb. AMD just wants to sell their 8gb stock.",
      "score": 14,
      "created_utc": 1748099938.0,
      "replies": []
    },
    {
      "id": "mu0o5pn",
      "author": "None",
      "body": "[removed]",
      "score": 20,
      "created_utc": 1748098855.0,
      "replies": [
        {
          "id": "mu0pa38",
          "author": "UnsorryCanadian",
          "body": "LLMs aren't limited by VRAM",
          "score": -27,
          "created_utc": 1748099206.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu12qw7",
      "author": "Aggravating-Dot132",
      "body": "They are not wrong btw. Most gamers play Counter strike or DotA type of games. You don't need more than 8gb there.",
      "score": 3,
      "created_utc": 1748103458.0,
      "replies": [
        {
          "id": "mu5wehy",
          "author": "MrMPFR",
          "body": "That crowd isn't going to purchase a RX 9060XT, they'll opt for the cheapest NVIDIA prebuilt on sale or whatever fits within their budget if they don't already have an old PC they can just keep using. AMD didn't justify the 9060XTs existence they peddled ragebait towards their consumers.",
          "score": 1,
          "created_utc": 1748177373.0,
          "replies": [
            {
              "id": "mu5x7a8",
              "author": "Aggravating-Dot132",
              "body": "Only if those are available to purchase, lol.",
              "score": 2,
              "created_utc": 1748177691.0,
              "replies": [
                {
                  "id": "mu6ct89",
                  "author": "MrMPFR",
                  "body": "They are they're just grossly inflated above MSRP. This GPU shortage BS has lasted almost three quarters and needs to stop.",
                  "score": 1,
                  "created_utc": 1748183172.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mucfacl",
          "author": "Short_11",
          "body": "You also don't need new 300$ 2025 GPU for those very old games... Buy old and cheap GPU accordingly.\n\n300$ 2025 GPU, should be design to run 2025 games.",
          "score": 0,
          "created_utc": 1748268700.0,
          "replies": [
            {
              "id": "muckvni",
              "author": "Aggravating-Dot132",
              "body": "Tell that to people who bought 3050.",
              "score": 2,
              "created_utc": 1748270466.0,
              "replies": [
                {
                  "id": "mucq5vd",
                  "author": "Short_11",
                  "body": "I do.\nThe rx6600 most of the time was cheaper and better, after the crypto boom.\nLess then 200$,  about 170$ iirc.\n\nFor 170$-200$ entry level 8gb card is fine imo.\nLike Rx470 / Gtx1050Ti / Gtx1650 Super / Rx5500XT for ex at thier time. Cheap crads for light games.",
                  "score": 0,
                  "created_utc": 1748272084.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu2l3h5",
      "author": "Banndrell",
      "body": "If most \"gamers\" are playing games from 2002-2010 at 1080p, these comments make complete sense. Those games could probably run on 1-2GB of VRAM, or less.",
      "score": 3,
      "created_utc": 1748121434.0,
      "replies": []
    },
    {
      "id": "mu3o77l",
      "author": "UnlimitedDeep",
      "body": "They\u2019re not wrong, enthusiasts are a small part of the market.",
      "score": 3,
      "created_utc": 1748136170.0,
      "replies": []
    },
    {
      "id": "mu43sbz",
      "author": "white_shiinobi",
      "body": "And the Reddit hive mind marches on\u2026",
      "score": 3,
      "created_utc": 1748142509.0,
      "replies": []
    },
    {
      "id": "mu0ryq8",
      "author": "Lehk",
      "body": "640k ought to be enough for anybody",
      "score": 15,
      "created_utc": 1748100046.0,
      "replies": [
        {
          "id": "mu1dn1v",
          "author": "cylonfrakbbq",
          "body": "My thoughts immediately went back to this.  I remember my uncle buying an 8088 PC back in the 80s and the salesman told him he would never need more than a couple hundred K of RAM ever.\n\nThing was obsolete in less than a year",
          "score": 1,
          "created_utc": 1748106941.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu3z2oi",
      "author": "afrogrimey",
      "body": "As somebody who has a 4060, 8gb can certainly get the job done in most cases.",
      "score": 7,
      "created_utc": 1748140508.0,
      "replies": []
    },
    {
      "id": "mu0tzzq",
      "author": "Slylok",
      "body": "Since most are still at 1080p then the claim is true.",
      "score": 5,
      "created_utc": 1748100685.0,
      "replies": [
        {
          "id": "mu4zakt",
          "author": "frostygrin",
          "body": "No, it's not. 1440p doesn't require that much VRAM. High resolution textures, raytracing, frame generation do - even at 1080p.",
          "score": 2,
          "created_utc": 1748159350.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0yvtl",
      "author": "justthisones",
      "body": "The card seems kinda fine but with a quick glance the price makes no sense when you can double the VRAM with 50 bucks. It should have 10GB or a lower price.",
      "score": 3,
      "created_utc": 1748102217.0,
      "replies": []
    },
    {
      "id": "mu2c994",
      "author": "None",
      "body": "they're probably correct\n\nquoting another reddit post bc i'm too lazy to verify, but over half of steam users are primarily running games at 1080p and a modern 8gb gpu can handle that\n\nthere's a huge market segment out there with aging systems who just want an affordable card to keep playing what they already play",
      "score": 3,
      "created_utc": 1748118439.0,
      "replies": [
        {
          "id": "mu5wrr9",
          "author": "MrMPFR",
          "body": "I wouldn't call $299 affordable or fitting for entry level gaming. No wonder NVIDIA is planning to launch a RTX 5050, it's a card made for this segment of the market.",
          "score": 0,
          "created_utc": 1748177520.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0o0ow",
      "author": "ChafterMies",
      "body": "My 2020 PS5 has more than 8GB VRAM.",
      "score": 6,
      "created_utc": 1748098811.0,
      "replies": [
        {
          "id": "mu0p8cg",
          "author": "UnsorryCanadian",
          "body": "That VRAM is shared with the CPU. Try playing modern games with 8GB of DDR5.",
          "score": -5,
          "created_utc": 1748099191.0,
          "replies": [
            {
              "id": "mu1c43k",
              "author": "Procrastinando",
              "body": "It uses around 12 GB of GDRR6 for the GPU  \n\nPC games use a lof of system memory because they need to store copies of the data that is streamed to the GPU, while that is not necessary with a shared memory model",
              "score": 3,
              "created_utc": 1748106461.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mu0rxm6",
      "author": "Biking_dude",
      "body": "Nvidia screws the pooch on their latest launch, including being stingy with VRAM. AMD comes in for the layup...and defends Nvidia's VRAM philosophy. Good jorb!",
      "score": 5,
      "created_utc": 1748100036.0,
      "replies": [
        {
          "id": "mu257hj",
          "author": "SourceNo2702",
          "body": "They actually didn\u2019t defend Nvidia\u2019s stance, they did the opposite.\n\nAMD was asked why they made an 8gb model to which they basically answered, *\u201dbecause there\u2019s a market for it? There\u2019s literally a 16gb model, why are you even asking us this?\u201d* and left it at that.",
          "score": 9,
          "created_utc": 1748115993.0,
          "replies": []
        },
        {
          "id": "mu2ms4s",
          "author": "getoutofheretaffer",
          "body": "Because they\u2019re right. 8 is enough for counter strike / rocket league / etc at 1080p. 8 is not enough for me, so I\u2019ll buy a card with more vram.",
          "score": 3,
          "created_utc": 1748122029.0,
          "replies": [
            {
              "id": "mu5wm75",
              "author": "MrMPFR",
              "body": "No one is buying a 9060XT 8GB for Counter Strike, Rocket League etc...",
              "score": 0,
              "created_utc": 1748177458.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mu0ja8q",
      "author": "skillerspure",
      "body": "lol fornite alone takes 8gb vvram",
      "score": 8,
      "created_utc": 1748097311.0,
      "replies": [
        {
          "id": "mu0x2yi",
          "author": "Jokuki",
          "body": "Considering Fortnite also plays on mobile and Switch, seems more of an issue of how much graphic fidelity you want for your game.",
          "score": 4,
          "created_utc": 1748101646.0,
          "replies": [
            {
              "id": "mu167h4",
              "author": "skillerspure",
              "body": "I wouldn\u2019t say fidelity. More like quality",
              "score": 0,
              "created_utc": 1748104582.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mu0k2yw",
          "author": "UnsorryCanadian",
          "body": "Fortnite isn't some indie game though. It's a miracle it ONLY asks for 8gb considering it's in UE5",
          "score": 2,
          "created_utc": 1748097562.0,
          "replies": []
        },
        {
          "id": "mu114le",
          "author": "None",
          "body": "[deleted]",
          "score": 1,
          "created_utc": 1748102935.0,
          "replies": [
            {
              "id": "mu1c4s0",
              "author": "mertats",
              "body": "The thing with vram is that it will not affect performance until you run out of it, the moment you run out of it your performance will tank to single digit frames.",
              "score": 1,
              "created_utc": 1748106466.0,
              "replies": [
                {
                  "id": "mu1ch8b",
                  "author": "None",
                  "body": "[deleted]",
                  "score": 1,
                  "created_utc": 1748106575.0,
                  "replies": [
                    {
                      "id": "mu1dxu8",
                      "author": "mertats",
                      "body": "It does depend on optimization but then there is also only so much you can optimize. \n\nA game like GTA6 is going to require 8GB at a minimum if you want to play at maybe low-medium settings and that game is going to be optimized.\n\n8GB is fine for old games, but newer games going to require more and more vram going forward.",
                      "score": 1,
                      "created_utc": 1748107033.0,
                      "replies": [
                        {
                          "id": "mu1fiw3",
                          "author": "None",
                          "body": "[deleted]",
                          "score": 1,
                          "created_utc": 1748107533.0,
                          "replies": [
                            {
                              "id": "mu1geq0",
                              "author": "mertats",
                              "body": "I need to upgrade my cpu, mb, and ram. So I\u2019ll also skip on 50XX, my 3080 probably could carry me a few more years in 1080p.",
                              "score": 2,
                              "created_utc": 1748107806.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu0sev9",
          "author": "Lehk",
          "body": "That\u2019s because unreal 5 is sloppy and inefficient as hell.",
          "score": 0,
          "created_utc": 1748100186.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu10rvh",
      "author": "crimxxx",
      "body": "Let\u2019s be real at this point in the game if your getting an 8 GB card at what is basically there lowest tier for both amd and nvidia, you probably are deciding 1080p is where you\u2019ll play. To go with that why buy a new card to play possibly not maxed 1080p gaming when you can probably still find a 2 or 3 gen cards that will mostly get you to the same place, or possibly a higher vram card that will probably play higher with higher resolution textures. Just my two cents but a 8GB low end card probably should not exist period and people in that market probably should just buy used, unless these cards start going down significantly. \n\nAnyone who wants to buy a 8GB card please just find used and save some money, it\u2019s not like there is some crazy amount of buying up of cards at the moment like a mining boom, you can probably find a decent deal, in fact for the same money just find a level higher card with 12 GB of vram used and you\u2019ll just be overall better off.",
      "score": 2,
      "created_utc": 1748102820.0,
      "replies": []
    },
    {
      "id": "mu141ps",
      "author": "snakeoilHero",
      "body": "Just when they could have knee capped the 5600, AMD finds a way to lose market share.",
      "score": 2,
      "created_utc": 1748103880.0,
      "replies": []
    },
    {
      "id": "mu16dqu",
      "author": "TheStaffmaster",
      "body": "Apparently these guys have not played Minecraft at max render distance with Shaders enabled.",
      "score": 2,
      "created_utc": 1748104639.0,
      "replies": []
    },
    {
      "id": "muce2v7",
      "author": "Short_11",
      "body": "So this brand new 300$ 2025 GPU targeting eSport games form 2019, and not targeting to be capable running AAA games from 2025 ?\n\nCan't wait for 300$ 2032 GPU that will finally target 2025 games.",
      "score": 2,
      "created_utc": 1748268309.0,
      "replies": []
    },
    {
      "id": "munyrfc",
      "author": "CuckAdminsDkSuckers",
      "body": "I DONT NEED TO BUY A NEW CARD TO PLAY COUNTERSTRIKE AT 1080P YOU UTTER CLOWNS",
      "score": 2,
      "created_utc": 1748420847.0,
      "replies": []
    },
    {
      "id": "muo2102",
      "author": "ThePafdy",
      "body": "Its a just a question of pricing.\n\n8 GB is totally fine if the card is priced accordingly. Low end memory (and other specs) for simpler games can be a good product, the issue currently is that there are no \u201elow end\u201c priced cards. 300$ is not low end.",
      "score": 2,
      "created_utc": 1748422797.0,
      "replies": []
    },
    {
      "id": "mu0sarc",
      "author": "Mjarf88",
      "body": "Most new games easily max out 8gb of vram in 1080p though?",
      "score": 3,
      "created_utc": 1748100150.0,
      "replies": []
    },
    {
      "id": "mu0tgc3",
      "author": "DarkLThemsby",
      "body": "Istg AMD keep getting handled golden opportunities, and just keep dropping the ball left right and center.",
      "score": 2,
      "created_utc": 1748100513.0,
      "replies": []
    },
    {
      "id": "mu1i00x",
      "author": "ga-co",
      "body": "Manufactures telling customers what they want instead of the other way around is a bad sign your company is headed in the wrong direction.",
      "score": 3,
      "created_utc": 1748108303.0,
      "replies": []
    },
    {
      "id": "mu1ixny",
      "author": "fukflux",
      "body": "The argument was that people mostly play on 1080p.\n\nOf course they fucking do - they don't have the hardware yet!",
      "score": 4,
      "created_utc": 1748108595.0,
      "replies": []
    },
    {
      "id": "mu0os2k",
      "author": "joestaff",
      "body": "Well, \"most gamers\" only play on their cellphones, so that is technically correct. But anyone buying a video card probably wants to be able to play any reasonably recent title.",
      "score": 4,
      "created_utc": 1748099048.0,
      "replies": []
    },
    {
      "id": "mu0inth",
      "author": "N-Haezer",
      "body": "If somebody's on a budget he's definitely on 1080p therefore 8GB VRAM is suitable for now and probably will for many years.",
      "score": 3,
      "created_utc": 1748097111.0,
      "replies": [
        {
          "id": "mu0npva",
          "author": "Zapador",
          "body": "Exactly my thought. If you buy a low end/entry level GPU it's really only well suited for 1080 and probably without many of the options that would increase VRAM usage, so 8 GB should be fine.\n\nI'm still on a 1080Ti with 11 GB and playing at 1440, I have never managed to use 8 GB of VRAM.",
          "score": 0,
          "created_utc": 1748098718.0,
          "replies": [
            {
              "id": "mu0uqpw",
              "author": "valqyrie",
              "body": "Older games aren't that bad on VRAM but new titles eat more and more. as you can see here;\n\n[https://www.youtube.com/watch?v=C0\\_4aCiORzE&t=348s](https://www.youtube.com/watch?v=C0_4aCiORzE&t=348s)\n\neven at 1080p you're not safe from it if you crank all the settings up. Also don't forget, you're buying a brand new card for $300+. You should at least have the luxury to play these games at 1080p high settings.",
              "score": 8,
              "created_utc": 1748100917.0,
              "replies": [
                {
                  "id": "mu13imu",
                  "author": "Zapador",
                  "body": "An 8 GB card is a low end/entry level card that, apart from not having a lot of VRAM, also doesn't have the processing power to really run anything with all the settings cranked up so the problem will really solve itself. You buy such a card to play at a moderate resolution with moderate settings and that will generally not require more than 8 GB of VRAM.\n\nIf you want to play at a higher resolution and/or with high settings you'll be buying another card that can actually handle that.",
                  "score": -3,
                  "created_utc": 1748103709.0,
                  "replies": [
                    {
                      "id": "mu15cz6",
                      "author": "valqyrie",
                      "body": "Bullshit. Where most players flock to 1440p and 4k, 1080p is already low end/entry level. If you are suggesting that a $300 brand new card is meant for 720p gaming I don't have anything else to say.\n\nNot only that; I have literally posted a link that shows how 5060ti is capable of playing 1080p high settings but got held back in 8gb version due to VRAM shortage. Also not everyone has this knowledge. Especially people who build a pc for the first time does not know if 8gb will be enough or not. 8gb vram should be a thing of past already. There's no need to defend a billion dollar company's planned obsolescence.",
                      "score": 4,
                      "created_utc": 1748104307.0,
                      "replies": [
                        {
                          "id": "mu17h1u",
                          "author": "Zapador",
                          "body": "I am suggesting that a 300$ entry level card is intended for 1080 on no more than medium settings. I never mentioned 720 anywhere, had you read the comment you initially replied to you would have noticed that I specifically mentioned 1080 and moderate settings.\n\nI do agree that 8 GB is still borderline too low today, just having 12 would make more sense as some games are poorly optimized. But my initial statement still stand, that you buy an entry level card to run at a modest resolution and with modest settings.",
                          "score": -2,
                          "created_utc": 1748104991.0,
                          "replies": [
                            {
                              "id": "mu4z69q",
                              "author": "frostygrin",
                              "body": "This logic works for slower GPUs. It doesn't work for VRAM - because VRAM shortage can have catastrophic impact on performance and image quality. If you don't have a lot of money, it's highly unwise to spend it on something that will give you trouble in a couple of years.",
                              "score": 1,
                              "created_utc": 1748159278.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "mu440yd",
                          "author": "TrojanZebra",
                          "body": "> Where most players flock to 1440p and 4k\n\n1080p still has the largest market share",
                          "score": 0,
                          "created_utc": 1748142617.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu5mttz",
          "author": "Kered13",
          "body": "> and probably will for many years\n\nNo. Games are coming out now that already require more than 8 GB of VRAM on 1080p.",
          "score": 0,
          "created_utc": 1748173140.0,
          "replies": [
            {
              "id": "mu5r3uj",
              "author": "N-Haezer",
              "body": "Examples?",
              "score": 1,
              "created_utc": 1748175141.0,
              "replies": [
                {
                  "id": "mu6w8ti",
                  "author": "spudsandcheese",
                  "body": "Monster hunter wilds needs 6gb minimum on lowest absolute settings at 1080, and even then struggles hard to maintain a stable 30fps.",
                  "score": 1,
                  "created_utc": 1748189172.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu0rtps",
      "author": "andy10115",
      "body": "This is a dumb take.",
      "score": 4,
      "created_utc": 1748100002.0,
      "replies": []
    },
    {
      "id": "mu0ytd4",
      "author": "LessonStudio",
      "body": "I would argue differently. As a programmer, I will program to the limits of what is generally available. I would be reluctant to make anything for general consumers which would benefit much from a 24GB card. \n\nBut, if there were a fairly large number of them out there, I would. I would not make it so it had to have 24GB, but that it would be pretty spectacular if they did.\n\nFor example, the LOD game which is played where the trees in the distance do that mutate into more detailed trees as you approach, sort of thing would become less apparent with more RAM. \n\nOther cool programming elements could be used where extreme texture compression could be used where the textures are then decompressed into VRAM. You can't do this if you are having to dance the textures in and out of the card.\n\nAnd I suspect many many many other cool tricks would start showing up if 20+GB was common.\n\nPlus, as an ML person, having a card with 24GB would win many hearts and minds. One of the limitations with many ML tools right now is VRAM, not processing power of the GPU. \n\nMost of nvidia's profits are now coming from ML/AI people, not gamers. The AI world make their tools for nvidia because they have the best cards for this. But, if AMD had a reasonably priced card with 24GB or way more, then the AI world would start making tools for those. \n\nIf I had the choice between two cards for ML:\n\n* 48GB but half the compute power\n* 8GB, but full compute power. \n\nI would (as would most) choose the 48GB all day long.\n\nCUDA is an nivida thing, but if AMD put out a cheap high RAM card, programmers would figure it out; both ML and game companies. I suspect if you talk to the people at unreal about consumer 48GB cards, they would laugh and say, \"When that happens, we will take advantage of it, but those narrow minded fools aren't doing that for less than $5k any time soon. They want to milk the AI datacenters for as long as they can.\"\n\nI will make a prediction:\n\nThere will be a new entrant in the video card world. A chinese one. They will make a fairly crappy high VRAM card for an insanely low price. It will stumble and trip for the first few releases. But, it will find its footing and become a major competitor. The US will contemplate banning it saying it is spying on AI companies.",
      "score": 2,
      "created_utc": 1748102196.0,
      "replies": [
        {
          "id": "mu1kchj",
          "author": "Inprobamur",
          "body": "AI companies flush with VC money are happy to pay several times more for a GPU that can hold their full model in memory, making a cheap GPU with loads of VRAM will undercut that. \n\nAMD just announced AI Pro R9700 32GB for over $2500, giving out more VRAM for cheaper offerings would undercut that.",
          "score": 2,
          "created_utc": 1748109038.0,
          "replies": [
            {
              "id": "mu61twg",
              "author": "MrMPFR",
              "body": "That card is a joke when the 5090 has much more powerformance and the same amount of VRAM for a lower on paper MSRP.",
              "score": 1,
              "created_utc": 1748179442.0,
              "replies": [
                {
                  "id": "mu6244z",
                  "author": "Inprobamur",
                  "body": "You can't buy 5090 at MSRP.",
                  "score": 1,
                  "created_utc": 1748179546.0,
                  "replies": [
                    {
                      "id": "mu6fpaf",
                      "author": "MrMPFR",
                      "body": "*\"or a lower on paper MSRP.\"*\n\nI know. But even at the regular $3K price it's a massive upgrade over the AI Pro R9700 32GB. IDK about impact the of AMD's professional drivers but it's nowhere near NVIDIA's CUDA optimization and performance.",
                      "score": 1,
                      "created_utc": 1748184105.0,
                      "replies": [
                        {
                          "id": "mu6h7mh",
                          "author": "Inprobamur",
                          "body": "Many applications don't care about anything other than power cost and VRAM amount.",
                          "score": 1,
                          "created_utc": 1748184576.0,
                          "replies": [
                            {
                              "id": "mu6v8q0",
                              "author": "MrMPFR",
                              "body": "So it's a niche card then considering how much AI market has grown.",
                              "score": 1,
                              "created_utc": 1748188862.0,
                              "replies": [
                                {
                                  "id": "mu7142m",
                                  "author": "Inprobamur",
                                  "body": "I guess it very much depends on the eventual price, it's possible that for large orders the price will be much lower. Nvidia just can't meet the current full demand.",
                                  "score": 2,
                                  "created_utc": 1748190667.0,
                                  "replies": [
                                    {
                                      "id": "mu89bqn",
                                      "author": "MrMPFR",
                                      "body": "If AMD offers volume discounts then they could sell a lot of cards but likely not anything amazing going by their historical market share and sales numbers.",
                                      "score": 1,
                                      "created_utc": 1748204202.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mu61lo3",
          "author": "MrMPFR",
          "body": "The solution to the LOD issue is dynamic LOD leveraging mesh shaders similar to the solution in UE5, doesn't need more VRAM.\n\nNVIDIA already has a implementation of this and it's called NTC, decompresses to BCn on runtime as a fallback for cards with less inference processing power.\n\nThere's work graphs, procedural geomtry and textures, and many other VRAM conserving technologies on the way so what'll probably eat VRAM nextgen won't be the game rendering and simulation but the LLMs and SLMs running the game AI, systems and NPCs.\n\nThe thing about AI will 100% happen. The Bolt graphics Path tracing startup with slots for LPDDR5 will be replicated by a Chinese company.   \nSo basically a shitty 10nm based GPU with an insane two tier memory solution, fast LPDDR5X close to GPU or GDDR6 and slow but massive capacity (terabytes potentially) of DDR5 or LPDDR5 memory later as a slot-in upgrade.   \nAnd AMD and NVIDIA will be very pissed when high bandwidth flash (HBF) becomes a thing. Looking forward to the day that NVIDIA's sandcastle gets kicked over, they've gone too far + the current monopoly is not a good thing.",
          "score": 1,
          "created_utc": 1748179355.0,
          "replies": [
            {
              "id": "mud11wr",
              "author": "LessonStudio",
              "body": ">  a shitty 10nm based GPU with an insane two tier memory solution\n\nBrilliant. I want one.\n\n> Looking forward to the day that NVIDIA's sandcastle gets kicked over\n\nI don't think they understand this. They see customers clamoring for their latest and greatest; scalpers grabbing up zillions, and selling zillions, and think, \"Those fools will never switch.\"\n\nBut, then some youtube influencer with 50,000,000 followers will post a video, \"Is it game over for nvidia?\" where they demo some chinese card like you described, where they conclude, \"If you do these things, you should buy chinese, if you do these things, you should stick with nvidia, for now.\"\n\nThen, 6 months later they might post, \"nvidia is a a dead man walking\" where they show how unreal just released a new version which uses the chinese cards properly.\n\nThen nvidia will realize that what you said about their abuses is how most GPU buyers have long felt.\n\nOn the LOD, I was talking more broadly. The LOD shift isn't only when one tree makes the change, but whole piles of stuff do that switch. Often it is delayed because the LOD info such as textures wasn't in the GPU and had to be loaded. Having way more RAM would allow for way more crap to be loaded and ready to go.",
              "score": 2,
              "created_utc": 1748275367.0,
              "replies": [
                {
                  "id": "mud69i1",
                  "author": "MrMPFR",
                  "body": "They prob already know too late for inference. NVLINK fusion is an attempt to earn money on NVLINK IP and switches. Never imagined we would ever see it so yeah it probably is that bad.\n\nLol yeah that's how tech influencers work. The Chinese card will remain shitty its sole purpose is to kill every other product in the LLM inference market, but I would certainly love to see a cheapo GPU take over entry level and prebuilts.  \nEven if it's incredibly slow in terms of TOPS it really doesn't matter if it can fit the entire LLM in memory. For LLM memory capacity> processing speed, and they can always glue the dies together with the AMD zen approach. This is the approach taken by bolt graphics as well with the Zeus design that's undergoing FPGA validation ATM.\n\nCorrect me if I'm wrong but the latest UE5 games have zero issue with popin or delayed LOD switching. Dynamic LOD is literally magic and we'll see it in many more games, AC Shadows is another game that has it but not for foliage rn. TBH I would rather take that and have GPU VRAM used for something else than a brute force preloading of everything.",
                  "score": 1,
                  "created_utc": 1748276958.0,
                  "replies": [
                    {
                      "id": "mueo6h1",
                      "author": "LessonStudio",
                      "body": "> GPU VRAM used for something else\n\nAgreed. My point was more, that if developers know that a notable number of cards out there have way more RAM, they will figure out cool things to do with it.\n\nI don't think developer have any love for nvidia either. \n\nWhen you start doing ML, winning your first battle with nvidia drivers, cudnn, and cuda, is a right of passage.",
                      "score": 2,
                      "created_utc": 1748293458.0,
                      "replies": [
                        {
                          "id": "muicoqr",
                          "author": "MrMPFR",
                          "body": "Dor sure. Probably something AI related considering how much work graphs is going to reduce VRAM consumption (IIRC AMD had a demo at GDC 2024 showing \\~50-80X reduction).   \nPS6 gen is going to be interesting. If it uses a PCIe Gen5 SSD we might see some even more radical changes than PS5 IO which really hasn't been tapped out in most cases. Hoping this acts as a potential VRAM multiplier and allows devs to do more wild things assuming we're going to get 24GB and at best a 32GB PS6 console.\n\nYeah but try doing that on everyone else's HW. The unfortunate truth is that NVIDIA is the least bad AI HW vendor ATM for general use :C",
                          "score": 1,
                          "created_utc": 1748351162.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu1il5d",
      "author": "Xendrus",
      "body": "I have a 5080 (which is supposed to use super strong AI algorithms to help with the vram usage, even more than the 5090 due to its vram being faster) that rides at near maxed out vram constantly and I'm not even at 4k. They're smoking crack through an exhaust pipe.",
      "score": 2,
      "created_utc": 1748108486.0,
      "replies": []
    },
    {
      "id": "mu3by0v",
      "author": "Weird-Assignment4030",
      "body": "AMD is right. The hardware frontier of the market is increasingly niche.",
      "score": 2,
      "created_utc": 1748131390.0,
      "replies": []
    },
    {
      "id": "mu3d9e4",
      "author": "HappyDeadCat",
      "body": "Wtf is this, who are you people?\n\n\nI haven't seen a 1080 display outside of office settings in 10 years.",
      "score": 2,
      "created_utc": 1748131903.0,
      "replies": [
        {
          "id": "mu5uv7e",
          "author": "Primum_Agmen",
          "body": "The only 1080p displays in my office are the laptops.",
          "score": 1,
          "created_utc": 1748176749.0,
          "replies": []
        },
        {
          "id": "mu650de",
          "author": "Reshish",
          "body": "Still using my Philips 220CW 1680x1050 monitor I bought like 15yrs ago.  \n\nWorks fine, doesn't really seem to matter.",
          "score": 1,
          "created_utc": 1748180587.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0pwo4",
      "author": "bigersmaler",
      "body": "Most gamers are on mobile or consoles. If you\u2019re on a desktop seeking a newly launched discrete graphics solutions, yes - you require more than 8GB now. Just launch with a 16GB for $350. Why even bother?",
      "score": 2,
      "created_utc": 1748099403.0,
      "replies": []
    },
    {
      "id": "mu1me2t",
      "author": "rowdydave",
      "body": "My old 10gb 3080 maxed out in cyberpunk and despite having the horsepower to do heavy raytracing I couldn't enjoy all the features due to hitting the vram limit and stuttering.\n\nWhat's the point in buying any card that has 8gb unless its a severely budget card when you won't even be able to take advantage of the performance in AAA titles. \n\nHave a 16gb card now and regularly see 9gb or more usage, also had a 8gb 4060 at some point and had tons of issues hitting the cap at 1080p even.",
      "score": 2,
      "created_utc": 1748109680.0,
      "replies": []
    },
    {
      "id": "mu0kz1y",
      "author": "Eokokok",
      "body": "NVIDIA did the same. It is pretty obvious truth, but Reddit mob hellbent on pointless words like future proofing cannot grasp that their 600\u20ac+ xx70 cards are in fact not entry level.",
      "score": 2,
      "created_utc": 1748097848.0,
      "replies": [
        {
          "id": "mu0lv6q",
          "author": "Elon61",
          "body": "Reddit thinks VRAM is free and all GPUs should come with at least 16gb as a result.",
          "score": -2,
          "created_utc": 1748098133.0,
          "replies": [
            {
              "id": "mu13q4y",
              "author": "Aggravating-Dot132",
              "body": "For what it worth, it's actually \"free\". Vram chips cost \\~10-20$, so the card will end up with +50-80$ at max.",
              "score": 4,
              "created_utc": 1748103776.0,
              "replies": [
                {
                  "id": "mu14ckl",
                  "author": "Elon61",
                  "body": "even if we take your (as far as i know, unsourced) numbers at face value, 80$ on the BOM of a 300$ card is absolutely massive...\n\nThat's around the same level as the silicon cost. or cooler costs. calling it \"Free\" is insane,",
                  "score": 0,
                  "created_utc": 1748103978.0,
                  "replies": [
                    {
                      "id": "mu1jycy",
                      "author": "Aggravating-Dot132",
                      "body": "It's actually not that big, I just took the usual 20$ and doubled it for the sake of greed. Up to x4 times for extreme greed.\n\nVram, as per cost, isn't a problem.",
                      "score": 1,
                      "created_utc": 1748108916.0,
                      "replies": [
                        {
                          "id": "mu1olgt",
                          "author": "Elon61",
                          "body": "You're reading headlines from a few years ago which quote the min bin G6 spot price at the time of an industry glut. that'was never the cost anyone paid for the modules on a GPU.\n\nBesides, G7 costs *a lot* more, at around 10$ a GB. maybe volume discounts get it down a bit but even at 8$/GB you're still looking at 128$ for 16gb, which again is *bom cost*.\n\nThe 2$/gb cost is a myth which people keep perpetuating because it sounds compelling but is utterly detached from reality.",
                          "score": 2,
                          "created_utc": 1748110394.0,
                          "replies": [
                            {
                              "id": "mu5zlrw",
                              "author": "MrMPFR",
                              "body": "~~GDDR6 20gbps 2GB modules are available for 8GB new at $8 a piece on AliExpress last time I checked.~~\n\n~~Oh and BTW those~~ *widely quoted 8Gb* spot prices have remained low and went down another \\~33% in the mean time, *indicating demand has been reduced even further*. Even 16Gb ICs have remained at a low spot price of $4/GB quoted by [DRAMeXChange.com](http://DRAMeXChange.com) in late 2024 (*you need a free login to view it)*. *The 8Gb IC price for GDDR6 on their website is an average and just this week they quoted a low of 1.45, a high of 2.9 with an average of 2.3 bucks. The big players bypass the open market with futures contracts directly at the source (mem producer) so you can bet the prices they get is a lot lower than the spot price average.* \n\n30-50% volume discounts which isn't unheard of in the components space brings that price down to $16-22.4 for 8GB of GDDR6 20gbps for massive players that bypass the open market by going directly to the source.\n\nIt's not that expensive. Last year Trendforce said GDDR7 is only 20-30% more expensive than GDDR6.\n\n$2-3/GB for 16Gb GDDR6 ICs isn't unreasonable for someone like AMD. *Hardware Unboxed also keeps claiming 20-30 bucks for 8GB of VRAM and 30 bucks for the entire clamshell overhead (includes VRAM) vs the 8GB 9060XT card and they have contacts in the AIB space, so I don't think that number is just something they pulled out of thin air.*  \n*The most likely thing is that GDDR6 16Gb IC's costs somewhere between $2.5-3/GB and that GDDR7 using Trendforce's guideline costs somewhere around \\~$3.2-4/GB.*",
                              "score": 1,
                              "created_utc": 1748178614.0,
                              "replies": [
                                {
                                  "id": "muext2p",
                                  "author": "Elon61",
                                  "body": "You're making a few non-trivial assumptions here.\n\n> GDDR6 20gbps 2GB modules are available for 8GB new at $8 a piece on AliExpress last time I checked. \n\nHow do you know these are not knockoffs, fakes, or salvaged chips? I've personally purchased multiple times \"brand new\" \"100% original\" chips from random AE sellers. That was most definitely *not* what i got in the mail. \n\nI did a quick search, i found \"legit looking\" ones in the 9-15$ range. \n\nMeanwhile, Micron GDDR6 hovers at 20$/16gb on mouser, though i suppose that's also not particularly representative. \n\n> 30-50% volume discounts which isn't unheard of in the components space \n\nWhile that is certainly the case, i'm not sure why you would assume these parts are not already priced at volume-ish cost? i really doubt those sellers only got a few thousands chips, though i don't really know who they could be in the first place so who's to say really.",
                                  "score": 1,
                                  "created_utc": 1748296607.0,
                                  "replies": [
                                    {
                                      "id": "muii7om",
                                      "author": "MrMPFR",
                                      "body": "That's a fair point so I've deleted that section from the original comment. Also forgot that it was AliBaba that had the lowest prices not AliExpress. Searched for this IC \"K4ZAF325BC-SC20\" used by Intel B580.  \nBut the pricing they gave was unit price not volume discounted price. With a larger order they'll probably sell for a much lower price.\n\nAlso please read the changes in the original comment that info is a lot more interesting than some shady AliExpress or AliBaba seller who sell refurbished ICs as new.",
                                      "score": 1,
                                      "created_utc": 1748353071.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mu5xg1d",
                  "author": "MrMPFR",
                  "body": "The cost with volume discounts is likely closer to $15-20 for 8GB of 20gbps GDDR6. Last I checked you could literally buy new GDDR6 20gbps 2GB modules off AliExpress at 8 bucks a piece.\n\nAdd a few extra bucks for different PCB, extra ICs and a backplate and the total cost for a clamshell shouldn't be more than $20-25. With channel markups and reasonable gross margin for AMD the $50 markup seems fair, although they did use to sell the extra VRAM overhead for higher GB moduls at close to cost.",
                  "score": 0,
                  "created_utc": 1748177785.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mu0nf6i",
              "author": "Eokokok",
              "body": "Not all, mate, only entry level. 24 for mid range, 32 for high end. That's why Reddit GPUs are killing the industry as best value per dollar.",
              "score": 1,
              "created_utc": 1748098626.0,
              "replies": [
                {
                  "id": "mu0ox5w",
                  "author": "UnsorryCanadian",
                  "body": "You said reddit, did you mean intel or AMD?",
                  "score": -1,
                  "created_utc": 1748099093.0,
                  "replies": [
                    {
                      "id": "mu0s1x8",
                      "author": "Eokokok",
                      "body": "No, I mean the imaginary Reddit GPUs, more VRAM and 100\u20ac below competition at every price bracket.",
                      "score": 2,
                      "created_utc": 1748100074.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu0uzg0",
      "author": "ackillesBAC",
      "body": "For 1080p sure, at the moment. \n\nBut also look at the future of storage. The bus and the storage will be as fast as VRAM so minimal VRAM will be all that's needed.",
      "score": 1,
      "created_utc": 1748100992.0,
      "replies": [
        {
          "id": "mu606cq",
          "author": "MrMPFR",
          "body": "100%. Work graphs, +10GB/S PCIE5.0 drives, neural shaders and other stuff arriving with 10th gen will reduce VRAM usage massively. The only thing I can see consuming massive amounts of VRAM in future games are various LLMs for AI and NPCs.",
          "score": 1,
          "created_utc": 1748178830.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu1bin7",
      "author": "lolschrauber",
      "body": "I don't pay too much attention but a ton of people are still on 1080p and most common cards don't run very high settings propably.\n\nIf the games are optimized well it could barely be enough i think?",
      "score": 1,
      "created_utc": 1748106272.0,
      "replies": []
    },
    {
      "id": "mu1dwgl",
      "author": "Reshish",
      "body": "There's probably some truth to that.  \n\nMost people probably don't push for high or ultra settings, and 8gb is currently the 'standard' for low/medium settings.\n\nHowever most people also will use a video card for probably ~5yrs, and in a few years I imagine even low/medium settings will need more than 8gb.\n\nFrom that perspective it's kinda a dick move to push an 8gb card, since it's got a baked in obsolescence that'll make people replace it with a newer card sooner.",
      "score": 1,
      "created_utc": 1748107021.0,
      "replies": [
        {
          "id": "mu634hq",
          "author": "MrMPFR",
          "body": "It won't change as long as the XSS is supported, easily another +4 years. The current situation won't change for the worse, we'll just see more games having issues, not a worsening of issues where some games require 10GB to even run 1080p low. Notice how proper nextgen games are not the worst examples, it's always games with broken or \"midgen last minute tagged on nextgen features\" engine. IIRC UE5 doesn't have any issues with 8GB at 1080p.\n\nBut buying a +$299 card only to play 1080p low in some newer games is completely unacceptable behavior  by AMD and NVIDIA. Nextgen has to be 12GB minimum, no more 8GB products.",
          "score": 1,
          "created_utc": 1748179915.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu1eqei",
      "author": "ScornedSloth",
      "body": "It's mostly true for now at 1080p as long as you aren't using ultra settings. That being said, the fact that they're making this statement just demonstrates that they're out of touch with the sentiment of well-informed gamers. The issue is when someone less-informed buys an 8gb card with the same model name and expects it to just work.",
      "score": 1,
      "created_utc": 1748107285.0,
      "replies": []
    },
    {
      "id": "mu1jdwv",
      "author": "NoMore414",
      "body": "I had a 3070 with 8GB of ram and it ran star citizen like absolute shit, so I upgraded to a 3070 with 12GB of ram same clock speed and all and it ran significantly better. AMD can lick my sack.",
      "score": 1,
      "created_utc": 1748108737.0,
      "replies": []
    },
    {
      "id": "mu1jjvd",
      "author": "deadfishlog",
      "body": "A-Ok when AMD says it and does it apparently",
      "score": 1,
      "created_utc": 1748108789.0,
      "replies": []
    },
    {
      "id": "mu24xmv",
      "author": "InvadedRS",
      "body": "It\u2019s a shame man",
      "score": 1,
      "created_utc": 1748115898.0,
      "replies": []
    },
    {
      "id": "mu2dh89",
      "author": "flyingcircusdog",
      "body": "Technically that's probably correct, but those players are also the same ones good to keep using old cards. Your newest product needs to be better than your old ones.",
      "score": 1,
      "created_utc": 1748118847.0,
      "replies": []
    },
    {
      "id": "mu2e6uy",
      "author": "madpropz",
      "body": "VR needs all the VRAM it can get, it's never enough \ud83d\ude05",
      "score": 1,
      "created_utc": 1748119086.0,
      "replies": []
    },
    {
      "id": "mu2swp0",
      "author": "softwarebuyer2015",
      "body": "great way to drive sales.\n\nno gamer thinks of themselves as  'most gamers'",
      "score": 1,
      "created_utc": 1748124228.0,
      "replies": []
    },
    {
      "id": "mu2u7en",
      "author": "MrEdinLaw",
      "body": "Man the same article gets posted by the same people every few hours a day on each sub with the trash title that doesn't support the text in it.",
      "score": 1,
      "created_utc": 1748124707.0,
      "replies": []
    },
    {
      "id": "mu2u7ua",
      "author": "Altruistic_Koala_122",
      "body": "Can't wait until we can download more vram.",
      "score": 1,
      "created_utc": 1748124711.0,
      "replies": []
    },
    {
      "id": "mu31do3",
      "author": "SolarSailer2022",
      "body": "I have a 3060 with 12GB VRAM. I've always been a bit puzzled by it, because I can get over 100fps but only on lower settings, IE I can never seem to utilize the VRAM fully. Maybe it's because I play in 1440 and not 1080",
      "score": 1,
      "created_utc": 1748127409.0,
      "replies": []
    },
    {
      "id": "mu33pv1",
      "author": "zpedroteixeira1",
      "body": "Those users will get a lot better value by buying second hand GPUs.",
      "score": 1,
      "created_utc": 1748128280.0,
      "replies": []
    },
    {
      "id": "mu3kedr",
      "author": "jert3",
      "body": "VRAM has never really meant anything up until AI/LLMs happened.  It's never had much of any use in gaming to have a 16gb card over an  8gb card in anything besides artificial benchmarks.",
      "score": 1,
      "created_utc": 1748134690.0,
      "replies": []
    },
    {
      "id": "mu4695t",
      "author": "Zingledot",
      "body": "IIRC, the launch 3080 was condemned for its 10gb, then kicked AMD's butt in 4k and even 8k, despite having 6 gb less memory. Different strategy using really expensive memory vs more cheap stuff.",
      "score": 1,
      "created_utc": 1748143627.0,
      "replies": []
    },
    {
      "id": "mu4iej9",
      "author": "Mistrblank",
      "body": "The games being developed today though need more.   I want to be able to play those too.",
      "score": 1,
      "created_utc": 1748149587.0,
      "replies": []
    },
    {
      "id": "mu4o3gs",
      "author": "stacker55",
      "body": "meanwhile doom is sitting at over 8gb used at medium settings",
      "score": 1,
      "created_utc": 1748152713.0,
      "replies": []
    },
    {
      "id": "mu4q71e",
      "author": "Snowblind45",
      "body": "expensive nvidia with house burning risk and crazy amd with low VRAM with crappy 3D modelling performance. And can't forget Intel with their kamikaze CPUs.",
      "score": 1,
      "created_utc": 1748153933.0,
      "replies": []
    },
    {
      "id": "mu4s455",
      "author": "semperknight",
      "body": "I don't get PC gamers at all and I am one.\n\nWhy is 1080p (which is what 8GB GPU is for), the norm?\n\nWalmart sells 70in 4k TV's for a few hundred during sales. 1440p gaming monitors go for $170. Why is everyone still using 1080?",
      "score": 1,
      "created_utc": 1748155070.0,
      "replies": []
    },
    {
      "id": "mu548w2",
      "author": "BohunkFunk",
      "body": "I just always wonder if it's worth to split the 8gb and 16gb, or if it'd be better for stock to focus on shipping one model or not. \n\nBut I do like the notion for this, if it's truly cheaper to make and sell the 8gb then screw it, do so. It'll help the 1080p esport gamers. And at least they don't neuter their chips or build off the previous fen architecture and name it the same thing. Fuck Nvidia for that.",
      "score": 1,
      "created_utc": 1748162378.0,
      "replies": []
    },
    {
      "id": "mu5ah0v",
      "author": "worldtriggerfanman",
      "body": "The fact there's a market for it means that market isn't gonna give a crap about this statement no matter what people think. It's good to have options.",
      "score": 1,
      "created_utc": 1748166257.0,
      "replies": []
    },
    {
      "id": "mu5fbbv",
      "author": "IT_techsupport",
      "body": "Amd never misses an oportunity.....",
      "score": 1,
      "created_utc": 1748169152.0,
      "replies": []
    },
    {
      "id": "mu5g1ow",
      "author": "brbcatsranaway",
      "body": "lol",
      "score": 1,
      "created_utc": 1748169576.0,
      "replies": []
    },
    {
      "id": "mu5pw89",
      "author": "Kuraiyuki",
      "body": "I used an RX6600 8GB for most of last year, good solid card and never let me down, but for some games I needed more VRAM, so I bought a RX 7800 XT 16GB, it will be fine for years, and had also been solid.\n\nIt all depends on what you do/play.\n\nIf your playing older games it's fine to have 8GB, I play/stream a mixture of older and newer games.\n\nGo for what you need, 8GB is still good.",
      "score": 1,
      "created_utc": 1748174595.0,
      "replies": []
    },
    {
      "id": "mu5svwr",
      "author": "ArnoldViniick",
      "body": "Ok,  so why not give it 10GB like the 3080 10GB?",
      "score": 1,
      "created_utc": 1748175911.0,
      "replies": []
    },
    {
      "id": "mu5tqio",
      "author": "None",
      "body": "Are VRAM chips really so expensive?",
      "score": 1,
      "created_utc": 1748176278.0,
      "replies": []
    },
    {
      "id": "mu658ft",
      "author": "Confident_Warning_32",
      "body": "Alcohol companies said most people don\u2019t need more than 1 drink\u2026",
      "score": 1,
      "created_utc": 1748180666.0,
      "replies": []
    },
    {
      "id": "mu6jcuj",
      "author": "LouisSal",
      "body": "What AMD said is true. Influencers make customers feel that they need is max performance",
      "score": 1,
      "created_utc": 1748185245.0,
      "replies": []
    },
    {
      "id": "mu6wgw8",
      "author": "allquckedup",
      "body": "Yeah. Bill Gates said something similar about computer several decades ago.  Didn\u2019t turn out that way did it? I know I have 32 GB off RAM.",
      "score": 1,
      "created_utc": 1748189241.0,
      "replies": [
        {
          "id": "mu7164g",
          "author": "TEDCOR",
          "body": "I remember those days. Our first x86 PC was a Seanix with a 1.6GB hard drive. My brother and I split a 13GB drive which cost just over $200 in maybe 1999 or 2000.",
          "score": 2,
          "created_utc": 1748190684.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu6wth6",
      "author": "Awkward_Pangolin3254",
      "body": "I'm still glad they went with 16GB on the 9070xt though. Dropping $700 on a new card with the same amount of RAM as my 10yo RX 480 would've been hard to stomach.",
      "score": 1,
      "created_utc": 1748189348.0,
      "replies": []
    },
    {
      "id": "mu72nn2",
      "author": "Alienhaslanded",
      "body": "All gamers need at least 12GB of VRAM with all of those terribly optimized games.",
      "score": 1,
      "created_utc": 1748191125.0,
      "replies": []
    },
    {
      "id": "mu7isji",
      "author": "azzers214",
      "body": "Straight up the standard gamer in 2025 doesn't demand graphical improvements year after year.\n\nThis wouldn't fly in 2000-2015 but it is what it is.  Unless gamers demand more from game companies or the technology there's absolutely no purpose in either spending more money for something only a fraction of the gaming market wants.\n\nIf they want to move the market, I'd actually suggest esports begin implementing minimum resolutions that icrease over time.  Other than that performance will always be sought which is easier at lower resolutions.",
      "score": 1,
      "created_utc": 1748195842.0,
      "replies": []
    },
    {
      "id": "mu92pow",
      "author": "CapmyCup",
      "body": "Wtf you mean \"gamers\" when it's GAMES that are hungry for VRAM ffs...",
      "score": 1,
      "created_utc": 1748214205.0,
      "replies": []
    },
    {
      "id": "mu9wuv0",
      "author": "Kyonkanno",
      "body": "I for one dont mind them offering a 8gb card. Just price it accordingly and i might even buy it",
      "score": 1,
      "created_utc": 1748225506.0,
      "replies": []
    },
    {
      "id": "mu9zuxf",
      "author": "lastreadlastyear",
      "body": "Hen why do amd cards suck compared ?",
      "score": 1,
      "created_utc": 1748226655.0,
      "replies": []
    },
    {
      "id": "mu9zzuw",
      "author": "NoGoodMarw",
      "body": "Upgraded fr 6gb card last year, Vram wasnt the issue at any point, i was just fucked due to general performance. The title seems on point or technically correct if someone is picky.\n\nMost people are also super lax with what they expect from performance.",
      "score": 1,
      "created_utc": 1748226709.0,
      "replies": []
    },
    {
      "id": "mua2j0q",
      "author": "NeurogenesisWizard",
      "body": "If it aint broke don't fix it, and Indie games are a thing too. To get the AAA experience people might choose consoles.",
      "score": 1,
      "created_utc": 1748227695.0,
      "replies": []
    },
    {
      "id": "muabxv0",
      "author": "showyourdata",
      "body": "true.. also, most gamer don't play triple A games.\n\nMaybe don't us gamers and use actual game number from triple a games?",
      "score": 1,
      "created_utc": 1748231605.0,
      "replies": []
    },
    {
      "id": "muaxfsp",
      "author": "SniperPilot",
      "body": "Fuck you AMD",
      "score": 1,
      "created_utc": 1748242464.0,
      "replies": []
    },
    {
      "id": "muf1om7",
      "author": "FashionBusking",
      "body": "Remember when a\"Tech Pundit\" who claimed that nobody would need more than 128 MB of memory?  \n\nWe don't hear from that guy anymore.\n\nBut now there's THIS GUY.",
      "score": 1,
      "created_utc": 1748297957.0,
      "replies": []
    },
    {
      "id": "mufxv8p",
      "author": "Arch3m",
      "body": "Tell that to my 1080ti and its 12 GB of VRAM. If a card released 8 years ago was getting more than 8GB, why should we have to settle for less today?",
      "score": 1,
      "created_utc": 1748309568.0,
      "replies": []
    },
    {
      "id": "mugr8om",
      "author": "MostAnonEver",
      "body": "amd can claim what they want, gamers will buy what they want. And just let the data reflect that their claims are their own claims and not representative of the broad consumer market.",
      "score": 1,
      "created_utc": 1748321507.0,
      "replies": [
        {
          "id": "muh9xqm",
          "author": "None",
          "body": "[deleted]",
          "score": 1,
          "created_utc": 1748331826.0,
          "replies": [
            {
              "id": "muhd0qq",
              "author": "MostAnonEver",
              "body": "I'm sure some people will want it for sure. But its definitely not recommended because it limits future use as games are more and more demanding. Its definitely worth the \\~50 bucks more to pick up 16gb vs 8gb unless youre looking to swap gpus in a few years.",
              "score": 1,
              "created_utc": 1748333712.0,
              "replies": [
                {
                  "id": "muhdjad",
                  "author": "None",
                  "body": "[deleted]",
                  "score": 1,
                  "created_utc": 1748334039.0,
                  "replies": [
                    {
                      "id": "muhegns",
                      "author": "MostAnonEver",
                      "body": "The issue isnt its existence. Its the false advertising nonsense that people want to stop. Dont sell us the 9060xt and market it for 1440p gaming and then come out and say 8gb is perfectly fine for 1080p because you know 8gb for 1440p is sht. People dont want amd to become another nvidia where they start announcing 4090 lvs of performance at \"549\" 5070 ti kekw. Shts fake af and everyone know it. Theres also a reason why nvidia doing some real shady sht with reviewers rn that you may or may not believe depending how much nvidia copium you on.",
                      "score": 1,
                      "created_utc": 1748334621.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "muii89i",
      "author": "Yama-k",
      "body": "Completely valid claim for a budget card",
      "score": 1,
      "created_utc": 1748353076.0,
      "replies": []
    },
    {
      "id": "muuiq6k",
      "author": "weissmanhyperion",
      "body": "What we need is game optimization and not unfinished early access bullshit sold as full release with the promise of future support if shit goes sideways.",
      "score": 1,
      "created_utc": 1748505936.0,
      "replies": []
    },
    {
      "id": "mu0kjn0",
      "author": "azab189",
      "body": "Frank at it again",
      "score": 1,
      "created_utc": 1748097711.0,
      "replies": []
    },
    {
      "id": "mu28xgc",
      "author": "ParaGord",
      "body": "640k should be enough for anyone",
      "score": 2,
      "created_utc": 1748117296.0,
      "replies": []
    },
    {
      "id": "mu0sntl",
      "author": "DDFoster96",
      "body": "\"No one will ever need more than 640k of RAM\"",
      "score": 1,
      "created_utc": 1748100265.0,
      "replies": []
    },
    {
      "id": "mu0ub5g",
      "author": "heatlesssun",
      "body": "Yeah, AMD ain't the patron saint of PC gaming that some nVidia haters think.",
      "score": 1,
      "created_utc": 1748100782.0,
      "replies": []
    },
    {
      "id": "mu0vym1",
      "author": "TCLG6x6",
      "body": "And i nearly believed that AMD finally got a grip in the GPU market.",
      "score": 1,
      "created_utc": 1748101297.0,
      "replies": []
    },
    {
      "id": "mu11f1l",
      "author": "XVO668",
      "body": "If devs are using less power hungry code and optimized engines, then yes 8gb is way too much.  \nBut lazynes and the \"we patch it after release\" mentality is having us buy more RAM, faster CPU's and last but not least GPU's with more VRAM.",
      "score": 1,
      "created_utc": 1748103028.0,
      "replies": [
        {
          "id": "mu62baw",
          "author": "MrMPFR",
          "body": "Games are made for console and then ported to PC. This has nothing to do with optimization and everything to do with PS5's doubled memory capacity over PS4. Devs are not going to bother making their game runnable at anything higher than low-medium 1080p on garbage tier compromised GPUs.\n\nThis is coming from a garbage tier 1060 6GB owner BTW.",
          "score": 1,
          "created_utc": 1748179620.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu1tseo",
      "author": "TakeTheWheelTV",
      "body": "You ain\u2019t gunna tell gamers what they need. Of any group, this isn\u2019t who you wanna war with lol",
      "score": 1,
      "created_utc": 1748112103.0,
      "replies": []
    },
    {
      "id": "mu3qdju",
      "author": "Blapanda",
      "body": "Wow, that is probably the reason why they showed the 8Gb Model for like 3 seconds and switched to another presentation layer of something else!!! /s",
      "score": 1,
      "created_utc": 1748137027.0,
      "replies": [
        {
          "id": "mu424qj",
          "author": "mromutt",
          "body": "And why all but one of the 9060 at computex was a 16gb model XD",
          "score": 1,
          "created_utc": 1748141781.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu3t58h",
      "author": "Random-Name-7160",
      "body": "Why is this news? He\u2019s absolutely correct. Market studies and data collected by Steam shows this to be true. That most people who casually play games don\u2019t need a card with more than 8gb. For them, paying a premium for a better card is a waste.\n\nHe also acknowledges that there are people like me. I\u2019m not an average gamer, I\u2019m an enthusiast. I prefer using larger, higher resolution monitors at smoother frame rate for longer gaming sessions, and I benefit from higher memory cards as a result. And there is a 16gb card for that too.\n\nSo, why the hell are people upset about this?? It makes no sense to me. \n\nIf you\u2019re going to direct anger anywhere, it should be at the scalpers, Nvidia\u2019s hostile business model, the Trump tariffs, China\u2019s hoarding of rare earth metals, and the rapid expansion of AI and digital currencies reliance of GPU hardware.\n\nIf anything, AMD should get some praise here for not abandoning the gaming community, or treating them like a third rate market and a liability. And Intel for rapidly investing in the GPU segment for AI, but also ensuring an offshoot for consumer gaming, a far less profitable market.",
      "score": 1,
      "created_utc": 1748138110.0,
      "replies": []
    },
    {
      "id": "mu0ssfs",
      "author": "mjh2901",
      "body": "With limited fab time available to make chips, are they  intentionally trying to limit vram to push ai shops to other products and not decimate gaming cards?",
      "score": 1,
      "created_utc": 1748100305.0,
      "replies": [
        {
          "id": "mu5zx6c",
          "author": "MrMPFR",
          "body": "No one is getting a 16GB card for AI, 24GB is the bare minimum. There's simply no excuse for the 8GB version of 9060XT.",
          "score": 1,
          "created_utc": 1748178734.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu17ue7",
      "author": "nice_guy_threeve",
      "body": "This could easily be true if the most demanding games spent more time on optimization.  But, because the processing power exists, they mostly don't have to.",
      "score": 1,
      "created_utc": 1748105111.0,
      "replies": []
    },
    {
      "id": "mu1cp6s",
      "author": "Grimzkunk",
      "body": "It doesn't take a degree to confirm that 12gb is required for 1440p on current demanding games and that 16gb will probably cover 1440p in 2-3 years from now demanding games.\n\nCan someone from Rockstar call AMD?",
      "score": 1,
      "created_utc": 1748106645.0,
      "replies": []
    },
    {
      "id": "mu1emsr",
      "author": "PetThatKitten",
      "body": "8gb is enough for 1080p\n\nDEFINITELY not for 1440p\n\nIve had both a 8gb and a 16gb vram card.",
      "score": 1,
      "created_utc": 1748107253.0,
      "replies": []
    },
    {
      "id": "mu1eol4",
      "author": "akaMichAnthony",
      "body": "Need vs want are two different conversations.  Maybe they\u2019re correct about the need part, maybe they\u2019re not.  \n\nGamers WANT more though, they want progress and improvement.  If 8GB VRAM keeps us at 1080, 60FPS then gamers WANT more VRAM.",
      "score": 1,
      "created_utc": 1748107269.0,
      "replies": []
    },
    {
      "id": "mu1itux",
      "author": "karduar",
      "body": "This is accurate. Most gamers play 1080p still. 8gb is fine for 1080p high in MOST situations.",
      "score": 1,
      "created_utc": 1748108562.0,
      "replies": [
        {
          "id": "mu6biud",
          "author": "MrMPFR",
          "body": "Yeah until it isn't. There are so many games by now that struggles beyond 1080p medium that it can no longer be ignored and we'll only see more of these games.",
          "score": 0,
          "created_utc": 1748182757.0,
          "replies": [
            {
              "id": "mu6bwpo",
              "author": "karduar",
              "body": "The issue with a lot of these games struggling is not a graphics issue. So many developers don't optimize their games and hope dlss/fsr will fix their performance.",
              "score": 2,
              "created_utc": 1748182881.0,
              "replies": [
                {
                  "id": "mu6q4o7",
                  "author": "MrMPFR",
                  "body": "The games literally run out of VRAM. See HUB's 5060 TI 8GB vs 16GB testing. This has nothing to do with optimization. PS5 has a certain amount of RAM and PC better meet or exceed that. This has been true for every single console generation.",
                  "score": 1,
                  "created_utc": 1748187325.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu1n5rk",
      "author": "econ101ispropaganda",
      "body": "Buying a graphics card has gotten so dumb i literally buy books now instead.",
      "score": 1,
      "created_utc": 1748109927.0,
      "replies": []
    },
    {
      "id": "mu20u05",
      "author": "Deliriousious",
      "body": "Most games I have played use virtually all of it\u2026 If 12gb is not enough\u2026 8gb really isn\u2019t enough.",
      "score": 1,
      "created_utc": 1748114469.0,
      "replies": []
    },
    {
      "id": "mu2791m",
      "author": "Tankeverket",
      "body": "10gb is barely enough anymore",
      "score": 1,
      "created_utc": 1748116711.0,
      "replies": []
    },
    {
      "id": "mu2ay2f",
      "author": "TheActualBranchTree",
      "body": "They shouldn't telling the gamers this, but rather the game developers.",
      "score": 1,
      "created_utc": 1748117993.0,
      "replies": []
    },
    {
      "id": "mu2ez1n",
      "author": "Nkechinyerembi",
      "body": "It is true, RIGHT NOW, but it does not support any kind of future proofing whatsoever. Do you need more than 8gig for 1080p- up to like 2560x1080... probably not right now, but that is rapidly not becoming the case. My old vega 64 frontier has 16 gig, and that is likely the only reason it is still any good at all.",
      "score": 1,
      "created_utc": 1748119348.0,
      "replies": []
    },
    {
      "id": "mu2hika",
      "author": "xSTSxZerglingOne",
      "body": "Can't have your card being relevant longer than a year or two. That would be unacceptable to the shareholders.",
      "score": 1,
      "created_utc": 1748120202.0,
      "replies": []
    },
    {
      "id": "mu34jwd",
      "author": "AmbientToast",
      "body": "I understand the logic and reasoning but the new minimum standard for these types of cards should be 12GB.",
      "score": 1,
      "created_utc": 1748128593.0,
      "replies": []
    },
    {
      "id": "mu4o9q1",
      "author": "Jmackles",
      "body": "IMO the problem is optimization these days. I don\u2019t care about hyper realistic games. I want a game that efficiently runs and feels good to play. We crossed that hurdle years ago but each new gen of games seems to interpret the release of a new gen of console as a challenge to use all of its power versus just making good use of it. On the other hand, idk wtf I\u2019m talking about",
      "score": 1,
      "created_utc": 1748152812.0,
      "replies": []
    },
    {
      "id": "mu4qwdh",
      "author": "ITGuy7337",
      "body": "Reddit doesn't want to accept that anyone should be able to play PC games at less than 1440p ultra settings.",
      "score": 1,
      "created_utc": 1748154347.0,
      "replies": []
    },
    {
      "id": "mu5xn2o",
      "author": "hyperforms9988",
      "body": "I don't see the point of the 8 GB version even existing to be honest.  Sure, some gamers aren't going to need it, but we're talking about a price difference of $50 between the 8 and 16 GB versions.  Is $50 really going to be a huge dealbreaker for people considering the doubling of VRAM?  They may not *need* it right now now now, but they may eventually, and that extra $50 may give them an extra couple of years of use with a greater library of games to play comfortably.  That should be well worth an extra $50 I would think to just about everybody.  $50 is what... like two fucking skins in a lot of games now? **There's** something you don't *need*.",
      "score": 1,
      "created_utc": 1748177859.0,
      "replies": []
    },
    {
      "id": "mu0i6cn",
      "author": "chrisdh79",
      "body": "From the article: AMD has stuck its head above the parapet in the increasingly fraught GPU VRAM discussion, with the company's chief architect of gaming solutions, and former Alienware co-founder, Frank Azor, claiming that most gamers have \"no use for more than 8GB\" of memory on their graphics cards. The statement follows the launch of the AMD Radeon RX 9060 XT, which comes in both 8GB and 16GB versions, and Nvidia coming under heavy criticism for only including 8GB of memory on the GeForce RTX 5060.\n\nAs I've just found in my Nvidia GeForce RTX 5060 review, 8GB is still just about enough memory to run many of the latest games at decent settings, as long as you don't go above a resolution of 1,920 x 1,080. However, demanding titles such as Indiana Jones and the Great Circle are already pushing VRAM requirements hard, with the RTX 5060 unable to cope with this game above the Medium graphics preset, even at 1080p, simply because it doesn't have enough memory. With the Radeon RX 9060 XT release date coming soon, it looks as though AMD is keen to stick up for the cheaper version of its new GPU.\n\nFrank Azor made the statement in a post on X (formerly Twitter), where he replied to PC hardware YouTuber Michael Quesada, who asked how putting 8GB of VRAM on a new graphics card can be justified in 2025. In response, Azor said that the \"majority of gamers are still playing at 1080p and have no use for more than 8GB of memory, adding that the \"most played games WW [worldwide] are mostly esports games. We wouldn't build it if there wasn't a market for it. If 8GB isn't right for you then there's 16GB. Same GPU, no compromise, just memory options.\"",
      "score": 0,
      "created_utc": 1748096954.0,
      "replies": [
        {
          "id": "mu0k66e",
          "author": "shofmon88",
          "body": "\u201cWe wouldn't build it if there wasn't a market for it. If 8GB isn't right for you then there's 16GB. Same GPU, no compromise, just memory options.\u201d\n\nThis\u2026 seems reasonable? Certainly it seems a better approach than Nvidia\u2019s at the moment.\u00a0",
          "score": 12,
          "created_utc": 1748097590.0,
          "replies": [
            {
              "id": "mu0ql2w",
              "author": "MiloIsTheBest",
              "body": "It seems reasonable because it's weasel words. The memory option is the compromise. It is entirely a compromised card.\u00a0\n\n\nCoulda made it a different card entirely* (edit) if it has a different purpose, but they didn't. They just followed NVIDIAs lead.",
              "score": -6,
              "created_utc": 1748099616.0,
              "replies": [
                {
                  "id": "mu0sg9l",
                  "author": "IolausTelcontar",
                  "body": "That isn\u2019t what a SKU is (stock keeping unit). The different 9060 XTs with different RAM have different SKUs.\n\nNow if you meant they should have different names to make it more obvious they have different specs, I don\u2019t disagree.",
                  "score": 1,
                  "created_utc": 1748100198.0,
                  "replies": [
                    {
                      "id": "mu0us4w",
                      "author": "MiloIsTheBest",
                      "body": "Yeah fine and in fact the different models from different AIBs are different SKUs. Slip of the finger.\u00a0\n\n\nI still think they shouldn't exist. New hardware shouldn't be coming out designed solely to run OLD games.",
                      "score": 3,
                      "created_utc": 1748100930.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mu2k3ud",
      "author": "whatnowwproductions",
      "body": "This is only correct in their hypothetical world where devs are using proper optimization techniques.",
      "score": 0,
      "created_utc": 1748121092.0,
      "replies": []
    },
    {
      "id": "mu0n5vs",
      "author": "xenocrows",
      "body": "And most gamers don't need GPU after they will became no gamers",
      "score": 0,
      "created_utc": 1748098545.0,
      "replies": []
    },
    {
      "id": "mu0szbp",
      "author": "valqyrie",
      "body": "Bullshit. For most consumers maybe, most \"gamers\" certainly need more than 8gb as news games eat more than 8gb vram even in 1080p. Unless they are willing to pay $300+ for a brand new card which requires them to turn down some settings otherwise it will stutter like hell in some certain games.",
      "score": 0,
      "created_utc": 1748100364.0,
      "replies": []
    },
    {
      "id": "mu0upe1",
      "author": "zyval",
      "body": "1440p is going mainstream and for that 8 gb is not enough for some games now. If you don't plan to upgrade soon you may have issues running new games down the road. \n\nWe are in the age of companies trying to justify worse prices and less inovation, so what do you expect from marketing?",
      "score": 0,
      "created_utc": 1748100905.0,
      "replies": []
    },
    {
      "id": "mu0wsha",
      "author": "Flight2039Down",
      "body": "Why do companies keep telling their customers what they need.  Make the product and let them decide.  AMD has a good chance to gain some marketshare from NVidia if NVidia keeps being shady, and they squander it with comments like this.",
      "score": 0,
      "created_utc": 1748101555.0,
      "replies": []
    },
    {
      "id": "mu1d7uq",
      "author": "remghoost7",
      "body": "It's going to be very interesting when the \"first\" hit game to use a real-time machine learning model comes into play.  \nEither image/mesh generation, text generation, text to speech, etc.\n\nThese models *demand* large amounts of VRAM.   \n8GB is barely enough for an SDXL model (by itself).\n\nImagine you have a procedurally generated game that generates meshes/models/textures on the fly based on user input.  \nYou're looking at at least 8-10GB *just for the AI models and context window.* That's not including the game itself.\n\nIn the next year or two, I'm guessing we're going to start seeing VRAM requirements in the 16GB range *for indie games*.  \nProbably specific requirements for Nvidia cards as well (since ROCm is nowhere near as mature as CUDA).\n\ntl;dr - Don't buy a card with less than 12GB of VRAM. More VRAM will be more beneficial than a 5% speed increase on a comparative card.",
      "score": 0,
      "created_utc": 1748106808.0,
      "replies": [
        {
          "id": "mu6cgvb",
          "author": "MrMPFR",
          "body": "What you're describing is so far out and out of reach of most gamer PCs that we won't see it until the PS6 generation post crossgen.  \nBut yeah don't buy a new 8GB card.",
          "score": 2,
          "created_utc": 1748183061.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu1gslq",
      "author": "Tommy__want__wingy",
      "body": "Clearly AMD doesn\u2019t look at the blades of grass.",
      "score": 0,
      "created_utc": 1748107924.0,
      "replies": []
    },
    {
      "id": "mu258tr",
      "author": "Thund3rF000t",
      "body": "Sorry but 16GB is the absolute minimum unless your purely playing 1080P. if you are doing 2K or 4K aka 1440P or higher you need at least 16GB!",
      "score": 0,
      "created_utc": 1748116006.0,
      "replies": [
        {
          "id": "mub37o6",
          "author": "Drestlin",
          "body": "2k = either DCI 2k (2048x1080) or 1920x1080  \n4k is either DCI 4k (4096x2160) or 3840x2160\n\n1920x2 = 3840\n\n2k is 1080p and not 1440p",
          "score": 1,
          "created_utc": 1748245805.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu2ifsf",
      "author": "megadarren",
      "body": "amd gpus will always be ass, driver support is fucking abysmal, banking on absurd marketing ploys is only gonna hurt them harder",
      "score": 0,
      "created_utc": 1748120516.0,
      "replies": []
    },
    {
      "id": "mu32jdd",
      "author": "cwm9",
      "body": "They are so shooting themselves in the foot.\n\nBoth AMD and nVidia are leaving the door wide open for Intel. \n\nThe 2nd gen ARC B60 is going to cost $500, have 24GB of RAM, and a dual shared memory variant with 48GB, and isn't great but decent for gaming.\n\nThat card is going to be crazy popular with AI enthusiasts, and Intel isn't that far from launching their 3rd Gen ARC, which I bet will also have a 24GB/48GB version too, and will probably be dramatically better for gamers. \n\nWhat AMD and nVidia have both failed to understand is that they are hitting the limits of die size.  They are mostly dependent on foundry improvements for speed gains because they are already pushing insane wattages on their massive high end chips.  There's no place left to go except incremental improvements in efficiency.\n\nBut Intel isn't even close to being foundry limited.  They're IP limited and working really hard to improve.   Their wattages are currently low and they have plenty of room to grow and catch up.\n\nSo while the big two are stuck with incremental improvements, Intel is going to sneak up on them by matching or coming close to matching their performance.  And they own their foundry.\n\nSo Intel can afford to offer lower prices and it's incentivzed to put more RAM on their cards so they can fight for access to the AI space.  Not just that, but they don't have to share foundry capacity on their 3rd Gen card.  (This gen they hired out.)\n\nI predict within a year Intel will be starting to take bites out of the graphics card space. \n\nI am personally going to get the B60 because I happen to have an interest in AI research and have been experimenting for 2 years.  Until now I've been stuck with my GTX980 on my desktop and my RTX1060 on my laptop and haven't upgraded because I was waiting for an inexpensive 24GB card.  I was so close to pulling the trigger on a 5070ti when I learned about the 48GB card and immediately cancelled my already placed order for the nVidia.\n\nIf 3rd Gen ARC is even close to a 4080 in performance, nVidia will be crushed by people opting for Intel's 24 GB ray trace and AI capable sub $600 cards.",
      "score": 0,
      "created_utc": 1748127844.0,
      "replies": []
    },
    {
      "id": "mu40lxi",
      "author": "pedronii",
      "body": "Brother I have 12GB and I run out of memory in some games, 16GB is how much you need to run modern games on max settings, 12GB is the bare minimum for a high end card",
      "score": 0,
      "created_utc": 1748141137.0,
      "replies": []
    },
    {
      "id": "mu0rlu9",
      "author": "hirespeed",
      "body": "I\u2019m not technical, so excuse my ignorance, but if they say you only need 8GB, then why do they sell a 16?",
      "score": 0,
      "created_utc": 1748099933.0,
      "replies": []
    },
    {
      "id": "mu0yaqq",
      "author": "Raokairo",
      "body": "You can take my 32gb from my cold dead hands.",
      "score": 0,
      "created_utc": 1748102032.0,
      "replies": []
    },
    {
      "id": "mu102le",
      "author": "SlavicNinjaOfficial",
      "body": "I'll be honest, there won't be much difference noticable once you set the textures to something high on 1080p like it's unnecessary to set textures to max on that resolution. I'm talking about those demanding games like helldivers 2 and cyberpunk.",
      "score": 0,
      "created_utc": 1748102593.0,
      "replies": []
    },
    {
      "id": "mu187e4",
      "author": "sicurri",
      "body": "I think there's a distinct difference between need and wants. They may think most gamers don't need more than 8gb of vram, however it's probably because most average gamers can't afford anything more. \n\nWho doesn't want gorgeous 4k hdr high fps quality of graphics? Anyone who says they don't need their games looking as good as possible has simply accepted the reality that the cost of a high-powered graphics card isn't worth it.\n\nI've had to accept that 8gb of vram is all I can afford, same for my brother. We don't complain because we can't complain. We can't afford more, unfortunately...",
      "score": 0,
      "created_utc": 1748105227.0,
      "replies": []
    },
    {
      "id": "mu1b3c3",
      "author": "Coysinmark68",
      "body": "And Steve Jobs once said he didn\u2019t think anyone would ever need more the 64k ram.  Things change.",
      "score": 0,
      "created_utc": 1748106138.0,
      "replies": []
    },
    {
      "id": "mu1b6m6",
      "author": "DGNightwing95",
      "body": "BS",
      "score": 0,
      "created_utc": 1748106167.0,
      "replies": []
    },
    {
      "id": "mu1gcrd",
      "author": "jaymemaurice",
      "body": "Nobody even comprehends what 64,000,000,000 very extremely fast bits can do, especially with billions more extremely fast bits almost instantly accessible, with billions of more very fast bits backing those. The entire industry has been relying on ignorance for over 10 years and an entire generation just demands more than 8Gb of VRAM because 8 seems like a small number next to 16. And in today\u2019s age the mythical billions of anything is minimalized without actual comprehension.",
      "score": 0,
      "created_utc": 1748107789.0,
      "replies": [
        {
          "id": "mu1jds2",
          "author": "jaymemaurice",
          "body": "Put it this way, if you consider a billion grains of sand, as the detail your eyes can see, would occupy about a solid cubic meter. And sure you can slice that up and say each grain of sand on that face of a cube might use 34grains of sand deep for deep colour information, you can still slice that 1M cube so many times. You can use so many of those grains of sand on so many mini abacuses or build so many objects and representations of objects. *but it is optimized and it still needs more than 8gb on the gpu* yeah right. Ignorance. The only reason why games need more than 8Gb vram is because 8Gb of vram is available\u2026 so there isn\u2019t a need for optimization.",
          "score": 0,
          "created_utc": 1748108736.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu1u1ok",
      "author": "Doulloud",
      "body": "For gamers I think this is true. Let's be real to we gamers are mostly playing indie titles that could be run on a PC from 2008",
      "score": 0,
      "created_utc": 1748112187.0,
      "replies": []
    },
    {
      "id": "mu24z86",
      "author": "LinoleumFulcrum",
      "body": "I gots me 128k of mem\u2019ry and that\u2019s hows I likes it",
      "score": 0,
      "created_utc": 1748115913.0,
      "replies": []
    },
    {
      "id": "mu2rpdi",
      "author": "Secret_Account07",
      "body": "Oh fuck right the fuck of \n\nI\u2019m still running an RTX 2060 Super and im maxed on vram on many games. This is a dumb as fuck take",
      "score": 0,
      "created_utc": 1748123794.0,
      "replies": []
    },
    {
      "id": "mu2ufdh",
      "author": "DarklyDreamingEva",
      "body": "The hell we don\u2019t!!!",
      "score": 0,
      "created_utc": 1748124789.0,
      "replies": []
    },
    {
      "id": "mu5sxps",
      "author": "alidan",
      "body": "ok, this came in my feed and im not reading it I just want to say a few things. \n\nlook at what AAA use to look like 10-15 years ago with under 2 gb of ram, and now games are bottlenecking with 16gb, they don't look 8x better to justify it. \n\nsure we don't need more than 8gb, but sadly we need more than 8gb because devs are not able to optimize to save their lives, and all the technology gen over gen is going into upscaleing.\n\nlook at crysis, when that came out nothing could play it over medium, not because it was unoptimized, I mean look at this game https://www.youtube.com/watch?v=fU-oRVFpJIU it ran like crap for justifiable reasons, and you can tell with today's knowledge where they cut corners to save frames. some of its just because they were looking at a between 720p and 1080p resolution and this is 4k, get to about 12:45 right there, even today, an effect from 2007 still looks that good.\n\nthe game was single core, needed 2 gb of ram, and wanted 640mb of video memory, you could run it maxed out on a 1gb memory card at a little sub 1080p, I built my little brothers computer with a quad core athlon and a 4850 at the time and this part of the game was the benchmark I used. \n\ntoday we have games like unbound that looks worse than need for speed from 10 years ago, and on a computer that runs need for speed with resources to spare at 4k cant even run unbound at 1080p above 20fps. the game does not look better than nfs, and thats down to aesthetic choices. \n\npersonally im 100% fine with everything not being perfect in the name of optimization, but new games cant even do that correctly either and they don't even optimize.",
      "score": 0,
      "created_utc": 1748175932.0,
      "replies": []
    },
    {
      "id": "mu6dt6v",
      "author": "3dgy_CunT69_911",
      "body": "Tell that to Doom the dark ages with its kernal32 vram crash. From what I\u2019ve read, the game WILL crash after loading a couple levels do to the game leaking more than 12 gb in vram. Some people do not have this issue but it has lead to consistent crashing for many.",
      "score": 0,
      "created_utc": 1748183495.0,
      "replies": []
    },
    {
      "id": "mu70fiv",
      "author": "TEDCOR",
      "body": "Yes we do!",
      "score": 0,
      "created_utc": 1748190461.0,
      "replies": []
    },
    {
      "id": "mu77hv6",
      "author": "Code_Monkey_Lord",
      "body": "That\u2019s ridiculous. 8GB might fine for older titles but textures in modern games are huge.",
      "score": 0,
      "created_utc": 1748192548.0,
      "replies": []
    },
    {
      "id": "mu0shvb",
      "author": "ireadthingsliterally",
      "body": "Hell, at 1080p I can't even get AAA games to use 8GB no matter what I turn on.  \nI usually end up around 6.5GB.",
      "score": -1,
      "created_utc": 1748100213.0,
      "replies": []
    },
    {
      "id": "mu0z2oy",
      "author": "RO4DHOG",
      "body": "People purchase AMD products, to save money.\u00a0 Less VRAM is less money.\n\n\nMost gamers don't use Virtual Reality or use A.I. generative tools that depend on VRAM.",
      "score": -1,
      "created_utc": 1748102278.0,
      "replies": []
    },
    {
      "id": "mu1y1us",
      "author": "unematti",
      "body": "To be fair... Yeah, it's mostly enough. Been playing games at 1440p on the 8gb 7700S. Now... That's nice and all... But I did have to reduce some settings SPECIFICALLY due to the ram amount. I don't NEED it. That might also mean I get to save a bit of money. And many people rather save money than turn everything up.\n\nSo most people don't need more. It's fine. Mediocre isn't bad, it's just nothing special.",
      "score": -1,
      "created_utc": 1748113520.0,
      "replies": []
    },
    {
      "id": "mu6amqi",
      "author": "sirkashii",
      "body": "Now I know why i turned to RTX4090 and soon RTX5090 and intel for MSFS",
      "score": -1,
      "created_utc": 1748182470.0,
      "replies": [
        {
          "id": "mu8diip",
          "author": "JProvostJr",
          "body": "So you go for baby intel cores, along with fake frames, AI nonsense and missing ROPS, from the snake oil leather jacket salesman. Nvidia has been sticking with 8-10GB for years, soooo. But yeah! stick it to the man \ud83e\udd21",
          "score": 2,
          "created_utc": 1748205539.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mu0jeqp",
      "author": "WhySpongebobWhy",
      "body": "Rage bait title, as always taking the quote out of context for views.",
      "score": -4,
      "created_utc": 1748097351.0,
      "replies": []
    }
  ]
}