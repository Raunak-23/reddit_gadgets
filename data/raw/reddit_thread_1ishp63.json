{
  "post": {
    "title": "NVIDIA RTX50 series doesn\u2019t support GPU PhysX for 32-bit games | As such, you will no longer be able to enjoy older GPU PhysX games at high framerates.",
    "author": "chrisdh79",
    "id": "1ishp63",
    "score": 1487,
    "created_utc": 1739898558.0,
    "selftext": "",
    "num_comments": 272,
    "subreddit": "gadgets",
    "url": "https://www.reddit.com/r/gadgets/comments/1ishp63/nvidia_rtx50_series_doesnt_support_gpu_physx_for/"
  },
  "comments": [
    {
      "id": "mdglftu",
      "author": "piscian19",
      "body": "Man Nvidia has put in a ton of work convincing me not to buy a 50 series if one ever becomes available. Really admirable. One of the few companies out not pushing fomo.",
      "score": 968,
      "created_utc": 1739899407.0,
      "replies": [
        {
          "id": "mdgof4e",
          "author": "Snake_eyes_12",
          "body": "Don't worry, they will still be bought out, scalped and every one will want one to show to their instagram \"friends\" and play valorant on their $1500 12GB card.",
          "score": 214,
          "created_utc": 1739900237.0,
          "replies": [
            {
              "id": "mdgxisz",
              "author": "bigjoe980",
              "body": "\"I spent 5000 dollarydoos on this gpu during peak scalping!\"\n\n\nBro you do nothing but play runescape and listen to spotify.",
              "score": 102,
              "created_utc": 1739902763.0,
              "replies": [
                {
                  "id": "mdi1ewt",
                  "author": "Creoda",
                  "body": "Spotify at 440fps though.\n\n  \n/s",
                  "score": 49,
                  "created_utc": 1739913677.0,
                  "replies": [
                    {
                      "id": "mdi27pc",
                      "author": "x925",
                      "body": "My monitor is 480hz, guess ill have to get a 5090 for spotify.",
                      "score": 24,
                      "created_utc": 1739913888.0,
                      "replies": [
                        {
                          "id": "mdist44",
                          "author": "redisprecious",
                          "body": "No!! It was a joke!! Damn it Kyle, save some p5u0s9s0y for the rest of us!!!",
                          "score": 3,
                          "created_utc": 1739921921.0,
                          "replies": []
                        },
                        {
                          "id": "mdqg68a",
                          "author": "ohiocodernumerouno",
                          "body": "o i c ur married also",
                          "score": 1,
                          "created_utc": 1740018611.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdkozk3",
                  "author": "Kent_Knifen",
                  "body": "And the funny thing is, RuneScape runs on a 0.6s tick system and no animations go above 60fps. At a certain point, frames become irrelevant due to engine limitations.",
                  "score": 4,
                  "created_utc": 1739947286.0,
                  "replies": []
                },
                {
                  "id": "mdir04m",
                  "author": "The_Durbinator",
                  "body": "\ud83e\udd80 $11 \ud83e\udd80",
                  "score": 8,
                  "created_utc": 1739921335.0,
                  "replies": [
                    {
                      "id": "mdjvj4q",
                      "author": "bigjoe980",
                      "body": "\ud83e\udd80 $13.99 \ud83e\udd80 nowadays actually\n\n\nLol.",
                      "score": 8,
                      "created_utc": 1739934677.0,
                      "replies": [
                        {
                          "id": "mdl0138",
                          "author": "The_Durbinator",
                          "body": "Oh damn, I'm from the UK so it's \ud83e\udd80 \u00a39.99 \ud83e\udd80 but that doesn't have the same ring to it \ud83d\ude05",
                          "score": 1,
                          "created_utc": 1739953579.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdgwvfr",
              "author": "psychocopter",
              "body": "This is part of the reason why I've been able to recognize that I wont need fo upgrade for a long time. I have a high end card from the previous generation, but I only occasionally play games that push the card for high fps. Outside of that, I mostly play easier go run indie titles and esports titles so there isnt a point in upgrading. I can always just lower some settings if I cant run something well and I have 24gb of vram so that shouldnt be an issue.",
              "score": 21,
              "created_utc": 1739902586.0,
              "replies": [
                {
                  "id": "mdh0vzf",
                  "author": "drmirage809",
                  "body": "Same here. Got myself a 4080 Super a while back and I feel like I'm solid. Barring disasters this thing should last me years before I have to start turning settings down.",
                  "score": 14,
                  "created_utc": 1739903689.0,
                  "replies": []
                },
                {
                  "id": "mdi086y",
                  "author": "thenerfviking",
                  "body": "TBH 90% of people playing PC games would probably be rock solid with the new Intel battlemage GPUs.",
                  "score": 4,
                  "created_utc": 1739913358.0,
                  "replies": [
                    {
                      "id": "mdjwwoa",
                      "author": "Snake_eyes_12",
                      "body": "We need Intel to really shake up this market. They are literally selling the same shit for much cheaper. And yes many would be happy with those GPUs.",
                      "score": 2,
                      "created_utc": 1739935166.0,
                      "replies": [
                        {
                          "id": "mdl4sr9",
                          "author": "nickdanger68",
                          "body": "I have a 3060 and I've seriously been considering one for an upgrade. Had my eyes on a 4070 (Super would be nice) before it came out, but the Battlemage makes more budget sense and seems to do almost as well or better in most games. Except Cyberpunk lol and that's part of what's holding me back.",
                          "score": 2,
                          "created_utc": 1739956505.0,
                          "replies": [
                            {
                              "id": "mdrn2xp",
                              "author": "drjmcb",
                              "body": "I actually have a 3060 and didn't know these existed till this very comment chain.",
                              "score": 1,
                              "created_utc": 1740037182.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdh8lfn",
                  "author": "ACanadianNoob",
                  "body": "I got a handheld recently and realized that maybe a super high end GPU isn't what we need. But getting bonked in Elden Ring because I am maidenless with no skill while being a passenger in a car on a road trip is, even if I have to be on low / medium settings while I'm there. My desktop with an RTX 3070 feels like a luxury prison that chains me to my desk at this point.",
                  "score": 4,
                  "created_utc": 1739905798.0,
                  "replies": [
                    {
                      "id": "mdhum07",
                      "author": "psychocopter",
                      "body": "I still prefer playing on keyboard and mouse, but gaming anywhere on my steam deck is very nice.",
                      "score": 3,
                      "created_utc": 1739911845.0,
                      "replies": []
                    },
                    {
                      "id": "mdibkuq",
                      "author": "None",
                      "body": "Yeah nah, gaming on an untrawide monitor on a PC is a far superior and far more immersive experience",
                      "score": 1,
                      "created_utc": 1739916514.0,
                      "replies": [
                        {
                          "id": "mdirdz3",
                          "author": "ACanadianNoob",
                          "body": "USB 4 is far from the best way to do this, but my Ally X can have a graphics card connected to it, and the price of docks has gone way down. You can have your cake and eat it too, just don't pair a super high end GPU with a thunderbolt dock because it will get bandwidth starved.\n\nI still have my gaming PC when I want high fidelity experiences. But I'm learning to chase fun instead of graphics.",
                          "score": 1,
                          "created_utc": 1739921458.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdgq4zi",
              "author": "Frenzie24",
              "body": "I have a buddy that did this for classic wow.  Ganking ally in 4k Infinity fps like a legend",
              "score": 6,
              "created_utc": 1739900718.0,
              "replies": []
            },
            {
              "id": "mdjprdo",
              "author": "inbox-disabled",
              "body": "Some of us just have old as fuck hardware and want to upgrade.  Don't lump us in with the rest. \n\nI get all the criticisms for the 50 series, especially the 5080, but it would still be a gigantic upgrade for me were I seriously looking to build right now. Hell, even some of the 30 lineup would be.",
              "score": 3,
              "created_utc": 1739932660.0,
              "replies": [
                {
                  "id": "mdjq7sw",
                  "author": "None",
                  "body": "[deleted]",
                  "score": 1,
                  "created_utc": 1739932818.0,
                  "replies": [
                    {
                      "id": "mdjqfc7",
                      "author": "inbox-disabled",
                      "body": "Why are you offended by someone telling you not everyone who wants to upgrade is some social media whoring twat? Who hurt *you*?",
                      "score": 1,
                      "created_utc": 1739932890.0,
                      "replies": [
                        {
                          "id": "mdjqn8z",
                          "author": "None",
                          "body": "[deleted]",
                          "score": 1,
                          "created_utc": 1739932967.0,
                          "replies": [
                            {
                              "id": "mdjqycm",
                              "author": "inbox-disabled",
                              "body": "Great rebuttal. Any other awful takes you want to spew? Sarcasm btw, don't bother.",
                              "score": -1,
                              "created_utc": 1739933076.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdldz5k",
              "author": "batose",
              "body": "This is artificial since there is hardly any of those cards on the market.",
              "score": 1,
              "created_utc": 1739961957.0,
              "replies": []
            },
            {
              "id": "mdm9adw",
              "author": "nipple_salad_69",
              "body": "on a 1080p monitor",
              "score": 1,
              "created_utc": 1739975134.0,
              "replies": [
                {
                  "id": "mdo8sc3",
                  "author": "Snake_eyes_12",
                  "body": "And a 5+ year old CPU.",
                  "score": 1,
                  "created_utc": 1739994958.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mdhq8r7",
          "author": "Figgoss",
          "body": "I've gone AMD (7900 GRE) this time and retired my 6-7 year old gtx 1080. Was hanging on for the 50 series. But price stock and poor performance have turned my head.",
          "score": 18,
          "created_utc": 1739910658.0,
          "replies": [
            {
              "id": "mdht0dv",
              "author": "Tavoneitor10",
              "body": "Just so you know, 4090s are still amazing",
              "score": 4,
              "created_utc": 1739911416.0,
              "replies": [
                {
                  "id": "mdhu9rd",
                  "author": "Figgoss",
                  "body": "Did look but couldn't find one.",
                  "score": 13,
                  "created_utc": 1739911755.0,
                  "replies": []
                },
                {
                  "id": "mdjuqfr",
                  "author": "TheRabidDeer",
                  "body": "Used 4090's are selling for more than they sold for at launch lol\n\nUsed market is dumb, and you can't get them new anymore.\n\nIt's just a bad market right now, and the lack of stock is just hyping up GPU's in a feedback loop of planned scarcity.\n\nIf I remember, before the 5000 series launch the 4080 and 4080 Super were always in stock and could not sell. Now that the 5000 series launched people are buying up the 4080's and 5080's and marking up the price.\n\nFOMO is a hell of a drug. It's not that great of a card. Have patience, things will settle eventually but it may take a bit.",
                  "score": 13,
                  "created_utc": 1739934395.0,
                  "replies": [
                    {
                      "id": "mdkmuwi",
                      "author": "None",
                      "body": "[removed]",
                      "score": 2,
                      "created_utc": 1739946173.0,
                      "replies": [
                        {
                          "id": "mdkosyg",
                          "author": "TheRabidDeer",
                          "body": "It reminds me a lot of the 3000 series launch. Which is weird because the 3000 series was actually decently priced and performance uplift over the 2000 series (if you got it at the original MSRP of $700). The 3000 series also had covid and the crypto boom driving demand on top of a lot of people looking to upgrade from their 900 or 1000 series cards with how big of a letdown RTX 2000 was.\n\nMeanwhile the 5000 series is a lackluster upgrade over a lackluster 4000 series with a huge price tag (MSRP is $1000 but really almost all cards sold in stores are closer to $1200), no crypto boom to deal with, and no covid. It is really bizarre.",
                          "score": 2,
                          "created_utc": 1739947186.0,
                          "replies": [
                            {
                              "id": "mg7td1k",
                              "author": "Nepu-Tech",
                              "body": "It's not bizarre, Nvidia saw how desperate people were and how much they were willing to pay for video cards. Now they made that the norm. They have 0 competition, AMD are in bed with them, Intel can't compete. Nvidia also has the Ai market cornered which means they can sell them chips for 40K a piece or more. So they don't care about gamers anymore, they can create artificial scarcity, and take advantage of scalpers. This is what happens when a Monopoly is created. The government would have to step in and break up Nvidia, but they probably won't.",
                              "score": 1,
                              "created_utc": 1741209193.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdlul3l",
                  "author": "gubasx",
                  "body": "They won't ever stop melting their power connectors though \ud83d\udc40\ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f",
                  "score": 2,
                  "created_utc": 1739969936.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mdk3fzq",
          "author": "MAXAMOUS",
          "body": "Have the budget, but honestly thinking of just getting a 4090 at this point. Can still get EVGA as well.",
          "score": 2,
          "created_utc": 1739937585.0,
          "replies": [
            {
              "id": "mdllxg8",
              "author": "Mourdraug",
              "body": "You mean that one prototype EVGA 4090?",
              "score": 1,
              "created_utc": 1739966190.0,
              "replies": [
                {
                  "id": "mdmlnox",
                  "author": "MAXAMOUS",
                  "body": "https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExZTBqcmJ0Y2hlNng1NmVzb3VvYmpicG5sczJnb3piNzdocW95ZjV4dyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/1hMk0bfsSrG32Nhd5K/giphy.gif\n\n ^^Imeant ^^4080",
                  "score": 1,
                  "created_utc": 1739978951.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mdirrwu",
          "author": "None",
          "body": "They're becoming AMDs best advertiser. I'm gonna ride my 3080 till the wheels fall off and then it's on to team red. Hell, Intel may even have good options by the time a 3080 is \"outdated\"",
          "score": 3,
          "created_utc": 1739921585.0,
          "replies": [
            {
              "id": "mdjio8m",
              "author": "typeguyfiftytwix",
              "body": "They always have been, that's the secret. I'll gladly buy from the company that pushes open source alternatives instead of paying off devs to use their exclusive BS. Nvidia Gsync, AMD freesync. NVidia whatever the fuck it is, AMD FSR. \n\nThat and AMD tends to have higher raw performance specifications especially per dollar, but worse software performance because of those shenanigans - which is worse in the short term on the biggest games that use those, but in long term meant my AMD build kept up for longer. It was never top of the line, but I went a lot longer before feeling the need to upgrade.",
              "score": 6,
              "created_utc": 1739930271.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdj98rc",
          "author": "ShaveTheTurtles",
          "body": "I read an article the other day that said they actually over produced the chips needed for their delayed AI server. So now there will be a glut of chips for the 50 series lol.",
          "score": 1,
          "created_utc": 1739927183.0,
          "replies": []
        },
        {
          "id": "mdkpm5u",
          "author": "prontoingHorse",
          "body": "Can actually understand why they would do this:\n\nThey're actually making bank selling silicon to companies rather than individual/gamers",
          "score": 1,
          "created_utc": 1739947622.0,
          "replies": []
        },
        {
          "id": "mdkzsh7",
          "author": "bokewalka",
          "body": "Indeed. I was more than ready to give them my money, but they have convinced me so hard not to do it, that I will postpone my decision at least one year.",
          "score": 1,
          "created_utc": 1739953434.0,
          "replies": []
        },
        {
          "id": "mdld3y7",
          "author": "Kiwi_CunderThunt",
          "body": "Or in other terms laughable, overpriced sets itself on fire possibly but we need Jensen to get a new jacket. I'll sit on my 5 year old card and AMD is looking not the price of a 2nd hand car",
          "score": 1,
          "created_utc": 1739961455.0,
          "replies": []
        },
        {
          "id": "mdm8vtq",
          "author": "nipple_salad_69",
          "body": "lol bro, you're really invested in physx? gtfo here. that system was a gimmick at best, barely any dev adoption. engines and 3rd party physics libraries run this party, not ever physx",
          "score": 1,
          "created_utc": 1739975002.0,
          "replies": []
        },
        {
          "id": "mdrsjw2",
          "author": "None",
          "body": "it's the OF influencers buying these 50s builds for their twitch streaming career. They go hand in hand.",
          "score": 1,
          "created_utc": 1740040458.0,
          "replies": []
        },
        {
          "id": "mdk60ko",
          "author": "soulsoda",
          "body": "The outrage generated by this is overblown. we're talking games older than 2013, that hardly anyone plays. \n\nHere's the 30 day steam average for the top games that still use physX 32-bit\n\nBorderlands 2 - 3,000 players\n\nAssasins Creed Blackflag - 1100 players\n\nArkham city: 700 players\n\nbioshock infinite: 360 players\n\n\n\nWould you be pissed if consoles didn't have backwards compatibility for 12+ year old games? Like a PS4 playing PS2 games out of the box? or a Wii playing N64 games? or a Switch playing wii games?\n\nCome on. PhysX sucks. There are better physic engines built into developer tools that are far more easy to implement, and run far better on GPUs and CPUs. Its like your asking for leaded gasoline, when we've invented UNleaded gasoline that won't poison everyone.  This is a game dev issue not a hardware issue. They should release a modern remastered version that doesn't need a crappy 13 year old physics engine that's dogshit. \n\nThere's plenty of reasons to hate on Nvidias latest release of 50 series cards like their insistence of using the 12vHPWR cable again with 0 load balancing measures, or the fact the 5080 is just a 4080 super super and doesn't have enough vram for the price point. or the fact the 5090 doesn't exist, when the 5080 shouldn't exist.",
          "score": -10,
          "created_utc": 1739938586.0,
          "replies": [
            {
              "id": "mdklbch",
              "author": "None",
              "body": "[deleted]",
              "score": 7,
              "created_utc": 1739945389.0,
              "replies": [
                {
                  "id": "mdkslng",
                  "author": "soulsoda",
                  "body": "You can play with PhysX turned off like every AMD and Intel GPU user. PhysX was always a shitty Nvidia gimmick, an optional gimmick that doesn't even work that well (40 series cards would also get 40-60 fps using physx). There will be a day when RTX is phased out too for something way better and faster for Raytracing calculations than a shitty Nvidia gimmick. \n\nYou can't expect them to keep supporting a defunct product that no one wants to keep using. \n\n> Would you have the same viewpoint if it killed off support for Skyrim, Half-Life 2, Portal, Starcraft, Diablo III, etc.\n\nYes i would. if they incorporated some bullshit gimmick and are still FULLY PLAYABLE WITHOUT SAID BULLSHIT GIMMICK, yes i have no  issue with it. \n\n>Oh, this game is 12 years old you, can't play it as well as you should be able to anymore.\n\nIts bloatware, let it go.",
                  "score": -1,
                  "created_utc": 1739949247.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdgp98z",
      "author": "internetlad",
      "body": "Physx was so damn cool and Nvidia buying them absolutely set gaming on a separate (and in my opinion lesser) fork in the road.\u00a0\n\n\nImagine if we had games that accentuated realistic physics on the scale that we demand graphical fidelity? That's what Physx cards did and I absolutely would pay for a separate card to do it.\u00a0\n\n\nShame it was only used for shit like flags and hair.\u00a0",
      "score": 265,
      "created_utc": 1739900471.0,
      "replies": [
        {
          "id": "mdie2rq",
          "author": "No-Bother6856",
          "body": "What I want is hardware accelerated \"ray traced\" audio. Like a real time simulation of how sound waves propagate between a source in the game and the player's character instead of just faking it. Sound bouncing off walls, sound being muffled because objects are between you and the source, actual echoes, etc. \n\nRight now the game audio is sort of like being suspended in an anechoic chamber and sounds are being played from speakers floating around you. They can move the \"speakers\" around the room to change the direction you are hearing things from or add various filters to the sound played over the speakers to simulate being in a room, or a warehouse, or being muffled by a closed door etc. But it isn't real. The sound can't reflect off things, objects can't get in the way. If you hear an echo its just a baked in reverb effect, not a real calculated reflection off an object in the world etc.",
          "score": 111,
          "created_utc": 1739917302.0,
          "replies": [
            {
              "id": "mdim1lp",
              "author": "EngineeringNo753",
              "body": "Did you know Forza horizon 5 did hardware accelerated audio ray tracing?",
              "score": 69,
              "created_utc": 1739919770.0,
              "replies": [
                {
                  "id": "mdiytxe",
                  "author": "ChaZcaTriX",
                  "body": "And Returnal. Really noticeable when you send some massive attack through an area.",
                  "score": 38,
                  "created_utc": 1739923861.0,
                  "replies": [
                    {
                      "id": "mdk9ry4",
                      "author": "Redfern23",
                      "body": "Avatar: Frontiers of Pandora too.",
                      "score": 6,
                      "created_utc": 1739940109.0,
                      "replies": []
                    },
                    {
                      "id": "mdjjkon",
                      "author": "DrMcTouchy",
                      "body": "Great, now I need to dust off my PS5 and play more Returnal.",
                      "score": 4,
                      "created_utc": 1739930570.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "mditoig",
                  "author": "No-Bother6856",
                  "body": "No, I'll have to look into that",
                  "score": 7,
                  "created_utc": 1739922206.0,
                  "replies": []
                },
                {
                  "id": "mdjdqsj",
                  "author": "NASAguy1000",
                  "body": "And they they reused the sounds from FH4. Dont get me wrong, i like it, and tunnel runs are fun as heck. but its borderline wasted without the unique sound each car provides.",
                  "score": -3,
                  "created_utc": 1739928656.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdiqysu",
              "author": "mule_roany_mare",
              "body": "You can definitely do it & pretty cheap too.\n\nThe BVH trees that RT cores accelerate can also be used for collision & proper sound simulation. Only they are a lot cheaper than simulating light.",
              "score": 14,
              "created_utc": 1739921323.0,
              "replies": [
                {
                  "id": "mditmhn",
                  "author": "No-Bother6856",
                  "body": "If its cheap enough, you probably don't need to use a dedicated coprocessor. I figured it would be heavy enough to drop your fps too much if you used the RT cores on your primary GPU.",
                  "score": -2,
                  "created_utc": 1739922188.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdjq3ey",
              "author": "kitsune223",
              "body": "Isn't this what amd true audio and Radeon rays about ?\n\nSadly devs didnt rush to those two as much as they did for ray tracing , though the latest amd hardware still supports them.",
              "score": 4,
              "created_utc": 1739932776.0,
              "replies": [
                {
                  "id": "mdpt9l4",
                  "author": "Wrathlon",
                  "body": "Because you can't put really cool sound effects into a flashy trailer.",
                  "score": 1,
                  "created_utc": 1740011008.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdlcjb8",
              "author": "zzazzzz",
              "body": "thats just HRTF and vavle bought the company behind it.",
              "score": 2,
              "created_utc": 1739961106.0,
              "replies": []
            },
            {
              "id": "mdjskvm",
              "author": "slayez06",
              "body": "isn't that what dolby atmos is????",
              "score": 1,
              "created_utc": 1739933644.0,
              "replies": []
            },
            {
              "id": "mdkb3gh",
              "author": "Corgiboom2",
              "body": "If you go to a gun range IRL, each shot reverberates off the walls in a direction away from you. I want that same effect in a game without faking it.",
              "score": 1,
              "created_utc": 1739940673.0,
              "replies": []
            },
            {
              "id": "mdkqwup",
              "author": "DXsocko007",
              "body": "Should have heard games with EAX in the early 2000s. Shit was insanely good.",
              "score": 1,
              "created_utc": 1739948324.0,
              "replies": [
                {
                  "id": "mdkul90",
                  "author": "None",
                  "body": "Can confirm",
                  "score": 1,
                  "created_utc": 1739950372.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdlt4cn",
              "author": "Xeadriel",
              "body": "Tbh audio is way easier to fake than raytracing. At least I\u2019ve never thought it sucks in a modern game.",
              "score": 1,
              "created_utc": 1739969358.0,
              "replies": []
            },
            {
              "id": "mdlz1zp",
              "author": "spboss91",
              "body": "I think avatar has it, the sound design blew me away using an atmos system.",
              "score": 1,
              "created_utc": 1739971617.0,
              "replies": []
            },
            {
              "id": "mdjioef",
              "author": "Eruionmel",
              "body": "This would be cool, but I want hair that doesn't look like play-doh before I want slightly better sound. I don't even have the sound on 100% of the time.",
              "score": -1,
              "created_utc": 1739930273.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdinupb",
          "author": "sharkyzarous",
          "body": "Arkham city was so cool.",
          "score": 12,
          "created_utc": 1739920340.0,
          "replies": [
            {
              "id": "mdjlsnf",
              "author": "PlayingDoomOnAGPS",
              "body": "Still is! I recently got it for Switch and am playing it all over again. I fucking LOVE this game!",
              "score": 2,
              "created_utc": 1739931313.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdke5t3",
          "author": "Eevilyn_",
          "body": "You wouldn\u2019t have. The PhysX cards were expensive.And they were meant to operate in a PCI lane alongside your GPU. But like no one bought those cards. After NVIDIA bought them, they made a feature were you could use your old GPU as a PhysX card - but no one did that either.",
          "score": 10,
          "created_utc": 1739942008.0,
          "replies": [
            {
              "id": "mdkxrj7",
              "author": "skateguy1234",
              "body": "I had GTX 770's in SLI with a GT 640 as PhysX card back in the day. Not enough games took advantage of it to be worth it if you didn't already have the extra GPU. Honestly even with it, it didn't matter, as again, not enough games made use of it IMO.",
              "score": 5,
              "created_utc": 1739952227.0,
              "replies": [
                {
                  "id": "mdx8686",
                  "author": "PerterterhTermertehh",
                  "body": "I think that\u2019s one of the single most impractical setups I\u2019ve ever heard of lol \nprobably smacked for the 3 games that worked on it though",
                  "score": 1,
                  "created_utc": 1740106772.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdl15u3",
              "author": "nicman24",
              "body": "the physx is arguably the start of cuda",
              "score": 1,
              "created_utc": 1739954273.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdkyrv2",
          "author": "Reliquent",
          "body": "The way it worked in Borderlands 2 with the porta potties was so cool. It's a damn shame it didn't catch on more.",
          "score": 4,
          "created_utc": 1739952827.0,
          "replies": []
        },
        {
          "id": "mdk5w0g",
          "author": "Fredasa",
          "body": "Huh.  Now I'm wondering whether somebody clever could force older games to source their PhysX workload from a second GPU.  Kind of like how they recently finagled with FSR.",
          "score": 2,
          "created_utc": 1739938536.0,
          "replies": [
            {
              "id": "mdn035v",
              "author": "Virtualization_Freak",
              "body": "I bet this still works. You can select in Nvidia settings what card to use for physx.\n\nI am disappointed the journalists haven't checked before making the articles about this.",
              "score": 1,
              "created_utc": 1739982974.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdkpqst",
          "author": "prontoingHorse",
          "body": "Os it still relevant today? Wonder if AMD could but it from them in that case or create something similar which would actually drive up the competition",
          "score": 2,
          "created_utc": 1739947692.0,
          "replies": []
        },
        {
          "id": "mdks6v9",
          "author": "Curse3242",
          "body": "Personally to me I would be way more onboard with my card having special stuff & be expensive to improve physics of a game than the current Upscaling & Reflections trend",
          "score": 2,
          "created_utc": 1739949023.0,
          "replies": []
        },
        {
          "id": "mdltty8",
          "author": "Xeadriel",
          "body": "What would that even look like in a game where you control characters? You can\u2019t possibly make a control scheme of a character that would even make use of the realistic physics. \n\nOther than that are there even any high budget games focused on physics simulation beyond simulators like flight simulator?",
          "score": 1,
          "created_utc": 1739969641.0,
          "replies": [
            {
              "id": "mdmbdk2",
              "author": "internetlad",
              "body": "You shoot a window. Shards of glass realistically splay out and a large enough shard is created. It's calculated to have enough mass, and velocity to cause damage and hits them in the arm, the face and the hand. The enemy reacts accordingly.\u00a0\n\n\nOr\n\n\nDestructible environments. Ever play teardown? Imagine that running underneath every other game with no additional cost for CPU.\u00a0\n\n\nOr\u00a0\n\n\nHitman/sniper elite games. A truck is driving by. The player releases some cloth out of a window above and it floats down in the breeze and gets pulled against the windshield with realistic slipstream modelling causing the truck to have to stop giving the player an opportunity to make a shot, or it just straight up crashes.\n\n\n\n\nOr\n\n\nGames with large animals/beast/enemies. Dragons, horses etc. Skyrim, whatever. Ragdolls now have mass and dragons crash out of the sky when shot creating a new opportunity to create risk for the player to have to avoid it, or an opportunity to crash into an enemy stronghold and cause destruction. Shooting an enemy's horse causes it to buckle forward with correctly calculated physics and the game not only behaves in a believable way, but also applies damage realistically to the enemy rider.\n\n\n\n\n\nThat's not even mentioning games that are made *specifically* with physics in mind. Puzzle games, simulators, Realistic liquid behavior models. It would be so cool.\u00a0\n\n\nSeriously. Physics in games are what we have been missing and everyone just accepts video game logic (which is fine. Not every game needs to be BeamNG) and this is what I mean that we could be in a completely different place with gaming if the industry didn't just say \"well it'll make for a nice screenshot in a magazine\" and actually made innovative games.\u00a0",
              "score": 2,
              "created_utc": 1739975809.0,
              "replies": [
                {
                  "id": "mdmdbpn",
                  "author": "Xeadriel",
                  "body": "okay yeah I'm convinced. but how to bring that up and how to  really get that running? because I feel like that would just blow up the prices of a pc even harder + main boards usually only have one speedy pcie, not two. as it is, a graphics card is just always needed and physics cards would just add on top of that, just like VR still being a niche market despite being really cool tech.",
                  "score": 1,
                  "created_utc": 1739976426.0,
                  "replies": [
                    {
                      "id": "mdmes1h",
                      "author": "internetlad",
                      "body": "Yeah that's what killed it in the first place. No game became the \"killer app\" to sell Physx. It almost has to become self-sustaining. There are enough cards sold to make it worthwhile to make games that require/heavily\u00a0utilize a physx card and there are enough games utilizing it that makes it a necessary purchase.\u00a0\n\n\n\nRegarding the software/hardware development i don't know enough to comment. I believe the original physx card ran on a standard pci slot so I don't know what bandwidth is required to make it viable for modern games/functions. I guess I just have this dream in my head even if it's not especially realistic, at least in the short term. A man can dream, though.\n\n\nEdit: [here's an old aegia Physx card listing on Newegg for reference](https://www.newegg.com/asus-physx-processing-unit-physxp1-128m-graw-a/p/N82E16814121015)",
                      "score": 1,
                      "created_utc": 1739976883.0,
                      "replies": [
                        {
                          "id": "mdmjgo4",
                          "author": "Xeadriel",
                          "body": "I think its more realistic to hope for graphics cards to become more general purpose. I mean they already do with AI, so utilizing and spitting that power is probably our best bet right now. Games just need to make those physics happen with graphics cards.\n\nThen just like it happened from cpu to GPU, another co-processor, the physics cards, would spring up once that is exhausted because monolithic potential is limited when it comes to hardware and software. and by that time, one can hope, all prices calm down as well, just like VR headsets are a bit more affordable right now.",
                          "score": 1,
                          "created_utc": 1739978319.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdgigwe",
      "author": "chrisdh79",
      "body": "From the article: Now here is something that caught me off guard. It appears that NVIDIA has removed GPU PhysX support for all 32-bit games in its latest RTX 50 series GPUs. As such, you will no longer be able to enjoy older GPU PhysX games at high framerates.\n\nThis means that the RTX 5090 and the RTX 5080 (and all other RTX50 series GPUs) cannot run games like Cryostasis, Batman: Arkham City, Borderlands 2, GRAW 2, Mirror\u2019s Edge, Assassin\u2019s Creed IV: Black Flag, Bioshock Infinite with GPU-accelerated PhysX. Instead, you\u2019ll have to rely on the CPU PhysX solution, which is similar to what AMD GPUs have been offering all these years.\n\nThis is such a shame as one of the best things about PC gaming is returning to older titles. The old PhysX games were quite demanding when they came out. I don\u2019t know if I\u2019m the minority here, but I really enjoyed most of them when they came out. And yes, when I got the RTX 4090, I tried Cryostasis\u2019 tech demo so that I could finally see all those PhysX effects with high framerates.\n\nNVIDIA claimed that the CUDA Driver will continue to support running 32-bit application binaries on GeForce RTX 40, GeForce RTX 30 series, GeForce RTX 20/GTX 16 series, GeForce GTX 10 series and GeForce GTX 9 series GPUs. However, it won\u2019t support them on the GeForce RTX 50 series and newer architectures.\n\nI honestly don\u2019t know why NVIDIA has dropped support for them. It\u2019s ironic because Mafia 2 with PhysX felt WAY BETTER than the ridiculous remaster we got in 2020. And now, if you want to replay it, you\u2019ll have to stick with an older GPU. We are going backward here.",
      "score": 234,
      "created_utc": 1739898580.0,
      "replies": [
        {
          "id": "mdh24vx",
          "author": "drmirage809",
          "body": "And you do not wanna run PhysX over your CPU. Trust me on that one. While modern CPUs are probably more than fast enough to handle the tech in the titles it was originally used in without even breaking a sweat, the tech itself was never optimized to run on modern CPUs. Or any CPU for that matter. It is slow as molasses on CPU, no matter what you throw at it. My 5800X3D couldn't do it and that thing can do almost anything.",
          "score": 62,
          "created_utc": 1739904031.0,
          "replies": [
            {
              "id": "mdh5vwu",
              "author": "Chrunchyhobo",
              "body": "It's going to be brutal for anyone trying to play Borderlands 2.\n\nThe game is already crippled by the DX9 draw call limit and it's multithreading capabilities only being able to properly utilise 3 cores (thanks Xbox 360).\n\nChucking the PhysX workload in there too is going to be horrendous.",
              "score": 43,
              "created_utc": 1739905053.0,
              "replies": [
                {
                  "id": "mdh6f85",
                  "author": "drmirage809",
                  "body": "DX9 issue can be solved quite easily I'd say. DXVK should be a drop in solution for that. Translates all the DX9 draw calls into Vulkan stuff. Everything else is gonna be a struggle.",
                  "score": 27,
                  "created_utc": 1739905197.0,
                  "replies": [
                    {
                      "id": "mdi52yf",
                      "author": "OffbeatDrizzle",
                      "body": "that awkward moment when the game runs better on linux",
                      "score": 14,
                      "created_utc": 1739914660.0,
                      "replies": [
                        {
                          "id": "mdja822",
                          "author": "drmirage809",
                          "body": "That\u2019s not as rare as you might think nowadays. Valve and co have done an incredible amount of work to make Proton and all the surrounding technologies really good. \n\nAlthough, this trick can also be used on Windows. DXVK can be used on any system that uses Vulkan. Just drop in the dependencies and you should be good. And if you\u2019re one of those people rocking an Intel Arc GPU then you already are. Intel\u2019s GPU team decided that prioritising modern API performance was the most important and that translation layers were good enough to handle the rest.",
                          "score": 14,
                          "created_utc": 1739927502.0,
                          "replies": []
                        },
                        {
                          "id": "mdm2qpk",
                          "author": "None",
                          "body": "You can use DXVK on Windows, just saying.",
                          "score": 1,
                          "created_utc": 1739972933.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdkr532",
                  "author": "DXsocko007",
                  "body": "Thank god BL2 PhysX was just goo and shit on the floor and nothing else. It was a waste in that game",
                  "score": 1,
                  "created_utc": 1739948449.0,
                  "replies": [
                    {
                      "id": "mdlr8pj",
                      "author": "Chrunchyhobo",
                      "body": "It was also environment cloth physics.\n\n>It was a waste in that game\n\nIt was fucking brilliant, one of the best visual implementations of PhysX out there.\n\nI was genuinely disappointed when it didn't come back in BL3.",
                      "score": 2,
                      "created_utc": 1739968587.0,
                      "replies": [
                        {
                          "id": "mdogv14",
                          "author": "DXsocko007",
                          "body": "Liar",
                          "score": 0,
                          "created_utc": 1739997114.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdjg6g0",
              "author": "extravisual",
              "body": "Removing PhysX support does not mean you can't have GPU accelerated physics. GPUs can still be used for physics with other APIs if somebody wants it.",
              "score": 3,
              "created_utc": 1739929457.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdgl13f",
          "author": "None",
          "body": "[deleted]",
          "score": 65,
          "created_utc": 1739899293.0,
          "replies": [
            {
              "id": "mdh2ot7",
              "author": "WilmarLuna",
              "body": "Not necessarily true. The thing with software is it usually includes security updates as well. If they've decided to sunset a feature, leaving the software in will eventually become a vulnerability for hackers to exploit. It's better to just remove the software then leave it in for a malicious 3rd party to figure out how to exploit.",
              "score": 16,
              "created_utc": 1739904182.0,
              "replies": [
                {
                  "id": "mdhedxw",
                  "author": "Pankosmanko",
                  "body": "Which is a shame because Nvidia 3D is stunning in so many games. I used it on surround monitors, and on 3D projectors to play games. Civ V, Dead Space, and Just Cause 3 are all amazing in 3D",
                  "score": 11,
                  "created_utc": 1739907397.0,
                  "replies": [
                    {
                      "id": "mdi9yrs",
                      "author": "backdoorwolf",
                      "body": "I\u2019m in the minority but I thoroughly enjoyed the late 2000\u2019s 3d era (video games and movies).",
                      "score": 9,
                      "created_utc": 1739916024.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mdgjxe8",
          "author": "hitsujiTMO",
          "body": "If you had a free pcie slit, you could always throw in a GTX 960 and offload the physx to that I would assume.\n\n\nBut that's only if you ever need to play one of these old games.",
          "score": 39,
          "created_utc": 1739898988.0,
          "replies": [
            {
              "id": "mdgloog",
              "author": "SsooooOriginal",
              "body": "Downvoting you on principle of that abominable typo \"pcie slit\", perverted tech priest, BEGONE!.",
              "score": 111,
              "created_utc": 1739899475.0,
              "replies": [
                {
                  "id": "mdgqnbi",
                  "author": "Djinnwrath",
                  "body": "DO NOT QUESTION HOW I WORSHIP THE OMNISSIAH!",
                  "score": 28,
                  "created_utc": 1739900860.0,
                  "replies": []
                },
                {
                  "id": "mdgmicx",
                  "author": "sambull",
                  "body": "You need to fill the slit",
                  "score": 17,
                  "created_utc": 1739899703.0,
                  "replies": [
                    {
                      "id": "mdgwnra",
                      "author": "dbmajor7",
                      "body": "\ud83d\udd27\ud83d\udca6",
                      "score": 3,
                      "created_utc": 1739902526.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdgm281",
              "author": "provocateur133",
              "body": "I have no idea how much it actually helped, back in the day I ran a 320mb 8800 GTS as a PhysX card for my primary ATI 5850. I was probably just wasting power.",
              "score": 15,
              "created_utc": 1739899579.0,
              "replies": [
                {
                  "id": "mdgp90s",
                  "author": "2roK",
                  "body": "lol",
                  "score": 5,
                  "created_utc": 1739900470.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "mdlbx9l",
              "author": "ValuableKill",
              "body": "Idk how many games support just offloading PhysX, but I don't think it's many (I think the game specifically needs an option for hardware dedicated PhysX to offload). Long story short, I think your library options that could benefit from that would be limited. \nNow you could choose to have an older secondary GPU for running everything (not just PhysX), but then you run into the issue of how many lanes your extra 16 slot PCIe actually has. An x4 lane likely won't cut it and an x8 lane might be good enough for your taste if you have a PCIe Gen 4.0 gpu, but likely not a Gen 3.0 and either way you are taking a hit to graphics. (However, if you do happen to have a second 16 slot PCIe that has the full x16 lanes, then none of this is a problem).\n\nPersonally, if you have an older GPU lying around, you probably have several older parts lying around, and I think at that point your best bet is to just build a second PC and use that when you want to play older PhysX games. I used old components I had to build the pc for my arcade cabinet for example. Sometimes having two PCs is better than trying to do it all on one.",
              "score": 1,
              "created_utc": 1739960743.0,
              "replies": [
                {
                  "id": "mdlecot",
                  "author": "hitsujiTMO",
                  "body": "The option is in the Nvidia driver controls.",
                  "score": 2,
                  "created_utc": 1739962174.0,
                  "replies": [
                    {
                      "id": "mdlgaf7",
                      "author": "ValuableKill",
                      "body": "Gotcha, I was not aware of that.\n\nIgnore me then.",
                      "score": 1,
                      "created_utc": 1739963248.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdgmqnq",
              "author": "joestradamus_one",
              "body": "That sounds interesting, is this SLI? I was too poor when that, I think, was popular. Well, time to jump down yet another rabbit hole.",
              "score": 2,
              "created_utc": 1739899767.0,
              "replies": [
                {
                  "id": "mdgoa8g",
                  "author": "hitsujiTMO",
                  "body": "No. Not SLI. PhysX is a whole separate GPU process that didn't require interaction with the graphics processing so could get offloaded to a dedicated GPU. The Nvidia driver has an option for selecting a card as a dedicated PhysX card. It's generally didn't require a powerful GPU either.\n\n\nIt was abandoned by Nvidia by the time most people had an old card they could use, so most never got to avail of the feature.",
                  "score": 21,
                  "created_utc": 1739900199.0,
                  "replies": [
                    {
                      "id": "mdgwjs3",
                      "author": "cat_prophecy",
                      "body": "Did people really forget that PhysX used to be available only as a separate card?",
                      "score": 13,
                      "created_utc": 1739902496.0,
                      "replies": [
                        {
                          "id": "mdgy9kf",
                          "author": "CosmicQuestor",
                          "body": "Some people in this thread are younger than some of those Physx cards you old fart.",
                          "score": 29,
                          "created_utc": 1739902968.0,
                          "replies": []
                        },
                        {
                          "id": "mdh1m1r",
                          "author": "drmirage809",
                          "body": "I've heard of those. Separate PhysX card was how the tech first got introduced before Nvidia bought the company that made it. \n\nReminds me a bit of how 3DFX did things when they started out. Instead of making full fat GPU they just provided the bits to do the 3D rendering. All the 2D stuff like text, UI, Windows, etc was done by the existing 2D card and you ran a little pass through cable at the back of your PC to link the two cards together.",
                          "score": 8,
                          "created_utc": 1739903888.0,
                          "replies": []
                        },
                        {
                          "id": "mdjf9cz",
                          "author": "Cigaran",
                          "body": "Dedicated cards for audio, graphics, and physics to keep as much load off the CPU as possible.",
                          "score": 3,
                          "created_utc": 1739929153.0,
                          "replies": []
                        },
                        {
                          "id": "mdii44e",
                          "author": "Bramdal",
                          "body": "You mean 20 years ago with Agea or what was the company called and their PPUs?\n\nYeah, 2005 was 20 years ago. Yeah time sucks wtf.",
                          "score": 2,
                          "created_utc": 1739918563.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdgnrvi",
                  "author": "ForTheBread",
                  "body": "Not SLI just offloading the phyx work to the second GPU. I do recall a video showing that introduced pretty significant lag though. Not sure ill be able to find that video again.",
                  "score": 5,
                  "created_utc": 1739900055.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mdhml2p",
          "author": "ShrimpShrimpington",
          "body": "To be fair, nothing could ever run Cryostasis.  That game had to be one of the worst optimization disasters of all time.  On launch you basically couldn't run it on existing hardware like Crysis, but unlike Crysis it never got better.  It still runs like ass on computers sizes of times more powerful than it was designed for.  Shame, because it's for a lot of cool ideas",
          "score": 4,
          "created_utc": 1739909647.0,
          "replies": []
        },
        {
          "id": "mdgjzhp",
          "author": "androidDude0923",
          "body": "Older GPUS are the only worth while cards anyways. Pick them up while u still can. Soon they\u2019ll become classics.",
          "score": 4,
          "created_utc": 1739899004.0,
          "replies": []
        },
        {
          "id": "mdjmu82",
          "author": "zacisanerd",
          "body": "Tbf black flag runs like dogshit on my 3060ti, although I\u2019m sure it\u2019s a cpu thread issue as turning off multicore fixes it :/",
          "score": 1,
          "created_utc": 1739931665.0,
          "replies": []
        },
        {
          "id": "mdl17v1",
          "author": "nicman24",
          "body": "i bet you it will just work in linux/ proton",
          "score": 1,
          "created_utc": 1739954307.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdgme2j",
      "author": "edcar007",
      "body": "A lot of PhysX effects are still impressive to this day, like cloth and fluid simulation. People saw it as a gimmick, and it kind of is, but I am a sucker for that kind of stuff. Plus, a decent amount of great games take advantage of it.\n\nSticking to my RTX 4090 until it spits blood and calls it quits.",
      "score": 100,
      "created_utc": 1739899670.0,
      "replies": [
        {
          "id": "mdh2ktv",
          "author": "drmirage809",
          "body": "I remember when I build my PC with a GTX1080 in it and one of the first things I wanted to try was Borderlands 2 with the settings cranked. Just to see what that PhysX toggle did. Goo! Slimy goo coming from everywhere! It looked so gross and I found it so funny.",
          "score": 23,
          "created_utc": 1739904152.0,
          "replies": [
            {
              "id": "mdhn3hs",
              "author": "QuickQuirk",
              "body": "yeah, I found it funny, but ultimately gimmicky.\n\nWhen it was all the rage, I was running AMD cards, so I never saw it anyway. Games still lookeds good.\n\nSo maybe those who grew up with these effects are feeling betrayed, but since I never had it, I'm pretty much *shrug*",
              "score": 2,
              "created_utc": 1739909790.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdgqrex",
          "author": "Frenzie24",
          "body": "Im still pretty happy with my 2060 super \ud83e\udd37\u200d\u2642\ufe0f\n\nI'm not a big AAA player, but the ones I do have are still 60 fps on medium to high and that's good enough for me.",
          "score": 9,
          "created_utc": 1739900891.0,
          "replies": [
            {
              "id": "mdjlhc2",
              "author": "Lucaboox",
              "body": "Are you running 1080p? I have a 3060 Ti and a lot of the games I play run less that 50 or drop from 60 pretty often but I do play in 1440p. I want to get a 5070 ti on launch but everything about it just sounds so horrible :(",
              "score": 1,
              "created_utc": 1739931206.0,
              "replies": [
                {
                  "id": "mdk0grv",
                  "author": "grumd",
                  "body": "I had a 3080 playing at 3440x1440 and upgraded to a 5080. The performance difference was massive. Whereas before I had to play with settings and drop to a lower dlss setting or to medium-high to get 60-70 fps, with a 5080 I can once again just crank everything to max and enjoy solid smooth gameplay on any game. My jaw dropped when I started Cyberpunk on my 4K tv, turned on Path Tracing and got 180 fps. Around 60 without framegen. Replayed Phantom Liberty to get some new endings and it was gorgeous.\n\nUnexpectedly, framegen was better than I thought. My main monitor is 3440x1440 240hz, so running at 70-80 fps for good latency and adding 4x framegen on top of that to get 240fps gives me super smooth gameplay while still being very responsive. It's not the same as native 240fps but it's definitely better than 80 fps. But if you don't have a high refresh rate monitor then it's not worth it. 4x framegen was made for 240hz monitors imo.\n\nEvery reviewer shat on the 5080, but it's a massive jump for 30-series and price to performance it's still better than even a used 4090. The prices are insane nowadays even on the used market.\n\nIf you can afford it without ruining your finances, go buy a 5070ti. You won't regret it, it's a huge upgrade over 3060 ti.",
                  "score": 1,
                  "created_utc": 1739936468.0,
                  "replies": [
                    {
                      "id": "mdk2mxv",
                      "author": "Lucaboox",
                      "body": "That\u2019s great to hear I\u2019m def gonna purchase it for sure if I can. Will be up on the 20th trying to snag one!",
                      "score": 1,
                      "created_utc": 1739937281.0,
                      "replies": [
                        {
                          "id": "mdk6hrx",
                          "author": "grumd",
                          "body": "What I used to get a 5080 was a Chrome extension Auto Refresh Plus. Not an ad, I'm not affiliated with them but it allowed me to buy a 5080 twice (I returned the first one). I opened a page on a local store, filtered the gpus to include only 5080, set up the extension to auto-refresh the page and search for \"Add to cart\" and it gave me a notification and auto-clicked on the add to cart button. You can set it up to refresh every 5-10 seconds for example. I couldn't get a 5080 on the first day because most websites didn't work and I tried refreshing manually, but the next day I found this extension and just enabled it to refresh pages all day and I think 2-3 times a day I've seen restocks and could get a card for myself. If you go this route I recommend you first test that it works on some in-stock items.",
                          "score": 2,
                          "created_utc": 1739938775.0,
                          "replies": [
                            {
                              "id": "mdk87g9",
                              "author": "Lucaboox",
                              "body": "I got my 3060 Ti in 2020 by using a discord that had alerts for stock I think that will be okay but I'll try and take a look at doing this too I guess.",
                              "score": 1,
                              "created_utc": 1739939465.0,
                              "replies": [
                                {
                                  "id": "mdkbb6b",
                                  "author": "grumd",
                                  "body": "Discord servers basically do the same thing, they have bots that refresh websites and post in Discord when stock is found. But idk I'd remove the middleman and would just set up an autorefresh myself. Or better yet do both",
                                  "score": 2,
                                  "created_utc": 1739940764.0,
                                  "replies": [
                                    {
                                      "id": "mdkdly6",
                                      "author": "Lucaboox",
                                      "body": "Yep planning on doing both got a few sites setup with 5070 Ti and the auto refresh thanks for the great tip!",
                                      "score": 2,
                                      "created_utc": 1739941764.0,
                                      "replies": [
                                        {
                                          "id": "mdlaxri",
                                          "author": "grumd",
                                          "body": "Good luck!",
                                          "score": 2,
                                          "created_utc": 1739960159.0,
                                          "replies": []
                                        },
                                        {
                                          "id": "mdmbjmu",
                                          "author": "grumd",
                                          "body": "Update after watching 5070ti reviews: only get it if you can somehow snatch it for $800-850 or so. If you see prices around $1000, it's not worth it. Check the used market for 4070ti, 4070ti super, 4080, 4080 super. People who bought 5080 or 5090 will be selling their old cards. Depending on the price of used cards and new 5070tis, it might be much better to get a used one. For example if new 5070tis are all $900+ but then you can find a 4070ti super for $700, then a used card will be a better buy.\n\nEven a 4070ti super is TWICE the performance of a 3060ti so you'll be happy with any of those.\n\nI wonder what's the price of a 7900 XTX where you're at? That card is basically better than a 5070ti.",
                                          "score": 1,
                                          "created_utc": 1739975863.0,
                                          "replies": [
                                            {
                                              "id": "mdo5cu8",
                                              "author": "Lucaboox",
                                              "body": "I\u2019ve wanted a 7900XTX but ever since 50 series came out they\u2019ve been completely out of stock and the used market where I am is even worse I really don\u2019t know what to do. Around me people don\u2019t even have any 40 series for sale it\u2019s all 3090 and 3080s for a grand or more. I saw a 4070 ti super for $950 used but that\u2019s crazy to me",
                                              "score": 1,
                                              "created_utc": 1739994044.0,
                                              "replies": [
                                                {
                                                  "id": "mdopd39",
                                                  "author": "grumd",
                                                  "body": "I'm in Poland and 50 series sell out in 15 seconds once they restock. But using the page refresher thing I get notifications every day and if I'm quick enough I can easily get one in a couple of days, because restocks happen every day. Tip: it helps to have an account in the store already and familiarize yourself with the checkout process. Try to buy something random and see how the checkout works. If there's an option to pick up and pay in the store - pick that, then you don't have to go through banking to buy it. If you can set up and save a delivery address in advance, that also helps. Stuff like that. And once you get a notification, click on it immediately and buy it.",
                                                  "score": 2,
                                                  "created_utc": 1739999369.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        },
                                        {
                                          "id": "mdnxohn",
                                          "author": "grumd",
                                          "body": "https://youtu.be/tVK2FBWcnEo?si=uNlEDfpch6XGixO3\n\nI think this is the 5070ti review I agree the most with",
                                          "score": 1,
                                          "created_utc": 1739991984.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdk0khc",
                  "author": "Frenzie24",
                  "body": "Yep, 1080p.  It's all my monitor can do anyway lol",
                  "score": 1,
                  "created_utc": 1739936507.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mdgt24g",
          "author": "Majorjim_ksp",
          "body": "Games these days don\u2019t have enough physics effects.. I don\u2019t get why.. it really adds to the immersion.",
          "score": 9,
          "created_utc": 1739901522.0,
          "replies": []
        },
        {
          "id": "mdgx4lt",
          "author": "BennieOkill360",
          "body": "I love physX",
          "score": 7,
          "created_utc": 1739902656.0,
          "replies": []
        },
        {
          "id": "mdjn83e",
          "author": "PlayingDoomOnAGPS",
          "body": "Man, if it weren't for crypto-scammers, I'd love to buy a used 4090 to upgrade my 3060 but I know it's almost a given that thing will be worn the fuck out and it's not worth the risk.",
          "score": 2,
          "created_utc": 1739931797.0,
          "replies": [
            {
              "id": "mg8tts3",
              "author": "Nepu-Tech",
              "body": "I would like to do the same but Nvidia being Nvidia they decided to remove them from the market to force people to upgrade. What we really need is competition on the GPU market or someone to break up Nvidia's monopoly. Otherwise we're screwed, nobody cares about gamers, or about preserving games.",
              "score": 2,
              "created_utc": 1741220283.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mdgnvhs",
      "author": "redkeyboard",
      "body": "Has anyone run benchmarks to see the impact?",
      "score": 40,
      "created_utc": 1739900084.0,
      "replies": [
        {
          "id": "mdh0bco",
          "author": "fullup72",
          "body": "this is exactly what I want to see. These games originally skewed performance towards Nvidia because of the hardware support, let's see how they fare now on a level field.",
          "score": 26,
          "created_utc": 1739903532.0,
          "replies": []
        },
        {
          "id": "mdh2ryw",
          "author": "drmirage809",
          "body": "Not exactly a benchmark, but I remember trying it when I was rocking an AMD GPU last year. PhysX was never optimized to run on a CPU so no matter what you throw at it, it's a slideshow.",
          "score": 7,
          "created_utc": 1739904207.0,
          "replies": [
            {
              "id": "mdh84d7",
              "author": "The8Darkness",
              "body": "Afaik Physx intentionally runs on only a single core on the cpu. You can imagine something made for thousands of gpu cores running like shit when beeing limited to a single cpu core",
              "score": 6,
              "created_utc": 1739905667.0,
              "replies": [
                {
                  "id": "mdhy69p",
                  "author": "drmirage809",
                  "body": "I remember reading something like that when I trying to figure out why it runs so poorly on the CPU. Turns out Nvidia did the bare minimum to make the CPU version work and put their efforts into making the GPU version work well, Makes sense from a business standpoint. It needed their cards to work, so it was a reason to buy their stuff.\n\nYeah, Nvidia have been doing this stuff for as long as they've been around. DLSS only working on their hardware is just the most recent example.",
                  "score": 6,
                  "created_utc": 1739912804.0,
                  "replies": [
                    {
                      "id": "mdil3ec",
                      "author": "Wakkit1988",
                      "body": "It wasn't nVidia, it was the developers. They had to, specifically, code for CPU multi-threading for PhysX. Most of those games were coded when having 1 or 2 extra threads was the norm, and developers weren't going to waste time coding for fringe or non-existent cases.\n\nIf those games were modernized to utilize 8+ threads, I doubt we'd feel the same way about it.",
                      "score": 5,
                      "created_utc": 1739919475.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdh3b4g",
              "author": "redkeyboard",
              "body": "Damn, that sucks. I really liked physx back then despite struggling to run it. Sucks if I ant to revisit those games it's at worse visuals than back then. Hopefully Nvidia patches it to better run off the CPU but I doubt it.\n\nThis is why proprietary technologies suck, in 12 years maybe discrete ray tracing will get deprecated too",
              "score": 4,
              "created_utc": 1739904352.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mdgojyd",
      "author": "amazn_azn",
      "body": "Maybe a naive question but, is this something that Nvidia could add back at a driver level, or a modder/developer could enable at a game level?\n\nOr is it just permanently dead on Nvidia 50 series?",
      "score": 13,
      "created_utc": 1739900274.0,
      "replies": [
        {
          "id": "mdgskey",
          "author": "Frenzie24",
          "body": "Iirc nvidia cards had cores to process physx and it isn't a driver issue.  Could be totally wrong and don't feel like searching.  Someone will correct \u2665\ufe0f",
          "score": 7,
          "created_utc": 1739901387.0,
          "replies": [
            {
              "id": "mdgxd44",
              "author": "KingZarkon",
              "body": "The post says they removed it for 32-bit games, which suggests the support is still there for 64-bit games. As such, I don't think it's a matter of removed hardware. Also Physx ran on the GPU's normal cores, not dedicated ones, as far as I know.",
              "score": 22,
              "created_utc": 1739902721.0,
              "replies": [
                {
                  "id": "mdinp01",
                  "author": "Wakkit1988",
                  "body": "There are, at the present time, zero games using 64-bit PhysX.\n\nThey effectively ended support.",
                  "score": 11,
                  "created_utc": 1739920289.0,
                  "replies": [
                    {
                      "id": "mdjsabs",
                      "author": "MetalstepTNG",
                      "body": "So, there's a chance you're saying?",
                      "score": 3,
                      "created_utc": 1739933542.0,
                      "replies": [
                        {
                          "id": "mdju7cf",
                          "author": "Wakkit1988",
                          "body": "It's definitely possible, but less likely now than ever. There are mainstream alternatives that have all but usurped it.",
                          "score": 3,
                          "created_utc": 1739934207.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mdkgane",
                      "author": "Sleepyjo2",
                      "body": "I'm fairly sure that every game engine since like 2015 links to the 64-bit libraries for PhysX by default. There are, in fact, games which use that 64-bit library.\n\nIn fact I just downloaded a random (free) modern game that uses PhysX and it has the 64bit dlls for PhysX and APEX sitting right there.\n\nTheres a reason the example titles are all around or before that time.\n\n  \nedit; The game in question was Strinova, for anyone curious.",
                      "score": 1,
                      "created_utc": 1739942975.0,
                      "replies": [
                        {
                          "id": "mdki888",
                          "author": "Wakkit1988",
                          "body": ">As of 2020, most games making use of PhysX run the physics effects exclusively on the CPU regardless of hardware, with hardware accelerated physics being limited to older games.[2] \n\n>Verified by User:Aemony on 2023-08-31\n>Hard to nail this down exactly, but as of 2023 there hasn't been any major games using GPU accelerated PhysX for almost close to a decade or so maybe? Meanwhile Unity games all used CPU accelerated PhysX for all of its physics.\n\nNo games use 64-bit PhysX utilizing GPU processing, which is what is the only thing remaining available in 50 series nVidia cards. The 64-bit dlls you see are for *CPU* processing.\n\nThey have effectively killed off GPU PhysX processing with this change. No games exist that currently use it.",
                          "score": 5,
                          "created_utc": 1739943886.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "mdhg3mi",
                  "author": "Frenzie24",
                  "body": "You're correct and I was getting worse crossed with the old dedicated physx cards",
                  "score": 1,
                  "created_utc": 1739907867.0,
                  "replies": []
                },
                {
                  "id": "mdh1zzv",
                  "author": "AndThisGuyPeedOnIt",
                  "body": "And modern CPUs and GPUs on these old games are still going to run them at a zillion FPS. This is a non-issue.",
                  "score": -10,
                  "created_utc": 1739903994.0,
                  "replies": [
                    {
                      "id": "mdieqb3",
                      "author": "No-Bother6856",
                      "body": "In the article, the author tests this and gets terrible framerates. Even modern CPUs aren't fast enough. \n\nYou will need to install an older nvidia GPU and configure it as your designated physx coprocessor for these games to run at speed with a 5090.",
                      "score": 3,
                      "created_utc": 1739917515.0,
                      "replies": [
                        {
                          "id": "mdio3dl",
                          "author": "Wakkit1988",
                          "body": ">You will need to install an older nvidia GPU and configure it as your designated physx coprocessor for these games to run at speed with a 5090.\n\nIt's like we've time traveled 20 years into the past.",
                          "score": 3,
                          "created_utc": 1739920416.0,
                          "replies": [
                            {
                              "id": "mdit31v",
                              "author": "No-Bother6856",
                              "body": "Yep, suddenly a dedicated physx card makes sense in 2025",
                              "score": 3,
                              "created_utc": 1739922011.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "mdi36jz",
                      "author": "Don-Tan",
                      "body": "i tried running arham asylum with max physx and settings on 1440p. Everytime i hit some physx leaves my fps would tank to 50 and when i got to a foggy area my fps would tank all the way to 40 \ud83d\udc80\n\nI have a RTX 5080 with a Ryzen 7 9800X3D",
                      "score": 5,
                      "created_utc": 1739914146.0,
                      "replies": []
                    },
                    {
                      "id": "mdiaul5",
                      "author": "lordraiden007",
                      "body": "False. Even a 5800X 3D or 5950X can\u2019t run consistently above 30fps when PhysX is in CPU mode (reportedly barely makes it into the mid-20\u2019s, and that\u2019s before you consider 1% lows), and there hasn\u2019t been an increase in such performance in newer generations. NVIDIA intentionally restricted it to a single-core on CPUs, so this will just be the way things are going forward unless we find a 3rd party compatibility solution or NVIDIA decides to graciously (/s) give us a translation layer or add back support for these things.",
                      "score": 1,
                      "created_utc": 1739916290.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdhc70d",
              "author": "vingt-2",
              "body": "I'm 99% sure those old PhysX APIs are implemented with standard GPGPU pipelines and it's more a matter of dropping some of the headache of supporting these features that barely any titles uses and hasn't been used in 10+ years.",
              "score": 7,
              "created_utc": 1739906790.0,
              "replies": [
                {
                  "id": "mdhfp64",
                  "author": "Frenzie24",
                  "body": "You're right.",
                  "score": 2,
                  "created_utc": 1739907758.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "mditdva",
          "author": "TheLepersAffinity",
          "body": "Well I think that\u2019s what they did if I understand the story right. They just removed the dedicated hardware that made the performance super good.",
          "score": 1,
          "created_utc": 1739922108.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdgs6lt",
      "author": "cloud12348",
      "body": "Another common proton/dxvk W",
      "score": 10,
      "created_utc": 1739901282.0,
      "replies": []
    },
    {
      "id": "mdigvti",
      "author": "Deliriousious",
      "body": "Literally everything is telling me that the 50 series shouldn\u2019t be touched with by a 10 foot pole.\n\nThey melt. They\u2019re technically worse than the 40 series. They use obscene amounts of power. And now this?\n\nJust looked at the games affected, nearly 1000, with a decent chunk being games from the last 5 years.",
      "score": 9,
      "created_utc": 1739918187.0,
      "replies": [
        {
          "id": "mdkgjg9",
          "author": "herbertfilby",
          "body": "Even older games, I see a ton I both recognize and enjoyed.",
          "score": 2,
          "created_utc": 1739943088.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdgrxku",
      "author": "wigitalk",
      "body": "List of games affected?",
      "score": 14,
      "created_utc": 1739901213.0,
      "replies": [
        {
          "id": "mdieqqm",
          "author": "CaveManta",
          "body": "I was going to post them. But then this list said it's possibly 927 games!\n\nhttps://www.pcgamingwiki.com/wiki/List_of_games_that_support_Nvidia_PhysX",
          "score": 12,
          "created_utc": 1739917518.0,
          "replies": [
            {
              "id": "mditu83",
              "author": "MakeThanosGreatAgain",
              "body": "Alan Wake 2 is on this list. Idk what to make of what I'm reading here",
              "score": 6,
              "created_utc": 1739922256.0,
              "replies": [
                {
                  "id": "mdj109k",
                  "author": "fixminer",
                  "body": "It only affects 32bit PhysX. The modern ones should all be 64bit. Also, I think modern PhysX implementations are rarely hardware accelerated anyway.",
                  "score": 9,
                  "created_utc": 1739924552.0,
                  "replies": [
                    {
                      "id": "mdj398s",
                      "author": "MakeThanosGreatAgain",
                      "body": "Seems like most are from the 360/PS3 era. Anyone know if it would just affect the physx stuff or would the whole game be a stuttering mess?",
                      "score": 2,
                      "created_utc": 1739925265.0,
                      "replies": [
                        {
                          "id": "mdjpqgn",
                          "author": "PlayingDoomOnAGPS",
                          "body": "Just PhysX stuff. I think, since AMD never had PhyX support, it would run at least as well as it would on an equivalent AMD card. So, for games from the 360/PS3 era, probably just fine.",
                          "score": 3,
                          "created_utc": 1739932651.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "mdl4v11",
                      "author": "SciGuy013",
                      "body": "There is no game that uses 64bit GPU physx implementation",
                      "score": 2,
                      "created_utc": 1739956543.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "mdjmmeo",
          "author": "Lucaboox",
          "body": "From what I saw the latest game with 32 bit physX is from 2013. So it\u2019s a few games but not a ton.",
          "score": 3,
          "created_utc": 1739931592.0,
          "replies": []
        },
        {
          "id": "mdqt2gp",
          "author": "FaultyToilet",
          "body": "Batman Arkham games?",
          "score": 3,
          "created_utc": 1740023197.0,
          "replies": []
        },
        {
          "id": "mdh1nrl",
          "author": "Darknessie",
          "body": "Cool, you volunteering to do the research for us",
          "score": -20,
          "created_utc": 1739903901.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdgpp32",
      "author": "Furey24",
      "body": "Very disappointed by this move.\n\nI am joking but wait until they announce its replacement DLPX....",
      "score": 8,
      "created_utc": 1739900595.0,
      "replies": []
    },
    {
      "id": "mdk7qt6",
      "author": "ashtefer1",
      "body": "I\u2019m still pissed PhysX died out. Everything I\u2019ve seen it used in blew me away. Games now are just HD static renders.",
      "score": 6,
      "created_utc": 1739939277.0,
      "replies": []
    },
    {
      "id": "mdgrd3a",
      "author": "Laserous",
      "body": "Nvidia stopped giving a shit about gamers when Crypto became their cash cow, and now AI is here to sustain it. From Zero-day exploits throttling GPU power to pouring R&D into making better and more efficient miners, they could care less about gamers who purchase a new card every~5 years.\n\nI went AMD and I am happy. I was with Nvidia for 20 years, but honestly they're just screwing up too much now to trust. A GPU is an expensive 5 year investment, and I'd rather have something solid than something as reliable as IKEA being marketed as old growth walnut.\n\nGo ahead fanbois, downvote me.",
      "score": 23,
      "created_utc": 1739901057.0,
      "replies": [
        {
          "id": "mdgyli5",
          "author": "spiritofniter",
          "body": "Agreed for over a decade; I was with my GTX 770M SLI until I got 7900 GRE last year.",
          "score": 2,
          "created_utc": 1739903061.0,
          "replies": []
        },
        {
          "id": "mdhly26",
          "author": "WirtsLegs",
          "body": "Tbf and users have had to run physx via CPU for ages, so not any better there",
          "score": 1,
          "created_utc": 1739909471.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdhc4ph",
      "author": "darkfred",
      "body": "GPU physx is is lousy on older games anyway, often underperforming CPU. \n\nEarly versions of PhysX were almost comically bad, to the extent that developers wondered if they were handicapped to make GPU look better. But the performance improved in the last couple years and any games using the very old versions of the SDK are probably running fast on modern hardware regardless.\n\nTLDR: you really only see the benefit of this in newer 64bit games anyway, which is probably why they are removing 32bit support. It just didn't matter.",
      "score": 8,
      "created_utc": 1739906773.0,
      "replies": [
        {
          "id": "mdjr1sl",
          "author": "PM_YOUR_BOOBS_PLS_",
          "body": "Oh, look.  Some common sense.  The article explicitly states AMD GPUs have had to use CPU physics the entire time anyways.  And, you know, it worked fine.  Sure, AMD hasn't been the performance king for a while, but it's not like this suddenly makes games unplayable.  It probably is literally unnoticeable playing any of these games on a 50 series card.",
          "score": 4,
          "created_utc": 1739933110.0,
          "replies": [
            {
              "id": "mdksjri",
              "author": "Jaesaces",
              "body": "If you read the article, it literally talks about how they played an old game affected like this on a 50-series card and we're getting like 15FPS.",
              "score": 3,
              "created_utc": 1739949218.0,
              "replies": [
                {
                  "id": "mdkz6dq",
                  "author": "PM_YOUR_BOOBS_PLS_",
                  "body": "I literally downloaded Arkam Asylum just to test it.  Here's my copy/pasted comment.\n\nYou are demonstrably full of shit. I've never played any of the Arkham games, but it just so happens they were on sale, so I bought the trilogy for $10 just to test what you're saying.\n\nI'm running a 5900X and 7900XTX. Just installed Arkham Asylum. Running at 4K, max settings, fixed the config file to run at 144 FPS.\n\nSwitching from no hardware physics to high/max hardware physics (which the launcher warned me would have a significant impact, since I don't have the hardware for it) resulted in...\n\nLiterally no performance impact. I literally took pictures to make sure.\n\n144 FPS, 61% GPU usage, and 14% CPU usage with physics off.\n\n144 FPS, 61% GPU usage, and 14% CPU usage with physics on at max.\n\nLiterally no change. This article is complete clickbait ragebait.",
                  "score": 3,
                  "created_utc": 1739953065.0,
                  "replies": [
                    {
                      "id": "mdl9srr",
                      "author": "Jaesaces",
                      "body": "> You are demonstrably full of shit. I've never played any of the Arkham games, but it just so happens they were on sale, so I bought the trilogy for $10 just to test what you're saying.\n\nI am just repeating what *they* claimed in the article.  Specifically:\n\n> So, I went ahead and downloaded the Cryostasis Tech Demo. I remember that tech demo running smoothly as hell with the RTX 4090. So, how does it run on the NVIDIA RTX 5090 with an AMD Ryzen 9 7950X3D? Well, see for yourselves. Behold the power of CPU PhysX. 13FPS at 4K/Max Settings.\n\nClearly people have been gaming without GPU PhysX for a long time without issue.  As I understand it, this tech demo leans *heavily* into PhysX and is quite old (thus using 32bit).  So they could definitely be cherry-picking here for the sake of the article, but there is a [link in the article](https://www.resetera.com/threads/rtx-50-series-gpus-have-dropped-support-for-32-bit-physx-many-older-pc-games-are-impacted-mirrors-edge-borderlands-etc.1111698/) to games that they expect or have tested to have performance issues related to the drop in support.",
                      "score": 4,
                      "created_utc": 1739959489.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdl292y",
      "author": "None",
      "body": "My 4090 just became more valuable, thanks Nvidia",
      "score": 3,
      "created_utc": 1739954935.0,
      "replies": [
        {
          "id": "mdrbzss",
          "author": "MagnaCamLaude",
          "body": "I'll give you my 4070 for it and will share my steam and neopets account with you (jk, I don't use neopets anymore)",
          "score": 2,
          "created_utc": 1740031217.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdla1ib",
      "author": "MichaelMottram",
      "body": "PC2 is not backwards compatible D:",
      "score": 3,
      "created_utc": 1739959630.0,
      "replies": []
    },
    {
      "id": "mdgm6ps",
      "author": "lart2150",
      "body": "Chances are a 50 series gpu and whatever cpu you pair it with will still pump out more FPS then your display can handle with vsync enabled on 10 year old games.  physx on the gpu was killer when we had 2 core/4 thread cpus.",
      "score": 20,
      "created_utc": 1739899614.0,
      "replies": [
        {
          "id": "mdgoi20",
          "author": "nohpex",
          "body": "Anecdotally, it's killer on modern CPUs too.\n\nI've tried running Arkham Asylum with PhysX turned on with a 5950X and 6800XT, and it completely tanks the frame rate to a stuttery mess from 300+.",
          "score": 23,
          "created_utc": 1739900260.0,
          "replies": [
            {
              "id": "mdjuy0x",
              "author": "PM_YOUR_BOOBS_PLS_",
              "body": "You are demonstrably full of shit.  I've never played any of the Arkham games, but it just so happens they were on sale, so I bought the trilogy for $10 just to test what you're saying.\n\nI'm running a 5900X and 7900XTX.  Just installed Arkham Asylum.  Running at 4K, max settings, fixed the config file to run at 144 FPS.\n\nSwitching from no hardware physics to high/max hardware physics (which the launcher warned me would have a significant impact, since I don't have the hardware for it) resulted in...\n\nLiterally no performance impact.  I literally took pictures to make sure.  \n\n144 FPS, 61% GPU usage, and 14% CPU usage with physics off.\n\n144 FPS, 61% GPU usage, and 14% CPU usage with physics on at max.\n\nLiterally no change.  This article is complete clickbait ragebait.",
              "score": 6,
              "created_utc": 1739934469.0,
              "replies": []
            }
          ]
        },
        {
          "id": "mdjlvdw",
          "author": "Lucaboox",
          "body": "Sadly no unless your monitor is 40hz https://youtu.be/mJGf0-tGaf4?si=jnFKoRwCUj1_qby6 EDIT sorry I\u2019m a bit wrong it does get a decent amount of fps in some of the Batman games I didn\u2019t even watch the own video I posted fully I\u2019m really sorry lol.",
          "score": 1,
          "created_utc": 1739931339.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdh2t5x",
      "author": "Xero_id",
      "body": "Lol, is the 50 series turning out to be the Nvidia Vista? I get they are no l9nger after the gamer base but this gen just seems like they missed the dart board.",
      "score": 2,
      "created_utc": 1739904216.0,
      "replies": []
    },
    {
      "id": "mdhnwbx",
      "author": "door_to_nothingness",
      "body": "Here I am still enjoying my 2080ti with no issues.",
      "score": 2,
      "created_utc": 1739910010.0,
      "replies": []
    },
    {
      "id": "mdhqyl9",
      "author": "MaroonIsBestColor",
      "body": "I\u2019m so happy I got a 4080 Super for msrp last year. The 50 series cards are absolute garbage value and have reliability issues on top of that.",
      "score": 2,
      "created_utc": 1739910858.0,
      "replies": []
    },
    {
      "id": "mdhrkoh",
      "author": "leovin",
      "body": "40 series prices just went up",
      "score": 2,
      "created_utc": 1739911027.0,
      "replies": []
    },
    {
      "id": "mdi8nsu",
      "author": "ctdom",
      "body": "Another reason to just start going to AMD.",
      "score": 2,
      "created_utc": 1739915647.0,
      "replies": [
        {
          "id": "mdjrxdl",
          "author": "Nickthemajin",
          "body": "You do know AMD never did physx at all right? This just means that Nvidias 5080/5090 will handle physx exactly the same as AMDs GPUs always have",
          "score": 1,
          "created_utc": 1739933416.0,
          "replies": [
            {
              "id": "mdju3jd",
              "author": "ctdom",
              "body": "My point still stands",
              "score": 2,
              "created_utc": 1739934170.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "mdiapig",
      "author": "luttman23",
      "body": "Fuck that then",
      "score": 2,
      "created_utc": 1739916247.0,
      "replies": []
    },
    {
      "id": "mdj8az6",
      "author": "mjh2901",
      "body": "So the 4090 remains the best card on the market.",
      "score": 2,
      "created_utc": 1739926878.0,
      "replies": []
    },
    {
      "id": "mdjs7e1",
      "author": "Xerain0x009999",
      "body": "The thing is, I doubt they will ever add it back. This makes the 40 series the ultimate Nvidia cards for older games.",
      "score": 2,
      "created_utc": 1739933514.0,
      "replies": []
    },
    {
      "id": "mdkqx3w",
      "author": "Less_Party",
      "body": "Okay but how much of a workload can the physX stuff from a game from like 2004 possibly be to a modern GPU or CPU?",
      "score": 2,
      "created_utc": 1739948328.0,
      "replies": []
    },
    {
      "id": "mdl4bd0",
      "author": "Skytras",
      "body": "This is a clusterfuck.",
      "score": 2,
      "created_utc": 1739956211.0,
      "replies": []
    },
    {
      "id": "mdmu644",
      "author": "chewedjew",
      "body": "My 3080 is still fine.",
      "score": 2,
      "created_utc": 1739981347.0,
      "replies": []
    },
    {
      "id": "mdohex1",
      "author": "Superflyt56",
      "body": "I just sitting here humble with my 3060 12gb. It's not much but it's an honest gpu",
      "score": 2,
      "created_utc": 1739997261.0,
      "replies": []
    },
    {
      "id": "mdpec8l",
      "author": "Trapgod99",
      "body": "The RTX40 series just keeps looking better as time passes",
      "score": 2,
      "created_utc": 1740006323.0,
      "replies": []
    },
    {
      "id": "mdh1vrb",
      "author": "yuzhnaya",
      "body": "Guess it's a GPU skip year again.",
      "score": 4,
      "created_utc": 1739903962.0,
      "replies": []
    },
    {
      "id": "mdglws5",
      "author": "Zaknokimi",
      "body": "Can someone ELI5 if I can play FFXI or not",
      "score": 4,
      "created_utc": 1739899537.0,
      "replies": [
        {
          "id": "mdgmqc3",
          "author": "Cactuszach",
          "body": "Shouldn\u2019t be a problem.",
          "score": 4,
          "created_utc": 1739899764.0,
          "replies": []
        },
        {
          "id": "mdgr9r1",
          "author": "Frenzie24",
          "body": "You and me with classic wow are just fine buddy!",
          "score": 2,
          "created_utc": 1739901032.0,
          "replies": []
        },
        {
          "id": "mdgrizj",
          "author": "gameprojoez",
          "body": "The issue only affects the GPU side, the CPU can still computes the physics.",
          "score": 1,
          "created_utc": 1739901102.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdi9fwb",
      "author": "No-Bother6856",
      "body": "So there is actually a legitimate reason someone might want a dedicated physx card now? Didn't have that on my 2025 bingo card",
      "score": 2,
      "created_utc": 1739915871.0,
      "replies": []
    },
    {
      "id": "mdhnlf5",
      "author": "Glidepath22",
      "body": "What a dumb thing to do",
      "score": 3,
      "created_utc": 1739909926.0,
      "replies": []
    },
    {
      "id": "mdgn7f4",
      "author": "PicnicBasketPirate",
      "body": "Anyone know what the most intensive physX game is and how it runs on a modern CPU?\n\n\nI'm all for giving out about Nvidia but I somehow doubt this will cause much of an issue.",
      "score": 3,
      "created_utc": 1739899896.0,
      "replies": [
        {
          "id": "mdgs5zg",
          "author": "Frenzie24",
          "body": "Not sure, but even RTS games use it heavily.  Not sure what Nvidia is thinking here besides the obvious- games aren't there target anymore",
          "score": 5,
          "created_utc": 1739901278.0,
          "replies": []
        },
        {
          "id": "mdgzdo8",
          "author": "Fedora_Da_Explora",
          "body": "To give you an idea, AMD cards have never supported PhysX and no one here even realized that. The calculations are fairly easy for even relatively modern cpu's.",
          "score": 3,
          "created_utc": 1739903277.0,
          "replies": []
        },
        {
          "id": "mdl0852",
          "author": "DangerousCousin",
          "body": "You won\u2019t be able to enable hardware Physx support in Mirrors Edge. That needs a supported Nvidia card or the FPS will tank to 15 or so",
          "score": 1,
          "created_utc": 1739953697.0,
          "replies": []
        }
      ]
    },
    {
      "id": "mdgxys3",
      "author": "FreezenXl",
      "body": "Mafia 2 comes to mind",
      "score": 1,
      "created_utc": 1739902886.0,
      "replies": []
    },
    {
      "id": "mdh7goh",
      "author": "LBXZero",
      "body": "As a long time owner of ATi and AMD GPUs, \"So?\"",
      "score": 1,
      "created_utc": 1739905485.0,
      "replies": []
    },
    {
      "id": "mdhn44x",
      "author": "Fairuse",
      "body": "The solution is easy. You can run PhysX on a different GPU. You really don't need much for PhysX. A 1060 will do the job in a single slot without adding much thermals.",
      "score": 1,
      "created_utc": 1739909795.0,
      "replies": []
    },
    {
      "id": "mdhozia",
      "author": "tentaphane",
      "body": "Does this mean I can't play OG Roller Coaster Tycoon at 670FPS on my new \u00a31000 GPU?! Outrageous",
      "score": 1,
      "created_utc": 1739910308.0,
      "replies": []
    },
    {
      "id": "mdhu7u2",
      "author": "BishopsBakery",
      "body": "Red team go, red team go!",
      "score": 1,
      "created_utc": 1739911741.0,
      "replies": []
    },
    {
      "id": "mdi1k11",
      "author": "AlteredCabron2",
      "body": "and games will drop physx going forward",
      "score": 1,
      "created_utc": 1739913715.0,
      "replies": [
        {
          "id": "mdjs21q",
          "author": "Nickthemajin",
          "body": "The latest games this affects are more than ten years old",
          "score": 1,
          "created_utc": 1739933462.0,
          "replies": [
            {
              "id": "mdjs9g3",
              "author": "AlteredCabron2",
              "body": "so i guess no real loss",
              "score": 1,
              "created_utc": 1739933534.0,
              "replies": [
                {
                  "id": "mdjsv3l",
                  "author": "Nickthemajin",
                  "body": "Exactly. It\u2019s not going to matter that much. Anything old enough to have 32bit physx will perform fine with the cpu handling the physx portion. Anyone who\u2019s played any of these titles on an amd gpu has already experienced this.",
                  "score": 1,
                  "created_utc": 1739933743.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdil6cv",
      "author": "MyrKnof",
      "body": "And people still buy them because of their \"superior\" gimmicks.. I mean features..",
      "score": 1,
      "created_utc": 1739919500.0,
      "replies": []
    },
    {
      "id": "mdjazx5",
      "author": "SuppleDude",
      "body": "Rubs his 4090 FE.",
      "score": 1,
      "created_utc": 1739927756.0,
      "replies": []
    },
    {
      "id": "mdk5170",
      "author": "boajuse",
      "body": "ha ha ha ha",
      "score": 1,
      "created_utc": 1739938202.0,
      "replies": []
    },
    {
      "id": "mdk9syw",
      "author": "Osiris121",
      "body": "forgotten ancestral technologies",
      "score": 1,
      "created_utc": 1739940121.0,
      "replies": []
    },
    {
      "id": "mdlgp01",
      "author": "arthurdentstowels",
      "body": "I want to build a mid range gaming PC this year and it's getting to the point where I'll be buying an \"old\" card because of the shit storm that Nvidia has brought.    \nEven if I had the money for the 50 series, I don't think it's a wise investment. I've got a whole load of research to do.",
      "score": 1,
      "created_utc": 1739963469.0,
      "replies": []
    },
    {
      "id": "mdlo8j9",
      "author": "Murquel",
      "body": "\ud83d\ude02 such nvidia wow useless",
      "score": 1,
      "created_utc": 1739967277.0,
      "replies": []
    },
    {
      "id": "mdlubyc",
      "author": "None",
      "body": "\u00a0* Could that limitation be fixed with an hypothetical wrapper?\n\n\n\u00a0* Will Linux open source drivers share the same limitation?",
      "score": 1,
      "created_utc": 1739969838.0,
      "replies": []
    },
    {
      "id": "mds7on1",
      "author": "DayleD",
      "body": "For those of you who do end up getting a high powered card, please sign them up for Folding at home.   \nThat way they're contributing to medical research as you browse Reddit.",
      "score": 1,
      "created_utc": 1740049511.0,
      "replies": []
    },
    {
      "id": "mfeuiuj",
      "author": "Xinra68",
      "body": "What's a shame is that none of this info is available at launch. We have to wait until after people discover these things. The 50 Series seems like it's a big misstep for Nvidia.",
      "score": 1,
      "created_utc": 1740825196.0,
      "replies": []
    },
    {
      "id": "mdgjm9r",
      "author": "TacticlTwinkie",
      "body": "Make dedicated PhysX cards great again.",
      "score": 1,
      "created_utc": 1739898902.0,
      "replies": [
        {
          "id": "mdgk99g",
          "author": "ObviouslyTriggered",
          "body": "The original PhysX cards don\u2019t support the GPU solvers anyhow. You can run an older GPU even at PCIe x1 speeds and just use it for the PhysX that is still supported. :)",
          "score": 1,
          "created_utc": 1739899079.0,
          "replies": [
            {
              "id": "mdgotzf",
              "author": "Demented_Alchemy",
              "body": "I remember the original dedicated PhysX cards and how they made PhysX supported games like ghost recon advanced warfighter 2 better. My question is, if I were to startup that old game today with a new NVIDIA chip, would GRAW2 support PhysX on the new Nvidia chip?",
              "score": 2,
              "created_utc": 1739900353.0,
              "replies": []
            },
            {
              "id": "mdgro1f",
              "author": "Frenzie24",
              "body": "So like XLI or crossfire but the elder GPU is just used for physx?  That's a sick idea.\n\nEdit: with no bridging of course",
              "score": 1,
              "created_utc": 1739901141.0,
              "replies": [
                {
                  "id": "mdh3pm2",
                  "author": "ObviouslyTriggered",
                  "body": "No SLI just 2 GPUs\u2026",
                  "score": 2,
                  "created_utc": 1739904462.0,
                  "replies": [
                    {
                      "id": "mdhftdq",
                      "author": "Frenzie24",
                      "body": "Hi there.  Read the no bridging part again buddy",
                      "score": -2,
                      "created_utc": 1739907789.0,
                      "replies": [
                        {
                          "id": "mdl0jn2",
                          "author": "DangerousCousin",
                          "body": "Dont get your panties in a wad about being corrected on the internet \n\nSLI is when both GPUs are working together on the same task: rendering. Whether they use a cable or not doesn\u2019t matter\n\nPhysx cards are just running Physx calculations to lighten the CPU load. So not SLI",
                          "score": 1,
                          "created_utc": 1739953891.0,
                          "replies": [
                            {
                              "id": "mdonsx2",
                              "author": "Frenzie24",
                              "body": "The fact that you continue to correct me when me when my initial comment directly said it isn't SLI is wonderful.\n\nI love how autistic reddit is \u2665\ufe0f",
                              "score": 1,
                              "created_utc": 1739998947.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "mdhcwwc",
              "author": "darkfred",
              "body": "Yep, early Physx cards only looked faster because the CPU implementation of PhysX was so bad. But the CPU implementation improved with updates and CPUs improved to the extent that turning on GPU physics in many of those games actually runs considerably slower.\n\neg: it doesn' really matter because games that rely on this are newer 64bit games. Old games already run fast with CPU only.",
              "score": 1,
              "created_utc": 1739906988.0,
              "replies": [
                {
                  "id": "mdi45va",
                  "author": "Don-Tan",
                  "body": "That is not true. I have a RTX 5080 and a Ryzen 7 9800X3D and Arham Asylum runs like ass with Physx set to high. Talking about 40 fps here",
                  "score": 2,
                  "created_utc": 1739914411.0,
                  "replies": [
                    {
                      "id": "mdnbrzn",
                      "author": "darkfred",
                      "body": "Did you actually try running a game that old or are you just repeating something you read somewhere. Did you compare it with and without using the exact same settings, and with other problematic things that might affect the framerate turned off (such as vsync)\n\nAccording to this comment: https://www.reddit.com/r/gadgets/comments/1ishp63/nvidia_rtx50_series_doesnt_support_gpu_physx_for/mdkz6dq/\n\nThere is no difference in Arkham in an apples to apples comparison\n\nWhich makes sense because there is NO amount of work that a game like arkham could be doing to justify the need for hardware physics. Hardware physics is needed for hundreds of thousands of objects physically interacting. Not 3-20. \n\nIf there is a performance difference it isn't the fault of physx, it would be developers massively misusing the system in some way.",
                      "score": 1,
                      "created_utc": 1739986117.0,
                      "replies": [
                        {
                          "id": "mdnci6w",
                          "author": "Don-Tan",
                          "body": "I will try unlocking the framerate today and make a few screenshots with and without physx. I think the game runs so poorly is because the physx implementation for cpu is single core but i can be wrong.\n\nEdit: But yes, i am not kidding. I tried running it on my machine yesterday because i was mindblown about that announcement from nvidia and wanted to make sure my 1000+\u20ac GPU wasn't running worse than my old GTX 1080 \ud83d\ude06\n\nAlso i always turn off vsync because of my gsync monitor so that's already checked.",
                          "score": 1,
                          "created_utc": 1739986312.0,
                          "replies": [
                            {
                              "id": "mdndxp6",
                              "author": "Don-Tan",
                              "body": "Also, the framedrops only occur with heavy physx based elements, like running through an area full of physx accelerated fog or a lot of physx debris and so on.",
                              "score": 1,
                              "created_utc": 1739986698.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdi2fhi",
      "author": "JoostinOnline",
      "body": "~~The important thing is that you can still run those effects over a CPU. 32 bit titles with PhysX will have a ton of headroom for any modern CPU. You should be able to run things just fine.~~\n\n~~I agree that it sucks to ever see support dropped in things, but it's not going to cut support in any meaningful way.~~\n\nEdit: Apparently it's a bigger deal than I realized. That sucks, because while very few 32 bit games used PhysX, it was one of the coolest technologies back in the day. Hopefully some kind of wrapper can be created to work around it.",
      "score": 1,
      "created_utc": 1739913945.0,
      "replies": [
        {
          "id": "mdi4i4a",
          "author": "Don-Tan",
          "body": "Sadly that is not true. I have a RTX 5080 and a Ryzen 7 9800X3D and Arkham Asylum runs like ass with Physx set to high. Talking about 40 fps here. Just tested it.",
          "score": 2,
          "created_utc": 1739914503.0,
          "replies": [
            {
              "id": "mdic86p",
              "author": "JoostinOnline",
              "body": "Are you sure that's the PhysX? I just played Arkham Origins, and both that and Arkham City have max settings that are basically impossible over 1080p.",
              "score": 2,
              "created_utc": 1739916714.0,
              "replies": [
                {
                  "id": "mdjrb9p",
                  "author": "Don-Tan",
                  "body": "Resolution doesn't matter still only 40 fps standing in physx fog on 1080p",
                  "score": 0,
                  "created_utc": 1739933201.0,
                  "replies": [
                    {
                      "id": "mdk37qm",
                      "author": "JoostinOnline",
                      "body": "Damn. Would you mind testing what it is when you turn just that off? I'd really appreciate the info.\n\nAlso, updating my original post.",
                      "score": 2,
                      "created_utc": 1739937498.0,
                      "replies": [
                        {
                          "id": "mdq5zye",
                          "author": "Lucaboox",
                          "body": "https://youtu.be/mJGf0-tGaf4?si=jnFKoRwCUj1_qby6 here\u2019s some test someone did a bit ago",
                          "score": 2,
                          "created_utc": 1740015155.0,
                          "replies": [
                            {
                              "id": "mdr46x7",
                              "author": "JoostinOnline",
                              "body": "That's awesome (and incredibly depressing), thank you. The more I think about it, the more it makes sense. I believe early PhysX titles were single threaded, so they'd run exceptionally bad on modern CPU's, nullifying a lot of the gains.",
                              "score": 1,
                              "created_utc": 1740027643.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "mdgsylw",
      "author": "Sylanthra",
      "body": "I wonder if this has any impact provided you pair your 50 series cart with an equally modern CPU. PhysX load from 15+ year old games isn't going to stress modern cpus much.",
      "score": 1,
      "created_utc": 1739901496.0,
      "replies": []
    },
    {
      "id": "mdksvec",
      "author": "BloodSteyn",
      "body": "Meh, just tell the iGPU on your CPU to take over.",
      "score": 1,
      "created_utc": 1739949400.0,
      "replies": []
    },
    {
      "id": "mdhq0dr",
      "author": "Crenorz",
      "body": "This is epic stupid. Windows has been x64 for over a decade. No excuse to be using 32-bit - and if you are, the framerate should be insane - as it is +10 years old",
      "score": -1,
      "created_utc": 1739910594.0,
      "replies": []
    },
    {
      "id": "mdhs26l",
      "author": "TimeSuck5000",
      "body": "Nvidia put all their eggs into AI and just as quickly Deepseek put that strategy to shame. Now we\u2019re paying the price.",
      "score": -1,
      "created_utc": 1739911158.0,
      "replies": []
    }
  ]
}