{
  "post": {
    "title": "New Leak Reveals NVIDIA RTX 5080 Is Slower Than RTX 4090",
    "author": "chrisdh79",
    "id": "1i9oky5",
    "score": 2274,
    "created_utc": 1737816816.0,
    "selftext": "",
    "num_comments": 442,
    "subreddit": "gadgets",
    "url": "https://www.reddit.com/r/gadgets/comments/1i9oky5/new_leak_reveals_nvidia_rtx_5080_is_slower_than/"
  },
  "comments": [
    {
      "id": "m93ogjc",
      "author": "fantasybro",
      "body": "Looks like I\u2019m skipping another generation",
      "score": 682,
      "created_utc": 1737818800.0,
      "replies": [
        {
          "id": "m9403gv",
          "author": "MVPizzle_Redux",
          "body": "This isn\u2019t going to get better. Look at all the AI investments Meta just made. I guarantee next year the performance gain year over year will be even more incremental",
          "score": 324,
          "created_utc": 1737822258.0,
          "replies": [
            {
              "id": "m94676t",
              "author": "Mrstrawberry209",
              "body": "Hopefully AMD might catch up and give Nvidia the reason to give us better upgrades...",
              "score": 110,
              "created_utc": 1737823988.0,
              "replies": [
                {
                  "id": "m94dz2n",
                  "author": "FrootLoop23",
                  "body": "AMD is smartly focusing on the mid range. That\u2019s where the majority of buyers are.",
                  "score": 136,
                  "created_utc": 1737826236.0,
                  "replies": [
                    {
                      "id": "m96o55p",
                      "author": "ak-92",
                      "body": "Good, as someone who has to buy high-end GPUs for professional use (as performance literally means money earned to live so no choice but to buy highest performance possible), I see that NVDIA convincing gamers to buy pro grade hardware as some-kind necessity is the biggest con any company has pulled in recent decades. Having slightly lower game settings, or few fos lower is not a tragedy, and saving hundreds or thousands for it is definitely worth it. For an average person paying 2k+ for a gpu to game is crazy.",
                      "score": 6,
                      "created_utc": 1737851492.0,
                      "replies": [
                        {
                          "id": "m9emui1",
                          "author": "saints21",
                          "body": "Yeah, it always cracks me up when people act like a game is broken and unplayable because it barely gets over 80 fps.\n\nMeanwhile millions of people manage to enjoy gaming as long as it's stableish around 30...",
                          "score": 3,
                          "created_utc": 1737955195.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m94x9e6",
                      "author": "wamj",
                      "body": "I do wonder what this\u2019ll mean on the low to mid range long term. Between intel and AMD, they might be able to build brand loyalty for people who aren\u2019t in the high end market now but will be in the future.",
                      "score": 3,
                      "created_utc": 1737831747.0,
                      "replies": [
                        {
                          "id": "m94yw8f",
                          "author": "mexodus",
                          "body": "Well brand loyalty doesn\u2019t really do anything when you do not provide the high end.",
                          "score": -4,
                          "created_utc": 1737832221.0,
                          "replies": [
                            {
                              "id": "m954kiy",
                              "author": "NotAComplete",
                              "body": "Why?",
                              "score": 3,
                              "created_utc": 1737833873.0,
                              "replies": [
                                {
                                  "id": "m956s7p",
                                  "author": "mexodus",
                                  "body": "What do you mean why? The statement above my comment says: \u201ebuild brand loyalty for non high end in order to keep them when they move to the high end. But they don\u2019t offer 5090 level high end - this is not a judgement just a simple thing. Unless they sell something like a 5090 (which I would very much welcome) - the brand loyalty will just not do what the statement says. You cannot convince people to buy products you don\u2019t have.",
                                  "score": 0,
                                  "created_utc": 1737834528.0,
                                  "replies": [
                                    {
                                      "id": "m957tf2",
                                      "author": "NotAComplete",
                                      "body": "I'm having a really hard time interpreting what you're trying to say, but it seems like you're saying there's no brand loyalty on midrange cards that give you more performance for your dollar, only high range cards? Is that accurate?",
                                      "score": 4,
                                      "created_utc": 1737834837.0,
                                      "replies": [
                                        {
                                          "id": "m9592oj",
                                          "author": "mexodus",
                                          "body": "No, sorry if I did not describe correctly: I am saying even if a customer is loyal to a mid range GPU brand - this loyality will NOT drive his decision when he/she decides to buy a high-end card because the mid-range GPU brand simply does not offer one (e.g., if intel doesn\u2019t produce a 5090 like GPU - the intel loyal customer that wants a 5090 like GPU will still switch despite intel loyality.)",
                                          "score": 2,
                                          "created_utc": 1737835217.0,
                                          "replies": [
                                            {
                                              "id": "m95shok",
                                              "author": "half3clipse",
                                              "body": "The high range GPU market your referring to basically does not exist. Nvida chases it because they can divert a small fraction of their fab time that would otherwise go to high end server cards for a marketing opportunity. And that's mostly brand recognition for the managers in charge of procurement who \"want the best\" \n\nAlmost none of Nvidas sales were consumers buying 4090s. Infact almost none of the 4090s sales were consumers either, they were \"not ai\" models bought by people using it as an alternative to the export restricted server cards. \n\nGlobally, the number of consumers with 4090s maybe a couple hundered thousand. There's about as many 4090s in consumers hands as there are 1660s still in use. There's far less than there are 1050s still being used. Almost all 4000 series cards in consumer use are the 4060, the 4060TI and the 4070. \n\n> customer is loyal to a mid range GPU brand this loyality will NOT drive his decision when he/she decides to buy a high-end card\n\nThis isn't a thing that happens. The conversion rate is so low it's irrelevant. The vast bulk of consumer sales is in the mid range, and they tend to not replace cards every generation.",
                                              "score": 2,
                                              "created_utc": 1737841132.0,
                                              "replies": []
                                            },
                                            {
                                              "id": "m95bqz9",
                                              "author": "NotAComplete",
                                              "body": "There is a high end market and a mid range, budget, value and I'm sure more. It's seems like youre saying brand loyalty only exists in the high end market.",
                                              "score": 1,
                                              "created_utc": 1737836034.0,
                                              "replies": [
                                                {
                                                  "id": "m95i8kg",
                                                  "author": "mexodus",
                                                  "body": "Nah - I will give up since I cannot convey my thoughts in an understandable way. I am saying if you are buying mid range cards and are loyal to one brand that only offers mid range cards - you are required to break that loyality if you want a high end card - and you will be star you simply cannot get it from the brand you are loyal to. So I very much believe that brand loyalty exist in every budget category. Just saying I don\u2019t believe people despite desiring high end will stay with mid range just for loyality reasons.",
                                                  "score": 0,
                                                  "created_utc": 1737838015.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m967wk5",
                                      "author": "FrootLoop23",
                                      "body": "I\u2019m glad that AMD doesn\u2019t offer a GPU that starts at $2k (because in the real world it will be much higher). I hope they never do.",
                                      "score": 1,
                                      "created_utc": 1737846047.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "m9pz3du",
                              "author": "wamj",
                              "body": "Unless intel and amd eventually get competitive in the high end market.",
                              "score": 1,
                              "created_utc": 1738104140.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m954oi8",
                      "author": "Numerlor",
                      "body": "amd is not doing anything smartly, they completely fucked up their current launch presumably because of nvidia's pricing",
                      "score": 71,
                      "created_utc": 1737833905.0,
                      "replies": [
                        {
                          "id": "m9674d7",
                          "author": "FrootLoop23",
                          "body": "The launch hasn\u2019t even happened yet. Nothing has been fucked up yet.",
                          "score": 42,
                          "created_utc": 1737845789.0,
                          "replies": [
                            {
                              "id": "m9685r9",
                              "author": "Numerlor",
                              "body": "Stores already have stock while basically nothing has been revealed about the GPUs and the first release date mention was in a tweet, it has been obviously pushed back as a reaction to nvidia's roundup.",
                              "score": 3,
                              "created_utc": 1737846131.0,
                              "replies": [
                                {
                                  "id": "m96bk80",
                                  "author": "FrootLoop23",
                                  "body": " Considering Nvidia hasn\u2019t released the 5070 models yet, it\u2019s probably smart that AMD decided to wait. Get it right on price and have the support for FSR4 day one. Let Nvidia go first with their competing product.\n Personally I don\u2019t want an Nvidia monopoly like they currently have. AMD doing well can only benefit us.",
                                  "score": 21,
                                  "created_utc": 1737847259.0,
                                  "replies": [
                                    {
                                      "id": "m97gq1e",
                                      "author": "QuickQuirk",
                                      "body": "yeap. AMD keeps rushing products to launch just because nvidia is launching. that's hurt them in the past.\n\nRelease a *good* product, well priced, when it's ready.",
                                      "score": 9,
                                      "created_utc": 1737861402.0,
                                      "replies": []
                                    },
                                    {
                                      "id": "m9fimaa",
                                      "author": "Numerlor",
                                      "body": "lmao they were planning $899/$749 https://videocardz.com/newz/retailer-confirms-powercolor-radeon-rx-9070-xt-red-devil-limited-edition-is-in-stock-talks-amd-pricing-strategy",
                                      "score": 0,
                                      "created_utc": 1737973578.0,
                                      "replies": [
                                        {
                                          "id": "m9gvr1o",
                                          "author": "FrootLoop23",
                                          "body": "Videocardz is your reputable source? An anonymous retailer is Bulgaria lol\u2026",
                                          "score": 2,
                                          "created_utc": 1737993110.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "m95q010",
                          "author": "RockerXt",
                          "body": "Id rather they take their time and do it right, even if debating pricing it apart of that.",
                          "score": 31,
                          "created_utc": 1737840369.0,
                          "replies": []
                        },
                        {
                          "id": "m95j25m",
                          "author": "MajesticTop8223",
                          "body": "Do not talk down about savior amd on reddit",
                          "score": 0,
                          "created_utc": 1737838265.0,
                          "replies": []
                        },
                        {
                          "id": "m9hme9z",
                          "author": "ChefCurryYumYum",
                          "body": "We don't know that AMD \"fucked up their current launch.\"\n\nThey have delayed the launch, presumably so reviewers will test the current 50x series against Nvidia's last gen cards where AMD doesn't think they will look that impressive for gen over gen.\n\nWe already are hearing of massive shortages of the 5090, while AMD has been stockpiling units of their next gen GPUs since December. \n\nI'm reserving judgement until the AMD products launch.",
                          "score": 1,
                          "created_utc": 1738000568.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m9c34a8",
                      "author": "themortalrealm",
                      "body": "You\u2019d be better off buying a mid range nvidia card unless you enjoy your games having optimization issues",
                      "score": 0,
                      "created_utc": 1737926378.0,
                      "replies": [
                        {
                          "id": "m9cxath",
                          "author": "FrootLoop23",
                          "body": "I have a 7900XT. Don\u2019t know what optimization issues you\u2019re talking about, unless you mean the sorry state PC games sometimes release in. GPU brand can\u2019t save you from that.",
                          "score": 1,
                          "created_utc": 1737934881.0,
                          "replies": [
                            {
                              "id": "ma7mit2",
                              "author": "Thelongdong11",
                              "body": "Indiana Jones requires rtx to play. The next doom game will also require rtx. AMD is gonna fall further behind if they don't get rtx right",
                              "score": 1,
                              "created_utc": 1738338564.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m948itc",
                  "author": "juh4z",
                  "body": "AMD gave up lol",
                  "score": 30,
                  "created_utc": 1737824653.0,
                  "replies": [
                    {
                      "id": "m94ek4r",
                      "author": "leberwrust",
                      "body": "They want to return to high end in 2026. I have no idea how well that will work tbh.",
                      "score": 12,
                      "created_utc": 1737826405.0,
                      "replies": [
                        {
                          "id": "m958tun",
                          "author": "juh4z",
                          "body": "I want the most competition possible, be that AMD, Intel or any other company, fuck NVidia.\n\nThat said, other companies just don't stand a chance, they can make good options for those on a budget, maybe even something mid range if you don't really care about ray tracing performance (although, you should, cause we already have games that require ray tracing capable gpus to run), but if you wanna play at 4k with ray tracing and all those shenanigans, Intel or AMD will never get you what you need.",
                          "score": 12,
                          "created_utc": 1737835142.0,
                          "replies": []
                        },
                        {
                          "id": "m963ezh",
                          "author": "TheKappaOverlord",
                          "body": "Realistically they'll release like one \"high end\" card in 2026 assuming they don't nope out realizing its too far gone, but they won't seriously return to high end card business. If they give now, they'll never reclaim what little foothold they had to begin with. Instead their home will be midrange cards.\n\nIts either Intel or bust. And unfortunately the calls indicate its bust.",
                          "score": 4,
                          "created_utc": 1737844578.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m95rh2a",
                  "author": "ZaeBae22",
                  "body": "I have more faith in Intel. AMD thinks 50-70$ undercuts are enough lmao",
                  "score": 1,
                  "created_utc": 1737840819.0,
                  "replies": []
                },
                {
                  "id": "m9bkzlt",
                  "author": "icebeat",
                  "body": "Lol, it is not going to happen, they are family",
                  "score": 1,
                  "created_utc": 1737921394.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m95o625",
              "author": "epraider",
              "body": "To a degree it\u2019s kind of a good thing. The technology is mature and your purchase holds its value longer and isn\u2019t rapidly outclassed by new hardware right around the corner, which in turn means the performance requirements for new games or tools aren\u2019t going advance past your purchase\u2019s capabilities for longer.",
              "score": 20,
              "created_utc": 1737839820.0,
              "replies": []
            },
            {
              "id": "m94oeqd",
              "author": "Vosofy",
              "body": "Good. Means I have no reason to drop 800. My 3080 can carry me until 70 series at least",
              "score": 4,
              "created_utc": 1737829222.0,
              "replies": []
            },
            {
              "id": "m96f8nx",
              "author": "Faranocks",
              "body": "Kinda doubt it. Nvidia is stuck on same node, next Gen should be up a node or two. I'm sure it will cost too much, but it might still at least be a decent uplift in performance.",
              "score": 2,
              "created_utc": 1737848496.0,
              "replies": []
            },
            {
              "id": "m949pd3",
              "author": "The_Deku_Nut",
              "body": "It's almost like we're reaching the limits of what can be accomplished using current materials.",
              "score": 12,
              "created_utc": 1737824995.0,
              "replies": [
                {
                  "id": "m94ffh3",
                  "author": "sdwvit",
                  "body": "Or there is no competition",
                  "score": 32,
                  "created_utc": 1737826652.0,
                  "replies": [
                    {
                      "id": "m963sbz",
                      "author": "TheKappaOverlord",
                      "body": "Nah. We really are reading the Limit as far as what can technically be done with current materials. \n\nThe *most* we can do as far as genuinely \"improving\" computing now is either make the already crazy big cards, even bigger, or we start figuring out how to shove quantum computing cores into our computers.\n\nThere being no competition means theres no reason for Nvidia to give a shit about quality control. So they can shit out the biggest turds imaginable now and theres no recourse until people either beg AMD to come back (won't happen) or Intel produces a competent alternative (won't happen)",
                      "score": 4,
                      "created_utc": 1737844698.0,
                      "replies": [
                        {
                          "id": "m999qbu",
                          "author": "V1pArzZz",
                          "body": "AMD or Intel could come back eventually, happened on cpu market where AMD was far behind and suddenly outperformed Intel. 7900xtx is pretty much a 4080 equivalent with bad RT so its not that hugely behind either.",
                          "score": 1,
                          "created_utc": 1737895315.0,
                          "replies": []
                        },
                        {
                          "id": "m99d6sj",
                          "author": "btown1987",
                          "body": "Tell me you don't know anything about quantum computing without telling me you don't know anything about quantum computing.",
                          "score": 1,
                          "created_utc": 1737896911.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m95pvnb",
                      "author": "CompromisedToolchain",
                      "body": "Ding ding!",
                      "score": -3,
                      "created_utc": 1737840332.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m95srgj",
                  "author": "bearybrown",
                  "body": "I doubt it, with how small the performance increased, I think they pull an Intel.",
                  "score": 5,
                  "created_utc": 1737841215.0,
                  "replies": []
                },
                {
                  "id": "m949yuf",
                  "author": "MVPizzle_Redux",
                  "body": "Or we\u2019re just figuring it out and are scaling up to meet goals that are still being developed",
                  "score": 6,
                  "created_utc": 1737825070.0,
                  "replies": [
                    {
                      "id": "m961k80",
                      "author": "bonesnaps",
                      "body": "Scalping up* to meet goals",
                      "score": 2,
                      "created_utc": 1737843983.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m95lgy2",
              "author": "IntrinsicGiraffe",
              "body": "Hoping AI would help with tech advancements like they are in other fields but I've been using this 1080 for too long! I need a VR capable GPU.",
              "score": 1,
              "created_utc": 1737838999.0,
              "replies": []
            },
            {
              "id": "m95sxac",
              "author": "illathon",
              "body": "Good reason why AMD and Intel need more support.",
              "score": 1,
              "created_utc": 1737841264.0,
              "replies": []
            },
            {
              "id": "m972a2v",
              "author": "DonArgueWithMe",
              "body": "Do you really think that companies like Facebook or Google are investing in AI for the difference it makes in gaming?!?",
              "score": 1,
              "created_utc": 1737856295.0,
              "replies": [
                {
                  "id": "m97420l",
                  "author": "MVPizzle_Redux",
                  "body": "No that\u2019s not what I\u2019m saying. What I\u2019m saying is they\u2019re all investing in AI so the hardware will be geared less towards gaming from Nvidias end since that\u2019s where the profit is coming from",
                  "score": 1,
                  "created_utc": 1737856905.0,
                  "replies": [
                    {
                      "id": "m977kkj",
                      "author": "DonArgueWithMe",
                      "body": "Do you think major AI farms are running 4090s/5090s? Sure somebody running a home ai project might, but anybody making an actual investment would be running professional hardware. Look up the nvidia h100 for an example, it's tens of thousands per chip with entire stacks costing up to nearly half a million. [example](https://viperatech.com/shop/nvidia-dgx-h100-p4387-system-640gb/?srsltid=AfmBOopq__FBwqKbjIJJlrrX4hF8tHfqFmQetIwQm70gnsqJ86_ngJHE-tU&gQT=2)",
                      "score": 2,
                      "created_utc": 1737858138.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m93y94z",
          "author": "SteveThePurpleCat",
          "body": "1060 rides out another generation!",
          "score": 36,
          "created_utc": 1737821721.0,
          "replies": [
            {
              "id": "m96z30v",
              "author": "Osmodius",
              "body": "Only replaced mine this year. What a hero of a card.",
              "score": 3,
              "created_utc": 1737855193.0,
              "replies": []
            },
            {
              "id": "m941he9",
              "author": "Lost_Knight12",
              "body": "What a beast of a card.\n\nSadly I had to upgrade from my EVGA 1060 6GB to a 4070 Ti Super once I bought a 1440p 240hz monitor.\n\nI would have spent another year on the 1060 if I stayed with my 1080p monitor.",
              "score": 8,
              "created_utc": 1737822656.0,
              "replies": [
                {
                  "id": "m95mm65",
                  "author": "microwavedave27",
                  "body": "I still use mine for 1080p 60Hz, can't really play every game anymore but there's still plenty of stuff it can play. 8 years and going strong.",
                  "score": 3,
                  "created_utc": 1737839348.0,
                  "replies": [
                    {
                      "id": "m95pxpb",
                      "author": "Hoagiewave",
                      "body": "I was using an Intel Quadro2000M (on a 2011 laptop) until 3 months ago. Most new games I turned down to like 480p or sometimes lower lmao, but it ran..... not horrible. DX12 only games becoming more and more common forced my hand. They didn't run at all, they didn't even open.",
                      "score": 1,
                      "created_utc": 1737840349.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m95pkm4",
              "author": "tramster",
              "body": "That\u2019s what I\u2019m still rolling with.",
              "score": 1,
              "created_utc": 1737840240.0,
              "replies": []
            },
            {
              "id": "m96rd29",
              "author": "kidmerc",
              "body": "A lot of new games coming out are requiring RTX cards now. 1060 rides another generation as long as you aren't playing anything new.",
              "score": 1,
              "created_utc": 1737852566.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m967ffz",
          "author": "None",
          "body": "I\u2019ve skipped 5 so far. Still hanging on. \n\nThough I do like the 4070s. I might get one. One day",
          "score": 9,
          "created_utc": 1737845892.0,
          "replies": [
            {
              "id": "m97h75x",
              "author": "QuickQuirk",
              "body": "Given that the 50 series so far seems to be both:\n1. Stagnant on performance per dollar\n2. Performance per watt\n\n... then the biggest competitor to the 50 series *is the 40 series*.\n\nGetting a 4070 might be a very reasonable choice. We'll know more after the 5070 releases.",
              "score": 13,
              "created_utc": 1737861579.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m949pka",
          "author": "Spacepickle89",
          "body": "Looks at 970\u2026\n\n*one more year\u2026*",
          "score": 17,
          "created_utc": 1737824996.0,
          "replies": [
            {
              "id": "m94ey56",
              "author": "S145D145",
              "body": "Honest question, wouldn't it be benefitial upgrading but to an older model at this point? Like you can get a 3060ti for 300 usd which isn't free but is not that expensive either.\n\n\nOf course this only makes sense if you have a reason to do so. If you are not even interested on newish games then i guess no point",
              "score": 24,
              "created_utc": 1737826515.0,
              "replies": [
                {
                  "id": "m95qh2f",
                  "author": "Abba_Fiskbullar",
                  "body": "Or even a 6650xt, which can be had for $200-ish, is much, much better than a 970.",
                  "score": 6,
                  "created_utc": 1737840513.0,
                  "replies": [
                    {
                      "id": "m96iba8",
                      "author": "Holovox",
                      "body": "That's what I did. Pretty happy with it. Most of the games I play run just fine at 1440p Medium to High settings. Even Cyberpunk.",
                      "score": 1,
                      "created_utc": 1737849536.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m94mk5b",
                  "author": "PatNMahiney",
                  "body": "Is that a used price? There's not much stock left for previous generations, so those don't really drop in price like one might expect.",
                  "score": 4,
                  "created_utc": 1737828699.0,
                  "replies": [
                    {
                      "id": "m94rugv",
                      "author": "S145D145",
                      "body": "Not really, I just looked up rtx 3060ti on [amazon.com](http://amazon.com) and looked at the first results lol\n\n  \nE: Ooh wait, I'm now realizing those were results for rtx 3060, not 3060ti. The ti is at 479. There's also a listing for the 4060 for 310 usd tho",
                      "score": 9,
                      "created_utc": 1737830199.0,
                      "replies": [
                        {
                          "id": "m94ty5m",
                          "author": "PatNMahiney",
                          "body": "I just looked on Amazon, and the first several results are 3060s, not 3060TIs. If I scroll far enough, I can find 3060TIs for ~$400, but that means you're paying the MSRP for a 4 year old card. Not a good deal.\n\nEven $300 for a 3060 isn't great. That's only $30 less than MSRP for a 4 year old card.",
                          "score": 4,
                          "created_utc": 1737830802.0,
                          "replies": [
                            {
                              "id": "m96ai6k",
                              "author": "Inayaarime",
                              "body": "well, the 3060 is one of the most wanted cards.. i think in Price/performance it's one of the best from the last 3 gens.. I could be wrong.    \nBut that would explain the price.",
                              "score": 0,
                              "created_utc": 1737846909.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m96aqb5",
                      "author": "1_Rose_ToRuleThemAll",
                      "body": "go to r/hardwareswap people sell cards all the time. Used 3080s for 370 isn't bad, still not great price but its a great card still imo",
                      "score": 2,
                      "created_utc": 1737846983.0,
                      "replies": []
                    },
                    {
                      "id": "m95pyp9",
                      "author": "Blue-Thunder",
                      "body": "https://www.reddit.com/r/hardwareswap/comments/1h3jpxt/canabh_hundreds_of_gtx_1070_rtx_3060_rtx_3060m/\n\nThese are ex mining cards. I bought a 5600XT from them back in November. No issues with the card at all.",
                      "score": 1,
                      "created_utc": 1737840358.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m950lpm",
                  "author": "hellowiththepudding",
                  "body": "I\u2019ve got a Vega 64 that was sub $300, 5 years ago. Upgrades in that price bracket are marginal, at best still.",
                  "score": 2,
                  "created_utc": 1737832719.0,
                  "replies": []
                },
                {
                  "id": "m9j9nez",
                  "author": "LGCJairen",
                  "body": "Can find a used 3080 for around 300-350",
                  "score": 1,
                  "created_utc": 1738017183.0,
                  "replies": []
                },
                {
                  "id": "m94wkta",
                  "author": "Spacepickle89",
                  "body": "Fair question, I just didn\u2019t have the time before and now o have a 1 year old so \u2026 less time",
                  "score": 1,
                  "created_utc": 1737831553.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m97om9t",
              "author": "THEROFLBOAT",
              "body": "Looks at mine....\n\nYOU CAN STILL PLAY DARKTIDE AT 480p MIN SETTINGS DAMMIT",
              "score": 2,
              "created_utc": 1737864408.0,
              "replies": []
            },
            {
              "id": "m98599x",
              "author": "PacketAuditor",
              "body": "You good bro? Said the same thing to my 3080....",
              "score": 2,
              "created_utc": 1737871873.0,
              "replies": []
            },
            {
              "id": "m94xps2",
              "author": "Velocyra",
              "body": "Lol I decided to finally upgrade fron the 970 last year.... to the 4090. Holding out def paid off",
              "score": 1,
              "created_utc": 1737831879.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m94m90v",
          "author": "Risley",
          "body": "looks like I get to say\u2026.GOTTEM",
          "score": 2,
          "created_utc": 1737828609.0,
          "replies": []
        },
        {
          "id": "m95ep13",
          "author": "OsmerusMordax",
          "body": "I just bought a 3060 last year, I think I\u2019ll be good for awhile.",
          "score": 1,
          "created_utc": 1737836936.0,
          "replies": []
        },
        {
          "id": "m962rbe",
          "author": "rebbsitor",
          "body": "I bought an RTX 2080 6 years ago.  At this rate I'll never upgrade lol",
          "score": 1,
          "created_utc": 1737844366.0,
          "replies": []
        },
        {
          "id": "m9693tn",
          "author": "Fredasa",
          "body": "We've known it for months, too.  \"Slower\" is a gobsmacking understatement.  Yeesh.  It's so little improved over the 4080 that you really do need a fps meter if you want to be concretely aware of a difference.",
          "score": 1,
          "created_utc": 1737846443.0,
          "replies": []
        },
        {
          "id": "m99aguc",
          "author": "Aestroj",
          "body": "Haven\u2019t bought since the 20xx gen, getting hard to skip",
          "score": 1,
          "created_utc": 1737895669.0,
          "replies": []
        },
        {
          "id": "m9btvyi",
          "author": "CosmicCreeperz",
          "body": "Why?  The 4090 is $1800, the 5080 is $1000.  \n\nWho cares what generation it is.  An old 911 Turbo S is still faster than a new Carerra.\n\nIf you have a 4090, keep it or upgrade to even more absurd 5090.",
          "score": 1,
          "created_utc": 1737923868.0,
          "replies": []
        },
        {
          "id": "m9dr5ew",
          "author": "None",
          "body": "Or buying a 4090? One of those is definitely more fun lol",
          "score": 1,
          "created_utc": 1737943866.0,
          "replies": []
        },
        {
          "id": "m9li8ut",
          "author": "None",
          "body": "Skipping untill this AI performance focus dies off and they start making real GPUS again",
          "score": 1,
          "created_utc": 1738045898.0,
          "replies": []
        },
        {
          "id": "m94s4ji",
          "author": "Top_Rekt",
          "body": "That'd what I'm planning on, mostly because I want a \"nice\u00a0 6090.",
          "score": 1,
          "created_utc": 1737830280.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93jsps",
      "author": "Gipetto",
      "body": "It would not be at all surprising if they\u2019re giving up gaming & rendering performance in favor of crypto and ai performance. NVIDIA is all in on riding those waves, and I wouldn\u2019t be afraid to wager that it\u2019ll start effecting their entire product line.",
      "score": 896,
      "created_utc": 1737817297.0,
      "replies": [
        {
          "id": "m93l5ba",
          "author": "Fatigue-Error",
          "body": "Deleted by User using PowerDeleteSuite",
          "score": 226,
          "created_utc": 1737817744.0,
          "replies": [
            {
              "id": "m94enrf",
              "author": "DingleBerrieIcecream",
              "body": "While this has been said before, it\u2019s also the case that 4K (on a 27\u201d monitor) approaches a threshold where people see very little gain if they upgrade to 6k or 8k. At least going beyond 4K will have very diminishing returns in terms of perceived visual fidelity.  Add to that that 120 or maybe 240hz refresh also begins to be a max speed that offers little if one goes beyond it. So once flagship GPU\u2019s can handle 4K 240hz signal, there becomes less room or need for improvement at some point.",
              "score": 42,
              "created_utc": 1737826434.0,
              "replies": [
                {
                  "id": "m95df3v",
                  "author": "zernoc56",
                  "body": "I honestly don\u2019t care about anything beyond 1440. 8k is *hilariously* overkill. I don\u2019t need a five hour game to take up the entirety of a 10 terabyte ssd by having grass textures that show pollen and whatnot on every blade, like jesus christ. If I want photorealistic graphics, I\u2019ll watch a movie.",
                  "score": 31,
                  "created_utc": 1737836544.0,
                  "replies": [
                    {
                      "id": "m98qou5",
                      "author": "missmuffin__",
                      "body": "I hear /r/outside also has photorealistic graphics with grass and pollen and all that.\n\n*edit:typo",
                      "score": 7,
                      "created_utc": 1737884377.0,
                      "replies": [
                        {
                          "id": "m9ckp22",
                          "author": "NobodyLikesMeAnymore",
                          "body": "tbh I tried outside once and the graphics are detailed, yes, but it's like there's no art direction at all and everything just comes together as \"meh.\"",
                          "score": 3,
                          "created_utc": 1737931249.0,
                          "replies": [
                            {
                              "id": "m9f2foh",
                              "author": "missmuffin__",
                              "body": "Yeah.  There's no game designer so it's kind of a mish mash of a variety of influences.",
                              "score": 3,
                              "created_utc": 1737963506.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m9b7n0b",
                          "author": "Exeftw",
                          "body": "So are you here or are you outside??",
                          "score": 1,
                          "created_utc": 1737917639.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m959qks",
                  "author": "pattperin",
                  "body": "Yeah I'm pretty close to being at a point where I just won't need a new GPU unless something crazy happens in game development techniques. I've got a 3080ti and I play in 4k, it shows it's warts at that resolution and I've got to play most games with DLSS on for a steady framerate above 60 fps. It gets me 120+ typically, but I'd rather have the higher native frame rate and lower latency so I'm going to upgrade when there are 4k cards that can do 4k 120+ with DLSS off. \n\n\n5080 might be that card, might not be. We will see once the benchmarks get released. Hoping this is the generation, willing to wait if not. But I've got high hopes for a 5080ti or super coming out and giving me what I am waiting for. I've got medium high hopes that the 5080 is what I'm looking for, but wouldn't be surprised if it's not quite where I want it to get to",
                  "score": 2,
                  "created_utc": 1737835420.0,
                  "replies": []
                },
                {
                  "id": "m97wd66",
                  "author": "Diedead666",
                  "body": "I'm 4k 32inch. I'm sensitive to resolution and even at this size I can not see the pixels. The issue with PC hardware is at high settings 4090 can't hold steady high frames. Even 30 more ream performance can not hold steady 120 real frames and even more fake frames you will feel it.",
                  "score": 1,
                  "created_utc": 1737867653.0,
                  "replies": []
                },
                {
                  "id": "m95rfwx",
                  "author": "PM_ME_OVERT_SIDEBOOB",
                  "body": "It\u2019s why I love how cheap TVs are nowadays. Visual performance has diminishing returns and 800$ and 2k$ don\u2019t look much different",
                  "score": 0,
                  "created_utc": 1737840809.0,
                  "replies": [
                    {
                      "id": "m961mxa",
                      "author": "GetFvckedHaha",
                      "body": "Huh?  There is a marked visual distinction between a 900-1000 dollar Samsung/LG/Sony 40ish inch OLED and a 2000-2300 dollar 70 inch of the same brand.",
                      "score": 10,
                      "created_utc": 1737844007.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93th4v",
              "author": "Juicyjackson",
              "body": "Its also getting so much harder to improve on modern architecture.\n\nRight now the 5090 is on 5nm, the size of a silicon atom is 0.2nm...\n\nWe are quickly going to run into physical limitations of silicon.",
              "score": 68,
              "created_utc": 1737820324.0,
              "replies": [
                {
                  "id": "m93xcp1",
                  "author": "cspinasdf",
                  "body": "the whole 3 nm, 5 nm chip size is mostly just marketing. They don't actually have any feature of that size. Like 5 nm chips have a gate pitch of 51nm and a metal pitch of 30nm. 3 nm chips have a gate pitch of 48nm and a metal pitch of 24 nm. So there is still quite a ways to go before we have to get smaller than individual atoms.",
                  "score": 136,
                  "created_utc": 1737821457.0,
                  "replies": [
                    {
                      "id": "m94p0pb",
                      "author": "Lied-",
                      "body": "Just to add onto this, the physical limitations of semiconductors are actually quantum tunneling phenomena, which occurs at these sub 50nm gate sizes.",
                      "score": 38,
                      "created_utc": 1737829395.0,
                      "replies": [
                        {
                          "id": "m9526pv",
                          "author": "thecatdaddysupreme",
                          "body": "Can you explain please?",
                          "score": 4,
                          "created_utc": 1737833179.0,
                          "replies": [
                            {
                              "id": "m953wbz",
                              "author": "TheseusPankration",
                              "body": "When the gates get too thin, electrons can pass through them like they are not there. This makes them a poor switch. The 5 nm thing is marketing. The features are in the 10s of nm.",
                              "score": 30,
                              "created_utc": 1737833676.0,
                              "replies": [
                                {
                                  "id": "m965vzz",
                                  "author": "thecatdaddysupreme",
                                  "body": "Fascinating. Thank you.",
                                  "score": 5,
                                  "created_utc": 1737845380.0,
                                  "replies": [
                                    {
                                      "id": "m98645l",
                                      "author": "ZZ9ZA",
                                      "body": "Think of it a bit like the resolution of a screen, but the smallest thing you can draw is much larger than one pixel\u2026",
                                      "score": 2,
                                      "created_utc": 1737872320.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "id": "m9546a4",
                              "author": "General_WCJ",
                              "body": "The issue with quantum tunneling is basically that electrons can \"phase through walls\" if those walls are thin enough.",
                              "score": 9,
                              "created_utc": 1737833758.0,
                              "replies": [
                                {
                                  "id": "m95dvf5",
                                  "author": "zernoc56",
                                  "body": "I imagine the Casimir effect is also a concern at some point as well.",
                                  "score": 3,
                                  "created_utc": 1737836681.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m955b7d",
                      "author": "jack-K-",
                      "body": "In regards to the marketing term for the node, I\u2019m pretty sure we can get down to the 1nm point eventually, GP of 42 and MP of 16, maybe a decade or so before we see it in gaming hardware, but at that point not only are we dancing next to quantum tunneling but also reaching the limits of current lithography resolution.",
                      "score": 1,
                      "created_utc": 1737834090.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m93u2ru",
                  "author": "ColonelRPG",
                  "body": "They've been saying that line for 20 years.",
                  "score": 36,
                  "created_utc": 1737820500.0,
                  "replies": [
                    {
                      "id": "m93w4k7",
                      "author": "philly_jake",
                      "body": "20 years ago we were at what, 90nm at the cutting edge? Maybe 65nm. So we\u2019ve shrunk by roughly a factor of 15-20 linearly, meaning transistor densities up by several hundred fold. We will never get another 20x linear improvement. That means that better 3d stacking is the only way to continue increasing transistor density. Perhaps we will move to a radically different technology than silicon wafers by 2045, but i kind of doubt it. Neither optical nor quantum computing can really displace most of what we use transistors for now, though they might be helpful for AI workloads.",
                      "score": 14,
                      "created_utc": 1737821099.0,
                      "replies": [
                        {
                          "id": "m93yc9n",
                          "author": "Apokolypze",
                          "body": "Forgive my ignorance but once we hit peak density, what's stopping us from making that ultra dense wafer... Bigger?",
                          "score": 6,
                          "created_utc": 1737821746.0,
                          "replies": [
                            {
                              "id": "m93z2up",
                              "author": "blither86",
                              "body": "Eventually, I believe, it's distance. Light only travels so fast and the processors are running at such a high rate that they start having to wait for info to come in.\n\nI might be wrong but that's one of the best ways to convince someone to appear with the correct answer ;)",
                              "score": 18,
                              "created_utc": 1737821963.0,
                              "replies": [
                                {
                                  "id": "m9483vx",
                                  "author": "Valance23322",
                                  "body": "There is some work being done to switch from electrical signals to optical",
                                  "score": 4,
                                  "created_utc": 1737824534.0,
                                  "replies": [
                                    {
                                      "id": "m94wcre",
                                      "author": "psilent",
                                      "body": "From what I understand that would increase speed by like 20% at best, assuming its speed of light in a vacuum and not glass medium. So we\u2019re not getting insane gains there afaik",
                                      "score": 2,
                                      "created_utc": 1737831489.0,
                                      "replies": [
                                        {
                                          "id": "m94z6xs",
                                          "author": "Valance23322",
                                          "body": "Sure, but that would let you make the chips 20% larger which could either help with cooling or to include more gates before running into timing issues",
                                          "score": 1,
                                          "created_utc": 1737832309.0,
                                          "replies": []
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m9g38f4",
                                      "author": "Bdr1983",
                                      "body": "I can assure you it's more than 'some work'.  \nI work in the photonics sector, and every day is like seeing a magician at work.",
                                      "score": 1,
                                      "created_utc": 1737983724.0,
                                      "replies": []
                                    }
                                  ]
                                },
                                {
                                  "id": "m94ilc3",
                                  "author": "Spacecowboy78",
                                  "body": "https://www.wsj.com/podcasts/wsj-the-future-of-everything/beyond-silicon-the-new-materials-charting-the-future-of-microchips/3A39B251-BE53-4BFF-BEBB-54136CBA4192",
                                  "score": 2,
                                  "created_utc": 1737827560.0,
                                  "replies": []
                                },
                                {
                                  "id": "m93zct5",
                                  "author": "Apokolypze",
                                  "body": "Ahh okay, that definitely sounds plausible. Otherwise, you're right, the best way to get the correct answer on the Internet is to confidently post the wrong one \ud83d\ude0b",
                                  "score": 2,
                                  "created_utc": 1737822043.0,
                                  "replies": [
                                    {
                                      "id": "m94gxay",
                                      "author": "ABetterKamahl1234",
                                      "body": "> Ahh okay, that definitely sounds plausible.\n\nNot just plausible, but factual. It's the same reason that dies just simply aren't made bigger entirely. As other guy says, speed of light at high frequencies is a physical limit we simply can't surpass (at least without rewriting our understanding in physics). \n\nIt'd be otherwise great as I'm not really limited by space, so having simply a physically large PC is a non-issue, so a big-ass die would be great and workable.",
                                      "score": 4,
                                      "created_utc": 1737827077.0,
                                      "replies": []
                                    }
                                  ]
                                },
                                {
                                  "id": "m94jrjl",
                                  "author": "DaRadioman",
                                  "body": "That's why chiplet designs work well, they keep the important things with more sensitive latency local.",
                                  "score": 1,
                                  "created_utc": 1737827896.0,
                                  "replies": []
                                }
                              ]
                            },
                            {
                              "id": "m94dy76",
                              "author": "danielv123",
                              "body": "Also, cost. You can go out and buy a B200 today, but it's not cheap. They retail for 200k (though most of it is markup).\n\n\nEach N2 wafer alone is 30k though, so you have to fit a good number of GPUs on that to keep the price down.\n\nThing is, if you were happy paying 2x the 5080 price for twice the performance, you would just get the 5090 which is exactly that.",
                              "score": 5,
                              "created_utc": 1737826229.0,
                              "replies": []
                            },
                            {
                              "id": "m94eoyu",
                              "author": "alvenestthol",
                              "body": "They are getting bigger, the 750mm^(2) of the 5090 (released in 2025) is 20% bigger than the 628mm^(2) of the 3090 (in 2020),  which is 12% bigger than the 561mm^(2) of the GTX Titan (in 2013).",
                              "score": 1,
                              "created_utc": 1737826443.0,
                              "replies": []
                            },
                            {
                              "id": "m94s120",
                              "author": "warp99",
                              "body": "Heat - although on die water cooling will buy us a bit of time.",
                              "score": 1,
                              "created_utc": 1737830251.0,
                              "replies": []
                            },
                            {
                              "id": "m95ctu5",
                              "author": "EVILeyeINdaSKY",
                              "body": "Heat dissipation is a partial reason, a silicon wafer can conduct heat only so fast. \n\nIf they go thicker, new methods of cooling will have to be worked out, possibly galleries inside the chip in which coolant may flow through, like an automotive engine.",
                              "score": 1,
                              "created_utc": 1737836364.0,
                              "replies": []
                            },
                            {
                              "id": "m99alwp",
                              "author": "V1pArzZz",
                              "body": "Yield, you can make them bigger but the bigger they are the lower success rate so they get more and more expensive.",
                              "score": 1,
                              "created_utc": 1737895736.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m93w8ew",
                      "author": "Juicyjackson",
                      "body": "We are actually quickly approaching the physical limitations.\n\nBack in 2005, 65nm was becoming a thing.\n\nNow we are starting to see 2nm, there isn't very much halving we can really do before we hit the physical size limitations of silicon.",
                      "score": 15,
                      "created_utc": 1737821131.0,
                      "replies": [
                        {
                          "id": "m940zmv",
                          "author": "NewKitchenFixtures",
                          "body": "Usually the semi industry only has visibility for the next 10 years of planned improvement.\n\nIMEC (tech center in Europe) has a rolling roadmap for semi technology.  It generally has what scaling is expected next.  A lot of it requires new transistor structure instead of just shrinking.\n\nhttps://www.imec-int.com/en/articles/smaller-better-faster-imec-presents-chip-scaling-roadmap",
                          "score": 13,
                          "created_utc": 1737822515.0,
                          "replies": [
                            {
                              "id": "m94jjc4",
                              "author": "poofyhairguy",
                              "body": "We see new structures with the AMD 3D CPUs. When that stacking is standard that will be a boost.",
                              "score": 6,
                              "created_utc": 1737827830.0,
                              "replies": [
                                {
                                  "id": "m9a6691",
                                  "author": "CatProgrammer",
                                  "body": "Don't they already have that? Their 3D Vcache.",
                                  "score": 1,
                                  "created_utc": 1737906994.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        },
                        {
                          "id": "m95e18t",
                          "author": "Knut79",
                          "body": "We have hit the physical limits long ago. Like 10x the size the 5nm ones are marketed as. Nm today is just \"the technology basically performs as if it was xnm and these sizes where possibe without physics screwing everything up for us \"",
                          "score": 4,
                          "created_utc": 1737836731.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m94rjl2",
                      "author": "warp99",
                      "body": "They have been saying exactly that for 50 years!",
                      "score": 1,
                      "created_utc": 1737830114.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m94369e",
                  "author": "Ashamed-Status-9668",
                  "body": "That\u2019s not really how it works with today\u2019s transistors. Moving to TSMC\u2019s 2nm brings the GAA transistor which has even more of a 3D shape. Think flat, then house and now a second story house. The transistors pack in tight but they have a vertical height to them. That is to say even 2nm from TSMC isn\u2019t touching physics limits albeit they do start dealing with quantum tunneling.",
                  "score": 1,
                  "created_utc": 1737823132.0,
                  "replies": [
                    {
                      "id": "m944e1a",
                      "author": "Juicyjackson",
                      "body": "Welp, I guess there is a lot I wasn't taught in my Computer Architecture class lol.\n\nAll I got from that class was PTSD, hardest class I have ever taken by far.",
                      "score": 3,
                      "created_utc": 1737823477.0,
                      "replies": [
                        {
                          "id": "m946hi1",
                          "author": "ChristopherDassx_16",
                          "body": "I'm in the same boat as you, hated that class",
                          "score": 1,
                          "created_utc": 1737824070.0,
                          "replies": []
                        },
                        {
                          "id": "m949rd4",
                          "author": "Ashamed-Status-9668",
                          "body": "Yeah. It depends when and how up to date the curriculum was. We had the first FinFET transistors in CPU\u2019s in late 2022. Before that transistors could be thought of as 2D and the way you were looking at would be valid. This is still what is in use today. Intels 18A and TSMC\u2019s 2nm move to GAA transistors for the first time this year.",
                          "score": 1,
                          "created_utc": 1737825011.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m95edbn",
                      "author": "Knut79",
                      "body": "Because 2nm is marketing not actual transistor or gate sizes. And hadn't been since 50-30nm it just means they are designed and perform as if they where 2nm and 2nm where possible without breaking.",
                      "score": 2,
                      "created_utc": 1737836836.0,
                      "replies": [
                        {
                          "id": "m9accrk",
                          "author": "Ashamed-Status-9668",
                          "body": "Yes. It didn't used to be that way with planar transistors. Folks that took courses 20 ish years ago on this subject and didn't keep up to date may not realize since FinFET's it hasn't been true anymore.",
                          "score": 1,
                          "created_utc": 1737908806.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m94vuoo",
                  "author": "SorryUseAlreadyTaken",
                  "body": "0.2 nm is the length of a bond, not an atom",
                  "score": 1,
                  "created_utc": 1737831349.0,
                  "replies": [
                    {
                      "id": "m94xgua",
                      "author": "Juicyjackson",
                      "body": "The atomic radius of Silicon is 111 picometers, which means diameter is 222 picometers.\n\n222 picometers is 0.22 nanometer.",
                      "score": 0,
                      "created_utc": 1737831808.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m94ffe9",
          "author": "haloooloolo",
          "body": "Crypto as in general cryptography or cryptocurrency mining?",
          "score": 9,
          "created_utc": 1737826651.0,
          "replies": [
            {
              "id": "m95cggm",
              "author": "malfive",
              "body": "They definitely meant cryptocurrency. The only people who still use \u2018crypto\u2019 in reference to cryptography are those in the security field",
              "score": 6,
              "created_utc": 1737836251.0,
              "replies": [
                {
                  "id": "m983wy7",
                  "author": "Hydraxiler32",
                  "body": "mostly just confused why it's mentioned as though it's still relevant. the only profitable stuff to mine is with ASICs which I'm pretty sure nvidia has no interest in.",
                  "score": 3,
                  "created_utc": 1737871191.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m94iq5y",
          "author": "slayez06",
          "body": "no one crypto mines on GPU's after ETH went to proof of stake. All the other coins are not profitable unless you have free electricity and the new GPU's are going to be even worse.",
          "score": 7,
          "created_utc": 1737827598.0,
          "replies": []
        },
        {
          "id": "m949cyg",
          "author": "elheber",
          "body": "It's a little simpler than that. The transistors on microchips are reaching their theoretical limit now. It's become almost impossible to make them any smaller, faster and more efficient. So the only direction left to go is bigger and more energy, or in using \"tricks\" like machine learning to boost performance synthetically.\n\nThe 5000 series is using the same 4nm transistor node size as the previous 4000 series. IMHO this is a highly skippable generation of GPUs.",
          "score": 5,
          "created_utc": 1737824894.0,
          "replies": []
        },
        {
          "id": "m93wyrr",
          "author": "NecroCannon",
          "body": "The thing that\u2019s pissed me off about AI the most is the fact that so many businesses are letting products get worse for the average person for the sake of something still hallucinating sometimes and doesn\u2019t even have a use for the average person yet\n\nYou\u2019d think after a year or two something would result from the AI push, but nope, still worse products. Even Apple based the 16/pro around AI just to not even have it be fully released until fucking next year or the year after. God I hope they piss off investors from the lack of returns eventually, so much money being burned and it\u2019s still not profitable, it will one day somehow, but not anytime soon",
          "score": 20,
          "created_utc": 1737821345.0,
          "replies": [
            {
              "id": "m95306c",
              "author": "Maniactver",
              "body": "The thing is, tech companies are expected to innovate. And one of the reasons that AI is the new big buzzword is that there isn't really anything else right now for techbros to impress investors with.",
              "score": 3,
              "created_utc": 1737833415.0,
              "replies": [
                {
                  "id": "m97ktea",
                  "author": "NutellaGood",
                  "body": "And then after everything is \"AI\", innovation will completely stop.",
                  "score": 1,
                  "created_utc": 1737862939.0,
                  "replies": [
                    {
                      "id": "m99016b",
                      "author": "Maniactver",
                      "body": "Not really, but it is possible that real innovation would come from somewhere outside of the big tech.",
                      "score": 1,
                      "created_utc": 1737890041.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m94hkod",
              "author": "ABetterKamahl1234",
              "body": "It's simply because the AI stuff *saves them money* and unless the hallucinations and other stuff is costing more than hiring people, it'll continue.\n\nBusiness ultimately only care about bottom line and profit margins. Everything else is just details to *get there*.",
              "score": 1,
              "created_utc": 1737827266.0,
              "replies": []
            },
            {
              "id": "m94gukd",
              "author": "ilyich_commies",
              "body": "Honestly I think it\u2019s good that companies are investing so many billions into a technology that isn\u2019t profitable in the short term but will completely change the world in the future. AI tech will eventually allow us to automate all human labor and completely eliminate scarcity, and whether they mean to or not, tech companies are helping bring about that future.",
              "score": -6,
              "created_utc": 1737827056.0,
              "replies": [
                {
                  "id": "m94hlqw",
                  "author": "NecroCannon",
                  "body": "I keep seeing this point but it instantly gets shut down when you take a look at the world around us and ask yourself\n\nHow are companies that only care about profits are going to survive no one being able to afford anything due to consolidation, while governments are taking two steps back for every step forward?\n\nThe reality would be, there\u2019d be a lot of people unemployed and suffering, but the people with money will be just fine",
                  "score": 12,
                  "created_utc": 1737827275.0,
                  "replies": []
                },
                {
                  "id": "m95xuwe",
                  "author": "vmsrii",
                  "body": "Then fucking sell it us then, when it\u2019s actually revolutionary! Not now, while it\u2019s still a piece of shit",
                  "score": 2,
                  "created_utc": 1737842799.0,
                  "replies": []
                },
                {
                  "id": "m94m7gl",
                  "author": "None",
                  "body": "Sorry but we\u2019ve been hearing this for 40 years now, and other than a cool few tech demos of Will Smith eating spaghetti and ChatGPT hallucinating half the time you ask for a line of code, I have yet to see anything interesting and actually usable come out of AI that people actually want.",
                  "score": 4,
                  "created_utc": 1737828597.0,
                  "replies": [
                    {
                      "id": "m94xbey",
                      "author": "Confuciusz",
                      "body": "I'd say that AlphaFold is a bit more important than Will Smith eating spaghetti. Other improvements are less ground-breaking on a surface level, but I'm saving a ton of time using LLMs for work and so do a lot of other people. In that sense it's having a direct positive impact on my work/life.",
                      "score": -1,
                      "created_utc": 1737831764.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m944aey",
              "author": "manipulativedata",
              "body": "The fact that you haven't found a use case for a modern LLM is more likely because you haven't tried it. \n\nProducts aren't degrading. They're getting better. No one is seriously claiming the 50 series isn't a better product than the 40 series because it factually isn't true. It just might not be as massive of a leap as... what... the last few generations? That's a terrible bar.\n\nI guess I'm trying to figure out why you're so unhappy. If you thought that thr AI features on the iPhone 16 weren't worthwhile, don't buy the product. If you think DLSS and the incremental performance boost for the 50 series isn't worthwhile, don't buy it. Just buy a 4090 and be happy with it. You don't need to be unhappy lol",
              "score": -13,
              "created_utc": 1737823448.0,
              "replies": [
                {
                  "id": "m9470gl",
                  "author": "NecroCannon",
                  "body": "No, I have tried it. Here\u2019s my opinion as an artist since they struggle there\n\nI make comics and animation, I learned the fundamentals which are important for execution well made art or to even break them to do your own thing. It has *no* idea of the fundamentals, I don\u2019t draw in a typical anime style so it struggles to work well with my projects, and there\u2019s no tools made that can take care of tedious tasks like it was *made* to do. Take animation, in between as tend to get sourced to other countries to be done for cheap, I don\u2019t have that money to do that with my projects, so it takes a long time to animate. However, instead of *listening* to artists about how AI could be used, instead they want to outright replace them while the leaders have no idea about what goes into well made products\n\nThat leads to this topic, of fucking course products are literally better on paper, they\u2019re not going to release an all around worse product. But they\u2019re sacrificing the consumer side of things for the sake of AI, meaning R&D doesn\u2019t go more into making sure they create a well rounded product bringing something to all kinds of consumers, but what makes investors happy.\n\nWhether you like AI or not, everyone can agree that a product should be finished and be as advertised when it hits shelves unless you just *want* to defend their mistakes for some reason. Everyone shouldn\u2019t be forced to participate or have their lives uprooted over an unwanted beta test. Until they stop trying to make a program that can almost do anything and instead use LLMs for specific, well defined tasks it\u2019s going to keep sucking. If it\u2019s something made to benefit *everyone*, one person shouldn\u2019t be having all their needs met while another deals with it failing at every use attempt.",
                  "score": 3,
                  "created_utc": 1737824221.0,
                  "replies": [
                    {
                      "id": "m94q9cf",
                      "author": "manipulativedata",
                      "body": "First, I don't want to get into the debate of the ethics of generative AI. AI is going to impact people and we need to be prepared for that. It's never going to replace the demand of original work though. People are always going to create, as they have since the beginning of history, but we are rushing too fast forward without understanding the consequences of current models and safeguarding livelihoods. As you pointed out though, outsourcing has claimed a significant number of jobs, and AI is likely to bring those jobs back before eliminating work in the western world.\n\nMy whole point in even commenting though is that AI is the consumer side of things. DLSS is a released product today that works. ChatGPT, Copilot, Gemini are released products today that work. They can help you today, right now. Anyone reading this post, with no programming experience, can get a walkthrough on how to create and deploy a working mobile app in a dev sandbox TODAY for free. AI isn't about someone dictating how you use it... it's about using it the way you want. \n\nSure, maybe it can't do the animation for you, but have you ever asked for ways to streamline your current process? It will help you with it. You can screen scare with GPT4's AVM and it will talk you through a quicker process. You can ask it to explain it to you in different ways, or ask simpler questions.\n\nI can't speak to iPhone specifically, but I can't tell you how fundamentally flawed it is to think R&D is bad for consumers. It's literally the only thing that capitalism forces companies to do to improve and iterate, and by the way...\n\nEven art is iterative. Iteration allows for significantly more complex things to be released. That's just the \n way things have worked since the beginning of time.",
                      "score": 0,
                      "created_utc": 1737829747.0,
                      "replies": [
                        {
                          "id": "m95z3or",
                          "author": "vmsrii",
                          "body": "The funny part is, literally everything you just listed can also be done by anyone, for free, after an hour-long tutorial on YouTube",
                          "score": 2,
                          "created_utc": 1737843195.0,
                          "replies": [
                            {
                              "id": "m96ko8c",
                              "author": "manipulativedata",
                              "body": "No lol. Videos aren't interactive or collaborative. Show me a series of videos one hour in length that will help choose and install software step by step, setup the correct environments, and write code that complies into a build in one hour that someone without any tech know how can follow.\n\nI am not surprised the people on reddit are delusional about generative AI but even your claim is hilariously wrong.\n\nYou've said two things that show you simply don't understand the discussion now lol \n\nIt only takes one person to scream to ruin a flight and only a few loud children to try to ruin technology they don't understand. It's ironic because 15 years ago, people expected you to read books to gain knowledge and now the default is to... what... watch YouTube? That's really what you're going to rest your laurels on?",
                              "score": 0,
                              "created_utc": 1737850328.0,
                              "replies": [
                                {
                                  "id": "m96tf1a",
                                  "author": "vmsrii",
                                  "body": ">No lol. Videos aren\u2019t interactive or collaborative. Show me a series of videos one hour in length that will help choose and install software step by step, setup the correct environments, and write code that complies into a build in one hour that someone without any tech know how can follow.\n\n[Okay, lol](https://youtu.be/kqtD5dpn9C8?si=IvYHmox6j7i7fA3I)\n\n[Here\u2019s another](https://youtu.be/jAm7xrRxEUE?si=nVdFcEc_HgI6XOm6)\n\n[And another, this one\u2019s a bit longer than an hour, apologies](https://youtu.be/ZzaPdXTrSb8?si=aTe1R7C0ieTwK_XE)\n\nIt\u2019s not the *ideal* way to learn programming, granted, but if it\u2019s between this and AI, then yeah, I\u2019m gonna \u201crest my laurels\u201d on whichever source can reliably tell me how many Rs are in \u201cStrawberry\u201d, if I ask",
                                  "score": 2,
                                  "created_utc": 1737853257.0,
                                  "replies": [
                                    {
                                      "id": "m96x6xx",
                                      "author": "manipulativedata",
                                      "body": "You have a basic misunderstanding of how LLMs work so you're asking the wrong questions apparently. That strawberry example is a good one because you can ask ChatGPT that, it'll get it wrong, then you can ask why it got wrong, and it'll explain it and tell you how to fix your prompt. \n\nYour videos are also already bad because they required knowledge beforehand and since you can't ask the video, you need to stop and Google within 5 minutes. On your rust one, he literally tells you to go find another site to have a better experience on a different playground without explaining the why or offering suggestions lol \n\nCurrent models of AI wont replace devs but the reasoning ones coming in the next generation or two will. You can deny it. You can cry about it. You can cite common examples of AI folly while clutching your pearls. Totally up to you.",
                                      "score": 1,
                                      "created_utc": 1737854534.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m95ybqm",
                  "author": "vmsrii",
                  "body": "The improvement in raw computational power versus energy draw has seen a pretty consistent parabolic drop every generation since the 10x0 cards, what are you smoking?",
                  "score": 1,
                  "created_utc": 1737842947.0,
                  "replies": [
                    {
                      "id": "m96edbs",
                      "author": "manipulativedata",
                      "body": "I'm not. I'm not complaining about the slightly \"narrower\" benchmark performance between the 4090 and 5080 either. I think the newer cards are cool but I still rock 2080Tis in both of my machines for a reason.\n\nPeople are just complaining about the -50 series because it's not some generational improvement and the person I responded to was blaming their poorly perceived idea that DLSS or AI in general was the issue... \n\nI'm saying that as DLSS improves, we'll see significant improvements in performance with only modest improvements in transitor tech and it'll be because generative AI does some of the work. \n\nThe LLM thing was a tangent because the person I'm replying to made specific comments about Apple phones and beta products, which told me they had a misunderstanding of what current LLMs and generative AI is.",
                      "score": 1,
                      "created_utc": 1737848208.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m93z9a3",
          "author": "correctingStupid",
          "body": "Odd they wouldn't just make a line of consumer AI dedicated cards and not sell mixes. Why sell one when you can sell two more precise cards?  I think they are simply pushing the gaming market into AI driven tech.",
          "score": 7,
          "created_utc": 1737822015.0,
          "replies": [
            {
              "id": "m941eme",
              "author": "Gipetto",
              "body": "Why make 2 different chips when you can sell the same chip to everybody?\nProfit.",
              "score": 25,
              "created_utc": 1737822634.0,
              "replies": []
            },
            {
              "id": "m95umg1",
              "author": "bearybrown",
              "body": "They are pushing the problems and solutions as a bundle. As gaming dev cutting corners with lighting and dumps it to ray tracing, the user also needs to be on same tech to utilize it. \n\nAlso since FG provide \"pull out of ass\" frames, they create an illusion that FG is improvement when it's actually a way to minimize development cost in terms of optimizing.",
              "score": 2,
              "created_utc": 1737841788.0,
              "replies": []
            },
            {
              "id": "m94eitn",
              "author": "danielv123",
              "body": "Gaming is barely worth it, I think we should be happy that we can benefit from the developments they make on the enterprise side. otherwise I am not sure if we would be seeing any gains at all.",
              "score": 2,
              "created_utc": 1737826394.0,
              "replies": [
                {
                  "id": "m98plle",
                  "author": "Plebius-Maximus",
                  "body": "Gaming still makes them billions. Nvidia aren't ones to turn down extra profit.\n\nThe margins aren't quite as high as data centre stuff, but it's a separate section of the market and still makes them a ton of money, so they aren't going to abandon it",
                  "score": 1,
                  "created_utc": 1737883711.0,
                  "replies": [
                    {
                      "id": "m98yq7o",
                      "author": "danielv123",
                      "body": "Sure, but they only have so many developers and have to decide which projects to allocate them to.",
                      "score": 1,
                      "created_utc": 1737889257.0,
                      "replies": [
                        {
                          "id": "m990hto",
                          "author": "Plebius-Maximus",
                          "body": "Same for any tech company. But Nvidia are currently the richest company on the planet. They have their pick of the best engineers/developers on the planet.\n\nThey aren't talent/resource starved at all, and can recruit the best in the business with relative ease for any projects they want to be done",
                          "score": 1,
                          "created_utc": 1737890314.0,
                          "replies": [
                            {
                              "id": "m990tqf",
                              "author": "danielv123",
                              "body": "Sadly can't recruit seniority. New staff takes a while getting to know the products to become really productive.",
                              "score": 1,
                              "created_utc": 1737890508.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m94z5wz",
              "author": "BrunoEye",
              "body": "Many motherboards, cases and PSUs wouldn't support two cards. They need to access similar data, having combined memory helps this significantly.\n\nAI will be behind most future graphical improvements. AI shaders will be a big deal, especially with traditionally demanding elements like dense foliage and translucency.",
              "score": 1,
              "created_utc": 1737832300.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m93mpi5",
          "author": "Davidx91",
          "body": "I said I was waiting on the 5070 Ti instead of a 4070Ti Super but if it\u2019s not even worth it then I\u2019ll wait on a AMD 9000 series since it\u2019s supposed to be like the 40 series just way way cheaper",
          "score": 11,
          "created_utc": 1737818246.0,
          "replies": [
            {
              "id": "m93od2v",
              "author": "namorblack",
              "body": "Would be a shame if AMD were corpos and charged exactly as high as market (not just you) is willing to pay (often \"not cheap\" due to demand).",
              "score": 4,
              "created_utc": 1737818769.0,
              "replies": [
                {
                  "id": "m948jr7",
                  "author": "bmore_conslutant",
                  "body": "They'll be just cheap enough to draw business away from Nvidia\n\nThey're not idiots",
                  "score": 2,
                  "created_utc": 1737824660.0,
                  "replies": []
                },
                {
                  "id": "m93t4hx",
                  "author": "Noteagro",
                  "body": "If past releases are any indication they will come in at a better bang for buck price range.",
                  "score": 3,
                  "created_utc": 1737820221.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m93rbg0",
              "author": "beleidigtewurst",
              "body": "Yeah, but nothing is supposed to be much faster than 4070Tis, so what gives, if it is cheaper?",
              "score": 1,
              "created_utc": 1737819687.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m942h7u",
          "author": "Ashamed-Status-9668",
          "body": "Naw it\u2019s just about the money. They have a small die that is cheap to make that they can sell for around 1K. Then they have no real competition. Until I see Intel or AMD laying waste to Nvidias lineup they are not giving up on gaming they are just milking customers.",
          "score": 2,
          "created_utc": 1737822938.0,
          "replies": []
        },
        {
          "id": "m94pq14",
          "author": "DanBGG",
          "body": "Yeah there\u2019s absolutely no way gaming market share matters at all now compared to AI",
          "score": 2,
          "created_utc": 1737829595.0,
          "replies": []
        },
        {
          "id": "m957leo",
          "author": "CrazyTillItHurts",
          "body": "Nobody is mining with a GPU these days",
          "score": 2,
          "created_utc": 1737834770.0,
          "replies": []
        },
        {
          "id": "m93zr36",
          "author": "cat_prophecy",
          "body": "I don't know why people are surprised that Nvidia is following the money. If they thought they could make more money but completely foregoing gaming cards altogether, they would do that. \n\nIt makes more business sense for them to sell a million cards to a few AI/crypto businesses than it does for them to sell that same amount to individual users.",
          "score": 1,
          "created_utc": 1737822158.0,
          "replies": []
        },
        {
          "id": "m94sd1i",
          "author": "Zed_or_AFK",
          "body": "Sure, but physical limitations are plying a factor here too. Can\u2019t really make transistors much smaller anymore. So it\u2019s impossible to be making big improvements without a bigger architecture overhaul. And, to some extent, isn\u2019t that\u2019s what\u2019s nVidia has been doing with their AI stuff, like pixel generation and frame generation?",
          "score": 1,
          "created_utc": 1737830347.0,
          "replies": []
        },
        {
          "id": "m94t495",
          "author": "redrumyliad",
          "body": "Crypto mining isn\u2019t profitable as much with eth being proof of stake isn\u2019t it?",
          "score": 1,
          "created_utc": 1737830563.0,
          "replies": []
        },
        {
          "id": "m94ueup",
          "author": "Pezotecom",
          "body": "what crypto uses graphics card?",
          "score": 1,
          "created_utc": 1737830934.0,
          "replies": []
        },
        {
          "id": "m95tj4i",
          "author": "kevihaa",
          "body": ">\u2026giving up on gaming\u2026in favor of crypto\u2026\n\n1. Crypto mining is largely dead at the consumer level\n2. Even amongst the handful of consumers still thinking mining crypto makes sense since Bitcoin is \u201cinevitably\u201d going to increase in value tenfold, none of them are buying a 500 MW card to mine\n3. There are purpose built cards for mining that make a ton more sense than buying a 5090\n\n>\u2026giving up on gaming\u2026in favor of AI\u2026\n\nNVIDIA is literally the only company that makes a GPU that can do 4k and ray tracing while hitting above 60 FPS. AMD has literally said they *aren\u2019t trying* to compete at this level anymore, and Intel has no plans of even attempting it. \n\nDoes it suck that having zero competition means that NVIDIA can continue to test how high they can price their cards?  Absolutely. But I have no idea where the \u201cthey\u2019ve given up on gamers\u201d narrative is coming from.",
          "score": 1,
          "created_utc": 1737841448.0,
          "replies": []
        },
        {
          "id": "m963n06",
          "author": "AlternativeAward",
          "body": "Crypto GPU mining is dead for years now. The demand is all AI",
          "score": 1,
          "created_utc": 1737844650.0,
          "replies": []
        },
        {
          "id": "m9872yd",
          "author": "TheMagicMrWaffle",
          "body": "Still not matching the performance",
          "score": 1,
          "created_utc": 1737872804.0,
          "replies": []
        },
        {
          "id": "m9aozil",
          "author": "kurotech",
          "body": "Yea they just want to chase the profits and that's it. Unless it effects their bottom line negatively then they will chase those fads like some hipster with diets",
          "score": 1,
          "created_utc": 1737912433.0,
          "replies": []
        },
        {
          "id": "m944br8",
          "author": "FauxReal",
          "body": "I agree, and that gamble will probably pay off for them. Would be nice if it also made it so gamers and game studios didn't feel pressure to upgrade this cycle as a result. \n\nP.S. the word you want is \"affected\" effects cause affects.",
          "score": 0,
          "created_utc": 1737823459.0,
          "replies": []
        },
        {
          "id": "m94vkbt",
          "author": "Mixels",
          "body": "So if both AMD and nVidia are abandoning gaming flagships to cater to AI/crypto/datacenter, does that means we're finally going to get 10+ years out of current and previous gen GPUs?",
          "score": 0,
          "created_utc": 1737831265.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93jkks",
      "author": "CMDR_omnicognate",
      "body": "If you look at its core numbers and clock speed, it\u2019s not significantly higher than the 4080 either. The 50 generation is basically just TI versions of the 40 gen but with significantly higher power consumption.",
      "score": 299,
      "created_utc": 1737817222.0,
      "replies": [
        {
          "id": "m93nmgm",
          "author": "SolidOutcome",
          "body": "Yea. Per watt performance of 5090 is same as 4090...and the extra 25% performance is due to an extra 25% watts, made possible with a better cooler.\n\nIt's literally the same chip, made larger, uses more power, and cooled better.",
          "score": 149,
          "created_utc": 1737818538.0,
          "replies": [
            {
              "id": "m94u8pi",
              "author": "grumd",
              "body": "If you power limit the 5090 to the same TDP as 4090, it still outperforms it by at least 10-20%. We need more reviews that test this, so far I've only seen der8auer do this test.",
              "score": 44,
              "created_utc": 1737830886.0,
              "replies": []
            },
            {
              "id": "m93qwmw",
              "author": "sage-longhorn",
              "body": "I mean they did warn us that Moore's law is dead. The ever increasing efficiency of chips is predicated on Moore's law, so how else are they supposed to give you more performance without more power consumption?\n\nNot that I necessarily agree with them but the answer they've come up with is AI",
              "score": 51,
              "created_utc": 1737819560.0,
              "replies": [
                {
                  "id": "m95grbl",
                  "author": "Dracekidjr",
                  "body": "Every line of thinking has a natural conclusion. At this point we need to create something fundamentally different to see the same gains.",
                  "score": 1,
                  "created_utc": 1737837566.0,
                  "replies": []
                },
                {
                  "id": "m94bqe1",
                  "author": "subtle_bullshit",
                  "body": "It\u2019s not dead. Clockspeed and power consumption have started to plateaued, but transistor count/density is still increasing.",
                  "score": -3,
                  "created_utc": 1737825586.0,
                  "replies": [
                    {
                      "id": "m966nlt",
                      "author": "Olde94",
                      "body": "I\u2019m not sure people knows mores law. You get downvoted but it\u2019s about transistor count and not performance. The two have just been closely connected most of the time",
                      "score": 8,
                      "created_utc": 1737845634.0,
                      "replies": [
                        {
                          "id": "m96typb",
                          "author": "jothrok",
                          "body": "I mean at this point in time we are quickly approaching a critical point where Moores law is going to hit its physical maximum based on how small we\u2019re able to make transistors. IIRC they\u2019re currently working on a transistor that is ~3 atoms of silicone. Sure electrons are smaller than that but at a certain point the electron phases through the silicon as if it weren\u2019t there. There other solution potentially to that issue but the traditional transistor isn\u2019t answer. Likely the next leap will be in quantum computing.",
                          "score": 1,
                          "created_utc": 1737853442.0,
                          "replies": [
                            {
                              "id": "m989hcz",
                              "author": "Olde94",
                              "body": "Uff, yeah i see Si atoms are 0,2nm\u2026",
                              "score": 1,
                              "created_utc": 1737874115.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m98vir6",
                      "author": "CJKay93",
                      "body": "Transistor density is still increasing but now so is the cost. It used to be cheaper to mass-produce the next smaller node in the long run, but it is so difficult to produce transistors of these sizes that each new node sees a significant increase in cost.",
                      "score": 2,
                      "created_utc": 1737887322.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93qjxu",
              "author": "TheLemmonade",
              "body": "+the funky AI features of course, if you\u2019re into that\n\nMaybe I am weird but I always hesitate to enable frame gen and dlss in games. I start with then off and see how I do for FPS. For some reason they just feel like a\u2026 compromise. Idk. It\u2019s like the reverse of the dopamine affect of cranking a game to ultra. \n\nI can\u2019t imaging enabling 4x frame gen would feel particularly *good* to me\n\nWonder if that\u2019s why some are underwhelmed?",
              "score": 22,
              "created_utc": 1737819452.0,
              "replies": [
                {
                  "id": "m93uwll",
                  "author": "CalumQuinn",
                  "body": "Thing is about DLSS, you should compare it to the reality of TAA rather than to a theoretical perfect image. DLSS quality can sometimes have better image quality than TAA on native res. It's a tool, not a compromise.",
                  "score": 13,
                  "created_utc": 1737820741.0,
                  "replies": [
                    {
                      "id": "m93x49r",
                      "author": "Kurrizma",
                      "body": "Gun to my head I could not tell the visual difference between DLSS (3.5) Performance and native 4K. I\u2019ve pixel peeped real close, I\u2019ve looked at it in motion, on my 32\u201d 4K OLED, I cannot tell the difference.",
                      "score": 14,
                      "created_utc": 1737821390.0,
                      "replies": [
                        {
                          "id": "m945amd",
                          "author": "Peteskies",
                          "body": "Look at things in the distance - stuff that normally wouldn't be clear at 1080p but is clear at 4k. Performance mode struggles.",
                          "score": 7,
                          "created_utc": 1737823732.0,
                          "replies": []
                        },
                        {
                          "id": "m94bzlz",
                          "author": "OramaBuffin",
                          "body": "Leaves swinging in the breeze on extremely distant trees is one thing I look for. With DLSS in some games they become completely motionless.",
                          "score": 1,
                          "created_utc": 1737825660.0,
                          "replies": []
                        },
                        {
                          "id": "m94ybx2",
                          "author": "opeth10657",
                          "body": "I play on a 5120x1440 monitor.  With DLSS in cyberpunk I can get a stable 60+ fps with a 3090ti and nearly maxed settings and I'd bet you couldn't tell visually if DLSS was on or not.\n\nWould literally be unplayable with those settings without DLSS.",
                          "score": 1,
                          "created_utc": 1737832057.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m943jzq",
                  "author": "thedoc90",
                  "body": "Multiframe gen will be beneficial on the 5090 to anyone running a 240-480hz oled. I can't see much use case outside of that because frankly, when framegen is applied to games running below 60fps it feels really bad.",
                  "score": 7,
                  "created_utc": 1737823240.0,
                  "replies": [
                    {
                      "id": "m95ag0s",
                      "author": "TheLemmonade",
                      "body": "Interesting!\n\nWondering out loud: What\u2019s the use case for 3-500 fps players? Is it often competitive shooters? Isn\u2019t lower input lag a priority over graphics power? Don\u2019t they always just set the graphics to the lowest setting possible regardless?",
                      "score": 1,
                      "created_utc": 1737835635.0,
                      "replies": [
                        {
                          "id": "m96cvsm",
                          "author": "thedoc90",
                          "body": "Frame generation in general is not going to ever be used in competetive shooter games. Some support it, like marvel rivals, but if you were to say get 90 fps in Marvel rivals at 1440p on a 165 hz gsync monitor without framegen and activate framegen it would, in the case of single framegen drop your rendered frames to 82 fps, so you're losing 8 frames per second of input and frame data because input can only happen on rendered frames, not on interpolated frames. You also lose 8 frames of reaction time per second because, let's say someone fires a projectile in your direction during and the timing coincides with an interpolated frame. The actual information that the projectile was fired will only be communicatwd on the next real frame. 3x framegen to 165hz will lock your fps to 54, and 4x will lock your fps to 40-ish. Below 60gps interpolated frame quality massively degrades even on 2x frame generation and the input lag becomes much more obvious.\u00a0\n\n\nThis is a lower fps example, but it'd be much the same for high fps users. If you're playing on a 480fps monitor and you can achieve 300 fps natively it'll be a net loss to add framegen. It also introduces rendering overhead so you will always lose some amount of real frames for fake ones.\n\n\nBest usecase for multi framegen is say you hit 120fps in the witcher 3 and you 4x framegen to 480. Not a competitive game, no advantage lost and a high starting framerate. Its a sink or swim technology that massively favors the high end cards.",
                          "score": 8,
                          "created_utc": 1737847703.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m96i96b",
                  "author": "droppinkn0wledge",
                  "body": "The fact you\u2019re even looking for a dopamine dump in your GRAPHICS is part of the problem.",
                  "score": 1,
                  "created_utc": 1737849516.0,
                  "replies": [
                    {
                      "id": "m97mti9",
                      "author": "TheLemmonade",
                      "body": "Why is that a problem? I love tinkering with my cool stuff.",
                      "score": 1,
                      "created_utc": 1737863705.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m93vpsx",
                  "author": "Ok-Bar-8785",
                  "body": "Valid point especially for the top tier cards, the my laptop rtx4060 it's a bit of a savour to get the frames n be happy with what IV got.\n\n Still feel a bit dirty that the new AI tech doesn't even go to the previous generation.",
                  "score": 1,
                  "created_utc": 1737820977.0,
                  "replies": [
                    {
                      "id": "m9401z6",
                      "author": "TheLemmonade",
                      "body": "Facts, really good point. Plus it would extend the life of the cards (at any tier) \n\nThe gen lock I understand, the features are (generally) enabled by hardware/architecture in these new cards",
                      "score": 2,
                      "created_utc": 1737822246.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93sway",
              "author": "Vokasak",
              "body": ">and the extra 25% performance is due to an extra 25% watts\n\nIt doesn't work that way.",
              "score": -1,
              "created_utc": 1737820154.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m93rlke",
          "author": "beleidigtewurst",
          "body": "Yeah, except 5090 got +33% beef on top of what 4090 had. \n\n5080 and below aren't getting even that.",
          "score": 7,
          "created_utc": 1737819773.0,
          "replies": []
        },
        {
          "id": "m9u46y8",
          "author": "mennydrives",
          "body": "3 days later:\n\nIdentical process node, nearly identical transistor count, identical cache, identical GB of RAM, 30% more bandwidth.\n\n2-8% more performance at 0-10% more power efficiency. If you were waiting, it's not _worse_ than a 4080 Super but you're not staring down much better.",
          "score": 1,
          "created_utc": 1738164878.0,
          "replies": [
            {
              "id": "m9ulnso",
              "author": "CMDR_omnicognate",
              "body": "Yeah i was waiting out on these cards since i have a 3080 currently, which would be find for most people but i have a monitor that's effectively 2 2k monitors bolted together so it has problems with some games. i'm kinda disappointed with the 5080, and annoyed since i could have upgraded a lot earlier. now i'm kinda wondering if i should just wait to see how the new AMD gpu's fair. i could get a 5090 with my current pc without having to upgrade anything else, even my PSU would be fine, but at like, \u00a32500 for the partner cards... i just don't think its worth it. plus i'm skeptical on the 12pin connector, given they had problems with the 4090's catching on fire and these 5090's draw even more powe.",
              "score": 2,
              "created_utc": 1738169800.0,
              "replies": [
                {
                  "id": "m9utnpg",
                  "author": "mennydrives",
                  "body": "Definitely wait for the new AMD GPUs if you can't just walk in and grab a 5080 off shelves today (or a 5090 at MSRP). There's a solid chance AMD could catch NVidia with their pants down, resulting in a price adjustment across the lineup.",
                  "score": 1,
                  "created_utc": 1738171986.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m93jc8k",
      "author": "hangender",
      "body": "So 5080 is slower than 5070 he he he",
      "score": 216,
      "created_utc": 1737817145.0,
      "replies": [
        {
          "id": "m940tph",
          "author": "Slay_Nation",
          "body": "But the more you buy, **the more you save**",
          "score": 42,
          "created_utc": 1737822468.0,
          "replies": [
            {
              "id": "m9410a3",
              "author": "ThePreciseClimber",
              "body": "The more you take, the less you have.",
              "score": 4,
              "created_utc": 1737822521.0,
              "replies": [
                {
                  "id": "m9447zl",
                  "author": "lennyxiii",
                  "body": "The higher you get, the lower you are.",
                  "score": 0,
                  "created_utc": 1737823429.0,
                  "replies": [
                    {
                      "id": "m94f0aj",
                      "author": "_subgenius",
                      "body": "The more left you turn the more right you go",
                      "score": 1,
                      "created_utc": 1737826533.0,
                      "replies": [
                        {
                          "id": "m94vb87",
                          "author": "dagamer2042",
                          "body": "\"Turn right to go left\" iykyk",
                          "score": 1,
                          "created_utc": 1737831192.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m94gqka",
      "author": "Exostenza",
      "body": "If the 5090 is roughly 20-30% faster than the 4090 and the 5080 has half the cores of a 5090 is anyone surprised by this in any way whatsoever?\u00a0\n\n\nI'm sure as hell\u00a0not.",
      "score": 28,
      "created_utc": 1737827024.0,
      "replies": [
        {
          "id": "m9buxv4",
          "author": "CosmicCreeperz",
          "body": "And the 4090 is almost twice the price of the 5080.\n\nAn old 911 Turbo S is faster than a new Carrera S.  And much more expensive.\n\nThey are different ranges of graphics cards entirely, why is this a surprise and who cares?",
          "score": 1,
          "created_utc": 1737924151.0,
          "replies": [
            {
              "id": "m9gsous",
              "author": "Exostenza",
              "body": "So happy I got my 4090 a year ago second hand for 1600 CAD!",
              "score": 0,
              "created_utc": 1737992226.0,
              "replies": [
                {
                  "id": "m9h5msl",
                  "author": "CosmicCreeperz",
                  "body": "Yeah and I\u2019d take a used 911 Turbo vs a new Carrera if they were the same price ;)",
                  "score": 1,
                  "created_utc": 1737995917.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m93j5g7",
      "author": "LobL",
      "body": "Who would have thought otherwise? Absolutely nothing in the specs pointed to the 5080 being faster.",
      "score": 95,
      "created_utc": 1737817081.0,
      "replies": [
        {
          "id": "m93k2ji",
          "author": "CMDR_omnicognate",
          "body": "The 4080 was quite a lot better than the 3090, it\u2019s not unreasonable to think people would assume the same would happen this generation. It\u2019s just nvidia didn\u2019t really try very hard this generation compared to last, there\u2019s hardly any improvement over the last one unfortunately",
          "score": 72,
          "created_utc": 1737817387.0,
          "replies": [
            {
              "id": "m93odqx",
              "author": "Crowlands",
              "body": "The 3090 was also criticised at the time for not having enough of a lead over the 3080 to justify the cost vs the 3080 though, this changed with the 40 series where the 4090 had a much bigger gap to the 4080 and probably ensures that the old pattern of previous gen being equivalent to a tier lower in the new gen is broken for good on the higher end cards, we'll have to wait and see if it still applies to lower end models such as 4070 to 5060 etc.",
              "score": 27,
              "created_utc": 1737818775.0,
              "replies": []
            },
            {
              "id": "m93mhx6",
              "author": "cetch",
              "body": "30 to 40 was a node jump. This is not a node jump",
              "score": 27,
              "created_utc": 1737818177.0,
              "replies": []
            },
            {
              "id": "m93p29o",
              "author": "LobL",
              "body": "Its just your lack of knowledge if that\u2019s what you think, Nvidia is absolutely trying their best to advance atm but as others have pointed out there wasn\u2019t a node jump this time. They are milking AI like crazy and have a lot to gain if they keep competitors far behind.",
              "score": 9,
              "created_utc": 1737818988.0,
              "replies": []
            },
            {
              "id": "m93s084",
              "author": "richardizard",
              "body": "It'll be time to buy a 4080 when the 50 series drops",
              "score": 2,
              "created_utc": 1737819895.0,
              "replies": []
            },
            {
              "id": "m93q5ki",
              "author": "mar504",
              "body": "Actually, it is completely unreasonable to make that assumption. LobL already said, this is clear to anyone who actually looked at the specs of these cards.   \n  \nThe 4080 had 93% as many CUDA cores as the 3090 but of a newer gen, the 4080 had a base clock 58% higher than the 3090. \n\nMeanwhile the 5080 has only 65% of the CUDA cores compared to the 4090 and a measly 3% increase in base clock. \n\nIf the change in specs were similar to last gen then it would be reasonable, but they aren't even close.",
              "score": 3,
              "created_utc": 1737819330.0,
              "replies": [
                {
                  "id": "m93u8ly",
                  "author": "CMDR_omnicognate",
                  "body": "yeah, i know that and you know that, but my point is 90% of people don't know that. even people who are pretty into tech don't often get into the details of these sorts of things to understand. they just assume we'll get similar performance increases every generation, hence it not being unreasonable that people would think that way",
                  "score": 6,
                  "created_utc": 1737820548.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m93wtdf",
              "author": "EnigmaSpore",
              "body": "True but the 3080/3090 used the same gpu chip. \n\n3090 is always going to be an outlier due it not really being a typical 80ti/90 class chip. The 1080ti, 2080ti, 4090, 5090 are all separate, bigger chips than their xx80 counterparts.",
              "score": 1,
              "created_utc": 1737821300.0,
              "replies": []
            },
            {
              "id": "m93lvpv",
              "author": "JerryLZ",
              "body": "They are saying we knew this just from the specs they released already. Barely anything changed and we already knew it wasn\u2019t a big enough bump to matter. Normally once those specs come out you would get a good idea of how much better the new card is but it\u2019s nearly identical on paper.\n\nYou would also be right about the assuming from the previous patterns but nobody should be assuming anymore since nvidia gave the specs.",
              "score": 1,
              "created_utc": 1737817980.0,
              "replies": []
            },
            {
              "id": "m94yauy",
              "author": "namatt",
              "body": "The 4080 was clocked much higher than the 3090, so that was expected.",
              "score": 0,
              "created_utc": 1737832049.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m93tkqz",
          "author": "Asleeper135",
          "body": "Specs don't always paint the whole picture. The 900 series was a pretty big boost in both performance and efficiency over the 700 series despite the specs being a relatively modest boost and being made on the same node. By the specs the 30 series should have been an astronomical leap over the 20 series, but in reality it was a pretty normal generational leap for graphics performance. That said, they usually are pretty telling, and based on the 5090 that is certainly the case with the 50 series.",
          "score": 5,
          "created_utc": 1737820354.0,
          "replies": [
            {
              "id": "m94yi7a",
              "author": "namatt",
              "body": "No, by the specs the 30 series's performance was exactly where it should have been compared to the 20 series",
              "score": 1,
              "created_utc": 1737832108.0,
              "replies": [
                {
                  "id": "m95363q",
                  "author": "Asleeper135",
                  "body": "The 3090 was only 55% faster the 2080 Ti (referencing TechPowerUp) despite have 2.53x the conpute performance. That is not how most generations scale.",
                  "score": 1,
                  "created_utc": 1737833463.0,
                  "replies": [
                    {
                      "id": "m95y0gs",
                      "author": "namatt",
                      "body": "But if you had heard how they achieved that increase in compute, i.e., if you looked at the specs, you wouldn't be surprised about that.",
                      "score": 1,
                      "created_utc": 1737842848.0,
                      "replies": [
                        {
                          "id": "m96187v",
                          "author": "Asleeper135",
                          "body": " No, looking at the specs leaves out the very important detail that they doubled CUDA core count per SM (or whatever they call them). It's a major architectural difference, which is exactly the kind of thing left out by just checking the specs.",
                          "score": 1,
                          "created_utc": 1737843875.0,
                          "replies": [
                            {
                              "id": "m979ajy",
                              "author": "namatt",
                              "body": "If you looked at incomplete specs, sure, you'd think that.",
                              "score": 1,
                              "created_utc": 1737858741.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m95zs7o",
          "author": "zushiba",
          "body": "No but Jenson saying that the 5070ti would be faster than a 4090 didn\u2019t exactly make the situation better.",
          "score": 1,
          "created_utc": 1737843410.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93k873",
      "author": "superpingu1n",
      "body": "Kicking myself for not buying a used 4090 last week but this confirm i will honor my EVGA 3080ti FTW until death.",
      "score": 58,
      "created_utc": 1737817440.0,
      "replies": [
        {
          "id": "m93pe5e",
          "author": "TheGameboy",
          "body": "One of the last great cards from the best GPU partner",
          "score": 28,
          "created_utc": 1737819092.0,
          "replies": [
            {
              "id": "m94nhu2",
              "author": "Neathh",
              "body": "Got an EVGA 3090ti. Greatest card I'll ever own.",
              "score": 9,
              "created_utc": 1737828962.0,
              "replies": [
                {
                  "id": "m96lqqr",
                  "author": "Mental_Medium3988",
                  "body": "i got an EVGA 3070. id be fine with keeping it if it had more ram but its my bottleneck right now. im not pushing the gpu otherwise. i think when i do upgrade im gonna put it in a frame on display in my room or somewhere. thanks EVGA and kingpin and everyone else there.",
                  "score": 3,
                  "created_utc": 1737850688.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m940f4j",
              "author": "superpingu1n",
              "body": "Love it till death",
              "score": 0,
              "created_utc": 1737822351.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m93ldrz",
          "author": "Fatigue-Error",
          "body": "Deleted by User using PowerDeleteSuite",
          "score": 13,
          "created_utc": 1737817821.0,
          "replies": [
            {
              "id": "m93ouno",
              "author": "supified",
              "body": "I've read somewhere that where graphic card makers are taking things the only time it is good to upgrade is when your current card no longer can support what you want to do with it.  I rocked a 1070 until just this year before moving to a 3070 and I'm not actually noticing any difference.  So my needs didn't justify upgrading.",
              "score": 11,
              "created_utc": 1737818921.0,
              "replies": [
                {
                  "id": "m96ipfv",
                  "author": "a_moniker",
                  "body": "I\u2019m still sitting on my 1070!",
                  "score": 1,
                  "created_utc": 1737849668.0,
                  "replies": [
                    {
                      "id": "m96kjzn",
                      "author": "supified",
                      "body": "Yeah, don't rush off that thing unless you find an actual reason.  I \\*thought\\* the newer card would make my vr better or something and the end result was a dud.",
                      "score": 1,
                      "created_utc": 1737850288.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93nkqt",
              "author": "lightningbadger",
              "body": "As a 3080 user this is almost best case scenario, since if it sucks I can actually get one and it'll still be a decent uplift after skipping the 40 series lol",
              "score": 3,
              "created_utc": 1737818523.0,
              "replies": [
                {
                  "id": "m967k80",
                  "author": "Elrric",
                  "body": "Im in the same boat as you but if the 5080 performs worse than the 4090, maybe a secondhand 4090 is not a bad option as they are roughly the same price in my area. \n\nBrand new they still go for 2100-2200\u20ac at least, I was down for the 5090, but 3300\u20ac is just unreasonable imo",
                  "score": 2,
                  "created_utc": 1737845935.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m93mw6x",
              "author": "-FourOhFour-",
              "body": "Good upgrade sure, good value upgrade not really, getting a 40 gen card would likely be better, between the age and people still upgrading to the latest and greatest for the sake of it decent chance they'll go down in price and with comparable stats to the 50s cheaper card wins",
              "score": 1,
              "created_utc": 1737818306.0,
              "replies": []
            },
            {
              "id": "m93zb9b",
              "author": "superpingu1n",
              "body": "I play in 4k on a 120hz TV and my 3080TI (undervolt) is still rocking every game. I will get killed for this but I hate playing DLSS. I only play in native so upgrading for a 5080 would not be worth.",
              "score": -1,
              "created_utc": 1737822031.0,
              "replies": [
                {
                  "id": "m942vjy",
                  "author": "virtikle_two",
                  "body": "Literally me. I'm rocking my 4090 for my PC in my office and a 3080 Ti in my htpc/couch setup. The 3080 Ti still runs everything VERY well.",
                  "score": 3,
                  "created_utc": 1737823050.0,
                  "replies": []
                },
                {
                  "id": "m94snva",
                  "author": "SrGoodbar",
                  "body": "no chance in hell you play 4k at 120hz with 3080ti in native res",
                  "score": 4,
                  "created_utc": 1737830433.0,
                  "replies": [
                    {
                      "id": "m956ag5",
                      "author": "superpingu1n",
                      "body": "Don't even think a 5090 would play 120fps 4k lol. Just saying im playing with 4k/120hz. Usually get 70-80fps on every game native/ultra.",
                      "score": -4,
                      "created_utc": 1737834380.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m945tsr",
                  "author": "None",
                  "body": "I tried control last night and it barely hits 30 fps",
                  "score": 2,
                  "created_utc": 1737823884.0,
                  "replies": []
                },
                {
                  "id": "m946156",
                  "author": "Peteskies",
                  "body": "Ray tracing off, obviously.\n\nI also am 3080ti on a 120hz TV and Indiana Jones is the first game I feel looks so much better with path tracing I want to wait until I upgrade.",
                  "score": 1,
                  "created_utc": 1737823941.0,
                  "replies": []
                },
                {
                  "id": "m945min",
                  "author": "Kiwi_In_Europe",
                  "body": "I mean you do you obviously but DLSS especially the new DLSS4 is just native visual quality with built in AA and performance boosts so it's a slightly confusing stance.",
                  "score": 0,
                  "created_utc": 1737823827.0,
                  "replies": [
                    {
                      "id": "m94nore",
                      "author": "7IGiveUp7",
                      "body": "I\u2019ll believe it when I see it. So far, it is very easy to tell upscaled vs native in person.",
                      "score": 5,
                      "created_utc": 1737829018.0,
                      "replies": [
                        {
                          "id": "m94ok5t",
                          "author": "Kiwi_In_Europe",
                          "body": "I mean I think it depends on the game and the implementation of DLSS. But cyberpunk for example looks pretty identical in both video comparisons and playing on my 1440p monitor.",
                          "score": 0,
                          "created_utc": 1737829265.0,
                          "replies": [
                            {
                              "id": "m94pm35",
                              "author": "7IGiveUp7",
                              "body": "I agree, but so far, on my 4k monitor, I have yet to see an upscaled game that matches native. I think there are a lot of external factors outside the upscaler itself that come into play. So, again, I\u2019ll believe when I see it.",
                              "score": 4,
                              "created_utc": 1737829564.0,
                              "replies": [
                                {
                                  "id": "m956rg0",
                                  "author": "superpingu1n",
                                  "body": "Playing 4k does show the dlss/native distorsion. I just can't unsee it. Most of people play 1080/2160 and can't tell the difference.",
                                  "score": 1,
                                  "created_utc": 1737834521.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m94o4kq",
                      "author": "superpingu1n",
                      "body": "The only game i had fun with DLSS was horizon forbidden west which was really well done compared to native. Otherwise, i see some artefacts and the camera motion always feels weird. I just can't stand DLSS only if needed as an emergency.",
                      "score": 1,
                      "created_utc": 1737829143.0,
                      "replies": [
                        {
                          "id": "m94oyi1",
                          "author": "Kiwi_In_Europe",
                          "body": "It might be worth trying again with DLSS4, it basically lets you use the NVIDIA app to override a game's native implementation (which can vary widely in quality, RDR2 for example has famously shitty DLSS) and run it direct from the app.",
                          "score": 2,
                          "created_utc": 1737829377.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93mp16",
              "author": "lucky_1979",
              "body": "My plan is to upgrade from my 3080 to 5070ti.  That should probably keep me going for another few years at least",
              "score": -2,
              "created_utc": 1737818242.0,
              "replies": [
                {
                  "id": "m93zz10",
                  "author": "superpingu1n",
                  "body": "Honestly, for people playing with DLSS and no 4k, there's no reason to get a 50XX. Should stick to the 4080.",
                  "score": -5,
                  "created_utc": 1737822223.0,
                  "replies": [
                    {
                      "id": "m945cdm",
                      "author": "lucky_1979",
                      "body": "If I wanted a 4080 I\u2019d buy one.  Not sure why people are getting upset by me buying a 5070ti to replace my 3080.  It\u2019s my money \ud83d\ude02",
                      "score": 0,
                      "created_utc": 1737823746.0,
                      "replies": [
                        {
                          "id": "m94dyy3",
                          "author": "Harflin",
                          "body": "I don't see the upset you see",
                          "score": 1,
                          "created_utc": 1737826235.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m93sm3q",
          "author": "Boltrag",
          "body": "Imagine being anywhere near current gen. Brought to you by 1080ti.",
          "score": 7,
          "created_utc": 1737820072.0,
          "replies": [
            {
              "id": "m9577n2",
              "author": "superpingu1n",
              "body": "1080ti is the best GPU ever made and can keep up pretty good if you don't push over 1080p.",
              "score": 5,
              "created_utc": 1737834655.0,
              "replies": [
                {
                  "id": "m98dr2x",
                  "author": "LaughingBeer",
                  "body": "Kept mine until last year. Probably the longest I held onto a graphics card. Gamed in 1440p. I had to start putting more modern games at the mid range graphical settings, but they still looked good. Upgraded to 4090 and I'm back to the highest settings in all games with no problems.",
                  "score": 4,
                  "created_utc": 1737876556.0,
                  "replies": [
                    {
                      "id": "m98fky2",
                      "author": "Miragui",
                      "body": "I did exactly the same, and the upgrade to the RTX 4090 seems better and better with all the reviews coming out. I think the RTX 4090 price might even shoot up due to the disappointing specs of the RTX 50XX series.",
                      "score": 3,
                      "created_utc": 1737877641.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m957ki6",
                  "author": "Boltrag",
                  "body": "I'm doing 1440p",
                  "score": 3,
                  "created_utc": 1737834761.0,
                  "replies": []
                },
                {
                  "id": "m98k134",
                  "author": "TrptJim",
                  "body": "Games are starting to require ray tracing and mesh shaders, such as Indiana Jones and Alan Wake 2 respectively, which Pascal and earlier GPUs do not properly support. We're getting close to where a 1080ti is no longer relevant for modern graphics. They held on for quite some time though - my GTX 1080 lasted me 7 years of use.",
                  "score": 2,
                  "created_utc": 1737880300.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m947v4o",
              "author": "cricks1492",
              "body": "Same. At this point I\u2019m just kinda riding it out until that bad boy dies.",
              "score": 1,
              "created_utc": 1737824465.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m942ydr",
          "author": "richardizard",
          "body": "They should drop in price when the 50 series comes out plus I'm sure you'll find plenty of them used",
          "score": 1,
          "created_utc": 1737823072.0,
          "replies": [
            {
              "id": "m957c1t",
              "author": "superpingu1n",
              "body": "Or people will realize 4090 is worth gold.",
              "score": 2,
              "created_utc": 1737834692.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m988hpi",
          "author": "LegacySV",
          "body": "The 5080 would the rtx 5070 ti would prob just be like 4080 performance",
          "score": 1,
          "created_utc": 1737873567.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m940fh9",
      "author": "SolarNachoes",
      "body": "Doesn\u2019t 5080 have less ram than 4090?",
      "score": 4,
      "created_utc": 1737822354.0,
      "replies": [
        {
          "id": "m98b0h3",
          "author": "None",
          "body": "Yep. But that doesn't really matter for most applications.",
          "score": 3,
          "created_utc": 1737874966.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m979mz7",
      "author": "None",
      "body": "[deleted]",
      "score": 15,
      "created_utc": 1737858864.0,
      "replies": [
        {
          "id": "m980y1h",
          "author": "Havakw",
          "body": "As a 3090 Ti user, even I wonder if it's worth such a hefty price and rather disappointing upgrade over a 4090. I may, yet again, sit this one out.",
          "score": 10,
          "created_utc": 1737869745.0,
          "replies": [
            {
              "id": "m98o2v6",
              "author": "mumbullz",
              "body": "Smart move tbh,I\u2019m betting they gate kept the vram upgrades to have a selling point for the next gen",
              "score": 3,
              "created_utc": 1737882784.0,
              "replies": [
                {
                  "id": "m9rozkw",
                  "author": "Havakw",
                  "body": "That may backfire, though. DeepSeek 32B downloads at 19 GB, runs very smoothly and fast on the 3090 Ti, and rivals the closedAI-o1.\n\nIt just shows that future top-of-the-line models may not, through more sophisticated training, even require more VRAM.\n\nAnd would even sophisticated games need 48 GB of VRAM?\n\nAlthough I wouldn't mind beefy VRAM upgrades in the future, I can imagine LLM training and inference going in the exact opposite direction.\n\nPresumably, they want them autonomous on a variety of AI hardware, like drones, phones, and robots\u2014not super-maxed-out $5000 PCs.\n\n#my2cents",
                  "score": 2,
                  "created_utc": 1738124395.0,
                  "replies": [
                    {
                      "id": "m9rra0q",
                      "author": "mumbullz",
                      "body": "I currently have a 3070 that i\u2019m pretty sure is close to being toasted, I\u2019d be lying if I said I fully understood what you are saying as I\u2019m not deeply entrenched into AI tech aside of some very superficial understanding of frame gen\n\nMy point is (as it stands) I really have no reason to buy anything other than what you have (a 3090ti) since (aside of fear of devs relying too much on frame gen in the coming years) I was hoping for something more tangible to buy into the newer gen cards to justify the prices",
                      "score": 1,
                      "created_utc": 1738125310.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m99be8f",
          "author": "FearLeadsToAnger",
          "body": "3080 here, not convinced.",
          "score": 6,
          "created_utc": 1737896102.0,
          "replies": []
        },
        {
          "id": "m9a02j1",
          "author": "SiscoSquared",
          "body": "Tbh at these prices and poor performance gains and vram im probably just going to hold onto my 3080 for a few more years still.",
          "score": 3,
          "created_utc": 1737905172.0,
          "replies": []
        },
        {
          "id": "m9d1xs1",
          "author": "MysteriousWon",
          "body": "I'm not upgrading until I have to start playing games on Low.",
          "score": 1,
          "created_utc": 1737936273.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93jhjq",
      "author": "Dirty_Dragons",
      "body": "It's also a hell of a lot cheaper than a 4090.",
      "score": 41,
      "created_utc": 1737817194.0,
      "replies": [
        {
          "id": "m93kbok",
          "author": "Jackal239",
          "body": "It isn't.  Current vendor pricing has most models of the 5080 around $1500.",
          "score": 12,
          "created_utc": 1737817471.0,
          "replies": [
            {
              "id": "m93o1u3",
              "author": "None",
              "body": "You buying from a scalper or in Canada? Lol",
              "score": 17,
              "created_utc": 1737818674.0,
              "replies": []
            },
            {
              "id": "m93l6n1",
              "author": "Dirty_Dragons",
              "body": "And how much do you think 4090 are going for now?\n\nNever mind the fact that you can't even buy a 50 series GPU yet.",
              "score": 34,
              "created_utc": 1737817756.0,
              "replies": [
                {
                  "id": "m93lscl",
                  "author": "Jackal239",
                  "body": "$1799 on Best Buy right now.  That's not significantly cheaper.",
                  "score": -14,
                  "created_utc": 1737817950.0,
                  "replies": [
                    {
                      "id": "m93ndlw",
                      "author": "Dirty_Dragons",
                      "body": "The 5080 is listed at $999.99 on[ Best Buy.](https://www.bestbuy.com/site/nvidia-geforce-rtx-5080-16gb-gddr7-graphics-card-gun-metal/6614153.p?skuId=6614153)\n\nWhat point are you trying to make?",
                      "score": 13,
                      "created_utc": 1737818460.0,
                      "replies": [
                        {
                          "id": "m93oib9",
                          "author": "Jackal239",
                          "body": "The FEs are going to get gobbled up by scalpers in seconds.  That price will only exist on paper just like when the 3080s launched.  The actual price that you will be able to buy one will be around $1500.\n\nIt's like saying Arizona Sweet Tea only costs 99 cents because the price is on the can.  It does not at 99% of retailers.",
                          "score": 0,
                          "created_utc": 1737818815.0,
                          "replies": [
                            {
                              "id": "m93zwht",
                              "author": "bites_stringcheese",
                              "body": "AIB pricing for 5080 is $1100 to $1300 if you ignore Asus. Still cheaper than a 4090, and many 4080S models.",
                              "score": 8,
                              "created_utc": 1737822202.0,
                              "replies": []
                            },
                            {
                              "id": "m94uptj",
                              "author": "gokarrt",
                              "body": "you might as well go whole-hog and compare scalper pricing.",
                              "score": 2,
                              "created_utc": 1737831021.0,
                              "replies": []
                            },
                            {
                              "id": "m93pfqp",
                              "author": "Dirty_Dragons",
                              "body": "Dude, I listed a primary source. That's it.\n\nFor the record, I bought my 4070 Ti at launch for MSRP.",
                              "score": 4,
                              "created_utc": 1737819105.0,
                              "replies": []
                            },
                            {
                              "id": "m993lh6",
                              "author": "None",
                              "body": "They took it off the can years ago",
                              "score": 1,
                              "created_utc": 1737892106.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m948qvr",
              "author": "rtyrty100",
              "body": "$999 is in fact cheaper than $1599. And if we\u2019re going to use AIB or inflated prices, then it\u2019s like 1500 vs 2100",
              "score": 5,
              "created_utc": 1737824718.0,
              "replies": []
            },
            {
              "id": "m9bvrwn",
              "author": "CosmicCreeperz",
              "body": "That\u2019s not nVidia\u2019s fault.  Their 4090 is $1800 and 5080 is $1000. They are for entirely different users and markets.\n\nMarkups and scalping have nothing to do with performance differences.",
              "score": 1,
              "created_utc": 1737924379.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m93l6fz",
          "author": "MachineStreet7107",
          "body": "And? The 4080 was faster and cheaper than the 3090. This article is focusing on the smaller jump in performance over the previous models.\n\nBut yes, it is less expensive than the 4090 was at launch. It\u2019s also less expensive than a Honda civic. Still sucks that we\u2019re getting less of a jump in performance.",
          "score": 0,
          "created_utc": 1737817754.0,
          "replies": [
            {
              "id": "m9bwvcr",
              "author": "CosmicCreeperz",
              "body": "3090 was never really marketed as a gaming-first card, 24 GB RAM was the main reason for the markup, which was more useful for content creators etc.  \n\n4090 was definitely marketed as an \u201centhusiast\u201d card, since the overall gaming performance was such a jump.",
              "score": 1,
              "created_utc": 1737924684.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m948lb7",
      "author": "getliquified",
      "body": "Well I have a 3080 so I'm still upgrading to a 5080",
      "score": 19,
      "created_utc": 1737824673.0,
      "replies": [
        {
          "id": "m94lw84",
          "author": "SFXSpazzy",
          "body": "This is where I am, if I\u2019m paying 1k+ for a card I\u2019m not buying a used marked up 4080/4080S. The jump from gen to gen isn\u2019t that big but from a 3080 to a 5080 will be a huge performance uplift. \n\nI have a 3080ti currently.",
          "score": 26,
          "created_utc": 1737828507.0,
          "replies": [
            {
              "id": "m96auvz",
              "author": "xtopcop",
              "body": "Coming from a 2080, so I have the same mindset. I\u2019m set on that 5080",
              "score": 6,
              "created_utc": 1737847025.0,
              "replies": []
            },
            {
              "id": "m94ymd8",
              "author": "opeth10657",
              "body": "Have a 3090ti atm, will probably eventually try for a 5090.  High end PC gaming has always been an expensive hobby, but if you can afford it...",
              "score": 1,
              "created_utc": 1737832142.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m94upna",
          "author": "grumd",
          "body": "I was also looking at a 5080, but been playing with my watercooled 3080's settings today and it's so well tuned that I'm kinda hesitant to let it go.",
          "score": 6,
          "created_utc": 1737831019.0,
          "replies": []
        },
        {
          "id": "m96mwf5",
          "author": "Mental_Medium3988",
          "body": "im on a 3070. if it had more vram id be fine with keeping it for a while. but im constantly hitting against that and it sucks. i use a super ultrawide and its just short of being what i need.",
          "score": 2,
          "created_utc": 1737851077.0,
          "replies": []
        },
        {
          "id": "m96hbjn",
          "author": "NotUnpredictable",
          "body": "2070 super here going for the 5080.",
          "score": 2,
          "created_utc": 1737849202.0,
          "replies": []
        },
        {
          "id": "m94x9dg",
          "author": "PM_ME_STEAM_KEY_PLZ",
          "body": "Have a 4070 and I\u2019m in a weird spot.",
          "score": 1,
          "created_utc": 1737831747.0,
          "replies": []
        },
        {
          "id": "m95nvjg",
          "author": "Brisslayer333",
          "body": "May as well have bought a 4080 super, woulda had it longer",
          "score": 1,
          "created_utc": 1737839732.0,
          "replies": []
        },
        {
          "id": "m95qcng",
          "author": "BlueLiquidPlus",
          "body": "Same, moved from a 1080 to a 3080\u2026 my new build will be a 5080\u2026 I can only assume, and hope, we will see a significant increase over the 3080s.",
          "score": 1,
          "created_utc": 1737840475.0,
          "replies": []
        },
        {
          "id": "m971jsd",
          "author": "Candle1ight",
          "body": "I'm tempted too, it's starting to struggle at 4k if I'm pushing settings. I'll see what it ends up actually costing, at MSRP it's tempting if it's scalped it's really not.",
          "score": 1,
          "created_utc": 1737856046.0,
          "replies": []
        },
        {
          "id": "m9590hz",
          "author": "FactHot5239",
          "body": "Shill.",
          "score": -2,
          "created_utc": 1737835198.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m950m0f",
      "author": "SpaceEggs_",
      "body": "![gif](giphy|3kzJvEciJa94SMW3hN)",
      "score": 3,
      "created_utc": 1737832721.0,
      "replies": []
    },
    {
      "id": "m953f7t",
      "author": "prroteus",
      "body": "I think my 4090 is going to be with me until my kids are in college at this point",
      "score": 3,
      "created_utc": 1737833537.0,
      "replies": []
    },
    {
      "id": "m96clrb",
      "author": "TheSmJ",
      "body": "The 50 series is really all about DLSS 4.0.",
      "score": 3,
      "created_utc": 1737847609.0,
      "replies": []
    },
    {
      "id": "m9837r4",
      "author": "i_am_banished",
      "body": "Me and my 3080 from 3 years ago just chilling and still playing everything i could possibly want to play. I'll keep this going until deus ex human revolution takes place.",
      "score": 3,
      "created_utc": 1737870843.0,
      "replies": []
    },
    {
      "id": "m93nxd1",
      "author": "KnightFan2019",
      "body": "How many more times am i going to see this same title in the next couple weeks?",
      "score": 7,
      "created_utc": 1737818634.0,
      "replies": []
    },
    {
      "id": "m94xjbk",
      "author": "namatt",
      "body": "Wow, who could have seen that coming?",
      "score": 2,
      "created_utc": 1737831827.0,
      "replies": []
    },
    {
      "id": "m95gki0",
      "author": "PoisonGaz",
      "body": "Tbh i haven\u2019t upgrade since i bought my 1080ti. Starting to finally see its age in some games but im not super hyped on this generation imo. Might just wait a while longer and buy a 4090 if this is accurate. certainly not shelling out 2 grand for current top of the line hardware",
      "score": 2,
      "created_utc": 1737837509.0,
      "replies": [
        {
          "id": "m97oipc",
          "author": "SigmaLance",
          "body": "I had a launch day 1080 and upgraded when the 4090 released.\n\nI foresee another huge gap in between upgrades for me if I even upgrade again at all. \n\nBy the time I do have to upgrade prices will have become even more ridiculous than they are now.",
          "score": 2,
          "created_utc": 1737864369.0,
          "replies": []
        },
        {
          "id": "m998zfr",
          "author": "MarcusarilliuS",
          "body": "I'm also still on a 1080ti. I'll see prices and available on the 5090 on Friday. If it's crazy high and low stock I'll just grab a used 4090.",
          "score": 1,
          "created_utc": 1737894949.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m95h9rn",
      "author": "dertechie",
      "body": "Fully expected this after seeing the specs and 5090 benches.  \n\nArchitectural improvements on the same node aren\u2019t going to beat 50% more cores.",
      "score": 2,
      "created_utc": 1737837722.0,
      "replies": []
    },
    {
      "id": "m95t41c",
      "author": "dudeitsmeee",
      "body": "\u201cMy money!!!\u201d",
      "score": 2,
      "created_utc": 1737841320.0,
      "replies": []
    },
    {
      "id": "m960ezl",
      "author": "KryanSA",
      "body": "I am SHOCKED. Shocked, I tell you.",
      "score": 2,
      "created_utc": 1737843612.0,
      "replies": []
    },
    {
      "id": "m93v95k",
      "author": "nicenyeezy",
      "body": "As someone with a 4090, this has soothed any fomo",
      "score": 5,
      "created_utc": 1737820842.0,
      "replies": [
        {
          "id": "m96mk4n",
          "author": "MJOLNIRdragoon",
          "body": "[Jesus](https://64.media.tumblr.com/ca8a75caa583bf6355843e3eced3f196/tumblr_ok08s8MnUD1v0ywk4o7_500.gif)",
          "score": 6,
          "created_utc": 1737850962.0,
          "replies": []
        },
        {
          "id": "m94a53j",
          "author": "flck",
          "body": "haha, yeah, that was my first thought. Granted I have a mobile 4090, so it's more like a desktop 4080, but still same probably applies to the mobile chips.",
          "score": 3,
          "created_utc": 1737825121.0,
          "replies": [
            {
              "id": "m98b5je",
              "author": "None",
              "body": "The performance uplift will be even worse for the mobile chips because they won't be able to just crank power to compensate.",
              "score": 2,
              "created_utc": 1737875044.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m95s6fv",
      "author": "NahCuhFkThat",
      "body": "For anyone wondering why this would be news or shocking...\n\nA reminder of the standard Nvidia themselves set with 10series: the GTX 1070 - the REAL last XX70 card - launched and it was faster than the GTX 980ti ($649) and GTX Titan X ($999) by a solid 8-10%. So, a 32% uplift from the GTX970.\n\nOh, and it launched cheaper than the Titan X and 980ti at just $379 MSRP.\n\nThis is like a humiliation ritual or some shit.",
      "score": 3,
      "created_utc": 1737841035.0,
      "replies": [
        {
          "id": "m9aa08r",
          "author": "cloudcity",
          "body": "From a value standpoint, 1070 is the GOAT in my opinion",
          "score": 2,
          "created_utc": 1737908117.0,
          "replies": [
            {
              "id": "m9e4348",
              "author": "djphatjive",
              "body": "They are dropping driver support for 10 series.",
              "score": 1,
              "created_utc": 1737947803.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m93sb8r",
      "author": "stdstaples",
      "body": "Yeah hardly a surprise",
      "score": 2,
      "created_utc": 1737819983.0,
      "replies": []
    },
    {
      "id": "m93vksa",
      "author": "Splatty15",
      "body": "Not surprised. I\u2019ll wait for the 9070 XT performance review.",
      "score": 2,
      "created_utc": 1737820937.0,
      "replies": []
    },
    {
      "id": "m946lb5",
      "author": "combatsmithen1",
      "body": "My 1070 still doing what I need",
      "score": 2,
      "created_utc": 1737824100.0,
      "replies": []
    },
    {
      "id": "m94bw82",
      "author": "LeCrushinator",
      "body": "The 5000 series is a minor performance bump, like 20-30%, and it was accomplished mostly though increased die size which means more power consumption, and because of heat the clock speeds were not increased. They were only able to go from a 5nm to a 4nm process which didn\u2019t give much room for efficiency improvements.\n\nFor the 5000 series they\u2019re mostly relying on increased compute power and DLSS 4 to accomplish gains. Because of the minor gains it\u2019s no surprise that a 5080 isn\u2019t faster than a 4090.",
      "score": 2,
      "created_utc": 1737825632.0,
      "replies": [
        {
          "id": "m98blez",
          "author": "None",
          "body": "It's more like 10-15%, if that, in apples-to-apples comparison.\n\nThe 5090 has 33% more CUDA cores, nearly 30% more power consumption, and massively improved memory bandwidth due to being on a 512-bit bus. That's the only reason it was able to beat a 4090 by \\~30%.\n\nThe 5080 has none of that. The spec sheet looks very similar to a 4080 Super. Very minor CUDA core count, very minor power increase, and very minor memory bandwidth increase relative to the 4080S means it'll be a slightly better 4080 Super.",
          "score": 1,
          "created_utc": 1737875296.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m94qwcf",
      "author": "pazkal",
      "body": "DO YOU LIKE MY JACKET",
      "score": 2,
      "created_utc": 1737829929.0,
      "replies": []
    },
    {
      "id": "m96kkpa",
      "author": "iamapinkelephant",
      "body": "These comparisons of raster performance aren't really relevant when the improvement between generations is meant to be, and has been touted by NVIDIA as, improvements in AI upscaling and frame-gen. \n\nAs much as articles and Redditors like to go brain dead and make absurd claims that additional frame-gen frames somehow increase input lag over just not having those frames exist at all, the way everything is moving is towards generative AI backed rendering.\nAt this point in time, everything has to move towards alternative rendering methods like AI gen unless we get a fundamental new technology that differs from the semiconductor.\n\nThat is unless you want to hear about how we all need three phase power to run our GPUs in the future.",
      "score": 2,
      "created_utc": 1737850295.0,
      "replies": []
    },
    {
      "id": "m93ir8s",
      "author": "kclongest",
      "body": "Well no shit",
      "score": -6,
      "created_utc": 1737816946.0,
      "replies": [
        {
          "id": "m93iyqb",
          "author": "Reablank",
          "body": "Wasn\u2019t the case last gen",
          "score": 21,
          "created_utc": 1737817018.0,
          "replies": []
        },
        {
          "id": "m93k4x2",
          "author": "MachineStreet7107",
          "body": "This breaks a long held chain that the new xx80 card is faster than the xx90 and so on for other models, generally. This new lineup of cards are barely faster than the last models when you discard all the software tricks Nvidia uses (which are genuine innovation, but the hardware jump is starting to get very small). Just more proof that Moore\u2019s law only gets stronger year after year.\n\nNot really a \u201cno shit\u201d scenario, but if being snarky makes you feel smart then go off king.",
          "score": 17,
          "created_utc": 1737817410.0,
          "replies": [
            {
              "id": "m93ln61",
              "author": "uiucfreshalt",
              "body": "\u201cLong held chain\u201d brother there have only been 3 xx90 cards, meaning there has been 2 times where xx80 was faster than the previous gen.",
              "score": 5,
              "created_utc": 1737817904.0,
              "replies": [
                {
                  "id": "m93mumq",
                  "author": "MachineStreet7107",
                  "body": "\u201cAnd so on for other models\u201d what did you think I meant by that? I was not only referring to xx90 models.\n\nThe 770 was faster than the 680, too. It is a long held chain.",
                  "score": 6,
                  "created_utc": 1737818291.0,
                  "replies": [
                    {
                      "id": "m93taoe",
                      "author": "uiucfreshalt",
                      "body": "Read that as \u201c5070 faster 4080, 4070 faster 3080\u201d, etc my b",
                      "score": 0,
                      "created_utc": 1737820271.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m93pa42",
              "author": "sylfy",
              "body": "The hardware improvements went into AI TOPS. If you look at  TOPS, the 5080 increases nearly 1.5x over the 4090. \n\nLike it or not, rasterization is dead and Nvidia is doubling down on AI. The people screaming about fake frames or fake pixels are going to be left screaming into the void, as they get left further and further begins with their AMD cards.",
              "score": -3,
              "created_utc": 1737819057.0,
              "replies": [
                {
                  "id": "m93q5wr",
                  "author": "MachineStreet7107",
                  "body": "Yup and to be honest it makes sense - Moore\u2019s law is alive as ever and software innovations (and the hardware to support it) is going to be key for making actually meaningful performance gains.",
                  "score": 2,
                  "created_utc": 1737819333.0,
                  "replies": []
                },
                {
                  "id": "m95jqiy",
                  "author": "Dragons52495",
                  "body": "Go watch a video on mfg. It's fucking ass. So yes fake frames are in fact shit.",
                  "score": 0,
                  "created_utc": 1737838471.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m945gu4",
              "author": "ImAShaaaark",
              "body": ">This breaks a long held chain that the new xx80 card is faster than the xx90 and so on for other models, generally.\n\nThose were on new nodes, and because of that the 4090 was *way* faster compared to the competition than the 3090.    Getting roughly 4090 performance with less power draw and for half the MSRP is fantastic, as that still represents a generational 30% improvement in raw raster performance with massive improvements in AI performance while staying on the same node.  It's unreasonable to assume we are gonna see 1080ti levels of improvement every generation.",
              "score": 0,
              "created_utc": 1737823782.0,
              "replies": [
                {
                  "id": "m94bbt6",
                  "author": "MachineStreet7107",
                  "body": "Where did I say I expect to see 1080ti levels of performance improvements every gen? All I stated was the improvement between gens is diminishing, which is expected but is still noteworthy.\n\nAnd what card gets 4090 performance with less power draw and half the cost? You must be referencing something utilizing 4x frame gen? 5070? It still doesn\u2019t reach the same performance as it compromises latency, IMO.\n\nFrame gen is a great innovation and I\u2019m excited to see it grow more but right now it has a notable trade off in latency. You\u2019re right tho, it is a cool feature that will be beneficial to consumers.",
                  "score": 2,
                  "created_utc": 1737825468.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m93kmdm",
              "author": "Valuable-Tomatillo76",
              "body": "It is a \u201cno shit\u201d situation if you even take a millisecond peak at the specs out of the corner of your cataract laden eyes. But I suppose the vast majority of people will never look at that nor be able to deduce anything from it.",
              "score": -23,
              "created_utc": 1737817569.0,
              "replies": [
                {
                  "id": "m93lia3",
                  "author": "IllllIIIllllIl",
                  "body": "It\u2019s wild that some people are so touchy they get *this* aggro by a level response to someone else\u2019s comment",
                  "score": 13,
                  "created_utc": 1737817860.0,
                  "replies": []
                },
                {
                  "id": "m93ljn9",
                  "author": "Fireal2",
                  "body": "\ud83e\udd13",
                  "score": 6,
                  "created_utc": 1737817873.0,
                  "replies": []
                },
                {
                  "id": "m93m0z8",
                  "author": "MachineStreet7107",
                  "body": "I\u2019ve seen the specs during the launch event, but I appreciate the insult. You must be a genius for reading spec sheets!! I could never.\n\n\nMy point is still 100% valid tho, they are reporting on the small jump in performance. The specs were surprisingly disappointing, as is the performance for this new gen of cards.\n\nNot sure who pissed in your cereal but maybe you could use your cataract laden eyes to read a book on anger management lol.",
                  "score": 5,
                  "created_utc": 1737818026.0,
                  "replies": [
                    {
                      "id": "m93mlr2",
                      "author": "Valuable-Tomatillo76",
                      "body": "You seem a bit angry",
                      "score": -5,
                      "created_utc": 1737818212.0,
                      "replies": [
                        {
                          "id": "m93n7sv",
                          "author": "MachineStreet7107",
                          "body": "I\u2019m not! But I appreciate the concern :-)",
                          "score": 3,
                          "created_utc": 1737818409.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m93lx0i",
          "author": "XTheGreat88",
          "body": "The 40 series was a pretty big jump over the 30 series",
          "score": 3,
          "created_utc": 1737817991.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93mzkg",
      "author": "Emu_milking_god",
      "body": "I get the feeling this gen might go like the 20 series awesome cards that birthed ray tracing but the 30 series made them irrelevant I feel. So hopefully the 60 series is where the next 1080ti will live.",
      "score": 1,
      "created_utc": 1737818336.0,
      "replies": [
        {
          "id": "m93ok5v",
          "author": "WhiteCharisma_",
          "body": "Based on how things are going I put the 4080 Super as the loosely modern rendition of the 1080ti. \n\nCheaper and stronger than its previous model the 4080. When it was in production it was cheaper to buy this then wait and get the 5080 before all the cards got massively overpriced.  Power difference is minimal asides from dlss 4. Runs cooler and less power hungry.\n\nNvidia knew what it was doing by cutting production off the same year it released this card.",
          "score": 3,
          "created_utc": 1737818831.0,
          "replies": [
            {
              "id": "m93yezf",
              "author": "ResponsibleQuiet6611",
              "body": "Yup, this further validates my decision to go with the 4080 Super. Got one 6 months ago and in Canada at the time it was $500-$1000 less than the cheapest 4080.\u00a0",
              "score": 1,
              "created_utc": 1737821769.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m948t9x",
      "author": "rtyrty100",
      "body": "It\u2019s a ton cheaper than a 4090. Makes sense",
      "score": 1,
      "created_utc": 1737824737.0,
      "replies": []
    },
    {
      "id": "m949z01",
      "author": "MrTibbens",
      "body": "Kind of lame. I was waiting to build a new PC till the 5000 series came out. Currently have a computer with a 2080 super which has been fine for years playing games at 1080 for 1440. I guess I have no choice.",
      "score": 1,
      "created_utc": 1737825071.0,
      "replies": []
    },
    {
      "id": "m94cjjg",
      "author": "ArchusKanzaki",
      "body": "Well, as long as the price is the same, I won't mind a 4080 Double Super.",
      "score": 1,
      "created_utc": 1737825820.0,
      "replies": []
    },
    {
      "id": "m94d23j",
      "author": "havnar-",
      "body": "![gif](giphy|VJHtXeMHViHRHvKGKm|downsized)",
      "score": 1,
      "created_utc": 1737825971.0,
      "replies": []
    },
    {
      "id": "m94dbl8",
      "author": "SingleHitBox",
      "body": "Waiting till 6080 or 7080, feels like game graphics haven\u2019t really warranted the upgrade.",
      "score": 1,
      "created_utc": 1737826048.0,
      "replies": []
    },
    {
      "id": "m94dcok",
      "author": "Agomir",
      "body": "Looks like my 1660 Ti is going to keep me going for another generation. Such an incredibly good value card. I've been wanting to significantly upgrade, to get ray tracing and to have enough vram to run Stable Diffusion XL, but most of the games I'm interested in run just fine (including BG3) and even VR performance is acceptable... So I can wait as long as it doesn't break...",
      "score": 1,
      "created_utc": 1737826057.0,
      "replies": []
    },
    {
      "id": "m94e74t",
      "author": "ILikeCutePuppies",
      "body": "I would point out that sometimes performance boosts for particular cards to appear in a driver update, but this is interesting.\n\nAlso, the card does probably do generative AI better than the 4090 if that's something people use.",
      "score": 1,
      "created_utc": 1737826301.0,
      "replies": []
    },
    {
      "id": "m94gsyb",
      "author": "qukab",
      "body": "This is all very frustrating. I\u2019ve been looking forward to this generation because my monitor (57\u201d Samsung Ultrawide) requires display port 2.1 to run at full resolution at 240hz. Currently have to run it at a lower resolution to achieve that. No 4 series cards support 2.1, all of the 5 series do. \n\nI have a 4070, so the plan was to upgrade to the 5080 and sell my existing card. \n\nIt\u2019ll obviously still be a performance upgrade, but not what I was expecting. Feel like I\u2019d be upgrading just for DP 2.1, which is kind of ridiculous.",
      "score": 1,
      "created_utc": 1737827043.0,
      "replies": [
        {
          "id": "m95eeca",
          "author": "GregoryfromtheHood",
          "body": "But you also will have multi frame generation which makes monitors like 4k 240hz pretty relevant now. As per the digital foundry video, if you can achieve somewhere like 90fps then MFG can take that up to 300 ish fps with a very minor, basically unnoticeable amount of added latency",
          "score": 1,
          "created_utc": 1737836845.0,
          "replies": [
            {
              "id": "m95gza3",
              "author": "qukab",
              "body": "True, which for some games I'm all about, but for competitive hero shooters (which I play a lot of), absolutely not. Frame gen stays off for those. Still a net positive, though, I play a lot of genres.",
              "score": 1,
              "created_utc": 1737837633.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m94kor0",
      "author": "staatsclaas",
      "body": "I\u2019m fine with things staying steady at the top for a bit. Really hard to have to keep up.",
      "score": 1,
      "created_utc": 1737828161.0,
      "replies": []
    },
    {
      "id": "m94lxj8",
      "author": "Shloopadoop",
      "body": "Ok so if I\u2019m on a 3080 and 5800X3D, and decently happy with my 4k performance\u2026used 4080/90? Hold out for 60 series? Recede further into my modded SNES and CRT cave?",
      "score": 1,
      "created_utc": 1737828518.0,
      "replies": [
        {
          "id": "m99buaa",
          "author": "FearLeadsToAnger",
          "body": "Exact same combo, I might pick up a 5080 toward the end of its product cycle if I can get a deal, otherwise 6 series. This doesn't seem like enough.",
          "score": 2,
          "created_utc": 1737896307.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m94pruy",
      "author": "SEE_RED",
      "body": "Anyone shocked by this?",
      "score": 1,
      "created_utc": 1737829610.0,
      "replies": []
    },
    {
      "id": "m94qqz5",
      "author": "Slow-Condition7942",
      "body": "gotta keep that release cadence no matter what!! didn\u2019t you think of the shareholder??",
      "score": 1,
      "created_utc": 1737829887.0,
      "replies": []
    },
    {
      "id": "m94utcg",
      "author": "Lunarcomplex",
      "body": "Thank god lmao",
      "score": 1,
      "created_utc": 1737831048.0,
      "replies": []
    },
    {
      "id": "m94x4gx",
      "author": "ShootFishBarrel",
      "body": "Looks like my 1080 Founder Edition is safe. Again.",
      "score": 1,
      "created_utc": 1737831707.0,
      "replies": []
    },
    {
      "id": "m952rms",
      "author": "EdCenter",
      "body": "Isn't the 5080 priced the same as the 4080? Seems like the 5080 is just the 4080 Super (2025 Edition).",
      "score": 1,
      "created_utc": 1737833346.0,
      "replies": []
    },
    {
      "id": "m959a5a",
      "author": "LiteralHorn",
      "body": "I\u2019m rocking a 2080 super so I\u2019m still getting this thing",
      "score": 1,
      "created_utc": 1737835281.0,
      "replies": []
    },
    {
      "id": "m95kith",
      "author": "LemurMemer",
      "body": "Have a 2080 Super and I\u2019m still most likely to cop the 5080, Im mostly concerned with power consumption and thermals",
      "score": 1,
      "created_utc": 1737838709.0,
      "replies": []
    },
    {
      "id": "m95may2",
      "author": "ThatTysonKid",
      "body": "Ill wait for the 60XX. My 3080 is good enough.",
      "score": 1,
      "created_utc": 1737839253.0,
      "replies": []
    },
    {
      "id": "m95mrmi",
      "author": "piotrek211",
      "body": "it was a known fact even before the announcement of the 5080 lol",
      "score": 1,
      "created_utc": 1737839395.0,
      "replies": []
    },
    {
      "id": "m95s661",
      "author": "TheGreatUdolf",
      "body": "how surprising. not.",
      "score": 1,
      "created_utc": 1737841033.0,
      "replies": []
    },
    {
      "id": "m95y06u",
      "author": "Madjack66",
      "body": "But isn't 5080 a bigger number than 4090?",
      "score": 1,
      "created_utc": 1737842845.0,
      "replies": []
    },
    {
      "id": "m960bct",
      "author": "Ghostrider215",
      "body": "What in the clickbait is this article",
      "score": 1,
      "created_utc": 1737843580.0,
      "replies": []
    },
    {
      "id": "m96fwxo",
      "author": "millsy98",
      "body": "Everyone knew this was going to be the case once the US ruling on restricting cards as powerful or more so than a 4090 from being sold in China. China will demand to get a \u2018high end model still, so the 5080 was always going to be at or below 4090D performance.",
      "score": 1,
      "created_utc": 1737848724.0,
      "replies": []
    },
    {
      "id": "m96j6tx",
      "author": "fpsfiend_ny",
      "body": "Damn....I may just keep my 4090 and wait until the 6xxx.\n\n![gif](giphy|gEvab1ilmJjA82FaSV|downsized)",
      "score": 1,
      "created_utc": 1737849832.0,
      "replies": []
    },
    {
      "id": "m96rmgz",
      "author": "marcosg_aus",
      "body": "So even if it doesn't out perform it, if it's close and cheaper than a 4090 and provides things like multiframe gen, maybe it's still a good thing? I don't know a lot about gpu's so admit I could be talking nonsense",
      "score": 1,
      "created_utc": 1737852654.0,
      "replies": []
    },
    {
      "id": "m975zqe",
      "author": "ARandomWalkInSpace",
      "body": "Rocking two 1070s that I bought used. Both are going strong.",
      "score": 1,
      "created_utc": 1737857582.0,
      "replies": []
    },
    {
      "id": "m98ey0r",
      "author": "lostoppai",
      "body": "5090 is too expensive and the 4090 is scalped to hell, I guess I'll wait and see how the 5080 Ti performs an year from now and its price",
      "score": 1,
      "created_utc": 1737877261.0,
      "replies": []
    },
    {
      "id": "m98xs42",
      "author": "sillypicture",
      "body": "My cards so far: geforce 4 --> 3090ti",
      "score": 1,
      "created_utc": 1737888691.0,
      "replies": []
    },
    {
      "id": "m99q8ff",
      "author": "14_In_Duck",
      "body": "OK AMD. Good one.",
      "score": 1,
      "created_utc": 1737901940.0,
      "replies": []
    },
    {
      "id": "m9aobvi",
      "author": "RonJDio",
      "body": "Holding out for the 6090",
      "score": 1,
      "created_utc": 1737912245.0,
      "replies": []
    },
    {
      "id": "m9atxb7",
      "author": "drewbiez",
      "body": "My trusty 3080ti out here doing the lords work. Guess he\u2019s sticking around.",
      "score": 1,
      "created_utc": 1737913831.0,
      "replies": []
    },
    {
      "id": "m9b3llc",
      "author": "MaygarRodub",
      "body": "My next rig is gonna be AMD and AMD.",
      "score": 1,
      "created_utc": 1737916522.0,
      "replies": []
    },
    {
      "id": "m9djeef",
      "author": "aedspitpopd",
      "body": "Money saved again",
      "score": 1,
      "created_utc": 1737941451.0,
      "replies": []
    },
    {
      "id": "m9i72n6",
      "author": "CatboiBrooke",
      "body": "Yeah this generation is a dud",
      "score": 1,
      "created_utc": 1738006312.0,
      "replies": []
    },
    {
      "id": "m94671e",
      "author": "DarkFate13",
      "body": "5000 series are crap",
      "score": 1,
      "created_utc": 1737823987.0,
      "replies": []
    },
    {
      "id": "m93p1fc",
      "author": "DoomSayerNihilus",
      "body": "The 5090 is only that much faster than a 4090.\nWhat did people expect the 5080 to magically outperform it.",
      "score": 1,
      "created_utc": 1737818981.0,
      "replies": []
    },
    {
      "id": "m94xdfh",
      "author": "Velocyra",
      "body": "As someone who bought the 4090 last year that is great news!",
      "score": 1,
      "created_utc": 1737831780.0,
      "replies": []
    },
    {
      "id": "m9a7k77",
      "author": "None",
      "body": "Fake frames and AI? No thanks.",
      "score": 1,
      "created_utc": 1737907399.0,
      "replies": []
    },
    {
      "id": "m945j45",
      "author": "g0ll4m",
      "body": "It is not slower for rendering and 3d apps, we have all the benchmarks",
      "score": 1,
      "created_utc": 1737823800.0,
      "replies": []
    },
    {
      "id": "m947fly",
      "author": "The_Real_Kingpurest",
      "body": "4070 ti is working fine i guess",
      "score": 1,
      "created_utc": 1737824343.0,
      "replies": []
    },
    {
      "id": "m94957q",
      "author": "Slipy1232",
      "body": "Agreed. Gonna just keep rocking my 4090 till the 6 series.",
      "score": 1,
      "created_utc": 1737824832.0,
      "replies": []
    },
    {
      "id": "m95tgzp",
      "author": "SolidusBruh",
      "body": "My 1050 will have to hold on for another year",
      "score": 1,
      "created_utc": 1737841431.0,
      "replies": []
    },
    {
      "id": "m96yz46",
      "author": "Zanian19",
      "body": "It outperforms my 4080 super by 8%, lol.\n\nYeah I think I'll wait a Gen or two.",
      "score": 1,
      "created_utc": 1737855154.0,
      "replies": []
    },
    {
      "id": "m98c379",
      "author": "unematti",
      "body": "They really hoped people would look at raw fps and accept the fake frames.",
      "score": 1,
      "created_utc": 1737875582.0,
      "replies": []
    },
    {
      "id": "m93m6p6",
      "author": "mockingbird-",
      "body": "No shit.\n\nThe GeForce RTX 5080 is probably ~5% faster than the GeForce RTX 4080 Super",
      "score": 0,
      "created_utc": 1737818078.0,
      "replies": []
    },
    {
      "id": "m9497gg",
      "author": "C_Ux2",
      "body": "Hope my 1080ti has some more left in the tank, I guess. xD",
      "score": 1,
      "created_utc": 1737824850.0,
      "replies": []
    },
    {
      "id": "m93k0dg",
      "author": "garry4321",
      "body": "In other, equally interesting news; 1 is less than 2",
      "score": -4,
      "created_utc": 1737817367.0,
      "replies": [
        {
          "id": "m93lx0s",
          "author": "JerryLZ",
          "body": "Prove it",
          "score": 0,
          "created_utc": 1737817991.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m94d850",
      "author": "None",
      "body": "I boycott them sine the 30 series and never looked back. They screwed us so damn hard i cant belive you still supporting this",
      "score": 0,
      "created_utc": 1737826021.0,
      "replies": [
        {
          "id": "m94wmwk",
          "author": "Mooide",
          "body": "Screwed us how?",
          "score": 1,
          "created_utc": 1737831569.0,
          "replies": [
            {
              "id": "m9563nk",
              "author": "None",
              "body": "Selling to scalpers u forgot this already?",
              "score": -1,
              "created_utc": 1737834324.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m9dfgv8",
      "author": "PSIwind",
      "body": "Honestly I dont know why people are so obsessed with upgrading. Maybe it's because I feel a 1080p screen is more than enough for PC gaming, or even on a TV for that matter personally. I want performance, not visuals to where I can see every individual blade of grass and the detail of them in a photorealistic way. My thing is \"Can I run this game at 1080p at good visual settings and use DLSS as an Anti Aliasing to help keep the GPU cooler and look better than TAA on?\". I have a 3080 and I'll be contempt with that for a long time. Everyone holding onto their 1080 and 1080 Ti still, you guys should at minimum upgrade to something like a 3000 series because RT required games are going to be more common as the RT in this case is just for standard lighting, not really reflections. A Steam Deck has RT cores, for gods sakes.",
      "score": 0,
      "created_utc": 1737940242.0,
      "replies": []
    },
    {
      "id": "m94by1c",
      "author": "MacGuyver913",
      "body": "I hate video card numbering. How hard is it to make the bigger the number, the better the card.",
      "score": -1,
      "created_utc": 1737825647.0,
      "replies": []
    },
    {
      "id": "m93xau5",
      "author": "BigInhale",
      "body": "AMD FTW!!!!",
      "score": -4,
      "created_utc": 1737821442.0,
      "replies": []
    },
    {
      "id": "m96hesw",
      "author": "6Kaliba9",
      "body": "It\u2018s dumb to release new gpu\u2018s EVERY YEAR anyway, let alone buy",
      "score": -2,
      "created_utc": 1737849232.0,
      "replies": [
        {
          "id": "m97nq17",
          "author": "SigmaLance",
          "body": "It\u2019s all relative really. Not everyone is upgrading year to year so a new release might fall within the timeframe of when people want to upgrade.\n\nIt\u2019s much the same with any product. TVs are refreshed yearly, cars, refrigerators etc.\n\nYear to year adoption does seem frivolous, but there are so many people buying things that yearly refreshes aren\u2019t necessarily a bad thing.",
          "score": 2,
          "created_utc": 1737864057.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m93j1a0",
      "author": "OK-Greg-7",
      "body": "and...stock price goes up anyway",
      "score": -8,
      "created_utc": 1737817042.0,
      "replies": [
        {
          "id": "m93jqmq",
          "author": "CMDR_omnicognate",
          "body": "Nvidia don\u2019t make money from their cards anyway, almost all of it comes from AI processors and the tech they make. Consumer GPU\u2019s only account for about 10% of their income",
          "score": 13,
          "created_utc": 1737817278.0,
          "replies": [
            {
              "id": "m93o9n8",
              "author": "drmirage809",
              "body": "Yep. The big money is in OpenAI, Google and the like buying those chips by the truckload. Which has me thinking that they won't be making a whole lot of 5090s. Because why would they sell those cards when they can sell that same chip for like 3 or 4 times the price to AI companies? All while bypassing board partners and storefronts taking their margins.",
              "score": 1,
              "created_utc": 1737818740.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m9794v0",
      "author": "junglehypothesis",
      "body": " But what if you prefer washy blurry AI-generated frames?",
      "score": -1,
      "created_utc": 1737858685.0,
      "replies": []
    },
    {
      "id": "m93m0ih",
      "author": "ntrubilla",
      "body": "Shocked.  Shocked, I tell you",
      "score": -2,
      "created_utc": 1737818022.0,
      "replies": []
    },
    {
      "id": "m93r1k3",
      "author": "beleidigtewurst",
      "body": "Lol, what is there to \"leak\", 5080 is barely has more beef than 4080, and we have seen how 5090, with 33% on top of what 4090 has, performs.",
      "score": -2,
      "created_utc": 1737819601.0,
      "replies": []
    }
  ]
}