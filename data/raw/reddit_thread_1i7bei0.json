{
  "post": {
    "title": "NVIDIA GeForce RTX 5090 3DMark performance leaks out",
    "author": "a_Ninja_b0y",
    "id": "1i7bei0",
    "score": 1230,
    "created_utc": 1737553471.0,
    "selftext": "",
    "num_comments": 397,
    "subreddit": "gadgets",
    "url": "https://www.reddit.com/r/gadgets/comments/1i7bei0/nvidia_geforce_rtx_5090_3dmark_performance_leaks/"
  },
  "comments": [
    {
      "id": "m8jqiyc",
      "author": "M4c4br346",
      "body": "I'm more interested in seeing the performance of that cooler on 5090.  \nIt's around half the thickness of 4090 and yet the card is 125w TDP higher than 4090.",
      "score": 247,
      "created_utc": 1737559132.0,
      "replies": [
        {
          "id": "m8k8r8y",
          "author": "tartare4562",
          "body": "There's a [video from Gamer Nexus](https://youtu.be/-p0MEy8BvYY?si=jaFq5n9uxdRPKYsU) with an in-depth interview of a thermal engineer at Nvidia about this, he even shows prototypes and testbeds they used. That card is a marvel of thermal management, honestly the most fascinating aspect of that card so far.",
          "score": 212,
          "created_utc": 1737564225.0,
          "replies": [
            {
              "id": "m8mqcmo",
              "author": "Ironlion45",
              "body": " I'll tell you, I stopped having to pay the heating bill after I installed a 4090 in my gaming PC.  :p    So thermal management is very much non-trivial either.\n\nBut other than that it kind of sounds like an over-clocked 4090 with better cooling.",
              "score": 37,
              "created_utc": 1737588953.0,
              "replies": [
                {
                  "id": "m8nru7n",
                  "author": "ClemsonJeeper",
                  "body": "I had to buy a 30 foot HDMI cable to move my rig that has a 4090 outside of my office. When gaming, it would easily raise the temperature in it uncomfortably during the summer.",
                  "score": 14,
                  "created_utc": 1737601014.0,
                  "replies": [
                    {
                      "id": "m8or8i6",
                      "author": "Sandman1920",
                      "body": "I feel this, but with a 3080. 3080 was already a heat generator with AAA games.\n\nI was forced to buy a window AC to level the temperature out at night.\n\nI can't imagine a 4090 temperatures heating my room",
                      "score": 2,
                      "created_utc": 1737616135.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8vebyo",
                  "author": "Oohwshitwaddup",
                  "body": "Thats not how it works. They produce the same heat but this one is just more efficient at transferring that heat to the air.\u00a0",
                  "score": 0,
                  "created_utc": 1737701377.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8kf4a3",
              "author": "Valtremors",
              "body": "I'd rather see a video where it is tested without the supervision of employees.\n\nUncontrolled environment.",
              "score": -85,
              "created_utc": 1737565954.0,
              "replies": [
                {
                  "id": "m8ko5fx",
                  "author": "tartare4562",
                  "body": "There's no test in that video. It's an interview. They explain how it works.",
                  "score": 80,
                  "created_utc": 1737568378.0,
                  "replies": [
                    {
                      "id": "m8l12we",
                      "author": "Valtremors",
                      "body": "Doesn't change my opinion.\n\nI'd rather see it tested. Properly.",
                      "score": -63,
                      "created_utc": 1737571818.0,
                      "replies": [
                        {
                          "id": "m8l9mz3",
                          "author": "l03wn3",
                          "body": "\u201dThanks for the link to the interview, but I\u2019d rather have a million dollars.\u201d Very \u201dNEXT!\u201d-energy.",
                          "score": 40,
                          "created_utc": 1737574098.0,
                          "replies": [
                            {
                              "id": "m8lamcq",
                              "author": "OMGItsCheezWTF",
                              "body": "But I didn't want an interview, I wanted a pony! :(",
                              "score": 16,
                              "created_utc": 1737574362.0,
                              "replies": []
                            },
                            {
                              "id": "m8o69lj",
                              "author": "KidsSeeRainbows",
                              "body": "ITS FOR THE CHURCH\n\nNEXT",
                              "score": 1,
                              "created_utc": 1737606265.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m8lbmag",
                          "author": "Ponald-Dump",
                          "body": "You\u2019ll see it tested properly tomorrow. What you watched was an interview. Do you not understand?",
                          "score": 27,
                          "created_utc": 1737574628.0,
                          "replies": []
                        },
                        {
                          "id": "m8lxopa",
                          "author": "tartare4562",
                          "body": "The videogame community is weird.",
                          "score": 13,
                          "created_utc": 1737580545.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8mllww",
          "author": "Dull-Alternative-730",
          "body": "It\u2019s pretty much 30% better but at the same time you got a factor in with the extra TP they\u2019re practically the same",
          "score": 10,
          "created_utc": 1737587449.0,
          "replies": [
            {
              "id": "m8o42rx",
              "author": "cvanguard",
              "body": "30% more performance for 28% more power and 25% more money. So zero gen on gen uplift or value improvement in reality.",
              "score": 1,
              "created_utc": 1737605401.0,
              "replies": []
            },
            {
              "id": "m8u7yve",
              "author": "No_Pilot_1974",
              "body": "Nah extra memory is a big deal. Just not for games",
              "score": 0,
              "created_utc": 1737684195.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8j9v1b",
      "author": "QuestGiver",
      "body": "Looks good but still waiting for 5080 to see where that lands in comparison that isn't 2k plus...",
      "score": 474,
      "created_utc": 1737553861.0,
      "replies": [
        {
          "id": "m8je43m",
          "author": "GrosBof",
          "body": "no it doesn't looks good, it's basically only more Watts to get more perf on the exact same tech.",
          "score": 246,
          "created_utc": 1737555305.0,
          "replies": [
            {
              "id": "m8jrl73",
              "author": "RobinVerhulstZ",
              "body": "Really feels like every gen after the goated pascal has progressively thrown more and more watts at the silicon and now it's just gotten completely ridiculous. Its like every new gpu worth a damn is friggin space heater at this point...",
              "score": 139,
              "created_utc": 1737559436.0,
              "replies": [
                {
                  "id": "m8kf94l",
                  "author": "gramathy",
                  "body": "the 3000 series was a solid bump even with the wattage increase\n\nthe 60ti was REALLY good even if the VRAM was lower than it should have been",
                  "score": 25,
                  "created_utc": 1737565990.0,
                  "replies": [
                    {
                      "id": "m8knm38",
                      "author": "TheConnASSeur",
                      "body": "Traded my gtx 970 for an rtx 3060ti. I was hoping for the same longevity. It looks like I'm going to get it, but only because NVidia is out of its mind.",
                      "score": 14,
                      "created_utc": 1737568236.0,
                      "replies": [
                        {
                          "id": "m8luoql",
                          "author": "gramathy",
                          "body": "I'll give nvidia the smallest amount of credit, DLSS upscaling *is* going to give those a longer lifespan than originally expected, but it's by accident because you can get away with 1080p levels of VRAM with DLSS to 1440p\n\nThat doesn't make it *perfect*, but it is going to be tolerable and will give it a year or two extra life.",
                          "score": 6,
                          "created_utc": 1737579745.0,
                          "replies": [
                            {
                              "id": "m8mjn4r",
                              "author": "TheConnASSeur",
                              "body": "I just bought a new 1080p monitor. I had that 970 for like 8 years. I got really used to gaming at 720p. 1080p looks incredible right now.",
                              "score": 1,
                              "created_utc": 1737586818.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m8l9sbn",
                          "author": "Spobely",
                          "body": "how the fuck did you trade a GTX970 for a 3060ti? Who would even accept that? I have a 970...",
                          "score": 8,
                          "created_utc": 1737574139.0,
                          "replies": [
                            {
                              "id": "m8llx80",
                              "author": "LegitosaurusRex",
                              "body": "Traded the 970 and $400 for it probably, lol",
                              "score": 11,
                              "created_utc": 1737577406.0,
                              "replies": [
                                {
                                  "id": "m8lnrm3",
                                  "author": "Spobely",
                                  "body": "That makes sense. Did you do it through some vendor? I wasn't sure what I was going to do with my current setup once I finally build a new one, but shaving some money off a GPU interests me for obvious reasons",
                                  "score": -1,
                                  "created_utc": 1737577905.0,
                                  "replies": [
                                    {
                                      "id": "m8m3jtj",
                                      "author": "isairr",
                                      "body": "It probably means he sold 970 and bought 3060ti",
                                      "score": 2,
                                      "created_utc": 1737582100.0,
                                      "replies": [
                                        {
                                          "id": "m8o0o7x",
                                          "author": "OmegaKitty1",
                                          "body": "He said traded not sold",
                                          "score": 0,
                                          "created_utc": 1737604118.0,
                                          "replies": [
                                            {
                                              "id": "m8okfkq",
                                              "author": "Odanobuneko",
                                              "body": "its a common turn of phrase to use \u201ctrade\u201d to represent replacing one thing with another.\n\n\u201cAt the end of the war the warrior traded his sword for a pen\u201d\n\nDoesn\u2019t mean the warrior literally traded his sword for a pen, but that he laid down arms in favour of writing",
                                              "score": 2,
                                              "created_utc": 1737612541.0,
                                              "replies": []
                                            }
                                          ]
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m8lzrrv",
                                      "author": "LegitosaurusRex",
                                      "body": "I'm not him, just some guy speculating/making a joke.",
                                      "score": 1,
                                      "created_utc": 1737581092.0,
                                      "replies": [
                                        {
                                          "id": "m8t4n6x",
                                          "author": "Spobely",
                                          "body": "that makes sense",
                                          "score": 0,
                                          "created_utc": 1737671793.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8jtx0p",
                  "author": "AlejoMSP",
                  "body": "I was gonna say this. More power means more heat. Soon you will all need a freezer for your gaming rigs!",
                  "score": 35,
                  "created_utc": 1737560095.0,
                  "replies": [
                    {
                      "id": "m8lg75m",
                      "author": "komvidere",
                      "body": "My 3080 Ti raises the temperature in my office by abt 2 degrees celcius after gaming for a while. It\u2019s nice in the winter though \ud83d\ude00",
                      "score": 7,
                      "created_utc": 1737575845.0,
                      "replies": [
                        {
                          "id": "m8m49o1",
                          "author": "QuickQuirk",
                          "body": "no surprise. Most space heaters are 800-1000 watts.\n\nWith the 5090, any machine becomes a serviceable mainstream space heater!\n... that's stuck on in the summer.",
                          "score": 3,
                          "created_utc": 1737582293.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8k7wm7",
                      "author": "GoldenBunip",
                      "body": "Those using the dumbass 110v system are going to need a dedicated cooker lines just to run a PC! \n\nThose of us in civilisation have a gen or two more before a gaming machine eats our 3Kw limit on standard plugs.",
                      "score": 15,
                      "created_utc": 1737563995.0,
                      "replies": [
                        {
                          "id": "m8k9gtp",
                          "author": "Still-Meaning3282",
                          "body": "Who uses 110 volt?",
                          "score": 0,
                          "created_utc": 1737564418.0,
                          "replies": [
                            {
                              "id": "m8ka7vh",
                              "author": "SpeedflyChris",
                              "body": "The US, no?",
                              "score": 13,
                              "created_utc": 1737564623.0,
                              "replies": [
                                {
                                  "id": "m8ke1l3",
                                  "author": "TheArmoredKitten",
                                  "body": "Its 120/110 to the neutral wire, but the US is actually a 240v country. We just use split leg power for domestic stuff since it's *technically* safer. You can get a NEMA 240 outlet run anywhere in your house and have it be up to code, but it's not something anybody does for a number of convenience reasons.",
                                  "score": 19,
                                  "created_utc": 1737565661.0,
                                  "replies": [
                                    {
                                      "id": "m8kh3sj",
                                      "author": "gramathy",
                                      "body": "Downside would be you'd have to run a new wire and that's expensive since you'd likely need to pay an electrician to do it\n\nNext time I move I'm probably going to want to spend some money making an actual server closet and I'll run 240 to that, but most of the loads are probably still going to be 120",
                                      "score": 11,
                                      "created_utc": 1737566491.0,
                                      "replies": [
                                        {
                                          "id": "m8luzpi",
                                          "author": "RollSomeCoal",
                                          "body": "You don't need new wire, can just indicate the white is another black and have no neutral. As far as size amps is amps, don't exceed in breaker or outlet the amps of original.",
                                          "score": 1,
                                          "created_utc": 1737579828.0,
                                          "replies": [
                                            {
                                              "id": "m8m93ad",
                                              "author": "TheArmoredKitten",
                                              "body": "You'll have to swap the outlets over to the ones for 240 styled plugs too or you're gonna have a bad time.",
                                              "score": 2,
                                              "created_utc": 1737583618.0,
                                              "replies": []
                                            }
                                          ]
                                        },
                                        {
                                          "id": "m8lxvf3",
                                          "author": "No-Bother6856",
                                          "body": "Before going to 240, there are also 20amp outlets available for 120v in the US. Admittedly, I don't have one where my PC is, but 20A instead of the standard 15A is an option.",
                                          "score": 1,
                                          "created_utc": 1737580594.0,
                                          "replies": [
                                            {
                                              "id": "m8mpspt",
                                              "author": "GoldenBunip",
                                              "body": "That\u2019s still less power than a standard uk socket. \nOur cookers are 45amps at 240v.",
                                              "score": 1,
                                              "created_utc": 1737588781.0,
                                              "replies": [
                                                {
                                                  "id": "m8n7ych",
                                                  "author": "gramathy",
                                                  "body": "when you say \"cooker\" do you mean a stove/oven combo? If we don't have gas, we have high capacity runs for large appliances like that",
                                                  "score": 2,
                                                  "created_utc": 1737594492.0,
                                                  "replies": []
                                                },
                                                {
                                                  "id": "m8mw0xc",
                                                  "author": "No-Bother6856",
                                                  "body": "Yes, but it means there is more room to go before you have to start running 240v circuits to your PC.",
                                                  "score": 1,
                                                  "created_utc": 1737590734.0,
                                                  "replies": []
                                                }
                                              ]
                                            },
                                            {
                                              "id": "m8n7tzr",
                                              "author": "gramathy",
                                              "body": "Those would potentially require higher gauge wire to be up to code, though",
                                              "score": 1,
                                              "created_utc": 1737594453.0,
                                              "replies": [
                                                {
                                                  "id": "m8n9zpx",
                                                  "author": "No-Bother6856",
                                                  "body": "They do, I have a few 20A outlets in my house already though. They have the advantage of working with everything the 15A 120v outlets work with meaning it wouldn't have to be just for a PC.\n\nThey are keyed so 20A devices can't plug into a 15A receptical but any 15A device can be plugged into a 20A receptical.",
                                                  "score": 1,
                                                  "created_utc": 1737595143.0,
                                                  "replies": [
                                                    {
                                                      "id": "m8ogof0",
                                                      "author": "gramathy",
                                                      "body": "Yeah I think some of my runs are like that, all my lighting is on 15A circuits but outlets are 15A outlets on 20A breakers",
                                                      "score": 1,
                                                      "created_utc": 1737610744.0,
                                                      "replies": []
                                                    }
                                                  ]
                                                }
                                              ]
                                            }
                                          ]
                                        },
                                        {
                                          "id": "m8m9wj0",
                                          "author": "TheArmoredKitten",
                                          "body": "You can run this stuff called armored cable through interior walls pretty quick, especially if there's a clear drop to the basement or wherever your panel is. It's not the cheapest stuff to buy, but it's way cheaper than an electrician. Read the spec sheet correctly and check your work thoroughly, but it might be easier than you'd expect (if you've got tools).",
                                          "score": 1,
                                          "created_utc": 1737583856.0,
                                          "replies": []
                                        },
                                        {
                                          "id": "m8kpvm6",
                                          "author": "lowcrawler",
                                          "body": "No you don't, you just need to connect the neutral to a different leg/finger on your panel.  You can go from 120 to 240 on the physical wires (though you likely have a lot of other junctions and receptacles on that circuit that make this impractical/dangerous unless you know exactly the electrical layout of your home).\n\nTo be clear:  You'd need to change your breaker panel setup (ganged together breakers) and you absolutely should not do this unless you know what you are doing and can do it according to code.  This reply was ONLY in response to the idea that you'd have to run a new physical wire to go from 120 to 240.",
                                          "score": -4,
                                          "created_utc": 1737568835.0,
                                          "replies": [
                                            {
                                              "id": "m8lddq9",
                                              "author": "TheArmoredKitten",
                                              "body": "That's extremely against code, and would also probably not work correctly. 240 breakers are ganged together so that they still trip on a fault through neutral. If you flip the leg on a 120 breaker, you'd almost certainly blow something up instantly.\n\nIt's also something you just can't do easily. The breakers are mounted on bus bar which has alternating fingers. You'd have to hack up your distribution panel to even start doing something so phenomenally dumb.",
                                              "score": 4,
                                              "created_utc": 1737575097.0,
                                              "replies": [
                                                {
                                                  "id": "m8m5283",
                                                  "author": "TooStrangeForWeird",
                                                  "body": "When I installed a tankless water heater I put in a 240v breaker. It has a positive, neutral, and ground. \n\nIf I swapped a 120v breaker for a 240v it would work fine on the same wiring as long as it was the same amp rating.",
                                                  "score": 1,
                                                  "created_utc": 1737582506.0,
                                                  "replies": []
                                                },
                                                {
                                                  "id": "m8lhskh",
                                                  "author": "lowcrawler",
                                                  "body": "Oh, I'm not saying you wouldnt' need to change the breakers.\n\nI\"m just saying the same physical WIRE is used for 120 and for 240.",
                                                  "score": 1,
                                                  "created_utc": 1737576274.0,
                                                  "replies": []
                                                }
                                              ]
                                            },
                                            {
                                              "id": "m8n8zwr",
                                              "author": "gramathy",
                                              "body": "Most US installs don't have 1:1 outlet to breaker equivalence. You do that and now your entire run of outlets, potentially in multiple bedrooms, is 240v, unless, as I said, you add a specific run for your computer to plug in to.",
                                              "score": 1,
                                              "created_utc": 1737594825.0,
                                              "replies": []
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                },
                                {
                                  "id": "m8l73mn",
                                  "author": "ToMorrowsEnd",
                                  "body": "us and japan, yes!",
                                  "score": 2,
                                  "created_utc": 1737573423.0,
                                  "replies": []
                                },
                                {
                                  "id": "m8kae5v",
                                  "author": "Still-Meaning3282",
                                  "body": "120 volts\u2026..for about 75 years now. \ud83d\ude02",
                                  "score": 3,
                                  "created_utc": 1737564670.0,
                                  "replies": [
                                    {
                                      "id": "m8kfvph",
                                      "author": "gramathy",
                                      "body": "that \"120\" can vary based on several factors (120 is what you get from the utility but that can change between your feed and the outlet) and is really more like 100-120. Devices need to be able to take a range of voltages",
                                      "score": 8,
                                      "created_utc": 1737566159.0,
                                      "replies": [
                                        {
                                          "id": "m8kqc6e",
                                          "author": "Still-Meaning3282",
                                          "body": "Yes. It varies. Not that much though. \nI usually get 122-124 volts in my house.",
                                          "score": -1,
                                          "created_utc": 1737568961.0,
                                          "replies": []
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m8kc3r7",
                                      "author": "xfjqvyks",
                                      "body": "[A whole 120v??](https://bdow.com/wp-content/uploads/2024/04/110aca1d-b2f9-40f0-905d-aa4d9d7ffd13.jpg)",
                                      "score": 1,
                                      "created_utc": 1737565131.0,
                                      "replies": [
                                        {
                                          "id": "m8kcevk",
                                          "author": "Still-Meaning3282",
                                          "body": "Yes I know it\u2019s slightly pedantic. But people really should be using the correct terminology after this long.",
                                          "score": -3,
                                          "created_utc": 1737565213.0,
                                          "replies": [
                                            {
                                              "id": "m8kds8p",
                                              "author": "tastyratz",
                                              "body": "WHEW I'm glad you were around to set the record straight. That 10v might just make it work now.\n\nIt's STILL 110 or 120v depending on where you look. It's also incredibly normal to see 125v and dips under 110v in practice on the US grid.",
                                              "score": 2,
                                              "created_utc": 1737565589.0,
                                              "replies": [
                                                {
                                                  "id": "m8kebax",
                                                  "author": "Still-Meaning3282",
                                                  "body": "It is always 120 Volt +/-5% in the US.  It has been for a long time.\n\nAt least we are beating Japan that uses 100 volt.",
                                                  "score": 0,
                                                  "created_utc": 1737565735.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m8kdhp9",
                                      "author": "NickCharlesYT",
                                      "body": "Still laughably low. My PC can pull a full kw easily between the components, monitor, and peripherals with just a mild overclock, and I have a 4070Ti Super that pulls a maximum of ~285w or so. 5090 is going to pull 300w more. That puts a standard 15A circuit at ~1300-1400w JUST on the computer. Never mind anything else plugged in to the same room, like lights, ceiling fan, maybe a laptop charging in the corner, etc. NEC code states a maximum sustained load on a 15A circuit shouldn't exceed 1440W, so we're right there already without factoring in literally anything else on the circuit. I've already had to split out my PC to a separate circuit because, thanks to modern code, it's somehow still permitted to allow one circuit to power *multiple rooms*. Found that out the hard way when I tried to use the PS5 in the other room while my PC was rendering out a video and my 3D printer was running (coincidentally about a 300w average load for that printer, so I could in theory do the same with a 5090 and a PS5 in two different rooms). Yep, had an electrician out ASAP to quote for dedicated 20A circuits, hopefully will be in the budget this year...",
                                      "score": -3,
                                      "created_utc": 1737565509.0,
                                      "replies": [
                                        {
                                          "id": "m8kgcmn",
                                          "author": "gramathy",
                                          "body": "1000w -285w = 715w for CPU + what, exactly? No consumer computer that i know of will get anywhere near that. Even an overlocked intel cpu and a 600w GPU is still going to just barely tip 1000w sustained. My 5900x at full chat doing transcoding is only about 300w, paired with a 7900xtx and it's no slouch.\n\nthere's no fucking way your computer pulls a kilowatt unless it's an *actual* server build that pulls 150w just for fans to keep the other 800w loads cool.",
                                          "score": 14,
                                          "created_utc": 1737566285.0,
                                          "replies": [
                                            {
                                              "id": "m8kv7vd",
                                              "author": "hellowiththepudding",
                                              "body": "OP: \"well i have a 1000watt power supply\"",
                                              "score": 2,
                                              "created_utc": 1737570271.0,
                                              "replies": []
                                            },
                                            {
                                              "id": "m8kwai6",
                                              "author": "NickCharlesYT",
                                              "body": "I can tell you it's 1kw because that's the value at which my connected UPS goes into overload and starts beeping at me to reduce the load or it cuts power. 850w is when the fan kicks on, and it does so often when rendering. So yeah, 1kw is absolutely possible and has happened. I have to turn a monitor or two off when doing a video render just to be safe.\n\nSo let's break it down. GPU is *rated* for 285w, that doesn't mean it's what it pulls at maximum. Mine is overclocked with a factory power limit closer to 300w, and I can push it 10% beyond that still with MSI afterburner, so let's call it 330w. \n\nCPU is an overclocked 14900K, I believe it's a 5.5GHz all core with 4.3 on the E cores and 5.5 on P cores. Pulls 310w or so and can saturate my LFII AIO easily if I'm not careful to set 100% fans before I start a long encode or render. So that's about 640w right there.\n\nI've got two additional PCI cards, hard to say what they pull but PCI spec allows for up to 75W per slot I'd guess 20-30w there between my capture card, sound card, and 10gb network card. Let's call it 110w for the motherboard, cooler, fans, and other peripherals because the PC itself idles at around 135w or so at the plug with the PCI cards not in use. Monitors, I'm looking at my energy monitor for them now. My ultrawide is currently pulling 58w at 70% brightness with RGB lights on, and my 4K secondary OLED monitor pulls anywhere between 40 and 70w depending on what's on the screen at 60% brightness and RGB on, but these are without HDR or high color accurate modes I usually use when not gaming, so that may be a little higher still especially with peak brightness levels turned up in the OSD for those modes. Third monitor is a Cintiq 16\" touch display which has a 30w power adapter. Audio mixer pulls 15w, powered studio speakers pull 20w each, KVM pulls 5 or so, and I have an external USB hub that can pull up to 100w but I have no idea how much it's actually using. Still, add all those values up and you get 998w before the USB hub and before any other peripherals directly connected to the PC. Oh and I have a MBP plugged in as well so there could be up to 100w going to that to charge it as well, or 30-100w in active use + charging.\n\nOver 1KW, yes it's happened. Happened even easier when I had a 3090 instead of my 4070Ti S. I don't know what to tell you, I'm clearly a *power* user \u00af\u2060\\\\\u2060_\u2060(\u2060\u30c4\u2060)\u2060\\_\u2060/\u2060\u00af",
                                              "score": -2,
                                              "created_utc": 1737570554.0,
                                              "replies": [
                                                {
                                                  "id": "m8ltups",
                                                  "author": "gramathy",
                                                  "body": "I'll definitely believe that power spikes with the 3090 would do it (especially with the 450w profile), and yeah, the whole system including peripherals can get around 1kw depending, but that's not just the PC which is what it sounded like you were describing",
                                                  "score": 2,
                                                  "created_utc": 1737579522.0,
                                                  "replies": []
                                                }
                                              ]
                                            }
                                          ]
                                        },
                                        {
                                          "id": "m8kdt5l",
                                          "author": "Still-Meaning3282",
                                          "body": "\ud83d\udc4c\ud83c\udffb\ud83d\ude00",
                                          "score": 0,
                                          "created_utc": 1737565596.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m8jvvf2",
                      "author": "locofspades",
                      "body": "Idk why more gpus dont have built in AIOS.  My Suprim X 4090 stays very cool, along with the whole pc.  Lots of cool air shooting out of my pc, no matter the load",
                      "score": -7,
                      "created_utc": 1737560641.0,
                      "replies": [
                        {
                          "id": "m8jwkqs",
                          "author": "ride_whenever",
                          "body": "The thermodynamics don\u2019t change, you\u2019re still burning the power and heating the room",
                          "score": 38,
                          "created_utc": 1737560836.0,
                          "replies": [
                            {
                              "id": "m8jy76w",
                              "author": "locofspades",
                              "body": "Sweet, its in a chilly basement anyways lol we use a space heater in the summer as its always chilly down there lol",
                              "score": -1,
                              "created_utc": 1737561286.0,
                              "replies": [
                                {
                                  "id": "m8jyyr3",
                                  "author": "elite_haxor1337",
                                  "body": "your pc actually works just as efficiently as your space-heater. It's extremely efficient at converting electricity into heat. Like greater than 99%",
                                  "score": 12,
                                  "created_utc": 1737561498.0,
                                  "replies": [
                                    {
                                      "id": "m8k0hdp",
                                      "author": "z3speed4me",
                                      "body": "I literally have closed the vent to my office bc when the desktop is on in winter I sure do not need the heat running in that room",
                                      "score": 4,
                                      "created_utc": 1737561921.0,
                                      "replies": [
                                        {
                                          "id": "m8k5b40",
                                          "author": "GainzghisKahn",
                                          "body": "Sometimes I open the window in winter just to take the edge off if it was a little warm that day. Even my ps5 heats up my office.",
                                          "score": 2,
                                          "created_utc": 1737563264.0,
                                          "replies": []
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m8kaq0v",
                                      "author": "SpeedflyChris",
                                      "body": "> Like greater than 99%\n\nShould be 100% regardless of the device, all of the other forms of energy it creates will become heat.",
                                      "score": 3,
                                      "created_utc": 1737564759.0,
                                      "replies": [
                                        {
                                          "id": "m8l0hv0",
                                          "author": "elite_haxor1337",
                                          "body": "~~Only if you're rounding up. Some of the energy goes into sound and signals. And light (rgb, etc). So it's not literally 100%. It's not much less than 100% but technically it is~~\n\nOn 2nd thought, you're right. The other forms of energy will just become heat. Even the light and sound that are produced as I said, will get converted to heat. The electrical signals will too. I suppose the *only* exception would be sound, light and signals that leak out of your space/system (however you define it). Someone else pointed out that light (and I'll add sound) coming from your monitor (or if you want, just the LED's in the PC so we can narrow the discussion to just the PC tower) can end up going out a window or thru a crack in a wall or something and therefore contribute no heat to your space/system; and the data sent thru an ethernet cable and any wireless signals transmitted could leak out of the room. But those would be purely semantic arguments and your point stands. Thanks for making me double check my incorrect assessment",
                                          "score": 2,
                                          "created_utc": 1737571665.0,
                                          "replies": []
                                        },
                                        {
                                          "id": "m8ladih",
                                          "author": "smootex",
                                          "body": "That would be my understanding as well. All the energy eventually gets converted to heat, just like an electric space heater.\n\nDoesn't mean it's just as *cost* efficient to heat with your gaming rig, many households have gas furnaces for their central heating and depending on where you live that gas is likely to be cheaper than electric, BTU to BTU, but efficiency wise it's 100%.",
                                          "score": 1,
                                          "created_utc": 1737574295.0,
                                          "replies": []
                                        }
                                      ]
                                    },
                                    {
                                      "id": "m8kynwv",
                                      "author": "OsmeOxys",
                                      "body": "Overly long fun nerd fact: Not 99%, but well and truly 100%! Well... Depending on how many external factors you account for, all of which are perfectly valid to include or exclude depending on the discussion. So you're not wrong about being 99.whatever% either. I'm guessing you already know the general idea at the very least, but I'm a big old nerd about anything electrical so here I go.\n\nYou can think of heat is the \"final form\" of energy, and efficiency as the measurement of desired work done before that energy inevitably becomes heat. If your desired work is to create heat, x/x is always going to equal 1. Friction is heat, light and sound being absorbed is heat, chemical decomposition is heat, even something snapping in half is heat. If it consumes energy, it is 100% efficient at generating heat. 1000w of electricity in, *exactly* 1000w of heat out (there's a delay with light/emf and sound being converted to heat, but inevitably).\n\nThe complicated part of heating efficiency is the external losses. The system as a whole is still turning 100% of energy into heat, but not necessarily where we want it. As a fitting example, the light from your monitor shining through your window is still going to create heat, but it's warming up the trees instead of you. Overall heat lost in generation and transmission can easily drop the useful-to-us efficiency to below 50%, which is why gas furnaces are significantly more efficient (which doesn't account for clean and cheap renewable energy sources) than electric heaters... With the exception of heat pumps, but I think I've rambled enough.",
                                      "score": 3,
                                      "created_utc": 1737571183.0,
                                      "replies": [
                                        {
                                          "id": "m8l6szb",
                                          "author": "elite_haxor1337",
                                          "body": "great points! Thanks for your comment. You're right that I know the basics (they covered heat at some point during Thermodynamics hehe). But I appreciate the correction because I hadn't considered that while some energy is used to produce light, sound, bluetooth/wifi signals, all of that will become heat as those waves attenuate... Such a cool topic. Now the *only* thing I'm still wondering about is what about the signals your ethernet cable is carrying from your PC? Surely that requires some energy and isn't converted to heat?",
                                          "score": 2,
                                          "created_utc": 1737573344.0,
                                          "replies": [
                                            {
                                              "id": "m8lm2f0",
                                              "author": "OsmeOxys",
                                              "body": "Still heat! There's still current flowing so resistance does it's thing, and there's still emf and attenuation just like with wireless signals. That's your loss, while the work is switching the transistors/mosfets/optocouplers/etc at the end. \n\nSignals like Ethernet not being considered as \"power\" is a weird thing that gets taught, presumably because it's so insignificant in most applications that it's easier to ignore it and just cover it all with a cable length rating. Once you get into the nitty gritty of it however, like electrical design, it can become a huge deal (read: pain in the ass).",
                                              "score": 2,
                                              "created_utc": 1737577444.0,
                                              "replies": []
                                            }
                                          ]
                                        }
                                      ]
                                    }
                                  ]
                                },
                                {
                                  "id": "m8k8kqk",
                                  "author": "sceadwian",
                                  "body": "If that were the only problem it would be fine. The concentration of that power is the problem. \n\nThe laws of physics are getting in the way.",
                                  "score": 1,
                                  "created_utc": 1737564176.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m8k9wc6",
                      "author": "None",
                      "body": "[deleted]",
                      "score": -3,
                      "created_utc": 1737564536.0,
                      "replies": [
                        {
                          "id": "m8kagqt",
                          "author": "SpeedflyChris",
                          "body": "> Winter electrical use for gaming should be free, I think, because the waste heat is still 100% efficient, just like a regular resistive HVAC heater.\n\nOnly \"free\" if you'd otherwise be using resistive electric heating.\n\nAt least where I live, gas heating is ~1/3rd the price of electric heating, or if you have a heat pump installed that's likewise going to be about 1/3rd the price of resistive electric heating.",
                          "score": 3,
                          "created_utc": 1737564689.0,
                          "replies": [
                            {
                              "id": "m8khar3",
                              "author": "gramathy",
                              "body": "I think the point is you'd be playing the game anyway, so the waste heat is \"free\" in that you're buying it regardless",
                              "score": 1,
                              "created_utc": 1737566543.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8k7cda",
                  "author": "sillypicture",
                  "body": "Where's that intel project where you can just keep installing new direct X versions?\n\nI feel like they really dropped the ball on getting into GPU space.",
                  "score": 1,
                  "created_utc": 1737563841.0,
                  "replies": []
                },
                {
                  "id": "m8l4hhc",
                  "author": "alidan",
                  "body": "nvidia always does this, they have a great gen and then sit on their dicks for quite a few after it and then decided amd caught up enough we need to go hard now.",
                  "score": 1,
                  "created_utc": 1737572721.0,
                  "replies": []
                },
                {
                  "id": "m8m49an",
                  "author": "TooStrangeForWeird",
                  "body": "I mean some of my little space heaters are 350-500W, so yeah it's literally a space heater worth of power lol.",
                  "score": 1,
                  "created_utc": 1737582290.0,
                  "replies": []
                },
                {
                  "id": "m8whmyz",
                  "author": "Inquisitor2195",
                  "body": "I mean, what else can they do? Shrinking transistors from what I understand is becoming increasingly difficult and running into issues with the fundamental laws of physics. Making bigger dies tanks your yields, gamers are already chaffing under the prices, no way they cut into their precious investors profit margins. So all that leaves is throwing more power at the problem and then trying to get the rest of the way with DLSS.",
                  "score": 1,
                  "created_utc": 1737723209.0,
                  "replies": []
                },
                {
                  "id": "m8jvbb6",
                  "author": "kikikza",
                  "body": "It's at the point where I straight up can't buy do a gaming PC because my apartment's electricity wouldn't be able to handle it (still on fuse boxes)",
                  "score": 1,
                  "created_utc": 1737560484.0,
                  "replies": [
                    {
                      "id": "m8lvxme",
                      "author": "RollSomeCoal",
                      "body": "Can you convert to 220v this lowers the amps and fuse requirement",
                      "score": 1,
                      "created_utc": 1737580081.0,
                      "replies": [
                        {
                          "id": "m8m3wl2",
                          "author": "kikikza",
                          "body": "Unfortunately I'm not able to, I'm in a very old apartment building",
                          "score": 1,
                          "created_utc": 1737582195.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8k1j6u",
              "author": "_c3s",
              "body": "Looks like they\u2019ve hit a wall on how much performance they can get per core, probably why we\u2019re seeing more improvements on DLSS and frame gen instead.",
              "score": 16,
              "created_utc": 1737562217.0,
              "replies": [
                {
                  "id": "m8k8hw4",
                  "author": "GoldenBunip",
                  "body": "Or the cores used for gaming are irrelevant now. Only tensor cores for ai are getting any real attention and development. \nThe rendering cores are just gaining from a node shrink.",
                  "score": 12,
                  "created_utc": 1737564154.0,
                  "replies": [
                    {
                      "id": "m8kavqa",
                      "author": "SpeedflyChris",
                      "body": "Is there even a node shrink this generation? I thought they were on the same node, hence the absurd power draw.",
                      "score": 9,
                      "created_utc": 1737564801.0,
                      "replies": [
                        {
                          "id": "m8kbtop",
                          "author": "GoldenBunip",
                          "body": "4n vs 4np  \nSo improved version of the node.",
                          "score": 9,
                          "created_utc": 1737565055.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8kli48",
                      "author": "_c3s",
                      "body": "Even then it could be that there isn\u2019t much left to gain down that road. But like how increase in speed when driving is not linear to amount of fuel used to do so, and the effect grows the faster you go.\n\nI think AMD was also just pulling the high end card this gen for the same reason, there\u2019s not much point, UDNA will also be a lot more AI driven.",
                      "score": 2,
                      "created_utc": 1737567675.0,
                      "replies": []
                    },
                    {
                      "id": "m8m4phi",
                      "author": "QuickQuirk",
                      "body": "pretty much this. It's very clear to anyone paying attention that nvidias design breif for this generation was \"How can we improve AI processing performance for our datacenter cards\" and then \"Think of every way you can to use AI to improve graphics rendering speeds, so we can sell gamers on the fable that we've improved performance.\"\n\nThe fact that they're advertising more fake frames as genuine performance uplift is maddening.",
                      "score": 2,
                      "created_utc": 1737582412.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8wi7gy",
                  "author": "Inquisitor2195",
                  "body": "My understanding is that shrinking transistors is running into the fundamental laws of physics. Still, they could at least give us some more VRAM, I swear in some games my 4070 spends half its life waiting for the stuff my system overflows into the regular old RAM.",
                  "score": 1,
                  "created_utc": 1737723436.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8k65a9",
              "author": "uav_loki",
              "body": "take it from someone who owned two radeon 290x ovens @ 300watt tdp each.    this isn\u2019t the way to go.",
              "score": 1,
              "created_utc": 1737563505.0,
              "replies": []
            },
            {
              "id": "m8kpcbl",
              "author": "scytob",
              "body": "Without a die shrink more gates means more power usage. Also fhey are using more of the cores than they used to. will be interesting to see what that does to power usage on the 40 series when they enable some of the new software feature\u2026..",
              "score": 1,
              "created_utc": 1737568693.0,
              "replies": []
            },
            {
              "id": "m8jvg6v",
              "author": "Zodaztream",
              "body": "You get 32gb of vram though",
              "score": 1,
              "created_utc": 1737560522.0,
              "replies": []
            },
            {
              "id": "m8jo6dj",
              "author": "rtyrty100",
              "body": "More performance at the same price sounds good to me (compared to 4080s).\nAnd even cheaper than the 4080!!",
              "score": -2,
              "created_utc": 1737558443.0,
              "replies": [
                {
                  "id": "m8jpdlr",
                  "author": "1Svagus",
                  "body": "Its not the same price though? Lmao",
                  "score": 10,
                  "created_utc": 1737558798.0,
                  "replies": [
                    {
                      "id": "m8js8pv",
                      "author": "A_Nice_Meat_Sauce",
                      "body": "4080 Super and 5080 are both the same MSRP, aren't they? That's probably what they're referring to",
                      "score": 8,
                      "created_utc": 1737559621.0,
                      "replies": [
                        {
                          "id": "m8jwxol",
                          "author": "rtyrty100",
                          "body": "I think you\u2019re the only one that got it",
                          "score": 1,
                          "created_utc": 1737560935.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8jwugc",
                      "author": "rtyrty100",
                      "body": "The 4080s and 5080 are the same price. But even better, the 5080 is cheaper than the 4080. What are the downvotes",
                      "score": 1,
                      "created_utc": 1737560911.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8kl9vm",
              "author": "nokinship",
              "body": "The watts are pretty much the same as the 3080.",
              "score": 0,
              "created_utc": 1737567613.0,
              "replies": []
            },
            {
              "id": "m8my2i8",
              "author": "justin_memer",
              "body": "Where does it say the power draw? The 4090 never even got near its TDP, this won't either.",
              "score": 0,
              "created_utc": 1737591375.0,
              "replies": []
            },
            {
              "id": "m8jfxin",
              "author": "Fit_Specific8276",
              "body": "i\u2019ll pretend that made sense",
              "score": -79,
              "created_utc": 1737555897.0,
              "replies": [
                {
                  "id": "m8jgsd4",
                  "author": "thedsider",
                  "body": "It made sense. Their point is that there is no significant improvement this generation.  A ~30% increase in performance was achieved by increasing the CUDA count by ~30% and the power consumption by ~30%.  The technology didn't get any more efficient, it just got scaled up.\n\nThose percentages are indicative, I can't remember exactly what they were but it was around 30% from memory",
                  "score": 68,
                  "created_utc": 1737556171.0,
                  "replies": [
                    {
                      "id": "m8jhemk",
                      "author": "GrosBof",
                      "body": "I don't think he is here to understand anything, but I applaud you trying :)",
                      "score": 28,
                      "created_utc": 1737556371.0,
                      "replies": []
                    },
                    {
                      "id": "m8jnan2",
                      "author": "-Dixieflatline",
                      "body": "In pure numbers, it isn't all that compelling of a generational change. However, it is interesting that they got 30% more CUDA cores into a 2 slot card though. Kind of makes me wonder if they could get close to 4090 performance in a single slot card with that CUDA density.",
                      "score": 4,
                      "created_utc": 1737558180.0,
                      "replies": [
                        {
                          "id": "m8jo0qc",
                          "author": "V1pArzZz",
                          "body": "Slot size is just cooler size, you can easily make a 1 slot 4090 or 5090 with a watercooler and radiator.\n\nAir cooler to dissipate 600W 1 slot will be very hard, already 2 slot is impressive.",
                          "score": 2,
                          "created_utc": 1737558396.0,
                          "replies": [
                            {
                              "id": "m8jruud",
                              "author": "-Dixieflatline",
                              "body": "True, but that doesn't change any part of my statement and I was only talking about this reference design card, not the eventual boutique aftermarket cooling support.",
                              "score": 2,
                              "created_utc": 1737559512.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m8jrnmp",
                      "author": "chabalba",
                      "body": "It makes sense for me to upgrade my 1060 for a 5080. It doesn't matter to me what performance the 5080 Vs the 4080 has. I think I will feel the difference between a 1060 and a 5080.",
                      "score": 3,
                      "created_utc": 1737559456.0,
                      "replies": [
                        {
                          "id": "m8krbrd",
                          "author": "youzongliu",
                          "body": "For sure, but that's not just a GPU upgrade anymore, you'd have to get a whole new PC for that.",
                          "score": 2,
                          "created_utc": 1737569226.0,
                          "replies": [
                            {
                              "id": "m8otqgw",
                              "author": "chabalba",
                              "body": "Yeah I got a Ryzen 7 9800x3d , new mobo, new PSU, new CPU cooler, new case, new ram. So yeah new pc for me after 9 years.",
                              "score": 1,
                              "created_utc": 1737617565.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m8jsctz",
                          "author": "4gionz",
                          "body": "You will for sure but depending what monitor you use you might be better off just picking up a cheap 4080...",
                          "score": 1,
                          "created_utc": 1737559654.0,
                          "replies": [
                            {
                              "id": "m8jump4",
                              "author": "kaeldrakkel",
                              "body": "Is there going to be such a thing? Considering these results I wouldn't think so",
                              "score": 2,
                              "created_utc": 1737560295.0,
                              "replies": []
                            },
                            {
                              "id": "m8otxal",
                              "author": "chabalba",
                              "body": "I have a Toshiba 55' 4k 144hz gaming TV I'm gonna use as my primary monitor",
                              "score": 1,
                              "created_utc": 1737617678.0,
                              "replies": [
                                {
                                  "id": "m8ovgxc",
                                  "author": "4gionz",
                                  "body": "Then ya 4k still needs all the power it can get",
                                  "score": 1,
                                  "created_utc": 1737618590.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m8jkhjc",
                      "author": "ehxy",
                      "body": "But but .. mfg 4 only works on the latest cards guys !",
                      "score": 2,
                      "created_utc": 1737557332.0,
                      "replies": []
                    },
                    {
                      "id": "m8jpu5a",
                      "author": "AnOddSprout",
                      "body": "This makes sense lol. I assumed it was something to do with that, but wasn\u2019t 100%",
                      "score": 1,
                      "created_utc": 1737558931.0,
                      "replies": []
                    },
                    {
                      "id": "m8jsv70",
                      "author": "RobinVerhulstZ",
                      "body": "Wouldnt be surprised if the pure raster perf of the 5080 is pmuch on par with an overclocked 4080 based on the specsheets...\n\nAmd's 9070's are honestly the most interesting chips of this gen simply because unlike nvidia it's entirely different from last gen on all fronts",
                      "score": 1,
                      "created_utc": 1737559800.0,
                      "replies": []
                    },
                    {
                      "id": "m8jsf95",
                      "author": "Relevant-Doctor187",
                      "body": "Chip power efficiency gains stopped at 14nm more or less.",
                      "score": 0,
                      "created_utc": 1737559674.0,
                      "replies": []
                    },
                    {
                      "id": "m8jidzl",
                      "author": "None",
                      "body": "[deleted]",
                      "score": -45,
                      "created_utc": 1737556682.0,
                      "replies": [
                        {
                          "id": "m8jp4o3",
                          "author": "Hobbit1996",
                          "body": "Is this a lost bot that thinks this is a ps5 post?",
                          "score": 8,
                          "created_utc": 1737558725.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8jm2t3",
                  "author": "alman12345",
                  "body": "Essentially they haven't switched nodes like they did for the past several generations and so packing more transistors into equal or lesser die space isn't an option this time, the only performance gains will be in extra transistors (which, if the 5080 has any, will lead to a bigger die) and more power to push the clocks of the card higher.",
                  "score": 3,
                  "created_utc": 1737557813.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jtpkc",
              "author": "pederbonde",
              "body": "When did gamers start caring about power draw. Are you gonna use it in a server room, otherwise i dont se the issue of it draws more power.\n\n\nAnd according to this performance gains is more than wattage increase.\u00a0",
              "score": -9,
              "created_utc": 1737560037.0,
              "replies": [
                {
                  "id": "m8jun3e",
                  "author": "stomith",
                  "body": "Yes, some will certainly use it in server rooms. Source: I support individuals who insist on still  using 1080\u2019s in server rooms.",
                  "score": 2,
                  "created_utc": 1737560298.0,
                  "replies": [
                    {
                      "id": "m8jvjpy",
                      "author": "pederbonde",
                      "body": "There must be more efficient card than that now right.\n\nYes that point i can see, you can only have the performance that you are able to cool",
                      "score": 1,
                      "created_utc": 1737560550.0,
                      "replies": [
                        {
                          "id": "m8jy7ay",
                          "author": "stomith",
                          "body": "There\u2019s many more efficient cards than that. They cost money though.",
                          "score": 2,
                          "created_utc": 1737561287.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8jue4c",
                  "author": "TheRed2685",
                  "body": "Uh\u2026you know electricity is getting hella expensive right?  I definitely care since i pay my own bills.",
                  "score": 2,
                  "created_utc": 1737560229.0,
                  "replies": [
                    {
                      "id": "m8ku5zd",
                      "author": "youzongliu",
                      "body": "I mean if you're just running one PC it's not enough to be a deciding factor though. It costs like $5-$10 max for electricity per month. You'll be better off worrying about how to decrease other costs than PC electricity usage.",
                      "score": 2,
                      "created_utc": 1737569992.0,
                      "replies": []
                    },
                    {
                      "id": "m8juxwy",
                      "author": "pederbonde",
                      "body": "Yea but even when electricity is as most expensive here it will cost like 0.3 dollars per hour. It wouldnt be an issue if you can afford the card",
                      "score": -3,
                      "created_utc": 1737560382.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8jvxo7",
                  "author": "Jaerba",
                  "body": "It's important for those of us with pretty lil' SFF PCs.  \n\nEDIT: Oh, I guess Corsair has a 1000 watt SFX PSU now.",
                  "score": 1,
                  "created_utc": 1737560658.0,
                  "replies": [
                    {
                      "id": "m8jx2jb",
                      "author": "pederbonde",
                      "body": "Ha ha its even smaler than mini itx right. Can you even fit a graphics card in thoose. Always wanted to build a small computer but the mother boards usually so expensive for some reason",
                      "score": 1,
                      "created_utc": 1737560973.0,
                      "replies": [
                        {
                          "id": "m8k1ph1",
                          "author": "Jaerba",
                          "body": "Yep!  I've got this little guy with a 3080ti and a Ryzen 5800X3D in it.\n\nhttps://www.sliger.com/products/cases/sm560/",
                          "score": 1,
                          "created_utc": 1737562267.0,
                          "replies": [
                            {
                              "id": "m8k2vnk",
                              "author": "pederbonde",
                              "body": "Nice, and 325mm would fit quite alot of gpus aswell. Its a bummer Nvidia banned turbo cards for the consumer market, it would fit quite nice in that chassi.. but om the other hand their kind of loud",
                              "score": 2,
                              "created_utc": 1737562591.0,
                              "replies": [
                                {
                                  "id": "m8k3b9p",
                                  "author": "Jaerba",
                                  "body": "I opted for push/pull instead of water cooling, but next time I'd probably water cool.  Headphones are necessary. :)",
                                  "score": 2,
                                  "created_utc": 1737562710.0,
                                  "replies": [
                                    {
                                      "id": "m8k5nck",
                                      "author": "pederbonde",
                                      "body": "Yea i considered watercooling aswell, but a custom loop cost almost as much as the computer itself. You can probably reuse alot of stuff for your next build. But still",
                                      "score": 2,
                                      "created_utc": 1737563360.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8jxsjf",
          "author": "Jack123610",
          "body": "I'm waiting for the 5080 to be like 2k anyway besides like a stock of three reference models just to see everyone react lmao",
          "score": 8,
          "created_utc": 1737561172.0,
          "replies": [
            {
              "id": "m8m4xib",
              "author": "QuickQuirk",
              "body": "yeah. the 5080 will settle at 1.5k, and the 5090 will be 2.5 to 3k.\n\nThen we'll see a 5090Ti with a a full unlocked die at 800w.",
              "score": 2,
              "created_utc": 1737582471.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jcy1j",
          "author": "XRustyPx",
          "body": "whos gonna tell him?",
          "score": 11,
          "created_utc": 1737554916.0,
          "replies": []
        },
        {
          "id": "m8jabqg",
          "author": "Bigfamei",
          "body": "Agreed. Good luck to those trying to get one. Waiting to hear about everything else.",
          "score": 9,
          "created_utc": 1737554022.0,
          "replies": []
        },
        {
          "id": "m8jg1gk",
          "author": "Corgi_Koala",
          "body": "I feel like 5080 demand is going to be insane.",
          "score": 3,
          "created_utc": 1737555932.0,
          "replies": [
            {
              "id": "m8jkt0v",
              "author": "SiscoSquared",
              "body": "Seeing how minimal the other performance increase is coupled with pathetic vram its going to be a pass from me, skipping this generation.",
              "score": 18,
              "created_utc": 1737557429.0,
              "replies": [
                {
                  "id": "m8jyfaw",
                  "author": "younggregg",
                  "body": "Seems like we're stuck in the constant loop of \"skipping this generation\" until it becomes multiple generations now",
                  "score": 17,
                  "created_utc": 1737561348.0,
                  "replies": [
                    {
                      "id": "m8k1tx7",
                      "author": "lightningbadger",
                      "body": "I skipped the last gen, so this can literally be a 10% uplift over the 4080 and I'll grab it, cause the 4080 was already a decent jump over the 3080",
                      "score": 7,
                      "created_utc": 1737562302.0,
                      "replies": [
                        {
                          "id": "m8k36rn",
                          "author": "younggregg",
                          "body": "So did I.. but my 3080 build was my first build in a decade (lost interest for awhile, life happened), as much as I like upgrading things I still cant seem to justify a 5080 jump, I don't think it will really affect much notable performance",
                          "score": 9,
                          "created_utc": 1737562675.0,
                          "replies": [
                            {
                              "id": "m8k40j8",
                              "author": "pay_student_loan",
                              "body": "I have a 3090 and while I\u2019ve been tempted to upgrade in the past, I really can\u2019t justify it whenever I think about it.",
                              "score": 5,
                              "created_utc": 1737562902.0,
                              "replies": [
                                {
                                  "id": "m8kbvdg",
                                  "author": "SpeedflyChris",
                                  "body": "Thing is, a 3080 or 3090 will still run basically any game out there, at high settings. Yes, if you want to use path tracing in 4k and all that it's probably not the one, but for my system on 1440p ultrawide my 3080 still handles anything I've thrown at it easily.",
                                  "score": 9,
                                  "created_utc": 1737565067.0,
                                  "replies": [
                                    {
                                      "id": "m8n3ysz",
                                      "author": "Master-Government343",
                                      "body": "On a single screen yeah",
                                      "score": 0,
                                      "created_utc": 1737593234.0,
                                      "replies": []
                                    }
                                  ]
                                },
                                {
                                  "id": "m8ue9mz",
                                  "author": "zero573",
                                  "body": "Same here.  My EVGA FTW3 3090 is still rocking it.",
                                  "score": 1,
                                  "created_utc": 1737686492.0,
                                  "replies": []
                                }
                              ]
                            },
                            {
                              "id": "m8k42zx",
                              "author": "lightningbadger",
                              "body": "My 3080 honestly isn't showing its age, but it's a bit of a hashed together job since this rig started as an i5-7500/ GTX 1660 rig\n\nSo this time I wanna make sure I do it properly from the ground up is all",
                              "score": 3,
                              "created_utc": 1737562921.0,
                              "replies": []
                            }
                          ]
                        },
                        {
                          "id": "m8mgs9g",
                          "author": "corut",
                          "body": "For me to drop $2K AUD on a 5080 it's going to need to be 70-80% better then my 3080 at lease. Currently looks like it's going to be in the 30-40% range though.\n\nNot complaining though, saved me $4k in graphics card and CPU upgrades",
                          "score": 1,
                          "created_utc": 1737585921.0,
                          "replies": [
                            {
                              "id": "m8mhf2a",
                              "author": "lightningbadger",
                              "body": "Yeahh Australia really gets the rough end of things tbh, your 3080 will easily last till the 60 series comes along as 4080 over 3080 is only a 20-30% uplift, and I don't see the 5080 being much more than the 4080",
                              "score": 1,
                              "created_utc": 1737586119.0,
                              "replies": [
                                {
                                  "id": "m8mzjru",
                                  "author": "corut",
                                  "body": "NVIDIAs own benchmark put the 5080 at only 11% better then the 4080 without dlss",
                                  "score": 1,
                                  "created_utc": 1737591839.0,
                                  "replies": []
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "id": "m8k64dl",
                      "author": "SiscoSquared",
                      "body": "I mean I have a 3080, the 5* series I was planning on getting but w/ the prices, performance and vram I'm probably going to skip it, the prices of GPUs are a tad crazy. TBH I'm angling at a console if anything, most games are made for console and optimized better for them too, except RTS, and a 3080 plays any RTS just fine.",
                      "score": 1,
                      "created_utc": 1737563497.0,
                      "replies": [
                        {
                          "id": "m8kwj5s",
                          "author": "youzongliu",
                          "body": "True but the biggest problem for me is so hard to mod any games and use cheats on console, that's why I always play on PC.",
                          "score": 0,
                          "created_utc": 1737570619.0,
                          "replies": [
                            {
                              "id": "m8l0uc8",
                              "author": "SiscoSquared",
                              "body": "Aside from a few certain games I never found cheating to be a significant issue, though I understand some games like tarkov (not my thing anyway) it's a big problem.",
                              "score": 1,
                              "created_utc": 1737571756.0,
                              "replies": [
                                {
                                  "id": "m8ll5jl",
                                  "author": "youzongliu",
                                  "body": "Oh really? How do you cheat on console? Cause most games don't have cheat codes, I have to use a trainer or cheat engine to do it.",
                                  "score": 1,
                                  "created_utc": 1737577197.0,
                                  "replies": [
                                    {
                                      "id": "m8ms0yy",
                                      "author": "SiscoSquared",
                                      "body": "I don't know how its done but it def. can happen.\n\nI had a modded original xbox that let me play ripped games, it was modded by soldering a special card to it that basically booted its own OS and would run any game (you could rent games from blockbuster and rip them from the disc then return, rinse and repeat).\n\nI also had a modded 360, it was modded by formatting the removable hard drive with some special code, and would do the same, let you play ripped games (not online though I think).\n\nI assume it would be something like this plus the additional steps for cheats... idk.\n\nI haven't had a console in years as I prefer PC, but with how games are more console oriented and the insane prices of PC I'm considering move back to console despite their many flaws/annoyances (like stupid subscriptions to play online...).",
                                      "score": 1,
                                      "created_utc": 1737589479.0,
                                      "replies": []
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8k32ee",
                  "author": "None",
                  "body": "Alot of people i know are sitting on 3080s and skipped 4080.",
                  "score": 4,
                  "created_utc": 1737562642.0,
                  "replies": [
                    {
                      "id": "m8klx68",
                      "author": "nokinship",
                      "body": "Upgrading every generation is crazy tbh.",
                      "score": 10,
                      "created_utc": 1737567787.0,
                      "replies": []
                    },
                    {
                      "id": "m8m0lxg",
                      "author": "U_Sam",
                      "body": "I\u2019m chilling with my 3060ti. It\u2019s perfectly fine.",
                      "score": 3,
                      "created_utc": 1737581314.0,
                      "replies": []
                    },
                    {
                      "id": "m8mh0ok",
                      "author": "corut",
                      "body": "A lot of people I know (inluding myself) are also planning to skip the 5080 as the perfromance uplift over the 3080 doesn't seem to be worth it for the price.",
                      "score": 3,
                      "created_utc": 1737585993.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8kltcc",
              "author": "nokinship",
              "body": "I'm waiting for TI/Super. FFVII Rebirth is recommending 16gbVRAM at 4k.   \n  \nA 5080 won't last very long if you want to play the latest games in 4k which I want to do since I have a 4k OLED TV to do exactly that.",
              "score": 3,
              "created_utc": 1737567759.0,
              "replies": []
            },
            {
              "id": "m8kbq06",
              "author": "Akrymir",
              "body": "Only for people not paying attention.  The performance is gonna be a touch better than 4080 super\u2026 except for AI performance, which is significantly better but only useful for MFG.",
              "score": 2,
              "created_utc": 1737565027.0,
              "replies": []
            },
            {
              "id": "m8jkdsz",
              "author": "chum_slice",
              "body": "I\u2019m hoping for a decently priced RTX 5070 with 4090 performance\u2026 \ud83d\ude2c\ud83e\udd14",
              "score": 5,
              "created_utc": 1737557300.0,
              "replies": [
                {
                  "id": "m8k7py4",
                  "author": "GrayDaysGoAway",
                  "body": "You can forget that. We're probably not gonna get 4090 performance from the 5080. Absolutely zero chance of getting it from the 70.",
                  "score": 10,
                  "created_utc": 1737563944.0,
                  "replies": []
                },
                {
                  "id": "m8kazsl",
                  "author": "SpeedflyChris",
                  "body": "Best I can do is a 5070 with sub-3080ti performance.",
                  "score": 5,
                  "created_utc": 1737564832.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m8jmz3f",
          "author": "PaulR79",
          "body": "In terms of specs it's barely better than the 5070 Ti which, frustratingly, they won't be making a Founder's Edition at least at launch. If I was going to to replace my GPU it would be 5070 Ti or, if I absolutely must have all the performance then 5090. Truth is my desktop gets used very little  (3070 Ti) since I picked up a laptop with 2070 in it.",
          "score": -3,
          "created_utc": 1737558083.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8jcvgx",
      "author": "z3speed4me",
      "body": "I am patiently awaiting the real world gaming implications. With and without DSSL on. AI is great but I'd like to see the actual compute power improvement it provides without all the shiny fancy things turned on",
      "score": 159,
      "created_utc": 1737554892.0,
      "replies": [
        {
          "id": "m8jz4g9",
          "author": "elite_haxor1337",
          "body": "deep sample super learning!",
          "score": 49,
          "created_utc": 1737561541.0,
          "replies": [
            {
              "id": "m8kcm3s",
              "author": "Akrymir",
              "body": "Up to our eyeballs in Nvidia white papers.",
              "score": 7,
              "created_utc": 1737565267.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8lctuo",
          "author": "Zedrackis",
          "body": "I was trying FSR for the first time on a game that is heavily cpu/netcode bound. It was interesting experience. The game was still lagged as hell with only servers on another continent, but the frame rate stopped bouncing between 120 and 6fps, making it buttery smooth. Even if I couldn't trigger the character abilities in real time because the net lag was still awful.",
          "score": 1,
          "created_utc": 1737574949.0,
          "replies": []
        },
        {
          "id": "m8julib",
          "author": "pederbonde",
          "body": "I dont get the frame generation and dlss hate. Regular dlss set to quality is youst fps gain without losing anything.\nAnd frame generation will make a game look smooth but you will have the latency of the \"real\" fps. But you dont lose anything here either",
          "score": -13,
          "created_utc": 1737560286.0,
          "replies": [
            {
              "id": "m8jvisu",
              "author": "OvenCrate",
              "body": "You'll actually have more latency than the real frame rate, because frame gen needs the next real frame to interpolate, so your display is always lagging behind by 1 real frame time. And DLSS Quality is nice, but it isn't the game changer it's touted to be. If all that \"AI\" silicon was just allocated to more raster compute units, we'd have similar frame rates without upscaling tricks.",
              "score": 48,
              "created_utc": 1737560543.0,
              "replies": [
                {
                  "id": "m8jwdld",
                  "author": "pederbonde",
                  "body": "Even at quality you get like 15-20 performance increase right.\n\nAh didnt know that about frame generation but that makes sense.\n\nYea i can se it fit some games ( some games you only want to look pretty ) and some dont",
                  "score": 6,
                  "created_utc": 1737560781.0,
                  "replies": [
                    {
                      "id": "m8k6gzb",
                      "author": "BassGaming",
                      "body": "Frame generation should only be used if you can't run the games otherwise due to input lag, as the person before mentioned.\n\nConcerning your last point, yeah I agree. Some games with very slow gameplay and beautiful graphics are good with DLSS. If you have fast paced games you get upscaling smudge back though. Even on quality you can see some blurryness and ghosting. One great example is racing games. Yes I do upscale those as well due to having no choice, but I wish I didn't have to.",
                      "score": 12,
                      "created_utc": 1737563597.0,
                      "replies": [
                        {
                          "id": "m8katl8",
                          "author": "GLTheGameMaster",
                          "body": "tbf that's old dlss/frame gen, reportedly the ghosting and input lag are vastly reduced on the new tech",
                          "score": 3,
                          "created_utc": 1737564785.0,
                          "replies": [
                            {
                              "id": "m8p4cak",
                              "author": "DaEnderAssassin",
                              "body": "Reduced is the key word here.\n\nReduced means \"Not removed\"",
                              "score": 1,
                              "created_utc": 1737624125.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8o3lb5",
                  "author": "RRR3000",
                  "body": "They kinda fix that latency issue with Reflex 2 though, at least on paper. Will be very interesting to see how well that ends up working in practice when the reviews start to come out.\n\nI kinda doubt it'll matter much to the average person anyways. When seriously playing competitive online shooters it may matter, but that's only a fraction of games. And most who are serious about it tend to play lowest settings for highest fps anyways.\n\nIn the bigger picture though, it's a difference of mere ms. In most singleplayer and a good chunk of multiplayer games not a big deal. Just look at how many use wireless input devices nowadays despite relatively more latency than wired. All consoles come with wireless controllers, and a good chunk of PC mice are too now. Yet people are fine with those because a few ms is negligible.",
                  "score": 1,
                  "created_utc": 1737605214.0,
                  "replies": [
                    {
                      "id": "m8p189q",
                      "author": "OvenCrate",
                      "body": "Wireless mice that use a proprietary radio protocol (so not Bluetooth) *can* have identical latency to wired mice. Especially the ones designed for gaming, e.g. Logitech's G series that uses their \"Lightspeed\" radio protocol. The USB HID polling rate of 1 kHz reads the cursor position every millisecond, and the actual read operation completes much faster than that. The input lag added by the radio communication between the mouse and the USB dongle is less than 1 ms.\n\nThe frame gen lag is also more than \"just a few ms\" in most cases. If the rendering runs at 30 fps which the frame gen tech boosts to 60, then each frame takes 33 ms to render. So the 60 fps with frame gen has at least 33 ms more input lag than the native 30 fps, probably a bit more because the \"AI\" calculations themselves also take time. That's comparable to the latency of streaming over the internet with GeForce Now (if you live close enough to the data center). Realistically, if you don't mind that much latency, you should just get GeForce Now Ultimate for 10 years for the same amount of money that buying your own RTX 5090 would cost you.",
                      "score": 1,
                      "created_utc": 1737622135.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8jxtpm",
              "author": "z3speed4me",
              "body": "Frame gen is great for high demand visually complex engines... 99% if people will never be able to tell the difference visually. However some games that frame interpretation and assumption to fill the gaps are not preferred if playing online when other variables are introduced for a network latency perspective. I don't want even more things screwing with what I'm \"actually\" seeing.\n\nAnyway my point is yes DSSL is cool, but the prior gen could probably come super close to where these cards are if they simply were able to enable to same features and tools. I simply want to see how much better the actual hardware itself is.",
              "score": 5,
              "created_utc": 1737561181.0,
              "replies": [
                {
                  "id": "m8jykq2",
                  "author": "pederbonde",
                  "body": "Yea makes sense, and there seems to be the same numbers of cuda cores on 4080 as on 5080 if the rumors is correct so the improvment is probably in ai. But 5090 has the dubble amount of cuda cores so it will be interesting to see the reviews on it",
                  "score": 3,
                  "created_utc": 1737561390.0,
                  "replies": [
                    {
                      "id": "m8k1ipp",
                      "author": "z3speed4me",
                      "body": "No way I am paying the 5090 premium though. The return on investment isn't there just so I can tell people \"I have a 5090\" and they can say in reply \"great waste of money\"",
                      "score": 2,
                      "created_utc": 1737562214.0,
                      "replies": [
                        {
                          "id": "m8kbjzm",
                          "author": "pederbonde",
                          "body": "Yea but Nvidia kind of fool us with their new naming.\nNo way that many bought titan card before they changed it to xx90. But now i have a 90 card aswell.. even if i know it kind of stupid. Bought it second hand at least.",
                          "score": 1,
                          "created_utc": 1737564983.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8jwqyy",
              "author": "secretagentstv",
              "body": "DLSS does not look as good as native rendering. Frame generation introduces artifacts and ghosting. Frame generation increases latency of the base frame rate. So, 60 FPS with FG to 120 feels like 30 FPS. FG feels laggy at anything under 80 FPS. That's why I only use FG when I am already getting high FPS. Adding 3 frames per rendered frame, means you are playing @ less than 1/3 the latency of the actual frame rate.",
              "score": 4,
              "created_utc": 1737560884.0,
              "replies": [
                {
                  "id": "m8ljvl5",
                  "author": "gokarrt",
                  "body": "> DLSS does not look as good as native rendering\n\nthis is about as correct as saying \"DLSS looks better than native resolution\".\n\nedit: i know this'll get downvoted to oblivion but seriously https://youtu.be/O5B_dqi_Syc",
                  "score": 5,
                  "created_utc": 1737576846.0,
                  "replies": []
                },
                {
                  "id": "m8jxthv",
                  "author": "pederbonde",
                  "body": "Oh havent tried frame gen, im still on 3000 series.\nBut dlss on quality i have never seen any strange artifacts but i have only used it on a couple of games",
                  "score": -1,
                  "created_utc": 1737561179.0,
                  "replies": [
                    {
                      "id": "m8jyvnt",
                      "author": "secretagentstv",
                      "body": "You can use FSR frame generation in quite a few games. There are some games you can use FSR FG and DLSS upscaling. I play cyberpunk with everything on high/ultra @1440p native with frame gen and get 140-180 fps. I can turn off the frame gen and turn on FSR upscaling, and the higher fps from FSR feels smoother. Frame generation makes it look smoother. But there are some issues with using either technologies.\n\n\nEdit: a word",
                      "score": 4,
                      "created_utc": 1737561474.0,
                      "replies": [
                        {
                          "id": "m8k0l6u",
                          "author": "pederbonde",
                          "body": "Oh thats alot of fps. Sometimes i drop to 70 fps on my 3090 @1440 uw without ray tracing, but its probably my cpu that is the bottleneck. Some core is almost @ 100%",
                          "score": 1,
                          "created_utc": 1737561951.0,
                          "replies": [
                            {
                              "id": "m8k22ng",
                              "author": "secretagentstv",
                              "body": "Cyberpunk is both CPU and GPU intensive! In the phantom liberty expansion, if I use upscaling, I see 100% CPU (7600X) usage. It causes a lot of FPS drops, so I have to cap my frame rate and use FG. And that's why I just bought a 9800x3D, I just have to wait until February 20th to get it.",
                              "score": 2,
                              "created_utc": 1737562370.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8kcige",
              "author": "kevihaa",
              "body": "Part of this is Nvidia\u2019s fault (5070 = 4090\u2026), but general perception is also an issue. \n\nToo many people are looking at DLSS / Frame Gen as all-or-none rather than just another tool to hit a target frame rate. Like, it\u2019s fundamentally no different from deciding between Low/Medium/High textures and deciding, within the constraints of the hardware you have, where you want to be when it comes to visuals vs FPS. \n\nIt\u2019s reductive to say DLSS / Frame Gen are \u201cfree\u201d frames, but, to me at least , the loss in fidelity from using AI upscaling is **way** less than the loss from needing to lower texture settings.",
              "score": 4,
              "created_utc": 1737565240.0,
              "replies": [
                {
                  "id": "m8kellu",
                  "author": "pederbonde",
                  "body": "Yea agree, 5070 = 4090 was quite stupid. Yea i dont see any difference with or without dlss on quality so i consider them free. But it could be my cheap screen that already have to of ghosting making it so i dont se any difference.\nRaw performance is of course better.\n\nBut in the past its have been almost the same price between amd and Nvidia. And amds ai upscaling have been far behind.\nI would have bought more amd cards if the price where better (we have 4 pcs in our family 2 Nvidia 1 amd and 1 Intel )",
                  "score": 0,
                  "created_utc": 1737565813.0,
                  "replies": []
                },
                {
                  "id": "m8kj44x",
                  "author": "Dangthing",
                  "body": "I don't think we should talk about DLSS and Frame Gen as if they are remotely similar. DLSS degrades image quality for direct FPS gain in a non-linear fashion = Quality vs Performance but Frame Gen degrades performance for FAKE performance. \n\nWhile supposedly the new frame gen is \"better\" than old ones it has had the latency of the normal frame rate while giving the higher number. So essentially if you had 30 FPS and used Frame Gen to get 60 FPS you would still FEEL like you were playing 30. There is also a hit to visuals. \n\nYour ability to see frame rate is fairly limited and this becomes dramatically more apparent at higher FPS BUT you can feel the differences in response very easily.",
                  "score": 0,
                  "created_utc": 1737567031.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jwswm",
              "author": "OramaBuffin",
              "body": "If you generally play things that aren't AAA, DLSS is often not an option at all. Or if it is you get 2.0 at best. So frame gen literally does not function as a selling point for that kind of gamer.",
              "score": 1,
              "created_utc": 1737560899.0,
              "replies": [
                {
                  "id": "m8jzop0",
                  "author": "pederbonde",
                  "body": "Yes but you dont need that kind of card of you not are interested in aaa games. Most popular indie games can be runned on a laptop, stardew factorio etc.\n\nYea it will be harder to review cards now a days, you cant only look at the fps numbers anymore",
                  "score": 4,
                  "created_utc": 1737561697.0,
                  "replies": [
                    {
                      "id": "m8kq9dp",
                      "author": "OramaBuffin",
                      "body": "There's a lot of games in the massive valley between Indie 2D Pixel Game and Assasins Creed IX:The RTX Reckoning that still benefit from powerful hardware when you want to push 144-240 fps at high resolutions though",
                      "score": 2,
                      "created_utc": 1737568940.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8ko305",
              "author": "nokinship",
              "body": "DLSS plus reflex is good at keeping latency low. It's the frame gen that increases latency.",
              "score": 1,
              "created_utc": 1737568361.0,
              "replies": []
            },
            {
              "id": "m8ljfu3",
              "author": "SpehlingAirer",
              "body": "When it comes to the actual performance of the GPU then frame gen provides a misleading result. It's still useful of course to see what you get with it turned on, but for something like a benchmark I want to see the real performance",
              "score": 1,
              "created_utc": 1737576724.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8khpko",
          "author": "PandaBambooccaneer",
          "body": "actual compute power is gonna be a few percentage points.  I'm not sure why folks are anti-AI DSSL tho, frames are frames, if it looks good, who cares if they aren't actual game frames or not",
          "score": -2,
          "created_utc": 1737566654.0,
          "replies": [
            {
              "id": "m8kw7s2",
              "author": "Rokku0702",
              "body": "People don\u2019t realize that we\u2019re heading into an era where AI is going to imagine photo realism for our frames instead of devs needing to make photo realism happen. They\u2019ll make games look about as good as they do now and have well trained AI leverage new chips to draw better fidelity over the PS5 scale graphics.",
              "score": -4,
              "created_utc": 1737570534.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8jaxmp",
      "author": "Cactuszach",
      "body": "Leaks out? Of the card? \ud83e\udd14",
      "score": 105,
      "created_utc": 1737554229.0,
      "replies": [
        {
          "id": "m8jemwk",
          "author": "LeCrushinator",
          "body": "The files are...in the computer!",
          "score": 57,
          "created_utc": 1737555475.0,
          "replies": [
            {
              "id": "m8jfjk2",
              "author": "jgor133",
              "body": "Cookies too\n\n![gif](giphy|xT0xeMA62E1XIlup68)",
              "score": 18,
              "created_utc": 1737555771.0,
              "replies": []
            },
            {
              "id": "m8jmugr",
              "author": "bonesnaps",
              "body": "The 5090 leaks are coming from inside the house!",
              "score": 3,
              "created_utc": 1737558044.0,
              "replies": [
                {
                  "id": "m8nbiy2",
                  "author": "LordRocky",
                  "body": "It\u2019s in the frakkin ship!",
                  "score": 1,
                  "created_utc": 1737595632.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jubg5",
              "author": "Void_Guardians",
              "body": "Its so simple",
              "score": 2,
              "created_utc": 1737560208.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jmntz",
          "author": "Actedpie",
          "body": "How do we patch up the leaks? Do we need a plumber?",
          "score": 3,
          "created_utc": 1737557988.0,
          "replies": [
            {
              "id": "m8ldam5",
              "author": "Zedrackis",
              "body": "Forget the Pinkerton's, someone call Mario and Luigi!",
              "score": 2,
              "created_utc": 1737575075.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8k2vzk",
      "author": "Presently_Absent",
      "body": "assuming this isn't a ridiculous leap in performance, what's the best bang-for-the-buck card right now? I'm not heavy into games but i do like the odd VR game, and do a lot of CAD/BIM work. Need to rebuild my PC this year as the GTX970 and 5th gen i7 are starting to show their age...",
      "score": 8,
      "created_utc": 1737562593.0,
      "replies": [
        {
          "id": "m8k9qca",
          "author": "aqua19858",
          "body": "I'd say the 4070 Super. For VR, though, you'll get a lot out of any of the X3D CPUs from AMD.",
          "score": 11,
          "created_utc": 1737564490.0,
          "replies": [
            {
              "id": "m8wj3pd",
              "author": "Inquisitor2195",
              "body": "I would agree with the 4070 Super, only pain point for me is the VRAM, but I honestly didn't find a better option when I went to upgrade, and it will probably only be an issue at 4k.",
              "score": 1,
              "created_utc": 1737723787.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8mxy4x",
          "author": "Nolejd50",
          "body": "7900xt is around 620$ on amazon these days.",
          "score": 6,
          "created_utc": 1737591337.0,
          "replies": []
        },
        {
          "id": "m8m6b62",
          "author": "QuickQuirk",
          "body": "The new intel Arc cards are scoring pretty well for bang vs buck at the sub 300 price point.\n\nThe AMD 6700/6800 and 7600/7700 also rank well, last I checked.\n\nNvidia wise, you're looking at the more expensive 4060, but at least you get DLSS.\n\nOtherwise, 2nd hand previous generation cards are excellent.",
          "score": 2,
          "created_utc": 1737582843.0,
          "replies": []
        },
        {
          "id": "m8o7snb",
          "author": "desertrijst",
          "body": "My upgrade path after the 970 has been 970 in sli, 1080ti (mid 2017), and since a year or so a 4090 (undervolted)\nAs I play on uwqhd (21:9, so widescreen 1440p) performance is very much sufficient at this time  the best option is always to postpone any gpu upgrade. Due to the time spent behind my pc I appreciate lower gpu power consumption and noise as well. I have a feeling I will be drawing more power without a noticable, or lets say needed fps boost at this time.\nI am still on a ryzen 5950x, so that would be my next upgrade  but that also means a new mobo.\nDepending on your budget, you could try to get a 50 series card, but budget wise I would get a second hand 4090 if I were you from someone who is going after a 5090.\nNote: coil whine is a thing on 4090s, I therefore went with a gigabyte gaming oc, as it had the least chance of having it and I got no noticable coil whine.",
          "score": 1,
          "created_utc": 1737606886.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8jer8t",
      "author": "Tovar42",
      "body": "I just want a 3070 with 24Vram",
      "score": 34,
      "created_utc": 1737555515.0,
      "replies": [
        {
          "id": "m8jhw9k",
          "author": "crumpetsucker89",
          "body": "You could pay a shop to mod it but for that cost you could just buy a used 3090",
          "score": 17,
          "created_utc": 1737556526.0,
          "replies": [
            {
              "id": "m8ktlsc",
              "author": "egguw",
              "body": "used 3090s are scalped to high heavens too",
              "score": 4,
              "created_utc": 1737569841.0,
              "replies": [
                {
                  "id": "m8uwt75",
                  "author": "crumpetsucker89",
                  "body": "True, but depending on the area you can sometimes find a deal",
                  "score": 1,
                  "created_utc": 1737693338.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8mjub4",
              "author": "Tovar42",
              "body": "I men a card that performs like that but with more Vram, they continuing to make cards that need more power for no gain and doubling the price every time is the worst",
              "score": 1,
              "created_utc": 1737586880.0,
              "replies": [
                {
                  "id": "m8uwou0",
                  "author": "crumpetsucker89",
                  "body": "Agreed, the price of the latest cards is excessive",
                  "score": 1,
                  "created_utc": 1737693291.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8p3zus",
              "author": "SoulOfTheDragon",
              "body": "Could you? It was originally designed to have 8GB and 16GB variants, to which there are jumpers on board too iirc. 24GB might be harder to get working if at all",
              "score": 1,
              "created_utc": 1737623904.0,
              "replies": [
                {
                  "id": "m8uwchz",
                  "author": "crumpetsucker89",
                  "body": "TBH I\u2019m not sure about 24GB but I suspect it could be done with some hackery.  Realistically though for the cost to do the upgrade and the potential issues you may have I think it would be better to buy another card.  Personally though I would love to upgrade my 3070 TI though with more VRAM lol.\n\nI have a 3080 TI in my main rig and always wonder how my 3070 TI would stack up if it had more VRAM.",
                  "score": 1,
                  "created_utc": 1737693155.0,
                  "replies": [
                    {
                      "id": "m8vvr9j",
                      "author": "SoulOfTheDragon",
                      "body": "I know the feeling. When 3070 was released I spends month drooling and waiting for the promised 16GB variant only for them to bin it due to everything selling out over MSRP regardless. I would have had my 3070 far longer if it had had more memory.",
                      "score": 1,
                      "created_utc": 1737711753.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8jjpky",
          "author": "SortOfaTaco",
          "body": "If you had a lot of bravery and soldering skills it can be done from what I understand",
          "score": 6,
          "created_utc": 1737557092.0,
          "replies": [
            {
              "id": "m8kcpyv",
              "author": "nicman24",
              "body": "it is not a skill issue, it is a the proper equipment costs more than a 4090",
              "score": 7,
              "created_utc": 1737565296.0,
              "replies": [
                {
                  "id": "m8kmt8o",
                  "author": "SortOfaTaco",
                  "body": "Yeah I said that very vaguely lol, I\u2019m sure the cost to do it outweighs just buying a card with more vram",
                  "score": 1,
                  "created_utc": 1737568022.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m8wjcc3",
          "author": "Inquisitor2195",
          "body": "Man, I would kill to have my 4070 Super with 24gb of VRAM, I probably wouldn't replace it for 2 gens, which is probably why no such thing exists.",
          "score": 1,
          "created_utc": 1737723882.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8je3b5",
      "author": "Greyboxer",
      "body": "I dont think this will be as popular on launch day as everyone is afraid of. I bought my 4090 on launch day on newegg and there were tons of them available. Sure they were all gone in about an hour or so, but it wasnt the spamming refresh button thing like the PS5. This is no PS5.",
      "score": 33,
      "created_utc": 1737555298.0,
      "replies": [
        {
          "id": "m8jjiak",
          "author": "Basquests",
          "body": "To be fair, a ps5 is significantly cheaper and is the whole gaming rig in one.\n\nThe consumer audience for a ps5 is much bigger than a $2k card*",
          "score": 55,
          "created_utc": 1737557031.0,
          "replies": [
            {
              "id": "m8jroqy",
              "author": "Gahvynn",
              "body": "Computer subreddits in the pre 2xxx series card days used to pride themselves on being able to build a solid gaming rig for $4-500 (without monitor and keyboard).  Now the same subs have the most upvotes rigs where the customization within the rig (lighting, cooling system) probably pushes more than half that cost.  It\u2019s been wild to watch, where a $500 card used to be expensive and now people are justifying spending 5x that or more.",
              "score": 33,
              "created_utc": 1737559465.0,
              "replies": [
                {
                  "id": "m8juy5z",
                  "author": "Dt2_0",
                  "body": "This might be finally changing with the new ARC cards and with AM4 still being widely accessible. I went to PC Part Picker, and with all new parts was able to build a pretty competent gaming tower for $583. They did not have pricing for the ARC B580 so I used the reference card and the MSRP pricing as place holders.\n\nhttps://pcpartpicker.com/list/wZtcMC\n\nIf you say... Bought the CPU used, and found an old case on Facebook Market, you would have a pretty good rig for about $500.\n\nConsoles were cheaper back then too. The PS4 was $400, the Xbox Series S was $300. Now the Series X is $500, the PS5 Pro is $700. So at less than $600, it compares pretty favorably.",
                  "score": 10,
                  "created_utc": 1737560384.0,
                  "replies": [
                    {
                      "id": "m8k4be4",
                      "author": "tocilog",
                      "body": "Isn't there an issue with the B580 not performing well with older CPUs?",
                      "score": 2,
                      "created_utc": 1737562985.0,
                      "replies": [
                        {
                          "id": "m8k54p5",
                          "author": "Dt2_0",
                          "body": "Ryzen 5000 is new enough that it will perform fine with B580.\n\nMake sure your motherboard BIOS is up to date so you can turn on Resizable BAR (which is the issue, CPUs without Resizable BAR), and you will be fine.",
                          "score": 4,
                          "created_utc": 1737563213.0,
                          "replies": []
                        },
                        {
                          "id": "m8ooor3",
                          "author": "CT4nk3r",
                          "body": "Yapp, especially with the exact CPU OP picked, you can watch hardware unboxed's video, it can perform worse than a cheaper/same price card by 20-30% on a ryzen 5 5600",
                          "score": 2,
                          "created_utc": 1737614753.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8krav2",
                      "author": "Blazr5402",
                      "body": "Yeah, you can put together a solid 1080p/60fps machine for around $600, which is about the same performance you'd get out of a PS5 or Series X. I believe the most used graphics card on Steam is still the 3060, so most PC gamers are not shilling out for thousand dollar GPUs",
                      "score": 0,
                      "created_utc": 1737569220.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8l6j8y",
                  "author": "loconessmonster",
                  "body": "To add do your comments, running on ultra settings is not a requirement. Honestly running on a mix of medium and high settings is what most people should do. The consoles don't run games on ultra either. If you want to build a budget system you still can with the expectation that you're not maxing out all the settings. I'd say you can still build a decent comparable console system for around $600-700 all-in.",
                  "score": 5,
                  "created_utc": 1737573273.0,
                  "replies": []
                },
                {
                  "id": "m8lohd1",
                  "author": "Psychast",
                  "body": "It's all relative to where you're at in life, as a broke teen/early 20's, putting together a $600 rig that ran stuff at 1080p was all I could manage and I was very proud of it, hitting anywhere over 60fps was good enough. Getting the absolute best value for your money was the aim of the game.\n\nBut you get older, get better paying jobs, and have the good fortune to afford nice things every few years or so. Then it becomes less about \"value\" and more about style and power, even at a premium cost. I built my dream rig a couple years ago, huge full tower case, 4090, i7-13700, DDR5 ram, NVME SSD, man all the works, 4k gaming on a big nice 4k screen, it's really great. I'm set for years and years. I'm just as proud of it as I am of my first rig, I don't need \"justify\" jack shit, value is simply not my primary factor anymore. It's a luxury item afterall, even at $600 it was a luxury item for teen me, it's a luxury item now at $3k, why are we pocket watching?",
                  "score": 3,
                  "created_utc": 1737578098.0,
                  "replies": [
                    {
                      "id": "m8lufyt",
                      "author": "Gahvynn",
                      "body": "I agree with your assessment completely.\n\nBut I don\u2019t think an entire sub transitioned from loving super cheap rigs to being able to afford nicer things, I think it\u2019s just the fact you used to be able to get a 1080P capable card and system for $5-600 and now the standard is either 1440P or 4K and a $1-2k GPU Plus the rest of the system.",
                      "score": 1,
                      "created_utc": 1737579680.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8jwy98",
                  "author": "OvenCrate",
                  "body": "PC building was never about price efficiency. Pre-built units are often better deals than getting all the components and DIY-ing it. Consoles will always be more bang for the buck, because they're purpose-built, at scale, for just gaming - and to top it off, manufacturers sell them at a loss that they then recoup in game sale fees later, thanks to their locked-down platforms granting them a monopoly on game distribution. It's a hobby, and hobbies have costs. As a broke college student, I had to make do with the LEGO experience of putting everything together and installing Windows. Now that I have more disposable income, I'll spend the price of a console on just water-cooling components, not because it makes the games play better but because I love to tinker with my system.",
                  "score": -1,
                  "created_utc": 1737560940.0,
                  "replies": [
                    {
                      "id": "m8k245r",
                      "author": "z3speed4me",
                      "body": "I've never seen a prebuild from a reputable place have a price better than what I could put together for the same parts, time is one thing but so is wasting money when you can do it yourself.",
                      "score": 10,
                      "created_utc": 1737562381.0,
                      "replies": [
                        {
                          "id": "m8kb5xz",
                          "author": "GLTheGameMaster",
                          "body": "Microcenter's Powerspec PCs are typically at-price or cheaper than building yourself. As well as what they said about consoles definitely being cheaper than a comparable PC DIY, though that's a different thing because they are limited in what they can do",
                          "score": 1,
                          "created_utc": 1737564878.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8m5yzo",
                      "author": "Sethithy",
                      "body": "That \u201cpre-builts are cheaper\u201d thing only came about recently with the scarcity of hardware post-pandemic. Consoles are more bang for your buck, if all do is play games. If you want to game AND do other work then getting a PC capable of gaming is usually a better bang for your buck as opposed to getting both a pc and a console.",
                      "score": 1,
                      "created_utc": 1737582752.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8jwnb9",
              "author": "diacewrb",
              "body": ">The consumer audience for a ps5 is much bigger than a $2k card*\n\nYou could buy a ps5 pro, xbox series x and switch oled for the same price the gpu, and still have change to spare for games.\n\nDrop it down to the standard models then probably change for the tv as well.",
              "score": 8,
              "created_utc": 1737560856.0,
              "replies": [
                {
                  "id": "m8m5emk",
                  "author": "QuickQuirk",
                  "body": "wild that a giant 70\" class TV can be had for less than the GPU. And that gives a much more noticeable gaming 'experience' improvement than the 5090 would.",
                  "score": 2,
                  "created_utc": 1737582599.0,
                  "replies": [
                    {
                      "id": "m8mu873",
                      "author": "Basquests",
                      "body": "Absolutely- people are always chasing.\n\nIts good to have options - some people do get a huge benefit from having the best. A professional shouldn't blink twice at getting high end stuff if it helps. If you're on a PC 12 hrs a day, yeah sure make it great.\n\nBut no one NEEDS the best of every tech. They want that. \n\nThe cost ($ and resources) thankfully makes people think a little, but not everyone is constrained by $.",
                      "score": 2,
                      "created_utc": 1737590168.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8jtbrc",
          "author": "Dt2_0",
          "body": "Yea, the reason 3000 series was so crazy was 1) limited supply due to the pandemic, and 2) 3000 series was a massive step up from the 2000 and 1000 series, and well priced. The 3080 at $800 was a legitimate major upgrade from the 1080ti at a similar price, which pulled a lot of people into purchasing a new card.",
          "score": 10,
          "created_utc": 1737559930.0,
          "replies": [
            {
              "id": "m8k39fl",
              "author": "CrazyTillItHurts",
              "body": "You are completely forgetting these things were bought up by Ethereum miners at an amazing premium, because you *would* end up making your money back",
              "score": 6,
              "created_utc": 1737562696.0,
              "replies": [
                {
                  "id": "m8k58el",
                  "author": "Dt2_0",
                  "body": "Yea this is also true. Man that was a wild time. But I was more talking about the Day 1 crazyness. Sold out in less than 1 second.",
                  "score": 1,
                  "created_utc": 1737563242.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jv86o",
              "author": "Greyboxer",
              "body": "Completely agree it was a game changer",
              "score": 1,
              "created_utc": 1737560460.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jp86a",
          "author": "Sobeman",
          "body": "They will limit stock on release so they can make headlines \"5090 sells out in seconds\" then push a bunch of \"this is actually good value\" articles.",
          "score": 3,
          "created_utc": 1737558754.0,
          "replies": [
            {
              "id": "m8jvb4y",
              "author": "Greyboxer",
              "body": "I would be shocked at anyone saying it\u2019s a good value",
              "score": 1,
              "created_utc": 1737560483.0,
              "replies": [
                {
                  "id": "m8m8cz2",
                  "author": "Sethithy",
                  "body": "It\u2019s (probably) a good value for people doing AI work or other types of productivity, but it\u2019s not a good value for gaming. Anyone buying a 5090 for gaming is an absolute fool.",
                  "score": 1,
                  "created_utc": 1737583407.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m8jwe5u",
          "author": "piscian19",
          "body": "I think it's interesting that the 3080s and 4090s aren't really dropping price on the secondary market. I think Nvidia got a little over confident after the bitcoin shortage. Most of us are already taken care of by now and  the excitement about new cards is offset a bit by AI fatigue.",
          "score": 2,
          "created_utc": 1737560785.0,
          "replies": [
            {
              "id": "m8lbdsp",
              "author": "SigmaLance",
              "body": "This has been happening since the 2000 series.\n\nI wanted to grab a 1080TI when the 2000 series dropped, but I couldn\u2019t even find one at MSRP.\n\nNo biggie\u2026I\u2019ll just wait for the 3000 series to drop then and grab a 2000 series for cheap.\n\nThey never dropped in price either.\n\nI grabbed the 4090 from Gigabyte when they mislabeled their prices and never looked back.",
              "score": 1,
              "created_utc": 1737574565.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8kcupl",
          "author": "nicman24",
          "body": "ML / AI / cuda goes brrrrrrrr",
          "score": 1,
          "created_utc": 1737565332.0,
          "replies": []
        },
        {
          "id": "m8mv4qi",
          "author": "Estrava",
          "body": "I tried to get a 4090 on launch day and they were all OOS\u2026",
          "score": 1,
          "created_utc": 1737590452.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8jvmcq",
      "author": "piscian19",
      "body": "well it's no 1080 Ti thats for sure.",
      "score": 4,
      "created_utc": 1737560571.0,
      "replies": []
    },
    {
      "id": "m8kwxm7",
      "author": "Kalinum1",
      "body": "If im getting my first pc, dont want to upgrade for a long tome, have a decent budget, is 5080 a good choice?",
      "score": 4,
      "created_utc": 1737570726.0,
      "replies": [
        {
          "id": "m8lktsz",
          "author": "Tebasaki",
          "body": "That's maybe what I'm aiming for.",
          "score": 2,
          "created_utc": 1737577108.0,
          "replies": []
        },
        {
          "id": "m8mayvi",
          "author": "Tugwater",
          "body": "I went with the 4080 in Fall 2023 for my first build. It\u2019s been a champ!",
          "score": 1,
          "created_utc": 1737584169.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8kitzt",
      "author": "online-optimism",
      "body": "Can't wait to upgrade to the 5090 and open the runescape launcher",
      "score": 7,
      "created_utc": 1737566955.0,
      "replies": []
    },
    {
      "id": "m8jd014",
      "author": "sulivan1977",
      "body": "![gif](giphy|JktYMtRC9hzTq)\n\nRelease the cards to Gamers Nexus already.  I want numbers I can trust.",
      "score": 59,
      "created_utc": 1737554935.0,
      "replies": [
        {
          "id": "m8jdoq3",
          "author": "flameofanor2142",
          "body": "He's too busy starting fights with other Youtubers",
          "score": 114,
          "created_utc": 1737555166.0,
          "replies": [
            {
              "id": "m8jeilo",
              "author": "VendettaAOF",
              "body": "Works 100 hours a week writing scripts for his youtuber beef videos.",
              "score": 37,
              "created_utc": 1737555436.0,
              "replies": []
            },
            {
              "id": "m8jei2x",
              "author": "sulivan1977",
              "body": "Nah he's got a second channel for that now.   And to be fair how often has Steve go in without having done his homework.",
              "score": 22,
              "created_utc": 1737555431.0,
              "replies": [
                {
                  "id": "m8jn5us",
                  "author": "CoreParad0x",
                  "body": "> And to be fair how often has Steve go in without having done his homework.\n\nFrankly this drama undermines his entire investigative journalism side. LTT brought valid criticisms of his methods with specific instances up in a wan show video recently. Steve has addressed none of them, and instead doubled down on some fairly mundane \"receipts\" that are supposed to show Linus's bad faith and poor conduct in response, but they really just don't. Especially not to the degree to justify the kind of stuff he's trying to justify.",
                  "score": 20,
                  "created_utc": 1737558139.0,
                  "replies": [
                    {
                      "id": "m8k7415",
                      "author": "RAZR31",
                      "body": "The hardware news video that came out yesterday actually addressed the issues Linus brought up. There is a link in the comments to the full blog post.\n\nBasically, Linus whined that Steve made some claims but provided no proof and that Linus would like to \"see the receipts\" (direct quote).\n\nSo Steve's blog post includes screenshots and text messages and emails of everything Linus asked for, proving Steve's claims to be true. Steve ends the blog post with the statement that he no longer feels comfortable talking to Linus in private due to continued poor professionalism and insults, but would like to continue a professional relationship with Luke. If Linus wants to talk to Steve, Steve is open to it, but Luke would need to be there as a witness.\n\nHere's the link to the blog post with all the proof Linus asked for, along with the promise of more proof if Linus continues to ask for more.\n\nhttps://gamersnexus.net/gn-extras/our-response-linus-sebastian",
                      "score": 13,
                      "created_utc": 1737563776.0,
                      "replies": [
                        {
                          "id": "m8p3s0a",
                          "author": "shwaah90",
                          "body": "I read it through, he's talking to him as a peer not an employee/employer it really doesn't support the claim of unprofessionalism or Linus being rude at all. I don't really care for either, Steve is an absolute charisma vacuum and Linus is loud and petulant but Steve's claims and hit pieces just come off as jealousy that LMG is the bigger channel despite not having the detail or possibly accuracy that Gamers Nexus does.",
                          "score": 1,
                          "created_utc": 1737623767.0,
                          "replies": []
                        },
                        {
                          "id": "m8lishu",
                          "author": "Fredasa",
                          "body": "It's been three hours and I'm still waiting for the LTT stan to get back to you on this one.  Is this one of those \"been real quiet since\" moments?",
                          "score": -4,
                          "created_utc": 1737576548.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8jsgn3",
                      "author": "Gahvynn",
                      "body": "Exactly.\n\nI\u2019ve stopped listening and have unsubbed from Steve because of all the points you bring up.\n\nChecking out the analytics it\u2019s clear I\u2019m in the minority, but having unhinged rants with \u201cfacts\u201d that later get in part proven false and there\u2019s zero attempt to address it kills his credibility with me.",
                      "score": -1,
                      "created_utc": 1737559685.0,
                      "replies": [
                        {
                          "id": "m8jws4a",
                          "author": "lowercaset",
                          "body": "The Linus \"we've hired a firm to investigate is and they determined that it can't be proven we did anything wrong so we could sue this ex employee if we wanted!\" thing when combined with what we see of how Linus communicates in private makes me think that maybe both should be ignored about this drama. (And tbh anything they say about each other)\n\nI'm glad GN is splitting drama content off to a separate channel because I have 0 interest in it. His tech reviews are still 10/10 for me.",
                          "score": 13,
                          "created_utc": 1737560893.0,
                          "replies": []
                        },
                        {
                          "id": "m8jv1kf",
                          "author": "CoreParad0x",
                          "body": "Yeah, as someone who has liked both channels it's becoming increasingly harder to side with Steve over this stuff. And the sad thing is he could have just left well enough alone. His 2 minute comment on LTT in the Honey video literally added nothing to overall content and was frankly even kind of awkward (even when I just first watched it without all this extra drama.)\n\nI personally won't unsub to him, I still think his hardware benchmarks are worth watching. That's what they've been great at. Unfortunately I don't know how much I'll watch their investigations channel, because this really undermines the quality of the rest of that work.",
                          "score": 3,
                          "created_utc": 1737560409.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8jiecc",
                  "author": "nirurin",
                  "body": "Well considering he got more things wrong than right in those attacks... not the best track record. \n\nHowever this is a boring subject nobody but Steve and his minions seem to care about.",
                  "score": -1,
                  "created_utc": 1737556685.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jfp5w",
              "author": "Rockinthislife",
              "body": "I don't know man he's not the one using the hard r or calling his colleagues less autistic.",
              "score": 4,
              "created_utc": 1737555822.0,
              "replies": [
                {
                  "id": "m8jwhcq",
                  "author": "ExtremeCreamTeam",
                  "body": "It's OK. I at least understood your reference, champ. \n\n<3",
                  "score": 4,
                  "created_utc": 1737560811.0,
                  "replies": []
                },
                {
                  "id": "m8jpq8x",
                  "author": "UrbanAnathema",
                  "body": "Linus\u2019 attitude comes across as dismissive and condescending in some of the texts. I can get why Steve took issue with that, along with LTT\u2019s plagiarism of his work. \n\nHe\u2019s upset about them playing more fast and loose than he\u2019d like with public accountability for what he sees as significant issues.\n\nAll of that is fair. \n\nBut his reaction has come across to most as overblown and his behavior at this point is doing more harm than good to his brand. \n\nIf it\u2019s legitimate, have a fucking conversation and air it out. If it\u2019s performative, I don\u2019t think it\u2019s doing him any favors. \n\nEither way, it should end.",
                  "score": 6,
                  "created_utc": 1737558900.0,
                  "replies": []
                },
                {
                  "id": "m8jowtf",
                  "author": "TheRedOwl17",
                  "body": "Retar* is not hard R, theres a very big difference.",
                  "score": 6,
                  "created_utc": 1737558661.0,
                  "replies": [
                    {
                      "id": "m8jwcgm",
                      "author": "ExtremeCreamTeam",
                      "body": "It's a reference to a Linus flub.\n\nhttps://youtu.be/MFDiuBomSuY",
                      "score": 10,
                      "created_utc": 1737560772.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8jxdii",
                  "author": "OramaBuffin",
                  "body": "Dude when you say it like that you're implying they said the N word. It's misleading as hell.",
                  "score": 2,
                  "created_utc": 1737561056.0,
                  "replies": [
                    {
                      "id": "m8li6g9",
                      "author": "elton_john_lennon",
                      "body": "Linus thought the hard r word meant rtrd, he found out he was wrong live on wan show.",
                      "score": 1,
                      "created_utc": 1737576379.0,
                      "replies": []
                    },
                    {
                      "id": "m8m9aic",
                      "author": "Sethithy",
                      "body": "https://youtu.be/MFDiuBomSuY?si=7Bv80pseGZnSnkCy",
                      "score": 1,
                      "created_utc": 1737583677.0,
                      "replies": []
                    }
                  ]
                },
                {
                  "id": "m8jqsog",
                  "author": "crying_lemon",
                  "body": "ohhh what happened here ?? spill the beans.",
                  "score": 1,
                  "created_utc": 1737559209.0,
                  "replies": [
                    {
                      "id": "m8jwrts",
                      "author": "ExtremeCreamTeam",
                      "body": "Read the texts GN has provided. \n\nAnd also watch this: https://youtu.be/MFDiuBomSuY",
                      "score": 6,
                      "created_utc": 1737560891.0,
                      "replies": [
                        {
                          "id": "m8jyxzt",
                          "author": "crying_lemon",
                          "body": "thanks!",
                          "score": 1,
                          "created_utc": 1737561492.0,
                          "replies": []
                        }
                      ]
                    },
                    {
                      "id": "m8k06tw",
                      "author": "Dt2_0",
                      "body": "Gamers Nexus fired another attack at Linus Tech Tips over the Honey drama, taking Linus completely out of context.\n\nFor reference, Linus and other creators, (likely including Steve) knew about Honey's Affiliate scrubbing several years ago. Linus chose not to make a video due to other creators having covered that issue, and it not affecting consumers at all. To him it would have sounded like \"Stop using Honey, it cuts into my pocket book when you do.\" What Linus did not know about at the time was that Honey had specific agreements with websites not to give the best codes to consumers. Now that the information is out, Gamers Nexus put out a video where they stated they joined a lawsuit against Honey, and attacked LTT for not doing the same years ago, ignoring the very important context above.\n\nThis, along with the attack video in Summer 2023, where much of what Gamers Nexus brought to the table was completely unfounded, or missing context has finally had Linus say. \"Ok, that is enough.\" On WAN show last week, Linus had a scripted statement that very clearly had been reviewed by LTT's legal team saying \"This unprofessional, and unethical behavior stops now. Either bring receipts, or stop attacking me\", along with a well worded Or Else. This affects Linus's brand, and the company that employs well over 100 people, and much of what has been thrown by GN is either found not true or misrepresented, setting an actually fairly strong case for a Libel suit.\n\nDuring that segment of the WAN, Linus personally extended an Olive Branch, asking for their relationship to go back to how it was a few years ago (remember, Steve was one of the people invited to the Linus Roast. They were, at least from LTT's perspective, on friendly terms).\n\nGamers Nexus responded by posting their receipts, much of which either does not, or only arguably supports their claims. Some of which make Steve seem immature himself.\n\nIt is very important to note that if this continues, the ultimate action is probably out of Linus' hands. He is not the CEO of Linus Tech Tips, and ultimately, legal decisions like this are the CEO's call.\n\nNeedless to say, Gamers Nexus, which appeared to be greatly unbiased has, in the last week or so, dug themselves a hole that has tarnished their reputation as reliable sources of data and industry news and investigations. Speculation is that Steve has a personal beef with Linus, or he is very concerned by competition from LTT Labs moving LTT into his wheelhouse. These are unconfirmed so take them with a grain of salt.\n\nSources: Gamers Nexus 2023 video on Linus Tech Tips.  \nhttps://www.youtube.com/watch?v=FGW3TPytTjc\n\nDr. Ian Cutress's break down of the 2023 situation highlighting unethical journalistic practices by Gamers Nexus.  \nhttps://www.youtube.com/watch?v=Ez9uVSKLYUI\n\nGamers Nexus Honey video:  \nhttps://www.youtube.com/watch?v=IKbFBgNuEOU\n\nThe Scripted Portion of last week's WAN Show.  \nhttps://www.youtube.com/watch?v=zDd5X1eE_n0\n\nGamers Nexus response to the WAN Show.  \nhttps://gamersnexus.net/gn-extras/our-response-linus-sebastian",
                      "score": 12,
                      "created_utc": 1737561839.0,
                      "replies": [
                        {
                          "id": "m8k1jhe",
                          "author": "crying_lemon",
                          "body": "just to let you know, i read the comment.  \nthanks a lot for the background, like it seems from my point of view, an unesesary problem that could have been avoided talking face to face and not doing this kind of things.\n\nthanks!",
                          "score": 6,
                          "created_utc": 1737562220.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8khvvw",
                  "author": "PandaBambooccaneer",
                  "body": "literally, who cares.",
                  "score": -1,
                  "created_utc": 1737566701.0,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "m8jjlw8",
          "author": "aenae",
          "body": "They have them. It is just that there is an embargo. You will see all the sites publishing their very long reviews at the same time soon.",
          "score": 3,
          "created_utc": 1737557061.0,
          "replies": []
        },
        {
          "id": "m8o6pq4",
          "author": "DrPoopyPantsJr",
          "body": "And I want a video that is actually entertaining instead of a boring ass lecture",
          "score": 1,
          "created_utc": 1737606447.0,
          "replies": [
            {
              "id": "m8q3ps0",
              "author": "sulivan1977",
              "body": "I get it.  You want to watch what you like..  I happen to like GN's.  You do you man.",
              "score": 1,
              "created_utc": 1737641150.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8kqubb",
      "author": "santathe1",
      "body": "The word \u201cout\u201d is kinda redundant if it\u2019s preceded by \u201cleaks\u201d.",
      "score": 3,
      "created_utc": 1737569097.0,
      "replies": []
    },
    {
      "id": "m8jbkgf",
      "author": "LupusDeusMagnus",
      "body": "I feel like synthetic benchmarks are somewhat useless because stuff isn\u2019t optimised for hardware, everyone expects specific driver drops to make their games work. So if you don\u2019t have a specific driver update for the game you want, the performance boost is can be anywhere.",
      "score": 8,
      "created_utc": 1737554447.0,
      "replies": [
        {
          "id": "m8jcbcs",
          "author": "Mainbaze",
          "body": "No reason to, but I just want to share that I\u2019ve never had drivers do a difference to me in 10 years of gaming. Just me?",
          "score": -8,
          "created_utc": 1737554702.0,
          "replies": [
            {
              "id": "m8jfi2q",
              "author": "neverfearIamhere",
              "body": "If you play alot of new release games as they drop you absolutely would notice a difference.  For quite a few games recently I've had to go back and install the game day driver because the pre-release one was awful.  Stalker 2 and Mechwarrior 5: Clans are the first I thought of.",
              "score": 4,
              "created_utc": 1737555758.0,
              "replies": [
                {
                  "id": "m8jit4f",
                  "author": "Mainbaze",
                  "body": "Fair, I can count on my hands the amount of new games I\u2019ve bought",
                  "score": -1,
                  "created_utc": 1737556814.0,
                  "replies": [
                    {
                      "id": "m8jo824",
                      "author": "PM_ME_STEAM_KEY_PLZ",
                      "body": "Yeah it makes a huge difference.",
                      "score": 2,
                      "created_utc": 1737558456.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m8jekdr",
      "author": "LeCrushinator",
      "body": "$2000 for a 20-30% increase over the previous gen card? I remember when performance was going up 50% per generation and the cards cost 1/4th that much (even when accounting for inflation). On top of all of that, the card is barely more efficient than the prior generation, which is highly disappointing.\n\nWe really need high-end competition for Nvidia because this is ridiculous.",
      "score": 19,
      "created_utc": 1737555452.0,
      "replies": [
        {
          "id": "m8m5zph",
          "author": "bunkSauce",
          "body": ">I remember when performance was going up 50% per generation and the cards cost 1/4th that much\n\nI've been buying nvidia GPU since before they started their current numbering scheme. Do you want to cite some evidence of this? There are very few generations with 50% performance improvement, though they do exist. But it was far from the norm.\n\nWe are late stage Moores law, and can't expect the same gains at the same price, but 50% performance gain from gen to gen looking at a specific model in each... that's a pretty big claim, considering most generational performance improvements for the last decade are around 15-35%. And the cost of the flagship model has almost always been pretty high, though GPUs have climbed more than any other component.\n\nIn 2013, Nvidia released the Titan for $2,499...",
          "score": 2,
          "created_utc": 1737582757.0,
          "replies": [
            {
              "id": "m8mmt8a",
              "author": "LeCrushinator",
              "body": "The Titan wasn\u2019t really intended as a top tier gaming card, it was for CUDA performance.\n\nI remember the 8800 GTS 512 being basically top tier (it and the 8800 Ultra traded blows depending on the game). It was $350 for what is basically the 4080 equivalent today. After inflation that\u2019s around $530. But the 4090 is dual slot so you can double that and consider it similar to SLI 2x from back then, so around $1060.",
              "score": 1,
              "created_utc": 1737587836.0,
              "replies": []
            },
            {
              "id": "m8oiw9t",
              "author": "fcman256",
              "body": "The titan was $1000 in 2013. I had one",
              "score": 1,
              "created_utc": 1737611785.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jjvli",
          "author": "SortOfaTaco",
          "body": "Isn\u2019t this what moores law is or whatever? I doubt we will ever see those type of performance gains per generation ever again",
          "score": 6,
          "created_utc": 1737557144.0,
          "replies": [
            {
              "id": "m8jqmq3",
              "author": "LeCrushinator",
              "body": "It used to be almost 50% per year, now it's not even 50% per generation (over 2 years). And that's honestly fine if it just can't be done, however, what's not fine is the pricing.\n\nIf GPU prices had increased at the same rate as inflation, a 4090 on release should've been around $1000, but it wasn't because Nvidia has no high-end competition. Now the 5090 should be around $1000 and the 4090 could be dropped in price 20-30% to $700-800. The problem is corporate greed, and the fact that some people are willing to pay the insane prices.",
              "score": 10,
              "created_utc": 1737559162.0,
              "replies": [
                {
                  "id": "m8ll4k5",
                  "author": "elton_john_lennon",
                  "body": "> If GPU prices had increased at the same rate as inflation,\n\nTHe way I understand it, scalping during mining craze did play a role in pricing because manufacturers finally saw the limits of what real non-mining people are still willing to pay for video game entertainment, but, R&D still plays role as well. It isn't the same to go from 90nm to 65nm, as it is going from 5nm to 3nm tech and pricewise. \n\nCost per speed increase going from Dacia Sandero to Ford Mustang, isn't the same as going from Ford Mustang to Bugatti Veyron etc.",
                  "score": 2,
                  "created_utc": 1737577189.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8kdvpe",
              "author": "Akrymir",
              "body": "No. Moores Law is about transistor density and it\u2019s been dead for a long time.",
              "score": 6,
              "created_utc": 1737565616.0,
              "replies": []
            },
            {
              "id": "m8k2hci",
              "author": "Chuzzletrump",
              "body": "Moore\u2019s law doesn\u2019t feel fitting for GPUs because at the end of the day, they could see a whole lot better performance with additional VRAM, but they\u2019re afraid theyll make a card too good to replace (see 1080s and 1080tis)",
              "score": 6,
              "created_utc": 1737562482.0,
              "replies": []
            },
            {
              "id": "m8my951",
              "author": "Othelgoth",
              "body": "We actually still are seeing them. It\u2019s just in new tech like attracting, texture compression etc. \n\nWe are near the end of the line for traditional raster me thinks.",
              "score": 1,
              "created_utc": 1737591433.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jq3z9",
          "author": "redbluemmoomin",
          "body": "Moores law is dead. We can't make an atom smaller. Node shrinks are getting more and more expensive and improvement is going to cease soon. 3NM is this year...that suggests two more cycles then nothing. End of the line. Hence the move to AI and not brute force render.",
          "score": 6,
          "created_utc": 1737559011.0,
          "replies": [
            {
              "id": "m8jvci8",
              "author": "andynator1000",
              "body": "\"3nm\" is a marketing term, it has no relation to the size of any physical feature.",
              "score": 8,
              "created_utc": 1737560494.0,
              "replies": [
                {
                  "id": "m8k2axd",
                  "author": "redbluemmoomin",
                  "body": "Right so TSMC don't know what they are talking about....\n\nhttps://www.tsmc.com/english/dedicatedFoundry/technology/logic/l_3nm\n\nit's a node improvement. Whether it's a relative measure or not..Moores law is still broken.",
                  "score": 0,
                  "created_utc": 1737562433.0,
                  "replies": [
                    {
                      "id": "m8ljyv9",
                      "author": "elton_john_lennon",
                      "body": "> Right so TSMC don't know what they are talking about....\n\nDoes TSMC say that \"3nm isn't a marketing term and it has relation to the size of any physical feature.\" ? \n\nYou wrote response as if that is exactly what they do and that it contradicts what is written in comment above, but I don't see anything like that on the page you provided.",
                      "score": 3,
                      "created_utc": 1737576871.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m8jac3k",
      "author": "Gabochuky",
      "body": "So about 35% more performance for 30% more power.\n\nSo its really more like a 5% increase.",
      "score": 35,
      "created_utc": 1737554026.0,
      "replies": [
        {
          "id": "m8jbj7j",
          "author": "steves_evil",
          "body": "Both are on a TSMC 5nm class node (4N, 4NP for ada and Blackwell respectively). Single digit efficiency gains are more or less expected without some major architectural overhaul.",
          "score": 15,
          "created_utc": 1737554435.0,
          "replies": []
        },
        {
          "id": "m8jbccb",
          "author": "killer_srb",
          "body": "And most importantly for 20% more money, so realistically I don't see any generational improvement (as it stands now according to the leaks).",
          "score": 42,
          "created_utc": 1737554369.0,
          "replies": [
            {
              "id": "m8jdv4k",
              "author": "Greyboxer",
              "body": "25% more money. $1600 + $400 is 25% of the 4090 price.",
              "score": 25,
              "created_utc": 1737555224.0,
              "replies": []
            },
            {
              "id": "m8jv8nj",
              "author": "ribbit43",
              "body": "seems like everything was focused on ai frame gen",
              "score": 1,
              "created_utc": 1737560464.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jbbl6",
          "author": "kentonj",
          "body": "By that toilet paper math, my bike is faster than a Lamborghini",
          "score": 76,
          "created_utc": 1737554362.0,
          "replies": [
            {
              "id": "m8jd0ac",
              "author": "jupatoh",
              "body": "And if my grandma had wheels she\u2019d be a bike!",
              "score": 23,
              "created_utc": 1737554938.0,
              "replies": [
                {
                  "id": "m8jjl7h",
                  "author": "juleztb",
                  "body": "Spoken like a true TV cook.",
                  "score": 3,
                  "created_utc": 1737557055.0,
                  "replies": []
                },
                {
                  "id": "m8jnk2z",
                  "author": "Barachiel1976",
                  "body": "\"Now now, Mr Scott.  Young minds, fresh ideas, be tolerant.\"",
                  "score": 3,
                  "created_utc": 1737558259.0,
                  "replies": [
                    {
                      "id": "m8kyz3j",
                      "author": "IolausTelcontar",
                      "body": "Up yur shaft.",
                      "score": 3,
                      "created_utc": 1737571265.0,
                      "replies": []
                    }
                  ]
                }
              ]
            },
            {
              "id": "m8jbr6o",
              "author": "Gabochuky",
              "body": "Thats actually how it works, for a true generstional leap you need to expect that same 35% uplift for the same amount of TDP.",
              "score": 25,
              "created_utc": 1737554512.0,
              "replies": [
                {
                  "id": "m8jh9pc",
                  "author": "kentonj",
                  "body": "No that's what you expect when chip fabrication allows for node sizes to be substantially smaller one generation to the next, which happened with the 40 series for the first time since the 10 series. \n\nExpecting meaningful reductions in the sizes of nodes every generation to accommodate per-wat performance gains is wild. Especially when we're going to have to start measuring by fractions of nanometers soon, if the trend of chip size efficiency even continues. It's not a generational expectation, for example the 20 series and the 30 series.",
                  "score": 4,
                  "created_utc": 1737556327.0,
                  "replies": [
                    {
                      "id": "m8jji03",
                      "author": "Gabochuky",
                      "body": "Yes, that's why I said \"true generational leap\"",
                      "score": 0,
                      "created_utc": 1737557029.0,
                      "replies": [
                        {
                          "id": "m8jo2c3",
                          "author": "kentonj",
                          "body": "Meaning what? If by \"generation\" you don't mean \"generation,\" then I'm afraid I have no idea what your point even is in the first place.",
                          "score": 5,
                          "created_utc": 1737558409.0,
                          "replies": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "id": "m8kvz8u",
                  "author": "Zed_or_AFK",
                  "body": "But that doesn\u2019t matter as long as the previous generation wasn\u2019t able produce 30% performance increase. The new generation did.",
                  "score": 0,
                  "created_utc": 1737570472.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8ke5bt",
              "author": "rooster_butt",
              "body": "except comparing 4090 to 5090 is comparing 2 same model lambos just released a year apart. Not really the same comparison.",
              "score": 2,
              "created_utc": 1737565690.0,
              "replies": []
            },
            {
              "id": "m8jd7j0",
              "author": "MrJohnnyDrama",
              "body": "If I'm going to need more power to get more performance, I might as well overclock my 4090 until it's stable.",
              "score": 3,
              "created_utc": 1737555005.0,
              "replies": [
                {
                  "id": "m8jfh1j",
                  "author": "Nixxuz",
                  "body": "4k series doesn't OC for shit. You'll be pulling a lot more power for very little actual gains.",
                  "score": 4,
                  "created_utc": 1737555749.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8jrohc",
              "author": "FrostyWalrus2",
              "body": "Put enough energy into rotating the chain and, theoretically, while ignoring structural support and other physics of that much power being on a bike frame and chain, it can be.",
              "score": 1,
              "created_utc": 1737559462.0,
              "replies": []
            },
            {
              "id": "m8jde1d",
              "author": "r1khard",
              "body": "Tracking gpu performance is done exactly how they stated at the highest levels of analysis.",
              "score": -1,
              "created_utc": 1737555066.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jjjzk",
          "author": "NoTearsOnlyLeakyEyes",
          "body": "90 series cards have been for ENTHUSIASTS for over a decade. IDK why people have started to pretend that's not the case? The people buying 5090s don't care about performance per watt or performance per dollar. They simply want the most powerful card money can buy, counter to whatever reddit echo chamber says otherwise.",
          "score": 17,
          "created_utc": 1737557045.0,
          "replies": [
            {
              "id": "m8jxxcx",
              "author": "OramaBuffin",
              "body": "Man getting rid of the Titans and rebranding them to xx90s was the best move Nvida ever made. Just infinite amounts of gamers with more money than sense obsessed with the idea of having the \"best\" card suddenly refusing to build with anything less.",
              "score": 3,
              "created_utc": 1737561210.0,
              "replies": [
                {
                  "id": "m8k5krh",
                  "author": "NeWMH",
                  "body": "A part of it is that other than housing and transportation there isn\u2019t much to sink money in to that isn\u2019t arbitrary.  People used to have to sink loads for media - newspaper/magazine subscriptions, books, CDs/tapes/records, VHS/DVDs, games prior to bundles\u2026now there\u2019s relatively cheap digital options for everything and you have to go out of your way to find hobby stuff worth sinking in. As well, travel was more interesting when everything wasn\u2019t connected, after a couple destinations on each continent the pull disappears for many.  Getting a stupid expensive graphics card is a splash compared to all that.",
                  "score": 3,
                  "created_utc": 1737563340.0,
                  "replies": []
                }
              ]
            },
            {
              "id": "m8kw6ae",
              "author": "Zed_or_AFK",
              "body": "Who would say something otherwise?",
              "score": 1,
              "created_utc": 1737570523.0,
              "replies": []
            }
          ]
        },
        {
          "id": "m8jb5aa",
          "author": "splitfinity",
          "body": "Is it 35% more? Or 50ish% more of you set the 100% standard on the 4090?",
          "score": 0,
          "created_utc": 1737554301.0,
          "replies": []
        },
        {
          "id": "m8jbowa",
          "author": "Doyouwantaspoon",
          "body": "Increase in performance to power ratio.. which is irrelevant. It still offers 35% more performance.\n\nNo one ever said \u201cI want to build the most efficient gaming PC\u201d",
          "score": -12,
          "created_utc": 1737554490.0,
          "replies": [
            {
              "id": "m8jcqag",
              "author": "edsonf1",
              "body": "If you\u2019d live in some \u201chotter than hell\u201d place in the world, like me, you would.\n\nBelieve me.",
              "score": 10,
              "created_utc": 1737554844.0,
              "replies": []
            },
            {
              "id": "m8jhoc3",
              "author": "dingo596",
              "body": "I have, I like to play games and I also like not sitting next to a furnace.",
              "score": 6,
              "created_utc": 1737556457.0,
              "replies": []
            },
            {
              "id": "m8jbui7",
              "author": "MultiMarcus",
              "body": "I am sure someone did, and those people probably game on a Mac.",
              "score": 13,
              "created_utc": 1737554543.0,
              "replies": [
                {
                  "id": "m8jc3mh",
                  "author": "CandyCrisis",
                  "body": "As a Mac gaming enthusiast I had a sensible chuckle.",
                  "score": 5,
                  "created_utc": 1737554629.0,
                  "replies": [
                    {
                      "id": "m8jcktm",
                      "author": "MultiMarcus",
                      "body": "Like I love my Mac, but I totally won\u2019t game on it, that being said it has some insane efficiency numbers. Performance per watt is basically unmatched by anything else on the market. Though Apple very clearly aren\u2019t willing to focus on gaming for Mac because they know that they want people to have very high resolution displays and with a system on a chip that just doesn\u2019t have the graphics performance to run most games well those resolutions. I do hope to see Apple develop some sort of DLSS equivalent because they have the money and technical know how to do it so maybe they could use the NPU to basically have a better AI up scaler for gaming and even video content.",
                      "score": 3,
                      "created_utc": 1737554791.0,
                      "replies": [
                        {
                          "id": "m8jde3m",
                          "author": "irrealewunsche",
                          "body": "> Like I love my Mac, but I totally won\u2019t game on it\n\nWhy not? My Mac mini is an absolute perfect gaming machine. It has enough GPU power (M4 Pro) to run everything I throw at it, and with GPTK I've been able to run every game I've tried from my Steam library.",
                          "score": 0,
                          "created_utc": 1737555066.0,
                          "replies": [
                            {
                              "id": "m8jeezb",
                              "author": "MultiMarcus",
                              "body": "Sure, and I game a lot with my dad playing on his M2 Max Mac Studio. It does well enough but I would rather play, as much as I detest windows, on my 4090 powered Windows PC. If Apple and/or GPU manufacturers had a solution to get an external GPU to work with a Mac I would be on board. At least if they made compatibility a bit easier. I know that there are crossover tools but anything with an anti-cheat is going to get mad at that.",
                              "score": 1,
                              "created_utc": 1737555403.0,
                              "replies": []
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8jbrky",
          "author": "NeuroPalooza",
          "body": "Except most of us don't care about power requirements? As long as it can feasibly be cooled the only metric the average consumer cares about is raw power. Preferably raw raster power.",
          "score": -9,
          "created_utc": 1737554515.0,
          "replies": [
            {
              "id": "m8jfymu",
              "author": "WhenPantsAttack",
              "body": "I\u2019d argue a large portion of gamers care about performance per dollar more than raw power and steam system specs would support that.",
              "score": 8,
              "created_utc": 1737555907.0,
              "replies": [
                {
                  "id": "m8jixy3",
                  "author": "kung-fu_hippy",
                  "body": "A large portion of gamers aren\u2019t buying the 5090 though. And don\u2019t have 4090s now. \n\nIf you care about performance per dollar more than raw power, are the top end GPUs ever a good idea?",
                  "score": 5,
                  "created_utc": 1737556856.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m8ljs4m",
      "author": "BOK1TT3N",
      "body": "I hope it doesn't leak out onto my other components!",
      "score": 2,
      "created_utc": 1737576820.0,
      "replies": []
    },
    {
      "id": "m8jhpe7",
      "author": "InevitableFly",
      "body": "I think I\u2019ll stick with my 2080S for another generation.",
      "score": 5,
      "created_utc": 1737556466.0,
      "replies": [
        {
          "id": "m8jm5co",
          "author": "coworker",
          "body": "Upgrade your monitor first",
          "score": 8,
          "created_utc": 1737557833.0,
          "replies": [
            {
              "id": "m8lus8w",
              "author": "Pm_me_your_beyblade",
              "body": "This is what i did. Had a 1070/6700k rig and a Dell standard 1440p monitor. Upgraded to the alienware 4k 240hz a year ago so I would be ready. My gpu is def not doing any justice to the monitor right now though lol",
              "score": 1,
              "created_utc": 1737579772.0,
              "replies": [
                {
                  "id": "m8m2omq",
                  "author": "coworker",
                  "body": "yep that commenter is talking about running games at 60fps and \"high fidelity\" (ie 1080p) like it's 2015 lol",
                  "score": 1,
                  "created_utc": 1737581869.0,
                  "replies": [
                    {
                      "id": "m8mim9c",
                      "author": "Pm_me_your_beyblade",
                      "body": "Yeah lol 2080 isn't that far off a 1070 considering how much progression there has been. And my 1070 is CHUGGING.",
                      "score": 1,
                      "created_utc": 1737586495.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8kih48",
          "author": "PandaBambooccaneer",
          "body": "SO this is my question.  I have a 2070 Super, and I was looking hard to nab a 5000 series before the tariffs go in.  i'm interested in your thought process as for why standing ground is good for this graphics card iteration",
          "score": 2,
          "created_utc": 1737566859.0,
          "replies": [
            {
              "id": "m8kjjif",
              "author": "InevitableFly",
              "body": "Im still pushing 60fps easily on most games I play at a high fidelity. And I havent even started to bothher tweaking performance for my games for draw distance or shadows to squeak out more performance. I dont personally care for 200+ fps and no games on the horizon for me are looking demanding enough to make me want to switch out the card just yet. From my poking around my 2080S is about on par between a 5060 and 5070 minus new feautres I just dont have. My take away is I dont have any compelling games that require more from my system than I currently have. I understand the buy now before tariff point of view but I have done that now for many items throughout life to buy it now before the price goes up and I have nearly regretted it each time. I might pay more waiting but Im not rushing into it and making a more informed/smarter decision.",
              "score": 3,
              "created_utc": 1737567145.0,
              "replies": [
                {
                  "id": "m8ksafz",
                  "author": "PandaBambooccaneer",
                  "body": "All of this is extremely valid.  Thank you for your time and point of view! I'm mostly in the same boat.  I just don't want to be shut out at a later date due to prices",
                  "score": 1,
                  "created_utc": 1737569486.0,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m8jhr6j",
      "author": "Eyelbee",
      "body": "CUDA seems to have maximized its architectural limits, they can't bring more performance without more watts",
      "score": 6,
      "created_utc": 1737556481.0,
      "replies": [
        {
          "id": "m8jll4p",
          "author": "glitchvid",
          "body": "No node bump this time so not exactly surprising, they dumped most of the extra transistors into AI slop hardware it seems.",
          "score": 12,
          "created_utc": 1737557665.0,
          "replies": [
            {
              "id": "m8jt193",
              "author": "Relevant-Doctor187",
              "body": "I always wondered why NVIDIA is leasing AI hardware. Sneaky suspicion that they take last gen AI cards and turn them into GPUs.",
              "score": 2,
              "created_utc": 1737559847.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8jndkp",
      "author": "pragmatic84",
      "body": "gonna stick with my 4080 super until the 6000 series i think",
      "score": 4,
      "created_utc": 1737558205.0,
      "replies": [
        {
          "id": "m8jvel1",
          "author": "Slidje",
          "body": "I can't find one with a waterblock anywhere. My 2070 super is fine so far though, so I'm not desperate",
          "score": 2,
          "created_utc": 1737560510.0,
          "replies": []
        },
        {
          "id": "m8jt7wy",
          "author": "ScarletNerd",
          "body": "Same, or at least until a 5080S or ti drops. 5090 is just completely unneeded for my 1440p gaming needs and it's looking like the 5080 is nothing but a power uplift. Definitely skipping this release year. My 4080S still runs everything absolutely fine.",
          "score": 2,
          "created_utc": 1737559901.0,
          "replies": [
            {
              "id": "m8k8a91",
              "author": "soulsoda",
              "body": "My issue with the 5080 is the 16gb of VRAM. Its so annoying, i don't care that its GDDR7 and \"fast\", its only 16gb, and i have games that won't care thats its GDDR7 and would use more than 16gb. \n\nVRAM isn't even that big of an expense on the card. It should have been 24gb. Hell they know it should have been 24gb, there's box leaks of 5080s saying 24gb on the box. They only did it so they can sell more 5080TIs or Supers with 24gb later. so stupidly greedy.",
              "score": 1,
              "created_utc": 1737564097.0,
              "replies": [
                {
                  "id": "m8kfyvi",
                  "author": "ScarletNerd",
                  "body": "Yeah I get it and there really should be a 24GB option at this point without spending $2000. Me personally though, so far at 1440p though I haven't maxed it out, although I'm usually playing with DLSS on quality so I can use full RT capabilities and have 60 FPS or better. CP2077 maxed out at 1440p with DLSS was completely fine at 16GB, but I can see how at 4K it's not enough.",
                  "score": 1,
                  "created_utc": 1737566182.0,
                  "replies": [
                    {
                      "id": "m8l414r",
                      "author": "soulsoda",
                      "body": "I do play 4k but I also play a lot of games when modded that can stack up vram use quickly (mount and blade, Skyrim etc), and DLSS does not really work well with mods. \n\nThey know what they did. They originally designed it with 24gb, but said hey wait we need that for the 5080TI/super.",
                      "score": 1,
                      "created_utc": 1737572599.0,
                      "replies": []
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "id": "m8jwc5a",
          "author": "183_OnerousResent",
          "body": "Same with my 4090, might be able to skip 6000 series and wait for 7000 even",
          "score": 1,
          "created_utc": 1737560770.0,
          "replies": []
        }
      ]
    },
    {
      "id": "m8jk2mc",
      "author": "sizzlinpapaya",
      "body": "Like, we can\u2019t get but so much graphically better can we? Especially for this significant price.",
      "score": 1,
      "created_utc": 1737557204.0,
      "replies": [
        {
          "id": "m8jkx74",
          "author": "imetators",
          "body": "For 2k one can build a pc which can run many games at 4k mid-high, all hardware included. What is the point of such expensive yet not so much more powerful pc? No idea..",
          "score": 3,
          "created_utc": 1737557463.0,
          "replies": [
            {
              "id": "m8jrk52",
              "author": "Responsible-Win5849",
              "body": "Same as when intel did the extreme edition pentium 4s, or the $1k+ consumer motherboards you can still buy. It lets the company show off and generates some extra money from \"whales\" who can always rationalize away the price to performance if they can be at the top of performance or say they have the best.",
              "score": 3,
              "created_utc": 1737559427.0,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "m8l3cv9",
      "author": "firedrakes",
      "body": "garbarge test",
      "score": 1,
      "created_utc": 1737572419.0,
      "replies": []
    },
    {
      "id": "m8lbuoo",
      "author": "Iamleeboy",
      "body": "I don\u2019t keep up with pc gaming as much as console. Are there any upcoming games that are looking to really push these new cards? \n\nI know cyberpunk was a bit of a poster boy for pushing the previous generations. But is there anything new to really showcase these cards?",
      "score": 1,
      "created_utc": 1737574689.0,
      "replies": []
    },
    {
      "id": "m8lguml",
      "author": "SteveThePurpleCat",
      "body": "I'm going to need to see its 3DMark06 results on default settings before going in for this one.\n\nShow me some *real* performance.",
      "score": 1,
      "created_utc": 1737576018.0,
      "replies": []
    },
    {
      "id": "m8n5l66",
      "author": "Adeno",
      "body": "I wonder how fast it can generate ai images via Stable Diffusion and other such things. I imagine this is already capable of encoding 1 hour videos within just minutes. I'm gonna upgrade from a GTX 660 (which can actually still run Dynasty Warriors Origins surprisingly even without DX12 capabilities).",
      "score": 1,
      "created_utc": 1737593744.0,
      "replies": []
    },
    {
      "id": "m8okdw6",
      "author": "stiinc2",
      "body": "Everyone saying oh it's easy to run 240.You're forgetting about permits as well. Go ahead, run without neutral or proper outlets, and see what your insurance says about your claim when your house burns down.",
      "score": 2,
      "created_utc": 1737612518.0,
      "replies": []
    },
    {
      "id": "m8p4wrt",
      "author": "Maraca_of_Defiance",
      "body": "My 3080 Alienware laptop is a space heater too . I can\u2019t imagine putting anything hotter in my office. \n\nGreat in the winter, terrible in the summer.",
      "score": 1,
      "created_utc": 1737624491.0,
      "replies": []
    },
    {
      "id": "m8jkosm",
      "author": "juleztb",
      "body": "I know that it's not popular, but it's not only raw performance. MFG has to be tested and looked at to really compare the cards. We're down to 4nm already. There isn't that much room for architectural improvements anymore, unless we switch to some completely new technology.        \nSo it's features like MFG and improvement of FG and it's latency in general that will play a huge role for the generations to come.      \nIgnoring these features because \"I only care about raw performance\" won't make any sense soon and is already not very reasonable.",
      "score": 0,
      "created_utc": 1737557393.0,
      "replies": [
        {
          "id": "m8k8ywf",
          "author": "Lamborghini4616",
          "body": "Fake frames and improved upscaling instead of real performance bumps sounds like hell. We need competitive pricing and actual gen on gen improvements, not just bumping up the power",
          "score": 3,
          "created_utc": 1737564284.0,
          "replies": [
            {
              "id": "m8kw8dw",
              "author": "juleztb",
              "body": "Competition doesn't remove physical limitations. With current materials and knowledge there are only 2-4 steps in minimizing structures left. GeForce GPUs are already at 4nm, there is 2nm and prototypes of 1,4nm structures. \nIt is already a problem that electrons jump these structures. This problem only increases with smaller structures. \nSo where do you want big jumps to come from then?\nThe better \"fake frame hell\" gets, the less you'll recognize them. \nMost people don't do even today.",
              "score": 1,
              "created_utc": 1737570539.0,
              "replies": [
                {
                  "id": "m8l38pn",
                  "author": "Lamborghini4616",
                  "body": "So you would rather fake frames instead of actual improvement? You want to pay for that me my guest. If that's the limitation then they should just keep improving the drivers on the cards we have already. The fact is that we will eventually surpass those limitations",
                  "score": -2,
                  "created_utc": 1737572388.0,
                  "replies": [
                    {
                      "id": "m8l6x24",
                      "author": "juleztb",
                      "body": "It's not about what I want.      \nIt's about physics.             \nIt feels like talking to someone denying climate change. You can not discuss with physics trying to reason with it \"well maybe get your shit together and make those electrons stop behaving like they do\".       \n\nFG and DLSS seem like a very good path in avoiding physical limitations by improving the performance with other means. And in contrary to further minimizing transistor sizes, there is much room for improvement. \n\nYes, maybe we will overcome these boundaries. But that cannot be forced.",
                      "score": 2,
                      "created_utc": 1737573374.0,
                      "replies": [
                        {
                          "id": "m8m01up",
                          "author": "agitatedprisoner",
                          "body": "High NA EUV hasn't yet been used on any chip brought to market and ASML has Hyper EUV planned for after that.  There's lots of room left to improve even in further miniaturization.",
                          "score": 1,
                          "created_utc": 1737581165.0,
                          "replies": [
                            {
                              "id": "m8mwv4w",
                              "author": "juleztb",
                              "body": "It's less about the manufacturing machinery and more about the limitations of semiconductor material, because of electrons jumping over structures if they're too small. \nAlso yes, I mentioned the 1,4nm prototypes currently in preproduction.\n\nStructures smaller than what the 1nm processes that are currently under commercial development are only academical at the moment. Silicon reaches its physical limitations as I mentioned. Universities are looking for new materials that might allow even smaller structures. But as far as I know - publicly available - there is nothing specific and promising on the horizon for now. \n\nSo at the current speed we have what? 5? Years until we reach the limit of our current materials. Then lowering the size of structures is over and we either need some new material that no one knows of at the moment or we need other ways to improve the performance. One that is currently used is predicting results before the calculation even starts. There may be others of course.",
                              "score": 1,
                              "created_utc": 1737590998.0,
                              "replies": [
                                {
                                  "id": "m8nn1j2",
                                  "author": "agitatedprisoner",
                                  "body": "Chips advertised as 2nm don't have 2nm features or gate sizes.  The gate pitch on the advertised 2nm chips is actually around 45nm.  Experts say quantum tunneling doesn't get to be a problem until around the 7nm feature size, far as I can tell.  Doesn't that mean chip features might someday be made ~6x as fine?  Wouldn't that mean being able to cram ~36x the transistors on those more advanced chips?  Seems to me that leaves lots of room for improvement.  The end may be near for cramming more transistors into a 2D surface but that's why semiconductor companies are looking to build up and out in 3D.  A 3D chip with actual 7nm feature sizes might be vastly more capable than any 2D chip on market today.",
                                  "score": 1,
                                  "created_utc": 1737599398.0,
                                  "replies": [
                                    {
                                      "id": "m8omb37",
                                      "author": "juleztb",
                                      "body": "That's why I wrote \"the 1nm process\", because that's what it's called. That's not the real size, true. \nThe problem doesn't start at 1nm but at the sizes of the 1nm process.      \nSo no, there isn't much room left. \n\n3D chips are a possibility, yes.      \nBut this comes with a very big caveat. Staying at the same size but going into the 3rd dimension means the same as just making the chip bigger in 2D: it will just need more power.      \nSo a GPU that draws 500W with a 2D chip will draw 1000W if the chip has one additional layer in the 3rd dimension. (Oversimplified, of course).       \nThat also means that the heat that has to be dissipated increases. And with every layer this gets more difficult, because the cooling contact isn't directly on the surface anymore but n layers above.     \nNot saying 3D isn't a thing. It probably will. But it's not the same as miniaturizing the structures, sadly.  By far.",
                                      "score": 1,
                                      "created_utc": 1737613497.0,
                                      "replies": [
                                        {
                                          "id": "m8rsb8k",
                                          "author": "agitatedprisoner",
                                          "body": "The motive to build in 3D given that it'd complicate heat dissipation isn't to pack in more chips but to minimize the distance between parts of whatever chips there might be.  Same reason it's not ideal to build a whole city along just one road.  Build out in 2D and people don't have to travel so far getting to the places they'd want to go.  Build out in 3D and it's even more so.  Maybe building chips in 3D is so hard as to be unfeasible but if people do figure out how to do it economically that'd stand to unlock plenty of room for semiconductor refinement/gains.",
                                          "score": 1,
                                          "created_utc": 1737658513.0,
                                          "replies": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "m8kt8pe",
      "author": "RecoilS14",
      "body": "ITT:  \"Wahh the new card isn't giving me new godlike powers and I'm not getting 2000% increase in fps.  Framegen is bad. AI is bad waaaaaaaah\"\n\nSeriously, you guys need to chill out.  We have been at the end of what hardware itself can do for a long time with diminishing returns and now you're complaining that because the FPS increase is based on software that Nvidia is conning you.",
      "score": 0,
      "created_utc": 1737569742.0,
      "replies": []
    },
    {
      "id": "m8n8eoc",
      "author": "KennKennyKenKen",
      "body": "'leaks out' \ud83e\udd22 weird wording",
      "score": 0,
      "created_utc": 1737594637.0,
      "replies": []
    }
  ]
}