type,id,author,title,score,created_utc,url,num_comments,subreddit,body,parent_id,depth,post_id
post,1irop82,a_Ninja_b0y,"AMD's Frank Azor says no 32 GB RX 9070 XT for you, probably because a 32 GB mid-range GPU didn't make much sense in the first place",595,2025-02-17 17:03:50,https://www.reddit.com/r/gadgets/comments/1irop82/amds_frank_azor_says_no_32_gb_rx_9070_xt_for_you/,114.0,gadgets,,,,
comment,mdawaje,None,,394,2025-02-17 19:46:00,,,,TFW 700 is midrange gifgiphyqZgHBlenHa1zKqy6Zn,,0.0,1irop82
comment,mdbvpc7,Fake_Disciple,,72,2025-02-17 22:32:55,,,,I remember as a kid I use to watch a lot channels where they build pcs back then 700 pc with everything was considered high end now thats just the price of a shitty GPU,mdawaje,1.0,1irop82
comment,mdd7vub,evonebo,,6,2025-02-18 02:59:16,,,,I think either you are not accounting for inflation or youre not remembering correctly,mdbvpc7,2.0,1irop82
comment,mdfhtfq,GhostDan,,8,2025-02-18 14:03:43,,,,In 1995 my first nonused computer cost me about 1200 It would be considered midrange at the time In 2000 my 2nd computer cost me about 500 and it had a Voodoo graphics card it was solidly midrange if not higher with that card Before the early 2000s markups were so high your local neighborhood kids were setting up computer manufacturing companies buying up the parts at OEM and putting them together and getting 23x profits sometimes,mdd7vub,3.0,1irop82
comment,mdd90z0,NorthEagle298,,40,2025-02-18 03:06:06,,,,Let me take you to a time before LED fans before tempered glass cases before SSDs and the system only had to run the Quake Arena demo and Diablo 1 Oh hell yeah we were building 500 PCs in the late 90s which is still 1000 adjusted for inflation,mdd7vub,3.0,1irop82
comment,mddbgjl,evonebo,,3,2025-02-18 03:20:46,,,,I honestly dont remember pcs being 500 Like emachines maybe later when they came out I was building them at a shop in silicon valley in the 90s,mdd90z0,4.0,1irop82
comment,mddd3zm,NorthEagle298,,12,2025-02-18 03:30:48,,,,Prices really started coming down in the late 90searly 00s,mddbgjl,5.0,1irop82
comment,mdk2db9,colin_colout,,-1,2025-02-19 03:53:00,,,,This reads like a confidently incorrect LLM hallucination from a 1 year old account Mr AdjNounNumber,mdd90z0,4.0,1irop82
comment,mdes19m,Fake_Disciple,,6,2025-02-18 10:53:48,,,,This was 10 to 15 years ago not 30,mdd7vub,3.0,1irop82
comment,mdg9kvx,MercenaryOne,,2,2025-02-18 16:27:44,,,,Hes definitely not remembering correctly my first PC was nearly 3000 in components considered high end and that was in 9394 It was before Win95 because I remember waiting in line at CompUSA for a copy P1 75mhz Sound Blaster 16 8MB EDO RAM 1GB HDD and a 4MB Hercules GFX card When I worked retail in 2002 I was astonished we were selling basic PCs that ran circles around my first built PC for nearly 500,mdd7vub,3.0,1irop82
comment,mdglfrj,evonebo,,1,2025-02-18 17:23:27,,,,Lol I dunno if you remember but back then it was a rough choice Do you put cdrom modem or sound card in the build Cant have all three cause on a budget I remember going to frys electronics central before frys every chance I had to look at components,mdg9kvx,4.0,1irop82
comment,mdfio1v,imnotokayandthatso-k,,1,2025-02-18 14:08:45,,,,Back then a dozen eggs was 3,mdbvpc7,2.0,1irop82
comment,mdb0uhb,tartare4562,,36,2025-02-17 20:07:05,,,,the face when when,mdawaje,1.0,1irop82
comment,mdbd8tv,None,,8,2025-02-17 21:05:00,,,,goddammit autocorrect,mdb0uhb,2.0,1irop82
comment,mdcjriz,tubular1845,,4,2025-02-18 00:41:44,,,,That feeling when,mdb0uhb,2.0,1irop82
comment,mdeco77,chunckybydesign,,2,2025-02-18 08:17:32,,,,I know right Like when when and then when,mdb0uhb,2.0,1irop82
comment,mdbf9sc,Eve_newbie,,8,2025-02-17 21:14:28,,,,Is it being listed for that I thought MSRP was close to 5550,mdawaje,1.0,1irop82
comment,mdbu7ad,MiloIsTheBest,,8,2025-02-17 22:25:31,,,,There are no official numbers There have been some listings randomly appear for between 700 and like 900 but they are not official yet and might be placeholders If the cards are 500 or 600 and MSRP stays to conversion in Australia unlike NVIDIAs padded rort MSRP which wasnt even met they might actually come in at below 1000AUD which would be nice being that the 7900XT was about 10001100AUD and this is a 70 that performs similarly hopefully with better RT but no indication it will quite match nvidia 2 years later But I bet they dont want to do that I bet they want to take the piss on pricing,mdbf9sc,2.0,1irop82
comment,mdbwkpd,Eve_newbie,,1,2025-02-17 22:37:18,,,,Plus with the tariff that keep being talked about it makes it really hard to give a MSRP if theres suddenly a 1050 price increase to get it into America,mdbu7ad,3.0,1irop82
comment,mdb3a14,Hattix,,24,2025-02-17 20:18:33,,,,Just correcting for inflation and in GBP because thats what I paid The 250 of a Radeon 9700 Pro king of the hill top of the shop undisputed framerate champion would be 454 today Itd buy me a basic level 7800XT,mdawaje,1.0,1irop82
comment,mda1kt5,CMDR_omnicognate,,111,2025-02-17 17:26:17,,,,The speculation was I think that it would be used for ai stuff rather than for gaming since most ai tasks are incredibly vram heavy,,0.0,1irop82
comment,mdae1kv,Hattix,,42,2025-02-17 18:23:05,,,,It probably will be maybe a Radeon Pro WX9070 or whatever Consumer gaming cards dont need 32 GB at this level of performance,mda1kt5,1.0,1irop82
comment,mdcwryo,Leafy0,,2,2025-02-18 01:54:06,,,,As what level of performance Theyre not out yet With how lame the generational uplift was with the 50 series I wouldnt be surprised if the card and was targeting to go against the 5070 ends up closer to the 5080 on nonrtx workloads,mdae1kv,2.0,1irop82
comment,mdehczs,alidan,,2,2025-02-18 09:05:29,,,,honestly textures do far more for improving graphics than anything else lighting comes in second just because the only methods we get are ray tracing which is garbage but easier to implement or incompetent people trying to optimize older or newer methods for inserting lighting,mdae1kv,2.0,1irop82
comment,mdehjq6,i_mormon_stuff,,2,2025-02-18 09:07:27,,,,Problem is the price of a WX9070 will likely be too high compared to the performance it can offer within a 32GB VRAM budget Would people who do AI prefer a 5090 32GB for 20002500 Or a much slower WX9070 32GB for the same price What AI people want in reality is a cheap card with a lot of VRAM and theyre willing to give up core performance to get the VRAM So a 9070 32GB at 1000 would sell like hot cakes to that crowd Something costing twice as much well then the 5090 is a better buy as its no doubt going to be faster,mdae1kv,2.0,1irop82
comment,mdabupy,daekle,,13,2025-02-17 18:13:12,,,,That was my thought Having a large vram is great for certain models even if they run a little slower Certain models like FLUX a stable diffusion based image generator just wont run on my puny little 6GB card at any speed Need more ram,mda1kt5,1.0,1irop82
comment,mdbbpmu,fliberdygibits,,76,2025-02-17 20:57:56,,,,AI has made me think GPU manufactures are allergic to adding more VRAM,,0.0,1irop82
comment,mdcepbm,mumbler1,,30,2025-02-18 00:13:56,,,,I can see them slapping an AI edition where its literally the same card but more VRAM and upcharge for the extra,mdbbpmu,1.0,1irop82
comment,mdciy5w,irregularjosh,,10,2025-02-18 00:37:16,,,,As someone thats wanting to do a bit of AI at home they might as well be saying No AI for you peasant,mdcepbm,2.0,1irop82
comment,mdcli3e,fliberdygibits,,4,2025-02-18 00:51:15,,,,Yep Give me a GPU with a bunch of RT cores and Vram Skip all the video encodedecode skip the texture pipelines etc But apparently Im stuck with 1216gb of vram unless I want to give up a limb no matter HOW many new GPU generations we get,mdciy5w,3.0,1irop82
comment,mdehmdd,alidan,,1,2025-02-18 09:08:12,,,,arent you able to pool gpus into a single gpu and effectively have a large vram pool natively in windows 10 whatever downside you would have in a game wouldnt be too much of a hurdle in a more prosumerenterprise application though throughput between gpus may be an issue outside of pcie 5,mdcli3e,4.0,1irop82
comment,mdeo8bm,akeean,,4,2025-02-18 10:15:42,,,,nope VRAM needs to be physically close to the compute cores in most of the common use cases Going through PCIe to grab something from a differeot GPUs VRAM would kill performance Even SLI where each GPU takes turns rendering frames or renders only part of the same frame is pretty much dead Joing GPUs nowadays is only server grade stuff for different workloads than gaming even then one monolithic card that puts everything on the same silicon would be faster Its just that you physically cant put all of that in one place still cool it while its working,mdehmdd,5.0,1irop82
comment,mdep549,alidan,,1,2025-02-18 10:25:01,,,,but the thing is a lot of the ai training stuff is at least to my understanding compartmentalized kind of like how raytracing is it effectively scaled linearly with more gpus tosses at the problem and the throughput issue was there in prior generations of pcie due to other bottlenecks its why nvidia had nvlink however that same bottleneck I dont believe is there anymore in pcie5 dont get me wrong its still latency and a performance hit but it should scale more performance for multiple gpus at least far more than an alternative solution if you really needed the extra space,mdeo8bm,6.0,1irop82
comment,mdg1doa,akeean,,2,2025-02-18 15:48:06,,,,Yeah you can work around some issues with more bandwidth and it certainly works for a lot of things otherwise H100 clusters for LLM wouldnt but with memory interlink you always run into physical limits on how fast electrons transmit information that will cause your cores to run dry or require massive caches cache is kind of big on a die and doesnt miniaturize so well with smaller architectures that require a lot of overhead logic to be filled tested and still be discarded if cache misses And then you also get interference and signal integrity issues Every centimeter counts Afaik for raytracing the BVH is a central bottleneck that each GPU in your cluster needs to somehow handle,mdep549,7.0,1irop82
comment,mdldy48,alidan,,1,2025-02-19 10:45:39,,,,im thinking of it more along the lines of any single ray bounce gives data that every other ray bounce can take advantage of in compositing a scene and doesnt need to necessarily be interacted with to do it unless im mistaken in the way ai works it essentially process a data set against other datasets at least my thinking is you could split the data set up in ways that allow the chunk on gpu to be processed then swapped out and put up against another data set without needing to constantly cross reference with the data across 2 gpus that way the data is loaded in in a large chunk and worked with if the data had to constantly go between gpus to get processed that kind of feels like a failure on people who are designing the processing method,mdg1doa,8.0,1irop82
comment,mdh9wfe,fliberdygibits,,1,2025-02-18 19:15:58,,,,You could in the past with NVLink but Nvidia got rid of it,mdehmdd,5.0,1irop82
comment,mdlexwg,alidan,,1,2025-02-19 10:55:05,,,,no windows 10 brought about the ability to pool gpus like this through pcie only sli always required the memory to be mirrored I dont know off other systemscustom solutions but even professional crap that required gpu acceleration still mirrored win 10 at its base feature set had the ability to pool both amd and nvidia cards to use them at the same time granted this was shown off for games and pool the memory for a larger dataset to be loaded onto it the problem was pcie 3 and 4 bandwith was not enough to fully utilize that however 5 kind of does have enough nvlink was just a proprietary way to have a high speed connection thats not based on the pcie interface,mdh9wfe,6.0,1irop82
comment,mdbw7n7,Macabre215,,11,2025-02-17 22:35:28,,,,Thats a big reason why,mdbbpmu,1.0,1irop82
comment,mdceped,arabidkoala,,3,2025-02-18 00:13:57,,,,I wonder if were ever going to start seeing RAM sockets in them Seems like it could be a more costeffective way of making GPUs without having to predict which use cases will require what configurations when making decisions about what fixed designs to manufacture Then again waste and scarcity are critical to high prices so I guess I can see why this would never happen,mdbbpmu,1.0,1irop82
comment,mdehtvv,alidan,,1,2025-02-18 09:10:19,,,,cant I have asked this before and effectively the only reason the ram in a gpu can run so fast is its proximity to the die take a look at laptops with soldered and socked ram the extra length of wire in causes a 40 throughput decrease dell has a solution for it but I dont think anyone adopted the new standard yet,mdceped,2.0,1irop82
comment,mddsle7,chizburger999,,1,2025-02-18 05:17:33,,,,Are AMD GPUs even good at AI related tasks,mdbbpmu,1.0,1irop82
comment,mddynqt,-Badger3-,,4,2025-02-18 06:06:26,,,,Theyre generally not as good as Nvidia cards but theyre viable if youre dicking around with homelab stuff,mddsle7,2.0,1irop82
comment,mddyf7s,fliberdygibits,,1,2025-02-18 06:04:26,,,,My 7800xt does pretty good I was more referring to GPU makers in general,mddsle7,2.0,1irop82
comment,mdefkrk,systemBuilder22,,7,2025-02-18 08:47:10,,,,Cistomers will go to the store with 1000 saved and will tell the retailer Id like a 5080 please and the retailer will say WE ARE ALL SOLD OUT AND THERE IS A 4 MONTH WAITING LIST BUT I HAVE THESE FANCY LOOKING 5070TI MODELS ON SALE FOR 950 WHATDOYA THINK And Jensen gets a new jacket,,0.0,1irop82
comment,mda0m59,Eokokok,,13,2025-02-17 17:21:51,,,,And Reddit kids wept,,0.0,1irop82
comment,mda774a,cagriuluc,,3,2025-02-17 17:52:02,,,,In just a couple more years 32 GB vram will be able to get you so much ai I am not sure whether it is a good move for now though,,0.0,1irop82
comment,mdbm3qw,paradoxbound,,1,2025-02-17 21:46:29,,,,Possibly in future you could see 32GB or Even 64GB cards With compute being split between traditional graphics and NPUs There will be some interesting games if that happens,mda774a,1.0,1irop82
comment,mdnm5wm,Kajega,,2,2025-02-19 18:15:02,,,,We have 32GB cards as of last month,mdbm3qw,2.0,1irop82
comment,mdnucr9,paradoxbound,,1,2025-02-19 18:51:32,,,,Sorry out of the loop a little with graphics cards I simply buy the best every 5 years or so I am even further behind this cycle as I spend money on fixing up an old RV with Starlink and bunch of solar batteries and networking My card is an ancient 1080 Wont make much difference to my next build which is a AMD 9800x3D paired with a 5090 in a 10 litre case Perfect for the RV that I am full timing in for much of the year A 32GB card sounds cool though I could pop it in a box in the house and access it remotely for au art and LLLMs I would like to see benchmarks again Nvidia and price,mdnm5wm,3.0,1irop82
comment,mda7ufy,Diciestaking,,9,2025-02-17 17:54:58,,,,What is even the point in 32gb in the first place I cant think of almost any game that would get close to that If you are using it for design reasons then thats another story,,0.0,1irop82
comment,mda9rc3,YourNightmar31,,58,2025-02-17 18:03:41,,,,AMD would make stacks selling these to AI enthusiasts and hobbyists,mda7ufy,1.0,1irop82
comment,mdab621,law_dweeb,,11,2025-02-17 18:10:06,,,,Doesnt the AI software need CUDA,mda9rc3,2.0,1irop82
comment,mdabxoz,echae,,25,2025-02-17 18:13:35,,,,Fair question AMD has a CUDA alternative called ROCm that is fully opensource,mdab621,3.0,1irop82
comment,mdavn5r,QuickQuirk,,16,2025-02-17 19:43:00,,,,Its a bit of a pain to get running but I got the lowly 780m running it with 16GB dedicated vram on a large LLM was funny seeing it actually work albiet somewhat slow,mdabxoz,4.0,1irop82
comment,mdb31sm,MmmmMorphine,,3,2025-02-17 20:17:29,,,,Been hearing different opinions on that especially with the worst case scenario of mixing nvidia and amd cards Supposedly llamacpp and many engines can handle it relatively natively without much set up Though I personally dont know Think youre right the performance is worse though not a huge amount but certainly not in line with what the hardware should be able to do,mdavn5r,5.0,1irop82
comment,mdbmmfr,QuickQuirk,,1,2025-02-17 21:48:59,,,,In this case the performance was worse because it was the integrated 780m GPU on the miniPC Im running as a server It was actually quite impressive given that it was a miniPC running a 13GB model But just getting ROCm to even recognise the GPU took some command line magic I found somewhere ROPCm seems to work on most of the AMD GPUs but they only officially support a subset Its definitely not as easy and simple as the nVidia setup and even that is a bit clunky,mdb31sm,6.0,1irop82
comment,mdcc4mj,Sporebattyl,,1,2025-02-17 23:59:51,,,,Can you point me to a guide how to do this I have a mini with a 780m and Ive been looking to get into local LLMs How slow is it,mdbmmfr,7.0,1irop82
comment,mdfg6j7,danielv123,,1,2025-02-18 13:54:03,,,,Is it significantly faster to run it on the 780m vs just the CPU directly,mdbmmfr,7.0,1irop82
comment,mdhbzwq,QuickQuirk,,1,2025-02-18 19:25:36,,,,It depended on the task The difference wasnt orders of magnitude but it was improved I cant remember by how much I was mostly just doing it to play rather than for serious work Should have written down my results Its a weak GPU but it still represents a collosal amount of compute compared to the CPU,mdfg6j7,8.0,1irop82
comment,mdhxphd,danielv123,,1,2025-02-18 21:04:37,,,,Yeah but usually LLMs are memory bandwidth bound and I assumed that as long as you use system memory its pretty similar in bandwidth,mdhbzwq,9.0,1irop82
comment,mdbugda,nooneisback,,4,2025-02-17 22:26:45,,,,Which just boils down to the same issue as CUDA vs OpenCL Just because something is open source doesnt mean it will be more popular CUDA can be set up by a lobotomite Go to hugging face pick a model feed it content you definitely own and voila We still dont even have PyTorch for ROCm on Windows let alone more than a handful of models that support it CUDA is so simple that I know physics professors that use it on a daily basis but cant share their screen on Zoom meetings,mdabxoz,4.0,1irop82
comment,mdabuc3,YouDoNotKnowMeSir,,12,2025-02-17 18:13:09,,,,CUDA is the most supported in many applications for AI CAD etc We are seeing more support for AMD and there are some open source libraries to help with this compatibility as well That being said it isnt perfect and probably wont be for another couple years But we are moving in the right direction,mdab621,3.0,1irop82
comment,mdfm6vb,tastyratz,,2,2025-02-18 14:28:47,,,,I know Rocm and zluda exists but I think youre right I have yet to actually get metastable running on a 5070 or 6080 Alternatives all fall apart for me too,mdabuc3,4.0,1irop82
comment,mdhhgic,YouDoNotKnowMeSir,,1,2025-02-18 19:50:38,,,,Yeah but hey Its good that theres finally competition and demand for it Things will change somewhat quick,mdfm6vb,5.0,1irop82
comment,mdcgwjf,Blue-Thunder,,2,2025-02-18 00:26:01,,,,It would create great incentive to turn that around,mdab621,3.0,1irop82
comment,mdabej3,kazuviking,,-6,2025-02-17 18:11:10,,,,Only deepseek would run good as anything else is optimized for CUDA,mda9rc3,2.0,1irop82
comment,mde3uvg,anonymousbopper767,,0,2025-02-18 06:52:13,,,,Nah Same shit 10 years ago when every kid was suddenly a twitch tuber pro and needed 32 core cpus No one is really doing anything that needs vram Just dont want to admit they see a bigger number and think its better Now go back to the 8GB you only use 6GB from,mda9rc3,2.0,1irop82
comment,mdedsha,inagy,,1,2025-02-18 08:28:58,,,,If you play 4 year old titles on a 1080p monitor then what you say is true 32 core CPUs made sense for streaming because you can dedicate a set of cores for the game and another set for the video encoding,mde3uvg,3.0,1irop82
comment,mdegqzy,bearybrown,,1,2025-02-18 08:59:12,,,,Most logical setup was offload video encoding to GPU using NVENC or AMD equivalent,mdedsha,4.0,1irop82
comment,mdehbot,inagy,,1,2025-02-18 09:05:06,,,,Afaik the general consensus back then in the Pascal era was that x264 fast was still better image quality wise than what NVENC could do I think this changed with the new encoder introduced in Turing,mdegqzy,5.0,1irop82
comment,mdei1c5,bearybrown,,1,2025-02-18 09:12:29,,,,Yes that is correct but if youre start up streamer and i31632gb ram with 1070 is more than enough for pre 20182020 games and still good enough for esports title,mdehbot,6.0,1irop82
comment,mdb323n,nicman24,,6,2025-02-17 20:17:31,,,,ai tiddies Yes you can and should judge me,mda7ufy,1.0,1irop82
comment,mdc1tqz,herroh7,,3,2025-02-17 23:03:54,,,,Could probably find a way with Skyrim mods,mda7ufy,1.0,1irop82
comment,mdad4sz,CrankoWanko,,1,2025-02-17 18:18:58,,,,Also 3D rendering It would still be a lot but it can be useful for certain things lots of big textures certain simulations etc,mda7ufy,1.0,1irop82
comment,mdef97v,systemBuilder22,,1,2025-02-18 08:43:54,,,,GTA V has a memory requirements predictor When i max everything out 4K with raytracing it says 25GB,mda7ufy,1.0,1irop82
comment,mdap0lu,Arctiiq,,1,2025-02-17 19:12:36,,,,I havent found a game that uses up all 23 gb in the xtx yet,mda7ufy,1.0,1irop82
comment,mdanetn,Oober3,,-10,2025-02-17 19:05:17,,,,It doesnt make sense It was just AMD subreddit copium a nice escapade from their usual nvidia bad i definitely dont regret my AMD card guyz seriously into please tell me I made the right choice buying a 7900xtx posts that make up like 90 of the sub,mda7ufy,1.0,1irop82
comment,mdef1bm,systemBuilder22,,2,2025-02-18 08:41:43,,,,NVidia 5070 Ti is 900 Nvidia 5080 is 1200 I No longer think the 9070xt is 600 Charging 23rds of those prices for equal perf leaves money ON THE TABLE I Now think best case the 9070xt is 700 NVidia price hikes and performance are just TOO DISAPPOINTING AMD only has to be A LITTLE DISAPPOINTING and they will clean up,,0.0,1irop82
comment,mdeipev,alidan,,1,2025-02-18 09:19:22,,,,it isnt even close to equal where it matters for nvidia ai and their extras nvidia nvenc dlss and other crap they offer adds more than enough value to the card to make up for its cost if amd is anywhere close to nvidia if amd makes their own ai gpu specific upscaling gg amd is forever dead because now you get to choose between the shttier card or the better card where as amd always had raw performance usually at better values than nvidia if you remove that and play in the area that nvidia is kicking damn near everyones ass in what value do you add other than making nvidia cards maybe a few dollars cheaper and before anyone says they can get better amd and nvidia have had video encode and decode for about as long as eachother and amd isnt even fucking close to the same quality I have a 7900xt I got it because it was a hell of a deal when I got it and I was on a 1060 amd cant even make a competitive video encoderdecoder something that would make them a must have for streamers or people who want to try streaming effectively a marketing segment that they could have had advertise their gpus but no they just cant what would make you think that them chasing nvidia would do anything else then be nvidias lesser,mdef1bm,1.0,1irop82
comment,mde6y5w,Den710nuggets,,1,2025-02-18 07:20:58,,,,Is frank azor not a car accident attorney,,0.0,1irop82
comment,mdjr1gz,mrblaze1357,,1,2025-02-19 02:45:07,,,,Everyone kept saying that they cant wait to see this on the shelves But Im just sitting here like if anything thats going to be a professional GPU in marketed as like a W9070 Youd only see it in like OEM builds similar to the Quadro series,,0.0,1irop82
comment,mdka076,oldmanjenkins51,,1,2025-02-19 04:43:25,,,,Im tired,,0.0,1irop82
comment,mdbbrli,No_Camel7011,,1,2025-02-17 20:58:11,,,,You dont say,,0.0,1irop82
comment,mda9gmp,MinimumArmadillo2394,,-7,2025-02-17 18:02:18,,,,It kinda doesnt Unless youre doing heavy ML stuff you arent going to even use 16GB in most games at max settings in 4k If you are doing ML stuff youre likely buying whoever GPU has the most memory anyway regardless of cost Edit you guys are completely missing the point Most gamers play in 1080p Most gamers only care about a reachable 60 fps Most gpus can hit that Anyone who wants 4k ultra settings with max ray tracing VR and DLSS are not buying a mid range gpu lmao Hop off my dick about what about this game When talking about whether or not 16 GB of VRAM is enough Your extreme outliars dont even matter when discussing most games,,0.0,1irop82
comment,mdak6mn,Fredasa,,11,2025-02-17 18:50:40,,,,Yeah thats certainly true for most games But the important red letter games tend also to be the ones that 1 have high VRAM demands by default and 2 are a modders paradiseand the most popular mods for such games tend to be the ones that improve texture detail When people express concerns over VRAM limits they really arent thinking about most games Theyre thinking about _those_ games The important ones,mda9gmp,1.0,1irop82
comment,mdalbbh,MinimumArmadillo2394,,-8,2025-02-17 18:55:46,,,,What games are important here Even skyrim with a huge texture overhaul in 4k with 100 mods didnt cap over 12 GB of VRAM for me Was one of the first things I tried The processing power was too low on my 1080 to run some of the visual overhauls but even my 3090 ran into processing bottlenecks with some of the mods The only things Ive seen use anywhere close to the 24GB my 3090 FTW3 has was an ML project I worked on for a few days for image generation,mdak6mn,2.0,1irop82
comment,mdaven8,Fredasa,,10,2025-02-17 19:41:56,,,,What games are important here _Cyberpunk 2077_ ca 2020 can almost saturate 16GB without a single damn mod installed While you cant yet point to another game of its Bethesdalike scope since its release you sure wont be futureproofing your PC if your brand new GPU has only 16GB,mdalbbh,3.0,1irop82
comment,mdax4f9,MinimumArmadillo2394,,-3,2025-02-17 19:49:51,,,,Can it Mine ran less than 8GB on 1440p on highest settings with a 3090 I even the official nvidia guide for the big new update shows you only need 8 unless you put raytracing on its highest setting which IMO added very little to the game,mdaven8,4.0,1irop82
comment,mdayxnb,Fredasa,,8,2025-02-17 19:58:12,,,,Can it Of course it can _Enabling DLSS 3 Frame Generation at 4K on top of max settings with RT brings the VRAM usage to a stunning 18 GB which means you better have a RTX 4090 This is without any upscaling though_ Not even some kind of unique scenario either I personally dont settle for anything less than 4K60 and havent since like 2019 and if I turned RT on I would definitely hit the cap,mdax4f9,5.0,1irop82
comment,mdb4vxv,Cry_Wolff,,2,2025-02-17 20:26:09,,,,How many people targeting 4K and RT will buy a mid range GPU,mdayxnb,6.0,1irop82
comment,mdb14s0,MinimumArmadillo2394,,-4,2025-02-17 20:08:27,,,,Why do you need a 4090 A 3080 will do just fine here The point is most people dont need or want to play at the highest of high settings and having all the VRAM for a mid level gaming system wont help anyone Mid level gamers dont care about ray tracing or 4k or anything like that Most mid level gamers just want mid to high settings at 1080p You dont buy a mid level card if youre wanting 60fps at 4k with max settings a ray tracing with dlss,mdayxnb,6.0,1irop82
comment,mdb8pzp,Fredasa,,2,2025-02-17 20:44:14,,,,Why do you need a 4090 A 3080 will do just fine here Speaking as a 3080 owner no it really wont _Cyberpunk 2077_ in 4K DLSS Quality on a 3080 hits the cap with almost complete reliability when I open the map That literally dictates how I play the game The game didnt do this in its 2020 launch iteration I have to say Thats with every other app on the PC closed and every scrap of VRAM I can spare devoted to the game Mid level gamers dont care about ray tracing or 4k or anything like that Were having a conversation about 16GB in most games at max settings in 4k per OP a few parents up,mdb14s0,7.0,1irop82
comment,mdbsp5x,MinimumArmadillo2394,,0,2025-02-17 22:18:07,,,,Were having a conversation about 16GB in most games at max settings in 4k per OP a few parents up I am the OP And yes that statement is still true Apart from one setting with DLSS and ultra extreme raytracing or whatever it can still run cyberpunk at ultra settings at 60 fps Most games is true Even still this is a mid level GPU Cyberpunk with ray tracing and the graphics on the update are clearly an outliar Acting like it cant play most games at 4k 60fps because it cant run ray tracing something most amd gpus struggle with anyway is fascious at best and outright misinformation at worst,mdb8pzp,8.0,1irop82
comment,mdawidj,alexanderpas,,5,2025-02-17 19:47:01,,,,Even skyrim with a huge texture overhaul in 4k with 100 mods didnt cap over 12 GB of VRAM for me Skyrim is over 10 years old Modern games have more than twice the VRAM usage compared to games from 10 years ago,mdalbbh,3.0,1irop82
comment,mdaxedh,MinimumArmadillo2394,,4,2025-02-17 19:51:07,,,,The mods is the point lol Those things are huge and have absolutely massive 4k textures constantly in vram Have you used them before Just one vfx overhaul was able to cripple my 1080 from 200 fps to less than 30 due to VRAM requirements,mdawidj,4.0,1irop82
comment,mddmoj9,FarSolar,,1,2025-02-18 04:34:04,,,,The mods have definitely scaled with the release of more powerful GPUs I remember running tons of lighting mods and HD texture replacers on my old Skyrim install and they ran on my 970s 35ish GB of VRAM without too much trouble,mdaxedh,5.0,1irop82
comment,mdbfhsh,dsmiles,,2,2025-02-17 21:15:31,,,,Even skyrim with a huge texture overhaul in 4k with 100 mods didnt cap over 12 GB of VRAM for me It would in VR There are several modpacks in VR that I cannot play with a 3080 12gb In fact the modpack I want to use Mad Gods Overhaul cannot hit 90fps best VR framerate for a Quest 23 with even a 4090,mdalbbh,3.0,1irop82
comment,mdbrubi,MinimumArmadillo2394,,-2,2025-02-17 22:13:56,,,,Most people arent playing in VR lmao People with mid range GPUs are not playing in VR either You expect people to buy a 1000 headset and a 600 gpu No lol,mdbfhsh,4.0,1irop82
comment,mdc907j,TanmanG,,1,2025-02-17 23:42:40,,,,As a student whos working with ML stuff I think I can speak on behalf of a lot of people who would very much would like to have access to greater amounts of VRAM locally without having to rely on IaaS or slow unstable techniques that repurpose RAM Ideally without breaking the bank on cards that cost more than a motorcycle or used car,mda9gmp,1.0,1irop82
comment,mdcap24,MinimumArmadillo2394,,-1,2025-02-17 23:52:02,,,,Yes I also have done quite a bit of ML stuff I have 3090s on a rig doing ML stuff right now I underclocked my gpu because ML stuff uses less processing power and more VRAM than most things Each one was only 700 for 24 gigs of VRAM which was a great deal Unless youre doing ML stuff a shit ton of RAM wont do you any good as a gamer And anyone doing ML stuff isnt going to buy a mid tier card They will buy whatever has the most VRAM most of the time regardless of price as generally a company would pay for it anyway If a company wont pay for it there is no reason to go AMD at this point because 3090s are 700 for a refurbished FE at microcenter Anyone making money doing ML stuff is buying beefier cards and anyone not making money is buying 3090s wherever they can get them for cheap,mdc907j,2.0,1irop82
comment,mdcikdu,Xendrus,,0,2025-02-18 00:35:10,,,,a reachable 60 fps was the standard maybe 10 years ago Id say a good amount of people are now aware how much better 120 looks and feels,mda9gmp,1.0,1irop82
comment,mdcj8cw,MinimumArmadillo2394,,1,2025-02-18 00:38:48,,,,Most people cant afford a monitor that does higher refresh rates or simply dont care,mdcikdu,2.0,1irop82
comment,mdcjo4h,Xendrus,,-1,2025-02-18 00:41:12,,,,Maybe 10 years ago 120 is incredibly affordable now and anyone who seesuses 120120 for even 1 second instantly see how amazing it is anyone not using it just isnt aware of how awful their experience actually is in comparison or theyre literally 11 and cant afford a 150 monitor ALSO even if you have a 60hz monitor getting 120fps on it will still feel better than 60 because of frame pacing so still good,mdcj8cw,3.0,1irop82
comment,mdcqu1u,MinimumArmadillo2394,,3,2025-02-18 01:20:52,,,,I chose a 4k monitor 4k 120 fps monitors with gsync are expensive Thats what I meant when I said most people cant afford them Adding gsync on a monitor now a days practically 2xs the price Im barely able to find a 4k 60 frame monitor thats 27 inches for less than 200 lol Edit Just checked pcpartpicker Cheapest monitor thats 4k 2628 inches GSync compatible and has a 144 refresh rate is 400 There are a total of 8 monitors with the average median price being 558 480 So yeah its not just 11 year olds who dont have 150 Its a lot of people who dont have 400 when you can go get a 1080p 27 inch monitor that has 4 star reviews for 120 Most dont care enough and it doesnt matter to them when playing cyberpunk that they have 60 or 120 FPS It matters to them that they can see the world in more detail,mdcjo4h,4.0,1irop82
comment,md9y5ls,dan_Qs,,-28,2025-02-17 17:10:16,,,,But my future proofing I cant use ultra max 2 texture settings on my mid range grafix card in 3 years any more 111,,0.0,1irop82
comment,mdajg13,1leggeddog,,-1,2025-02-17 18:47:21,,,,Someone is going to make on and put up a video onYoutube,,0.0,1irop82
comment,mda4k7b,Practical_Orchid_568,,-13,2025-02-17 17:40:02,,,,I read Anne frank,,0.0,1irop82
comment,mdddshx,Vandorol,,-6,2025-02-18 03:35:03,,,,Why do you need 32GB My 5080 shares memory with the system so its like having 32 Games seem to run fine Indiana Jones maxed out runsnatb130 fps,,0.0,1irop82
