type,id,author,title,score,created_utc,url,num_comments,subreddit,body,parent_id,depth,post_id
post,1lad3we,chrisdh79,AMD deploys its first Ultra Ethernet ready network card â€” Pensando Pollara provides up to 400 Gbps performance | Enabling zettascale AMD-based AI cluster.,640,2025-06-13 11:05:12,https://www.reddit.com/r/gadgets/comments/1lad3we/amd_deploys_its_first_ultra_ethernet_ready/,66.0,gadgets,,,,
comment,mxknx0p,synthdrunk,,53,2025-06-13 14:59:07,,,,Been out of HPC for a while is Ethernet really the interconnect these days Thats wild to me,,0.0,1lad3we
comment,mxkyv5m,WolpertingerRumo,,44,2025-06-13 15:50:26,,,,Yes Were up to cat 82 but in essence its still the same There is fibre but Copper is still standard,mxknx0p,1.0,1lad3we
comment,mxm3mf5,synthdrunk,,9,2025-06-13 19:04:06,,,,Whats done about the latency,mxkyv5m,2.0,1lad3we
comment,mxo1ijy,CosmicCreeperz,,14,2025-06-14 01:25:02,,,,I think on the NIC RDMA remote DMA basically zero copy where the data goes directly from the wire into application memory with no OS or CPU involvement is the biggest optimization and on switches cutthrough switching ie the switch starts forwarding the frame before it has received the whole thing But Im sure there are tons of other optimizations,mxm3mf5,3.0,1lad3we
comment,mxo6wa7,lunar_bear,,11,2025-06-14 01:56:40,,,,I dont think its cutthrough But the latency is reduced by replacing TCP with UDP The RDMA sits atop UDP packets But it is still lossless delivery because the switches are essentially doing a kind of QOS to ensure the UDP delivery And there are advanced congestion control algorithms at play Read about stuff like PFC and ECN,mxo1ijy,4.0,1lad3we
comment,mxoymgt,CosmicCreeperz,,3,2025-06-14 05:04:46,,,,Yeah cutthrough is for reducing switch latency not for this NIC Its important for for switches between the hosts And sure RoCEv2 is over UDP but the main point is the NIC can transfer data directly to app RAM in these cases even directly to GPU RAM via PCIe without the CPU being involved,mxo6wa7,5.0,1lad3we
comment,mxozi9j,lunar_bear,,4,2025-06-14 05:12:09,,,,Yeah I understand RDMA RDMA isnt new What is relatively novel is moving that RDMA off of a pointtopoint network like Infiniband and putting it on a packet switched network like Ethernet All things being equal that Infiniband is going to be faster just due to less protocol overheador you knowheaders in the frame Ethernet also isnt new So with Ultra Ethernet and to a lesser extent RoCEv2 the question becomes WTF are they doing to the Ethernet frame and to congestion control and other mitigations to make it suitably fast and low latency for HPC And beyond thatat what point do we just say its good enough because its 40 cheaper than Infiniband,mxoymgt,6.0,1lad3we
comment,mxrzycm,lunar_bear,,1,2025-06-14 18:00:46,,,,cutthrough is largely for fibre channel storage switches High speed Ethernet switches are storeandforward,mxoymgt,6.0,1lad3we
comment,mxxrxgc,CosmicCreeperz,,2,2025-06-15 17:12:40,,,,Its standard in fiber channel yeah but the whole point of why its interesting here is its now being used more in HS Ethernet switching to reduce latency I was answering commenters question on that It was actually originally invented for and used in the first Ethernet switches its just more complicated and expensive to implement and not really usable with mixed rate networks etc where it may need to buffer Definitely a resurgence with more recent ultra HS Ethernet though thats the point,mxrzycm,7.0,1lad3we
comment,mxxs9l9,lunar_bear,,1,2025-06-15 17:14:23,,,,Well my point is I have several Nvidia SN5600 800GbE switches their fastest Ethernet switch and it is storeandforward,mxxrxgc,8.0,1lad3we
comment,mxxwrvg,CosmicCreeperz,,2,2025-06-15 17:36:58,,,,It certainly supports a cut through mode even if you arent using it,mxxs9l9,9.0,1lad3we
comment,mxxy79f,lunar_bear,,1,2025-06-15 17:44:08,,,,I mean you may be right but Im not seeing how its applicable to this convo Im running RoCEv2 on it followed all the guides even had the setup evald by Nvidia Theres nothing involving cutthrough Not saying its impossible or that it wont somehow be incorporated in Ultra Ethernet As for the real world today Im already using the fastest Ethernet products that are generally available and they are all just using storeandforward Thats why the depth and speed of packet buffers is such a big deal,mxxwrvg,10.0,1lad3we
comment,mxz5dxb,CosmicCreeperz,,1,2025-06-15 21:27:34,,,,Its applicable because the original commenter asked what technologies are being used these days with HS Ethernet to reduce latency and cut through in switches is a significant technique being used when latency is a priority Its just a fact your individual experience is what it is but it doesnt change that Youre the one who jumped in to my general answer to that question with your own anecdotes Convo wasnt originally about you And from NVIDIAs OWN WHITE PAPER on them NVIDIA Spectrum switches operate in a cutthrough forwarding mode by default which offers lower latency compared to storeandforward switching Cutthrough switching forwards packets as soon as the destination MAC address is read minimizing delay but it can lead to forwarding corrupted packets if errors are present NVIDIA Spectrum switches are designed to handle this by having large shared buffers that can accommodate traffic bursts and minimize packet loss Also a brief post and config guide on their support portal Guess maybe you dont actually know everything about it,mxxy79f,11.0,1lad3we
comment,mxz6bvk,lunar_bear,,1,2025-06-15 21:32:47,,,,oh come now I never said I know everything about it Just that I use these daily I configure them myself and cutthrough hasnt come up at any time in my experience oh well my feelings arent hurt,mxz5dxb,12.0,1lad3we
comment,mxz797g,CosmicCreeperz,,1,2025-06-15 21:37:59,,,,Ok sure not meaning to hurt anyoness feelings and Im sure you are an expert in this field overall but I just thought it was pretty obvious why it was applicable to this convo that was not actually a one involving you originally,mxz6bvk,13.0,1lad3we
comment,mxz7gvf,lunar_bear,,1,2025-06-15 21:39:10,,,,lets be friends the networking world has room for us both sorry if I offended you,mxz797g,14.0,1lad3we
comment,mxpzntk,Doppelkammertoaster,,0,2025-06-14 10:58:09,,,,You seem to know this shit Does it still make a difference if one uses wifi or ethernet cable from the modem to the machine these days,mxo1ijy,4.0,1lad3we
comment,mxr5rrb,CosmicCreeperz,,7,2025-06-14 15:25:53,,,,Well we are talking 2000 just for these NICs and like 20k for a switch this speed Vastly different from consumer networking At home Ethernet will always be lower latency and have no chance at interference from other WiFi networks or your microwave etc But honestly for many people WiFi can have higher total throughput I just upgraded my home network I actually have 10Gb switches now but currently only 1 computer that can do 10Gbps Ethernet and a laptop that can do 25G with a USB Ethernet adapter but also a bit under 2Gbps with WiFi But my PHONE now gets 16Gbps with WiFi And those are WiFi 6 6e7 devices would be even faster IMO for most people the only reason to have multi Gig Ethernet is to connect WiFi 6e7 mesh APs together in a larger home since if you want to get multi Gig WiFi speeds the range is limited,mxpzntk,5.0,1lad3we
comment,mxrf7zn,Doppelkammertoaster,,2,2025-06-14 16:14:39,,,,Thank you,mxr5rrb,6.0,1lad3we
comment,mxrznef,lunar_bear,,1,2025-06-14 17:59:11,,,,Nvidia ConnectX7 NIC is only around 1750,mxr5rrb,6.0,1lad3we
comment,mxpzkc2,ioncloud9,,3,2025-06-14 10:57:18,,,,Ive never pulled anything higher than Cat6a There is little demand to getting more than 10G Ethernet to the workstation over copper Most things that need PoE can do fine with a slower connection High end WiFi APs with lots of radios usually have dual ports or one SFP port for a fiber connection and a poe port for management and power,mxkyv5m,2.0,1lad3we
comment,mxq5d64,WolpertingerRumo,,2,2025-06-14 11:44:21,,,,I am currently installing an 82 between two switches and between the switches and servers Thats the only reason to do it Thats why 82 also is optimised for short ranges You dont need more,mxpzkc2,3.0,1lad3we
comment,mxs08i7,lunar_bear,,1,2025-06-14 18:02:15,,,,These are HPCgrade or Telcograde datacenter networks Its literally for supercomputers And not much else,mxpzkc2,3.0,1lad3we
comment,mxs0sc2,ioncloud9,,1,2025-06-14 18:05:09,,,,Yeah thats what I suspected There are few use cases outside of that Even in data centers youd think fiber would be the preferred option,mxs08i7,4.0,1lad3we
comment,mxs1dy1,lunar_bear,,1,2025-06-14 18:08:19,,,,Dude this can use fiber Its going to use fiber Thats just the Layer 1 medium Whether its Ethernet or Infiniband both can use either fiber or copper but as switch density increases fiber becomes a necessity the gauge of copper becomes too thick to manage the cabling in such a way that it doesnt trap heat and block airflow,mxs0sc2,5.0,1lad3we
comment,mxq2cc0,mark-haus,,3,2025-06-14 11:20:39,,,,Its incredible to me how much longevity the Ethernet standard has Obviously its evolved a lot even in the medium used but the same basic concept holds,mxkyv5m,2.0,1lad3we
comment,mxm7ocw,gramathy,,9,2025-06-13 19:23:55,,,,Notably Ethernet is just the framinglayer 2 process You can transmit Ethernet over any medium with a variety of encoding schemes and connections like this are not twisted pair cable they are generally either fiber using either multiple strands or multiple wavelengths in parallel or directly attached shielded copper common for inrack data center connections from 10gbps and higher that effectively just connect the data lines on one card to the data lines on the other with no other intermediary,mxknx0p,1.0,1lad3we
comment,mxnckzi,chrisni66,,5,2025-06-13 22:57:02,,,,Great point It is technically possible to run Ethernet over carrier pidgeon although the packet loss latency and jitter is a bit of a problem,mxm7ocw,2.0,1lad3we
comment,mxnih3l,jaredb,,3,2025-06-13 23:30:36,,,,RFC 2549,mxnckzi,3.0,1lad3we
comment,mxnl3v9,chrisni66,,3,2025-06-13 23:45:49,,,,An excellent RFC but over looks some important points Like the section on NAT challenges rightly points out the pigeon may eat the NATs but omits any discussion on the fact that making a Private pidgeon Public negates its ability to find its way back home Edit its also not explained how you would train the pigeon to rewrite the IP for the NAT How would it even hold the pen,mxnih3l,4.0,1lad3we
comment,mxo5m30,lunar_bear,,2,2025-06-14 01:49:03,,,,You may wanna read about Slingshot if youve been away for a while,mxknx0p,1.0,1lad3we
comment,mxnlg40,lynxblaine,,1,2025-06-13 23:47:48,,,,Ethernet in its own is not the primary interconnect Fibrecopper cables may connect the fabrics like Ethernet but its infiniband or slingshot The top three supercomputers use slingshot Which is a very modified Ethernet network with fabric manager Current gen is 200GbE next gen is 400GbE,mxknx0p,1.0,1lad3we
comment,mxntu5n,synthdrunk,,1,2025-06-14 00:39:02,,,,Im familiar with infiniband from the day that was my confusion,mxnlg40,2.0,1lad3we
comment,mxpevp0,paradoxbound,,1,2025-06-14 07:32:32,,,,Depends on the cluster and expected work loads but Ethernet is one option Infiniband and the Intel spin off whos name escapes me is another player,mxknx0p,1.0,1lad3we
comment,my27tmn,IDDQD-IDKFA,,0,2025-06-16 11:12:49,,,,Ethernet is a protocol Copper or fiber are the interconnect types Both are widely used In HPC racks a lot of it is copper DAC cables internally with fiber uplinks,mxknx0p,1.0,1lad3we
comment,mxjrm68,andygon,,88,2025-06-13 12:01:51,,,,Err the name loosely translates to thinking about dicks in Spanish lol,,0.0,1lad3we
comment,mxkd1k2,santathe1,,22,2025-06-13 14:06:20,,,,And if you get their card you wont need to just think of them,mxjrm68,1.0,1lad3we
comment,mxl9im0,picardo85,,9,2025-06-13 16:41:19,,,,So youre saying its made for browsing porn faster,mxjrm68,1.0,1lad3we
comment,mxmwny0,CosmicCreeperz,,3,2025-06-13 21:28:44,,,,Only an AI cluster can really calculate optimal tip to tip efficiency,mxjrm68,1.0,1lad3we
comment,mxnv88e,karatekid430,,2,2025-06-14 00:47:32,,,,Yeah I was thinking what the hell are they doing,mxjrm68,1.0,1lad3we
comment,mxkac8k,Top-Respond-3744,,11,2025-06-13 13:52:16,,,,How many 8K movies can it download in a second,,0.0,1lad3we
comment,mxkzwdl,Macho_Chad,,10,2025-06-13 15:55:18,,,,0284 if the movie is 176GB and youre pulling 50GBs,mxkac8k,1.0,1lad3we
comment,mxkzzoa,Top-Respond-3744,,4,2025-06-13 15:55:44,,,,I can wait that long,mxkzwdl,2.0,1lad3we
comment,mxl0cej,Macho_Chad,,7,2025-06-13 15:57:23,,,,Im gonna wait another 10 years for bettercheaper hardware so I only have to wait 1 second,mxkzzoa,3.0,1lad3we
comment,mxl6teq,Top-Respond-3744,,2,2025-06-13 16:28:21,,,,It was less than 3rd of a second No,mxl0cej,4.0,1lad3we
comment,mxlkskp,Macho_Chad,,5,2025-06-13 17:33:38,,,,At that rate youll download 0284 movies per second so 3 seconds,mxl6teq,5.0,1lad3we
comment,mxlp6mo,Top-Respond-3744,,3,2025-06-13 17:54:24,,,,Oh I cannot read apparently,mxlkskp,6.0,1lad3we
comment,mxlpjli,Macho_Chad,,1,2025-06-13 17:56:06,,,,Its alright fam,mxlp6mo,7.0,1lad3we
comment,mxo20fu,CosmicCreeperz,,2,2025-06-14 01:27:58,,,,As long as you have 200GB of RAM to store it in Not writing it to any storage that fast,mxkzwdl,2.0,1lad3we
comment,mxjmydk,rip1980,,30,2025-06-13 11:29:37,,,,Erm I get its tweaked for lower latency but is it cheaper than existing commodity 800gbe flavors Because the upto 25 tweaks wouldnt seem to offset the raw speed,,0.0,1lad3we
comment,mxnihss,flickerdown,,9,2025-06-13 23:30:43,,,,Cheaper is relative in the space this is being used for You will spend appreciably more on storage and compute than you will on network This becomes a rounding error problem esp if the gain in performance due to UEs packet ordering etc achieves better utilization,mxjmydk,1.0,1lad3we
comment,mxrsbcu,tecedu,,0,2025-06-14 17:22:16,,,,Ehhh not really a good storage will set 300k for a cluster Compute a 128cpu epyc with 640mhz ram is around 20k The networking is about 2 switches so 60k Nics are around 25k a pop in my small cluster we have around 12 so 30k Then comes cables if you go dac cables its cheap enough but still about 5k in cables without that transceivers would be close to 20k So 110k for network compared to 300k for storage which is not insignificant,mxnihss,2.0,1lad3we
comment,mxry31s,flickerdown,,1,2025-06-14 17:51:10,,,,I mean I work for a storage company in this space and I have access to our BoMs Switching is a negligible cost compared to software licensing for storage support compute and storage medium themselves Soyeah,mxrsbcu,3.0,1lad3we
comment,mxrz659,tecedu,,1,2025-06-14 17:56:43,,,,I mean yeah when you get into Huge 100 nodes clusters yes I got the pricing of the company I work at cluster Storage I included ddn boxes rough pricing For us everytime we need to purchase a new node its about 1215 networking price,mxry31s,4.0,1lad3we
comment,mxs19w7,flickerdown,,1,2025-06-14 18:07:43,,,,Ah DDN See THAT is where youre overpaying,mxrz659,5.0,1lad3we
comment,mxsn0op,tecedu,,1,2025-06-14 20:05:51,,,,Ah no I just run a plain nfs on top of block netapp e series I just wanted ddn for some high tier appliance out of box,mxs19w7,6.0,1lad3we
comment,mxtbi1o,farsonic,,2,2025-06-14 22:20:52,,,,There are a lot of smarts in these pollara NICs that are purely operating using RoCEv2 offload at this point and Ultra Ethernet in the near future with a firmware change When using Pollara RoCEv2 QPs are modified down to the packet level to adjust the source port to the known number of upstream switch uplinks to increase entropy for ECMP hashing providing packet spraying Memory pointers are added to each packet as wellthis combination allows for retransmission of a single packet always and not larger parts of the flow The approach allows for packet spraying selective acknowledgement congestion control and individual packet retransmission and put of order delivery into memory The smarts here make RoCEv2 sing on standard Ethernet networks that now only require ECN to be configured Ultra Ethernet builds on this and will be a multi vendor standard for Interop,,0.0,1lad3we
comment,mxwb1xa,Svardskampe,,1,2025-06-15 12:10:08,,,,The fastest nvme speeds currently available are 75 gbps btw,,0.0,1lad3we
comment,mxjjyhi,danielv123,,-7,2025-06-13 11:07:32,,,,Why would one want to use one of these over a Mellanox offering,,0.0,1lad3we
comment,mxjm14i,Ordinary_dude_NOT,,8,2025-06-13 11:22:56,,,,Its in the article please read it,mxjjyhi,1.0,1lad3we
comment,mxk6cf1,French87,,-6,2025-06-13 13:30:29,,,,Can u just tell us pls,mxjm14i,2.0,1lad3we
comment,mxkc5ix,Ordinary_dude_NOT,,10,2025-06-13 14:01:44,,,,AMD claims that its Pollara 400GbE card offers a 10 higher RDMA performance compared to Nvidias CX7 and 20 higher RDMA performance than Broadcoms Thor2 solution The Pensando Pollara 400GbE NIC is based on an inhouse designed specialized processor with customizable hardware that supports RDMA adjustable transport protocols and offloading of communication libraries,mxk6cf1,3.0,1lad3we
comment,mxrshc6,tecedu,,1,2025-06-14 17:23:06,,,,Higher price per perf,mxjjyhi,1.0,1lad3we
comment,mxkdel5,imaginary_num6er,,0,2025-06-13 14:08:11,,,,Because its still better than Intels card,mxjjyhi,1.0,1lad3we
comment,mxrrnu7,None,,0,2025-06-14 17:19:01,,,,WWYUE,,0.0,1lad3we
